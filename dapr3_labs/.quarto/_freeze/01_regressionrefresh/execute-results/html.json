{
  "hash": "7b4b71da47b98d0cb99b53540d304645",
  "result": {
    "markdown": "---\ntitle: \"Regression Refresh and Clustered Data\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n:::frame\n**Preliminaries**  \n \n1. Open Rstudio, and **create a new project for this course!!** \n2. Create a new RMarkdown document or R script (whichever you like) for this week. \n\nThese are the main packages we're going to use in this block. It might make sense to install them now if you do not have them already.  \n<!-- (note, the rstudio.ppls.ed.ac.uk server already has `lme4` and `tidyverse` installed for you).   -->\n\n+ __tidyverse__ : for organising data \n+ __patchwork__: for organising plots\n+ __ICC__ : for quickly calculating intraclass correlation coefficient\n+ __lme4__ : for fitting generalised linear mixed effects models\n+ __parameters__ : inference!\n+ __pbkrTest__  : more inference!\n+ __HLMdiag__ : for examining case diagnostics at multiple levels\n+ __lmeresampler__ : for bootstrapping!\n+ __effects__ : for tables/plots\n+ __sjPlot__ : for tables/plots\n+ __broom.mixed__ : tidying methods for mixed models\n\n\nYou can install all of these at once using:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstall.packages(c(\"tidyverse\",\"ICC\",\"lme4\",\"parameters\",\"pbkrTest\",\"effects\",\"broom.mixed\",\"sjPlot\",\"HLMdiag\"))\n# the lmeresampler package has had some recent updates. better to install the most recent version:\ninstall.packages(\"devtools\")\ndevtools::install_github(\"aloy/lmeresampler\")\n```\n:::\n\n\n:::\n\n\n\n\n\n:::lo\n__This Week__  \n\n\n:::\n\n\n# Exercises: Linear Models & Pooling\n\n:::{.callout-note collapse=\"true\"}\n## Regression Refresh\n\nRecall that in the DAPR2 course last year we learned all about the linear regression model, which took the form:\n\n$$\n\\begin{align}\\\\\n& \\text{for observation }i \\\\\n& \\color{red}{Y_i}\\color{black} = \\color{blue}{\\beta_0 \\cdot{} 1 + \\beta_1 \\cdot{} X_{1i} \\ + \\ ... \\ + \\ \\beta_p \\cdot{} X_{pi}}\\color{black} + \\varepsilon_i \\\\ \n\\end{align}\n$$\n\nAnd if we wanted to write this more simply, we can express $X_1$ to $X_p$ as an $n \\times p$ matrix (samplesize $\\times$ parameters), and $\\beta_0$ to $\\beta_p$ as a vector of coefficients:\n\n$$\n\\begin{align}\n& \\color{red}{\\mathbf{y}}\\color{black} = \\color{blue}{\\boldsymbol{X\\beta}}\\color{black} + \\boldsymbol{\\varepsilon} \\\\\n& \\quad \\\\\n& \\text{where} \\\\\n& \\varepsilon \\sim N(0, \\sigma) \\text{ independently} \\\\\n\\end{align}\n$$\nIn R, we fitted these models using:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(y ~ x1 + x2 + .... xp, data = mydata)  \n```\n:::\n\n:::\n\n:::frame\n__Data: Wellbeing Across Scotland__  \n\nIn DAPR2, one of the examples we used in [learning about linear regression](https://uoepsy.github.io/dapr2/2122/labs/1_04_mlr.html) was in examining the relationship between time spent outdoors and mental wellbeing. In that example researchers had collected data from 32 residents of Edinburgh & Lothians.  \n\nResearchers want to study this relationship across all of Scotland. They contact all the Local Authority Areas (LAAs) and ask them to collect data for them for them, with participants completing the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being, and being asked to estimate the average number of hours they spend outdoors each week.  \n\nTwenty of the Local Authority Areas provided data. It is available at [https://uoepsy.github.io/data/LAAwellbeing.csv](https://uoepsy.github.io/data/LAAwellbeing.csv), and you can read it into your R environment using the code below: \n\n::: {.cell layout-align=\"center\" code-copy='true'}\n\n```{.r .cell-code}\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\n```\n:::\n\nThe dataset contains information on 132 participants. You can see the variables in the table below\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"mdecankfku\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#mdecankfku table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#mdecankfku thead, #mdecankfku tbody, #mdecankfku tfoot, #mdecankfku tr, #mdecankfku td, #mdecankfku th {\n  border-style: none;\n}\n\n#mdecankfku p {\n  margin: 0;\n  padding: 0;\n}\n\n#mdecankfku .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#mdecankfku .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#mdecankfku .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#mdecankfku .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#mdecankfku .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mdecankfku .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mdecankfku .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mdecankfku .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#mdecankfku .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#mdecankfku .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#mdecankfku .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#mdecankfku .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#mdecankfku .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#mdecankfku .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#mdecankfku .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#mdecankfku .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#mdecankfku .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#mdecankfku .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#mdecankfku .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mdecankfku .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#mdecankfku .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#mdecankfku .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#mdecankfku .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mdecankfku .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#mdecankfku .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#mdecankfku .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mdecankfku .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mdecankfku .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#mdecankfku .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mdecankfku .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#mdecankfku .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mdecankfku .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mdecankfku .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mdecankfku .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mdecankfku .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mdecankfku .gt_left {\n  text-align: left;\n}\n\n#mdecankfku .gt_center {\n  text-align: center;\n}\n\n#mdecankfku .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#mdecankfku .gt_font_normal {\n  font-weight: normal;\n}\n\n#mdecankfku .gt_font_bold {\n  font-weight: bold;\n}\n\n#mdecankfku .gt_font_italic {\n  font-style: italic;\n}\n\n#mdecankfku .gt_super {\n  font-size: 65%;\n}\n\n#mdecankfku .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#mdecankfku .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#mdecankfku .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#mdecankfku .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#mdecankfku .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#mdecankfku .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#mdecankfku .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">ppt</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Participant ID</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">name</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Participant Name</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">laa</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Local Authority Area</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">outdoor_time</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Self report estimated number of hours per week spent outdoors</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">wellbeing</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">density</td>\n<td headers=\"description\" class=\"gt_row gt_left\">LAA Population Density (people per square km)</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\nRead in the Local Authority data from [https://uoepsy.github.io/data/LAAwellbeing.csv](https://uoepsy.github.io/data/LAAwellbeing.csv) and plot the bivariate relationship between wellbeing and time spent outdoors.   \n\nThen, using `lm()`, fit the simple linear model:  \n\n$$\n\\text{Wellbeing}_i = \\beta_0 + \\beta_1 \\cdot \\text{Hours per week spent outdoors}_i + \\varepsilon_i\n$$\n\nThink about the assumptions we make about the model:\n\n$$\n\\text{where} \\quad \\varepsilon_i \\sim N(0, \\sigma) \\text{ independently}\n$$\nHave we satisfied this assumption (specifically, the assumption of *independence* of errors)? \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-1' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-1', 'sol-start-1')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-1\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\") \n\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimplemod <- lm(wellbeing ~ outdoor_time, data = scotmw)\nsummary(simplemod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = wellbeing ~ outdoor_time, data = scotmw)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.4395  -7.5658  -0.3175   6.0831  26.7208 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   39.2723     2.6674  14.723   <2e-16 ***\noutdoor_time   0.1603     0.1462   1.096    0.275    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.43 on 130 degrees of freedom\nMultiple R-squared:  0.009155,\tAdjusted R-squared:  0.001534 \nF-statistic: 1.201 on 1 and 130 DF,  p-value: 0.2751\n```\n:::\n:::\n\n\nOur model from the previous question will assume that the residuals for all participants are independent of one another. But is this a reasonable assumption that we can make? Might we not think that the residents of the highlands might have generally higher levels of wellbeing than those living in Glasgow? Additionally, the association between outdoor time and wellbeing might be different depending on where you live?  \n\nThe natural grouping of the people into their respective geographic area introduces a level of *dependence* which we would be best to account for.  \n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\nTry running the code below.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n```\n:::\n\nThen try editing the code to include an aesthetic mapping from the LAA to the color in the plot.  \n\nHow do your thoughts about the relationship between outdoor time and wellbeing change?\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-2' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\n\nFrom the second plot, we see a lot of the LAA appear to have a positive relationship (outdoor time is associated with higher wellbeing). There seem to be differences between LAAs in both the general wellbeing level (residents of Na h-Eileanan Siar  - the outer hebrides - have high wellbeing), and in how outdoor time is associated with wellbeing (for instance, outdoor time doesn't seem to help in Glasgow City).  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- ggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n\np2 <- ggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing, col = laa))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n:::{.callout-note collapse=\"true\"}\n## Complete Pooling\n\nWe can consider the simple regression model (`lm(wellbeing ~ outdoor_time, data = scotmw)`) to \"pool\" the information from all observations together. In this 'Complete Pooling' approach, we simply ignore the natural clustering of the people into their local authority areas, as if we were unaware of it. The problem is that this assumes the same regression line for all local authority areas, which might not be that appropriate. Additionally, we violate the assumption that our residuals are independent, because all of the residuals from certain groups will be more like one another than they are to the others.  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Complete pooling can lead to bad fit for certain groups](01_regressionrefresh_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=350px}\n:::\n:::\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n## No Pooling  \n\nThere are various ways we could attempt to deal with the problem that our data are in groups (or \"clusters\"). With the tools you have learned in DAPR2, you may be tempted to try including LAA in the model as another predictor, to account for all LAA-related variation in wellbeing:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(wellbeing ~ outdoor_time + laa, data = scotmw)\n```\n:::\n\n\nThis approach gets termed the \"No Pooling\" method, because the information from each cluster contributes *only* to an estimated parameter for that cluster, and there is no pooling of information across clusters. This is a good start, and is nice because it eliminates _all_ of the LAA-level variation when estimating the coefficient for `outdoor_time`. But it has some considerable drawbacks in that it a) involves estimating *a lot* of parameters, and b) doesn't allow for the effect of outdoor time on wellbeing to be different for each LAA. \nExtending this to include an interaction term `outdoor_time * laa` results in even more parameters, and the loss of the effect of interest (the effect of outdoor_time on wellbeing, within a given LAA). Furthermore, we have high variance in the estimates at each LAA because data from each LAA contributes to _only_ that LAA's slope.  \n\n\n:::\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\nFit the linear model below which accounts for the grouping of participants into their different local authorities, but holds the association between outdoor time and wellbeing as constant across LAAs:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod1 <- lm(wellbeing ~ outdoor_time + laa, data = scotmw)\n```\n:::\n\n\nCan you construct a plot of the **fitted** values from this model, coloured by LAA?  \n\n:::{.callout-tip collapse=\"true\"}\n### Hint  \nyou might want to use the `augment()` function from the **broom** package\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-3' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(broom)\naugment(mod1) %>%\n  ggplot(.,aes(x=outdoor_time, y=.fitted, col=laa))+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\nWhat happens (to the plot, and to your parameter estimates) when you include the interaction between `laa` and `outdoor_time`?  \nDoes it improve the model fit?  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-4' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod2 <- lm(wellbeing ~ outdoor_time * laa, data = scotmw)\n\nbroom::augment(mod2) %>%\n  ggplot(.,aes(x=outdoor_time, y=.fitted, col=laa))+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n:::\n\nWe can see now that our model is fitting a different relationship between wellbeing and outdoor time for each LAA. This is good - we're going to get better estimates for different LAAs (e.g. wellbeing of residents of the Highlands increases with more outdoor time, and wellbeing of residents of Glasgow does not).  \n\nWe can see that this model provides a better fit - it results in a significant reduction in the residual sums of squares:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(mod1, mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: wellbeing ~ outdoor_time + laa\nModel 2: wellbeing ~ outdoor_time * laa\n  Res.Df    RSS Df Sum of Sq   F   Pr(>F)   \n1    111 2826.9                             \n2     92 1864.4 19    962.57 2.5 0.001975 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nIn order to account for the heterogeneity between LAAs in the `wellbeing~outdoor_time` relationship, this approach requires estimating a whole bunch of parameters (i.e. interaction terms between the `outdoor_time` slope and _every_ LAA). Additionally, these interaction terms will tend to have low statistical power because they are using fewer observations (only those within each cluster) to estimate parameters which only represent within-cluster effects.  \n\n\n</div><p class=\"solution-end\"></p>\n\n  \n<br>\n\n\n# Exercises: Advanced Data Wrangling\n\nWith more complex data structures comes more in-depth data wrangling in order to get it ready for fitting and estimating our model. Typically, the data we get will not be neat and tidy, and will come in different formats. Often we simply get whatever our experiment/questionnaire software spits out, and we have to work from there. When you are designing a study, you can do work on the front end to minimise the data-wrangling. Try to design an experiment/questionnaire while keeping in mind what the data comes out looking like.  \n\nBelow we have some data from a fake experiment. We've tried to make it a bit more difficult to work with - a bit more similar to what we would _actually_ get when doing real-life research.   \n\n:::frame\n__Data: Audio interference in executive functioning__  \n\n\n\n\n\nThis data is from a simulated study that aims to investigate the following research question: \n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\n24 healthy volunteers each completed the Symbol Digit Modalities Test (SDMT) - a commonly used test to assess processing speed and motor speed - a total of 15 times. During the tests, participants listened to either no audio (5 tests), white noise (5 tests) or classical music (5 tests). Half the participants listened via active-noise-cancelling headphones, and the other half listened via speakers in the room.  \n\nThe data is in stored in two separate files - the researcher administering the tests recorded the SDMT score in one spreadsheet, while details of the audio used in the experiment are held in a separate sheet.  \n\n:::{.callout-note collapse=true icon=false appearance=\"simple\"}\n#### ef_music.csv  \n\n1. Information about the audio condition for each trial of each participant is stored in __.csv__ format at [https://uoepsy.github.io/data/ef_music.csv](https://uoepsy.github.io/data/ef_music.csv). The data is in long format (1 row per participant-trial).  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|variable   |description                                                                                  |\n|:----------|:--------------------------------------------------------------------------------------------|\n|PID        |Participant ID                                                                               |\n|trial_n    |Trial Number (1-15)                                                                          |\n|audio      |Audio heard during the test ('no_audio', 'white_noise','music')                              |\n|headphones |Whether the participant listened via speakers in the room or via noise cancelling headphones |\n:::\n:::\n\n:::\n:::{.callout-note collapse=true icon=false appearance=\"simple\"}\n#### ef_sdmt.xlsx\n\nInformation on participants' Symbol Digit Modalities Test (SDMT) for each trial is stored in **.xlsx** format at [https://uoepsy.github.io/data/ef_sdmt.xlsx](https://uoepsy.github.io/data/ef_sdmt.xlsx). The data is in wide format (1 row per participant, 1 column per trial).   \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|variable |description             |\n|:--------|:-----------------------|\n|PID      |Participant ID          |\n|Trial_01 |SDMT score in trial 1   |\n|Trial_02 |SDMT score in trial 2   |\n|Trial_03 |SDMT score in trial 3   |\n|...      |SDMT score in trial ... |\n|...      |SDMT score in trial ... |\n|Trial_15 |SDMT score in trial 15  |\n:::\n:::\n\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\nGet the data into your R session. \n\n__Note:__ For one of the files, this is a bit different to how we have given you data in previous exercises. You may remember that for a __.csv__ file, you can read directly into R from the link using, `read_csv(\"https://uoepsy.......)`.  \n\nHowever, in reality you are likely to be confronted with data in all sorts of weird formats, such as __.xlsx__ files from MS Excel. Have a look around the internet to try and find any packages/functions/techniques for getting both the datasets in to R. \n\n:::{.callout-tip collapse=\"true\"}\n### Hint  \nFor the __.xlsx__ data:\n\n- Step 1: download the data to your computer  \n- Step 2: load the __readxl__ package.  \n- Step 3: use the `read_xlsx()` function to read in the data, pointing it to the relevant place on your computer. \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-5' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\nReading in the data for each condition is easy, as it's just the same as we have been doing in DAPR previously: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nef_music <- read_csv(\"https://uoepsy.github.io/data/ef_music.csv\")\nhead(ef_music)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  PID    trial_n  audio       headphones\n  <chr>  <chr>    <fct>       <fct>     \n1 PPT_01 Trial_02 no_audio    speakers  \n2 PPT_01 Trial_08 no_audio    speakers  \n3 PPT_01 Trial_11 no_audio    speakers  \n4 PPT_01 Trial_13 no_audio    speakers  \n5 PPT_01 Trial_15 no_audio    speakers  \n6 PPT_01 Trial_01 white_noise speakers  \n```\n:::\n:::\n\n\nThe other data is a bit more tricky, but we can actually do all these steps from within R. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 1 - Download the data:  \ndownload.file(url = \"https://uoepsy.github.io/data/ef_sdmt.xlsx\", \n              destfile = \"ef_sdmt.xlsx\", mode = \"wb\")\n# Step 2\nlibrary(readxl)\n# Step 3\nef_sdmt <- read_xlsx(\"ef_sdmt.xlsx\")\nhead(ef_sdmt)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  PID    Trial_01 Trial_02 Trial_03 Trial_04 Trial_05 Trial_06 Trial_07 Trial_08\n  <chr>     <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n1 PPT_01       38       31       33       13       19       22       24       23\n2 PPT_02       47       43       30       38       56       61       58       55\n3 PPT_03       29       36       29       34       44       36       35       41\n4 PPT_04       23       14        8       36       27       16       26       15\n5 PPT_05       22       24       18       19       23       15       32       18\n6 PPT_06       29       27       37       39       36       40       28       26\n# ℹ 7 more variables: Trial_09 <dbl>, Trial_10 <dbl>, Trial_11 <dbl>,\n#   Trial_12 <dbl>, Trial_13 <dbl>, Trial_14 <dbl>, Trial_15 <dbl>\n```\n:::\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n:::{.callout-note collapse=\"true\"}\n## Pivoting dataframes  \n\nOne of the more confusing things to get to grips with is the idea of reshaping a dataframe.  \nFor different reasons, you might sometimes want to have data in wide, or in long format. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Source: https://fromthebottomoftheheap.net/2019/10/25/pivoting-tidily/](https://www.fromthebottomoftheheap.net/assets/img/posts/tidyr-longer-wider.gif){fig-align='center' width=80%}\n:::\n:::\n\n\nWhen the data is wide, we can make it long using `pivot_longer()`. When we make data longer, we're essentially making lots of columns into 2 longer columns. Above, in the animation, the wide variable **x**, **y** and **z** go into a new longer column called **name** that specifies which (x/y/z) it came from, and the values get put into the **val** column.  \n\nThe animation takes a shortcut in the code it displays above, but you could also use `pivot_longer(c(x,y,z), names_to = \"name\", values_to = \"val\")`. To reverse this, and put it back to being wide, we tell R which columns to take the names and values *from*: `pivot_wider(names_from = name, values_from = val)`.  \n\n:::\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n\nIs each dataset in wide or long format? We want them both in long format, so try to reshape either/both if necessary.\n\n:::{.callout-tip collapse=\"true\"}\n### Hint  \n__Hint:__ in the tidyverse functions, you can specify all columns between column **x** and column **z** by using the colon, `x:z`.  \n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-6' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\nOnly the SDMT data is in wide format:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(ef_sdmt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  PID    Trial_01 Trial_02 Trial_03 Trial_04 Trial_05 Trial_06 Trial_07 Trial_08\n  <chr>     <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n1 PPT_01       38       31       33       13       19       22       24       23\n2 PPT_02       47       43       30       38       56       61       58       55\n3 PPT_03       29       36       29       34       44       36       35       41\n4 PPT_04       23       14        8       36       27       16       26       15\n5 PPT_05       22       24       18       19       23       15       32       18\n6 PPT_06       29       27       37       39       36       40       28       26\n# ℹ 7 more variables: Trial_09 <dbl>, Trial_10 <dbl>, Trial_11 <dbl>,\n#   Trial_12 <dbl>, Trial_13 <dbl>, Trial_14 <dbl>, Trial_15 <dbl>\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nef_sdmt_long <-\n  ef_sdmt %>%\n  pivot_longer(Trial_01:Trial_15, names_to = \"trial_n\", values_to = \"SDMT\")\n\nhead(ef_sdmt_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  PID    trial_n   SDMT\n  <chr>  <chr>    <dbl>\n1 PPT_01 Trial_01    38\n2 PPT_01 Trial_02    31\n3 PPT_01 Trial_03    33\n4 PPT_01 Trial_04    13\n5 PPT_01 Trial_05    19\n6 PPT_01 Trial_06    22\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n:::{.callout-note collapse=\"true\"}\n## Joining dataframes  \n\nThere are lots of different ways to join data-sets, depending on whether we want to keep rows from one data-set or the other, or keep only those in both data-sets etc. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Check out the help documentation for them all using `?full_join`.](images/messy/joins.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\nNow comes a fun bit.  \nWe have two datasets for this study. We're interested in how the type of audio (information on this is contained in `ef_music.csv`) interferes with scores on an executive functioning task (scores are held in the `ef_sdmt.xlsx`).  \n\nWe're going to need to join these together!   \n\nWe can just stick them side by side, because they're in different orders:\n  \n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(ef_music)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  PID    trial_n  audio       headphones\n  <chr>  <chr>    <fct>       <fct>     \n1 PPT_01 Trial_02 no_audio    speakers  \n2 PPT_01 Trial_08 no_audio    speakers  \n3 PPT_01 Trial_11 no_audio    speakers  \n4 PPT_01 Trial_13 no_audio    speakers  \n5 PPT_01 Trial_15 no_audio    speakers  \n6 PPT_01 Trial_01 white_noise speakers  \n```\n:::\n:::\n\n:::\n\n::: {.column width=\"10%\"}\n<!-- empty column to create gap -->\n:::\n\n::: {.column width=\"40%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(ef_sdmt_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  PID    trial_n   SDMT\n  <chr>  <chr>    <dbl>\n1 PPT_01 Trial_01    38\n2 PPT_01 Trial_02    31\n3 PPT_01 Trial_03    33\n4 PPT_01 Trial_04    13\n5 PPT_01 Trial_05    19\n6 PPT_01 Trial_06    22\n```\n:::\n:::\n\n:::\n\n::::\n\nProvided that both data-sets contain information on participant number and trial number, which uniquely identify each observation, we can join them together by matching on those variables!  \n\n:::{.callout-tip collapse=\"true\"}\n### Hint  \n\nWe're going to want to use one of `left/right/semi/anti/full_join()`, and give the function both the long formatted datasets.  \nWe should end up with 600 rows (40 participants * 15 trials each).\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-7' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata <- full_join(ef_music, ef_sdmt_long)\nhead(efdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  PID    trial_n  audio       headphones  SDMT\n  <chr>  <chr>    <fct>       <fct>      <dbl>\n1 PPT_01 Trial_02 no_audio    speakers      31\n2 PPT_01 Trial_08 no_audio    speakers      23\n3 PPT_01 Trial_11 no_audio    speakers      23\n4 PPT_01 Trial_13 no_audio    speakers      24\n5 PPT_01 Trial_15 no_audio    speakers      34\n6 PPT_01 Trial_01 white_noise speakers      38\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n<br>\n\n\n# Exercises: Clustering & ICC\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\nContinuing with our audio/executive functioning study, consider the following questions:  \n  \nWhat are the units of observations?  \nWhat are the groups/clusters?  \nWhat varies *within* these clusters?  \nWhat varies *between* these clusters?  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-8' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\n\nWhat are the units of observations? __trials__  \nWhat are the groups/clusters? __participants__  \nWhat varies *within* these clusters? __the type of audio__    \nWhat varies *between* these clusters? __whether they listen via headphones or speakers__  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\nCalculate the ICC, using the `ICCbare()` function from the **ICC** package.  \n\nWhat does it show?  \n\n:::{.callout-tip collapse=\"true\"}\n### Hint  \n\nRemember, you can look up the help for a function by typing a `?` followed by the function name in the console.  \n\n:::\n  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-9' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n47% of the variance in SDMT scores is explained by the participant groupings.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ICC)\nICCbare(x = PID, y = SDMT, data = efdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4782452\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n:::{.callout-note collapse=\"true\"}\n## ICC\n\nThink back to the lectures, and about what the ICC represents - the ratio of the variance between the groups to the total variance.  \nYou can think of the \"variance between the groups\" as the group means varying around the overall mean (the black dots around the black line), and the total variance as that plus the addition of the variance of the individual observations around each group mean (each set of coloured points around their respective larger black dot):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(efdata, aes(x=PID, y=SDMT))+\n  geom_point(aes(col=PID),alpha=.3)+\n  stat_summary(geom = \"pointrange\")+\n  geom_hline(yintercept = mean(efdata$SDMT,na.rm=T))+\n  theme(axis.text.x = element_text(angle=60,hjust=1))+\n  guides(col='none')\n```\n\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-31-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nYou can also think of the ICC as the correlation between two randomly drawn observations from the same group. \nThis is a bit of a tricky thing to get your head round if you try to relate it to the type of \"correlation\" that you are familiar with. Pearson's correlation (e.g think about a typical scatterplot) operates on *pairs of observations* (a set of values on the x-axis and their corresponding values on the y-axis), whereas ICC operates on *data which is structured in groups*.  \n  \n::: {.callout-note collapse=\"true\"}\n### Optional: ICC as the expected correlation between two observations from same group\n\nLet's suppose we had only 2 observations in each group.  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n  cluster observation   y\n1 group_1           1   4\n2 group_1           2   2\n3 group_2           1   4\n4 group_2           2   2\n5 group_3           1   7\n6 group_3           2   5\n7     ...         ... ...\n```\n:::\n:::\n\n\n\nThe ICC for this data is 0.18:\n\nNow suppose we *reshape* our data so that we have one row per group, and one column for each observation to look like this:\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 4     2    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 3     8    \n6 group_6 6     7    \n7 ...     ...   ...  \n```\n:::\n:::\n\nCalculating Pearson's correlation on those two columns yields 0.2, which isn't quite right. It's close, but not quite.. \n\n:::imp \nThe crucial thing here is that it is completely arbitrary which observations get called \"obs1\" and which get called \"obs2\".  \nThe data aren't paired, but __grouped.__ \n:::\n\nEssentially, there are lots of different combinations of \"pairs\" here. \nThere are the ones we have shown above:\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 4     2    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 3     8    \n6 group_6 6     7    \n7 ...     ...   ...  \n```\n:::\n:::\n\nBut we might have equally chosen these:\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 2     4    \n2 group_2 2     4    \n3 group_3 7     5    \n4 group_4 7     2    \n5 group_5 3     8    \n6 group_6 6     7    \n7 ...     ...   ...  \n```\n:::\n:::\n\nor these:\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 2     4    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 8     3    \n6 group_6 6     7    \n7 ...     ...   ...  \n```\n:::\n:::\n\n\nIf we take the correlation of all these combinations of pairings, then we get our ICC of 0.18!\n\n__ICC = the expected correlation of a *randomly drawn pair* of observations from the same group.__\n\n<!-- We could even do this via simulation, and write our own customised function! -->\n<!-- The code below creates a function for us to use. Can you figure out how it works?  -->\n<!-- ```{r} -->\n<!-- get_random_pair <- function(){ -->\n<!--   my_sub = sample(unique(bball$sub), 1) -->\n<!--   my_obs = sample(bball$hrv[bball$sub == my_sub], size=2) -->\n<!--   my_obs -->\n<!-- } -->\n<!-- ``` -->\n<!-- Try it out, by running it several times.  -->\n<!-- ```{r} -->\n<!-- get_random_pair() -->\n<!-- ``` -->\n\n<!-- Now let's make our computer do it loads and loads of times: -->\n<!-- ```{r} -->\n<!-- # replicate is a way of making R execute the same code repeatedly, n times. -->\n<!-- sims <- replicate(1e6, get_random_pair()) -->\n<!-- # t() is short for \"transpose\" and simple rotates the object 90 degrees (so rows become columns and columns become rows) -->\n<!-- sims <- t(sims) -->\n<!-- cor(sims[,1], sims[,2]) -->\n\n<!-- ``` -->\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n### Optional - Extra difficult. Calculate ICC manually  \n\n\nWe have equal group sizes here (there are 2 $\\times$ 12 participants, each with 15 observations), which makes calculating ICC by hand a lot easier, but it's still a bit tricky.  \n\nLet's take a look at the formula for ICC\n\n$$\n\\begin{align}\nICC \\; (\\rho) = & \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2_e} \\\\\n\\qquad \\\\\n= & \\frac{\\frac{MS_b - MS_e}{k}}{\\frac{MS_b - MS_e}{k} + MS_e} \\\\\n\\qquad \\\\\n= & \\frac{MS_b - MS_e}{MS_b + (k-1)MS_e} \\\\\n\\qquad \\\\\n\\qquad \\\\\n\\text{Where:} & \\\\ \nk = & \\textrm{number of observations in each group} \\\\\n\\qquad \\\\\nMS_b = & \\textrm{Mean Squares between groups} \\\\\n = & \\frac{\\text{Sums Squares between groups}}{df_\\text{groups}}\n= \\frac{\\sum\\limits_{i=1}(\\bar{y}_i - \\bar{y})^2}{\\textrm{n groups}-1}\\\\\n\\qquad \\\\\nMS_e = & \\textrm{Mean Squares within groups} \\\\\n= & \\frac{\\text{Sums Squares within groups}}{df_\\text{within groups}} \n= \\frac{\\sum\\limits_{i=1}\\sum\\limits_{j=1}(y_{ij} - \\bar{y_i})^2}{\\textrm{n obs}-\\textrm{n groups}}\\\\\n\\end{align}\n$$\nSo we're going to need to calculate the grand mean of $y$, the group means of $y$, and then the various squared differences between group means and grand mean, and between observations and their respective group means.  \n\nThe code below will give us a new column which is the overall mean of y. This bit is fairly straightforward. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata %>% mutate(\n  grand_mean = mean(SDMT)\n)\n```\n:::\n\n\n\n:::rtip\nWe have seen a lot of the combination of `group_by() %>% summarise()`, but we can also combine `group_by()` with `mutate()`!\n:::\n\nTry the following:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata %>% mutate(\n    grand_mean = mean(SDMT)\n  ) %>% \n  group_by(PID) %>%\n  mutate(\n    group_mean = mean(SDMT)\n  )\n```\n:::\n\n\n\n:::rtip\n**The grouping gets carried forward.**  \n\nUsing `group_by()` can quite easily land you in trouble if you forget that you have grouped the dataframe. \n\nLook at the output of `class()` when we have grouped the data. It still mentions something about the grouping. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata <- efdata %>% mutate(\n    grand_mean = mean(SDMT)\n  ) %>% \n  group_by(PID) %>%\n  mutate(\n    group_mean = mean(SDMT)\n  )\n\nclass(efdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n:::\n\n\nTo remove the grouping, we can use `ungroup()` (we could also just add this to the end of our code sequence above and re-run it):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata <- ungroup(efdata)\nclass(efdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n:::\n\n\n:::\n\nNow we need to create a column which is the squared differences between the observations $y_{ij}$ and the group means $\\bar{y_i}$.  \nWe also want a column which is the squared differences between the group means $\\bar{y_i}$ and the overall mean $\\bar{y}$.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdata <- efdata %>% \n  mutate(\n    within = (SDMT-group_mean)^2,\n    between = (group_mean-grand_mean)^2\n  )\n```\n:::\n\n\nAnd then we want to sum them:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nssbetween = sum(efdata$between)\nsswithin = sum(efdata$within)\n```\n:::\n\n\nFinally, we divide them by the degrees of freedom. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Mean Squares between\nmsb = ssbetween / (24-1)\n# Mean Squares within \nmse = sswithin / (360-24)\n```\n:::\n\n\nAnd calculate the ICC!!!\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ICC\n(msb-mse) /(msb + (14*mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4782452\n```\n:::\n:::\n\n\n:::\n:::\n\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\nWe have two variables of interest here: \n\n- `audio` (type of audio listened to in a trial)\n- `headphones` (whether or not the participant had headphones on)\n\nWe're going to look at them separately for now (we'll get on to addressing the research question next week).  \n\nCompare how the estimates and the uncertainty (the standard errors) for the `audio` coefficients compare between these two models:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod1 <- lm(SDMT ~ audio, data = efdata)\nmod2 <- lm(SDMT ~ audio + PID, data = efdata)\n```\n:::\n\n\nand look how the `headphones` coefficients compare between these two:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod3 <- lm(SDMT ~ headphones, data = efdata)\nmod4 <- lm(SDMT ~ headphones + PID, data = efdata)\n```\n:::\n\n\nWhat do you notice?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nRecall our answers to question 8: \n\nWhat are the units of observations? __trials__   \nWhat are the groups/clusters? __participants__  \nWhat varies *within* these clusters? __the type of audio__    \nWhat varies *between* these clusters? __whether they listen via headphones or speakers__  \n\n:::\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-10' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\nOur standard errors for the `audio` coefficients become narrower when we account for participant-level differences (`mod2`). \n\nThis makes sense, because `mod2` explains some variation in the audio groups as being due to participants - the highest \"white noise\" point is actually still a decrease in SDMT compared to \"no_audio\" _for that participant_. Whereas `mod1` doesn't know that that highest \"white noise\" point is high _because_ it comes from a specific participant. Put another way, having a separate line for each participant (RH plot below), gives us more confidence in the differences between audio-types.  \n\nBecause we have perfectly balanced data (every participant has the same number of trials in each audio-type) then our estimates here do not actually change at all.  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-48-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nIn contrast, our estimates for `headphones` coefficients _do_ change when we include `PID` in the model. And the standard errors actually get _larger_. \nThis is because the inclusion of the participant in `mod4` accounts for some of the variance in each group, which means that our comparison between \"speakers\" and \"headphones\" is actually a comparison between two groups of 12 participants (RH plot below), rather than 2 groups of 180 trials (LH plot below).  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01_regressionrefresh_files/figure-html/unnamed-chunk-49-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nThis sort of perfectly balanced design has traditionally been approached with extensions of ANOVA (\"repeated measures ANOVA\", \"mixed ANOVA\"). These methods can partition out variance due to one level of clustering (e.g. subjects), and can examine factorial designs when one factor is within cluster, and the other is between. You can see an example [here](example_00_anova.html) if you are interested. However, ANOVA has a lot of constraints - it can't handle multiple levels of clustering (e.g. children in classes in schools), it will likely require treating variables such as time as a factor, and it's not great with missing data.  \nThe multi-level model (MLM) provides a more flexible framework, and this is what we will begin to look at next week.  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n",
    "supporting": [
      "01_regressionrefresh_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}