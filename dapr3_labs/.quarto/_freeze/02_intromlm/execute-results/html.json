{
  "hash": "15ca10af6638ce299ab0f6a29f030a2a",
  "result": {
    "markdown": "---\ntitle: \"Introducing Multilevel Models\"\nlink-citations: yes\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n:::lo\n**A Note on terminology**\n\nThe methods we're going to learn about in the first five weeks of this course are known by lots of different names: \"multilevel models\"; \"hierarchical linear models\"; \"mixed-effect models\"; \"mixed models\"; \"nested data models\"; \"random coefficient models\"; \"random-effects models\"; \"random parameter models\"... and so on).   \n\nWhat the idea boils down to is that **model parameters vary at more than one level.** This week, we're going to explore what that means.  \n\nThroughout this course, we will tend to use the terms \"mixed effect model\", \"linear mixed model (LMM)\" and \"multilevel model (MLM)\" interchangeably. \n:::\n\n\n\n# Introducing Multilevel Models\n\n:::yellow \n\nMultilevel Models (MLMs) (or \"Linear Mixed Models\" (LMMs)) take the approach of allowing the groups/clusters to vary around our $\\beta$ estimates. \n\nIn the lectures, we saw this as:\n\n\n$$\n\\begin{align}\n& \\text{for observation }j\\text{ in group }i \\\\\n\\quad \\\\\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}}\\color{black} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1i} \\cdot x_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{\\beta_{1i}}\\color{black} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\quad \\\\\n& \\text{Where:} \\\\\n& \\gamma_{00}\\text{ is the population intercept, and }\\color{orange}{\\zeta_{0i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{00} \\\\\n& \\gamma_{10}\\text{ is the population slope, and }\\color{orange}{\\zeta_{1i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{10} \\\\\n\\end{align}\n$$\n\n\nWe are now assuming $\\color{orange}{\\zeta_0}$, $\\color{orange}{\\zeta_1}$, and $\\varepsilon$ to be normally distributed with a mean of 0, and we denote their variances as $\\sigma_{\\color{orange}{\\zeta_0}}^2$, $\\sigma_{\\color{orange}{\\zeta_1}}^2$, $\\sigma_\\varepsilon^2$ respectively. \n\nThe $\\color{orange}{\\zeta}$ components also get termed the \"random effects\" part of the model, Hence names like \"random effects model\", etc. \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-1' class=\"fa fa-hand-o-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-1', 'opt-start-1')\"> <span class=\"olab\">Optional Alternative notation</span></span></div><div class=\"optional-body\" id = \"opt-body-1\" style=\"display: none;\">\n\n\nMany people use the symbol $u$ in place of $\\zeta$.  \nIn various resources, you are likely to see $\\alpha$ used to denote the intercept instead of $\\beta_0$.  \n\nSometimes, you will see the levels collapsed into one equation, as it might make for more intuitive reading. This often fits with the name \"mixed effects\" for these models:\n\n\n$$\n\\color{red}{y_{ij}}\\color{black} = (\\color{blue}{\\beta_0}\\color{black} + \\color{orange}{\\zeta_{0i}}\\color{black}) \\cdot 1 + ( \\color{blue}{\\beta_{1}}\\color{black} + \\color{orange}{\\zeta_{1i}} \\color{black}) \\cdot x_{ij}  +  \\varepsilon_{ij} \\\\\n$$\n\n\nAnd then we also have the condensed matrix form of the model, in which the Z matrix represents the grouping structure, and the $u$ (or $\\zeta$) are the estimated random deviations. \n\n$$\n\\mathbf{y} = \\boldsymbol{X\\beta} + \\boldsymbol{Zu} + \\boldsymbol{\\varepsilon}\n$$\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n:::\n\n# Fitting Multilevel Models\n\n## Introducing **lme4** \n\n:::rtip\n\nWe're going to use the `lme4` package, and specifically the functions `lmer()` and `glmer()`.  \n\"(g)lmer\" here stands for \"(generalised) linear mixed effects regression\". \n\nYou will have seen some use of these functions in the lectures. The broad syntax is:  \n<br>\n<div style=\"margin-left:50px;\">**lmer(*formula*, REML = *logical*, data = *dataframe*)**</div>    \n<br>\n\nWe write the first bit of our **formula** just the same as our old friend the normal linear model `y ~ 1 + x + x2 + ...`, where `y` is the name of our outcome variable, `1` is the intercept (which we don't have to explicitly state as it will be included anyway) and `x`, `x2` etc are the names of our explanatory variables.  \n\nWith **lme4**, we now have the addition of __random effect terms)), specified in parenthesis with the `|` operator (the vertical line | is often found to the left of the z key on QWERTY keyboards).  \nWe use the `|` operator to separate the parameters (intercept, slope etc.) on the LHS, from the grouping variable(s) on the RHS, by which we would like to model these parameters as varying.  \n\n__Random Intercept__  \nLet us suppose that we wish to model our intercept not as a fixed constant, but as varying randomly according to some grouping around a fixed center. \nWe can such a model by allowing the intercept to vary by our grouping variable (`g` below): \n\n:::statbox\n<center>`lmer(y ~ 1 + x + (1|g), data = df)`</center>\n\n$$\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{Y_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot X_{ij}} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\end{align}\n$$\n\n:::\n\n\n\n\n__Random Slope__  \nBy extension we can also allow the effect `y~x` to vary between groups, by including the `x` on the left hand side of `|` in the random effects part of the call to `lmer()`.\n\n:::statbox\n<center>`lmer(y ~ 1 + x + (1 + x |g), data = df)`</center>\n\n$$\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1i} \\cdot x_{ij}} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{\\beta_{1i}} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\end{align}\n$$\n\n:::\n:::\n\n\n\n## Estimation\n\n### Maximum Likelihood (ML)  \n\nRemember back to DAPR2 when we introduced logistic regression, and we briefly discussed **Maximum likelihood** in an explanation of how models are fitted.  \n\nThe key idea of *maximum likelihood estimation* (MLE) is that we (well, the computer) iteratively finds the set of estimates for our model which it considers to best reproduce our observed data. Recall our simple linear regression model of how time spent outdoors (hrs per week) is associated with mental wellbeing: \n\n$$\n\\color{red}{Wellbeing_i} = \\color{blue}{\\beta_0 \\cdot{} 1 + \\beta_1 \\cdot{} OutdoorTime_{i}} + \\varepsilon_i\n$$\n\nThere are values of $\\beta_0$ and $\\beta_1$ and $\\sigma_\\varepsilon$ which maximise the probability of observing the data that we have. For linear regression, these we obtained these same values a different way, via minimising the sums of squares. And we saw that this is not possible for more complex models (e.g., logistic), which is where we turn to MLE.  \n\n:::statbox\nTo read about the subtle difference between \"likelihood\" and \"probability\", you can find a short explanation [here](./lvp.html){target=\"_blank\"}\n:::\n\nIf we are estimating just one single parameter (e.g. a mean), then we can imagine the process of *maximum likelihood estimation* in a one-dimensional world - simply finding the top of the curve: \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![MLE](images/intro/mle.png){#fig-mle fig-align='center' width=350px}\n:::\n:::\n\nHowever, our typical models estimate a whole bunch of parameters. The simple regression model above is already having to estimate $\\beta_0$, $\\beta_1$ and $\\sigma_\\varepsilon$, and our multi-level models have far more! With lots of parameters being estimated and all interacting to influence the likelihood, our nice curved line becomes a complex surface (see Left panel of @fig-multisurf). So what we (our computers) need to do is find the maximum, but avoid local maxima and singularities (see @fig-maxima). \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![MLE for a more complex model](images/multisurftb.png){#fig-multisurf fig-align='center' width=49%}\n:::\n:::\n\n\n### Restricted Maximum Likelihood (REML)\n\nWhen it comes to estimating multilevel models, maximum likelihood will consider the fixed effects as unknown values in its estimation of the variance components (the random effect variances). This leads to biased estimates of the variance components, specifically biasing them toward being too small, especially if $n_\\textrm{clusters} - n_\\textrm{level 2 predictors} - 1 < 50$. Restricted Maximum Likelihood (REML), however, separates the estimation of fixed and random parts of the model, leading to unbiased estimates of the variance components.  \n\n:::rtip\n`lmer()` models are by default fitted with REML. This is better for small samples. \n:::\n\n\n:::sticky\n__Model Comparisons in MLM__\n\nWhen we compare models that differ in their fixed effects via comparing model deviance (e.g. the likelihood ratio), REML should __not__ be used as only the variance components are included in the likelihood. Functions like `anova()` will automatically refit your models with `ML` for you, but it is worth checking.   \n  \nWe __cannot__ compare (either with ML or REML) models that differ in both the fixed and random parts. \n\n:::\n\n\n### Model Convergence\n\nFor large datasets and/or complex models (lots of random-effects terms), it is quite common to get a *convergence warning*.  There are lots of different ways to [deal with these](https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html) (to try to rule out hypotheses about what is causing them).  \n\nFor now, if `lmer()` gives you convergence errors, you could try changing the optimizer. Bobyqa is a good one: add `control = lmerControl(optimizer = \"bobyqa\")` when you run your model.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlmer(y ~ 1 + x1 + ... + (1 + .... | g), data = df, \n     control = lmerControl(optimizer = \"bobyqa\"))\n```\n:::\n\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-2' class=\"fa fa-hand-o-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-2', 'opt-start-2')\"> <span class=\"olab\">What *is* a convergence warning??</span></span></div><div class=\"optional-body\" id = \"opt-body-2\" style=\"display: none;\">\n\n\nThere are different techniques for maximum likelihood estimation, which we apply by using different 'optimisers'. Technical problems to do with **model convergence** and **'singular fit'** come into play when the optimiser we are using either can't find a suitable maximum, or gets stuck in a singularity (think of it like a black hole of likelihood, which signifies that there is not enough variation in our data to construct such a complex model).  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![local/global maxima and singularities](images/intro/mle2.png){#fig-maxima fig-align='center' width=49%}\n:::\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n# Exercises: Intro MLM\n\n## Cross-Sectional: Wellbeing Across Scotland\n\n:::frame\nRecall our dataset from last week, in which we used linear regression to determine how outdoor time (hours per week) is associated with wellbeing in different local authority areas (LAAs) of Scotland. We have data from various LAAs, from Glasgow City, to the Highlands.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"kxsksstuek\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#kxsksstuek .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#kxsksstuek .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#kxsksstuek .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#kxsksstuek .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#kxsksstuek .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#kxsksstuek .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#kxsksstuek .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#kxsksstuek .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#kxsksstuek .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#kxsksstuek .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#kxsksstuek .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#kxsksstuek .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#kxsksstuek .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kxsksstuek .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#kxsksstuek .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#kxsksstuek .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kxsksstuek .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#kxsksstuek .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kxsksstuek .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#kxsksstuek .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kxsksstuek .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kxsksstuek .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kxsksstuek .gt_left {\n  text-align: left;\n}\n\n#kxsksstuek .gt_center {\n  text-align: center;\n}\n\n#kxsksstuek .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#kxsksstuek .gt_font_normal {\n  font-weight: normal;\n}\n\n#kxsksstuek .gt_font_bold {\n  font-weight: bold;\n}\n\n#kxsksstuek .gt_font_italic {\n  font-style: italic;\n}\n\n#kxsksstuek .gt_super {\n  font-size: 65%;\n}\n\n#kxsksstuek .gt_two_val_uncert {\n  display: inline-block;\n  line-height: 1em;\n  text-align: right;\n  font-size: 60%;\n  vertical-align: -0.25em;\n  margin-left: 0.1em;\n}\n\n#kxsksstuek .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#kxsksstuek .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#kxsksstuek .gt_slash_mark {\n  font-size: 0.7em;\n  line-height: 0.7em;\n  vertical-align: 0.15em;\n}\n\n#kxsksstuek .gt_fraction_numerator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: 0.45em;\n}\n\n#kxsksstuek .gt_fraction_denominator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: -0.05em;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">ppt</td>\n<td class=\"gt_row gt_left\">Participant ID</td></tr>\n    <tr><td class=\"gt_row gt_left\">name</td>\n<td class=\"gt_row gt_left\">Participant Name</td></tr>\n    <tr><td class=\"gt_row gt_left\">laa</td>\n<td class=\"gt_row gt_left\">Local Authority Area</td></tr>\n    <tr><td class=\"gt_row gt_left\">outdoor_time</td>\n<td class=\"gt_row gt_left\">Self report estimated number of hours per week spent outdoors</td></tr>\n    <tr><td class=\"gt_row gt_left\">wellbeing</td>\n<td class=\"gt_row gt_left\">Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.</td></tr>\n    <tr><td class=\"gt_row gt_left\">density</td>\n<td class=\"gt_row gt_left\">LAA Population Density (people per square km)</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n:::\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\nUsing `lmer()` from the **lme4** package, fit a model predict `wellbeing` from `outdoor_time`, with by-LAA random intercepts.  \nPass the model to `summary()` to see the output. \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-3' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\nri_model <- lmer(wellbeing ~ outdoor_time + (1 | laa), data = scotmw)\nsummary(ri_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: wellbeing ~ outdoor_time + (1 | laa)\n   Data: scotmw\n\nREML criterion at convergence: 865.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.2409 -0.7497  0.1170  0.6401  1.8282 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n laa      (Intercept) 106.39   10.314  \n Residual              25.16    5.016  \nNumber of obs: 132, groups:  laa, 20\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept)  38.00590    2.63507  14.423\noutdoor_time  0.22540    0.07092   3.178\n\nCorrelation of Fixed Effects:\n            (Intr)\noutdoor_tim -0.454\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\nSometimes the easiest way to start understanding your model is to visualise it. \n \nLoad the package **broom.mixed**. Along with some handy functions `tidy()` and `glance()` which give us the information we see in `summary()`, there is a handy function called `augment()` which returns us the data in the model plus the fitted values, residuals, hat values, Cook's D etc.. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nri_model <- lmer(wellbeing ~ outdoor_time + (1 | laa), data = scotmw)\nlibrary(broom.mixed)\naugment(ri_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 132 × 14\n   wellbeing outdoor_time laa          .fitted .resid  .hat .cooksd .fixed   .mu\n       <dbl>        <dbl> <fct>          <dbl>  <dbl> <dbl>   <dbl>  <dbl> <dbl>\n 1        37           20 West Lothian    32.3  4.66  0.139 8.07e-2   42.5  32.3\n 2        34           23 Falkirk         31.7  2.31  0.192 3.11e-2   43.2  31.7\n 3        39           29 Falkirk         33.0  5.95  0.195 2.12e-1   44.5  33.0\n 4        42           21 Scottish Bo…    40.1  1.90  0.163 1.68e-2   42.7  40.1\n 5        37           10 Dumfries an…    37.3 -0.338 0.167 5.47e-4   40.3  37.3\n 6        42           19 Argyll and …    43.9 -1.91  0.122 1.14e-2   42.3  43.9\n 7        38           13 Perth and K…    46.0 -8.04  0.139 2.41e-1   40.9  46.0\n 8        44           21 East Renfre…    44.5 -0.488 0.168 1.15e-3   42.7  44.5\n 9        47           16 Inverclyde      43.1  3.92  0.195 9.17e-2   41.6  43.1\n10        35           12 Midlothian      33.0  1.96  0.161 1.75e-2   40.7  33.0\n# … with 122 more rows, and 5 more variables: .offset <dbl>, .sqrtXwt <dbl>,\n#   .sqrtrwt <dbl>, .weights <dbl>, .wtres <dbl>\n```\n:::\n:::\n\n\nAdd to the code below to plot the model fitted values, and color them according to LAA. \n(you will need to edit `ri_model` to be whatever name you assigned to your model).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(ri_model) %>%\n  ggplot(aes(x = outdoor_time, y = ...... \n```\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-4' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(ri_model) %>%\n  ggplot(aes(x = outdoor_time, y = .fitted, col = laa)) + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\nWe have just fitted the model:\n\n$$\n\\begin{align}\n& \\text{For person } j \\text{ in LAA } i \\\\\n& \\color{red}{\\textrm{Wellbeing}_{ij}}\\color{black} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot \\textrm{Outdoor Time}_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\color{blue}{\\beta_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\end{align}\n$$\n\n\nFor our estimates of $\\gamma_{00}$ (the fixed value around which LAA intercepts vary) and $\\beta_1$ (the fixed estimate of the relationship between wellbeing and outdoor time), we can use `fixef()`.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfixef(ri_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) outdoor_time \n  38.0059003    0.2253954 \n```\n:::\n:::\n\nCan you add to the plot in the previous question, a thick black line with the intercept and slope given by `fixef()`?  \n\n:::hints\n**Hint:** `geom_abline()`\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-5' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(ri_model) %>%\n  ggplot(aes(x = outdoor_time, y = .fitted, col = laa)) + \n  geom_line() + \n  geom_abline(intercept = fixef(ri_model)[1], slope = fixef(ri_model)[2], lwd = 2)\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\nBy now, you should have a plot which looks more or less like the left-hand figure below (we have added on the raw data - the points).  \n<div style=\"display:inline-block; width: 55%;vertical-align: top;\">\n\n::: {.cell layout-align=\"center\" fig.asp='1'}\n::: {.cell-output-display}\n![Model fitted values](02_intromlm_files/figure-html/fig-modfit-1.png){#fig-modfit fig-align='center' width=80%}\n:::\n:::\n\n</div>\n<div style=\"display:inline-block; width: 40%;vertical-align: top;\">\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Summary model output<br>lmer(wellbeing~1 + outdoor_time + (1|laa),<br>data = scotmw)](images/intro/summarylmer2.png){#fig-lmersummap fig-align='center' width=400px}\n:::\n:::\n\n</div>\n<br>\n<br>\nWe're going to map the parts of the plot in @fig-modfit to the `summary()` output of the model in @fig-lmersummap. Match the coloured sections Red, Orange, Yellow and Blue in @fig-lmersummap to the descriptions below of @fig-modfit A through D. \n\nA) where the black line cuts the y axis\nB) the standard deviation of the distances from all the individual LAA lines to the black lines\nC) the slope of the black lines\nD) the standard deviation of the distances from all the individual observations to the line for the LAA to which it belongs.\n\nCan you also match those same coloured sections in @fig-lmersummap to the mathematical terms in the model equation:  \n\n\n$$\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{Wellbeing_{ij}}\\color{black} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot OutdoorTime_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\quad \\\\\n& \\text{where} \\\\\n& \\color{orange}{\\zeta_0}\\color{black} \\sim N(0, \\sigma_{\\color{orange}{\\zeta_{0}}}\\color{black})  \\text{ independently} \\\\\n& \\varepsilon \\sim N(0, \\sigma_{\\varepsilon}) \\text{ independently} \\\\\n\\end{align}\n$$\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-6' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\n\n+ Yellow = B = $\\sigma_{\\color{orange}{\\zeta_{0}}}$\n+ Red = D = $\\sigma_{\\varepsilon}$    \n+ Blue = A = $\\gamma_{00}$  \n+ Orange = C = $\\beta_{1}$     \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\nFit a model which allows *also* (along with the intercept) the effect of `outdoor_time` to vary by-LAA.   \n\nThen, using `augment()` again, plot the model fitted values. What do you think you will see?  \nDoes it look like this model better represents the individual LAAs? Take a look at, for instance, Glasgow City.  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-7' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrs_model <- lmer(wellbeing ~ 1 + outdoor_time + (1 + outdoor_time | laa), data = scotmw)\n\naugment(rs_model) %>%\n  ggplot(aes(x = outdoor_time, y = .fitted, col = laa)) + \n  geom_line() + \n  geom_point(aes(y=wellbeing), alpha=.4)\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n## Longitudinal: Wellbeing Over Time\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\nAnother very crucial advantage of these methods is that we can use them to study how people change over time.  \n\n:::frame\n__Wellbeing in Work: Longitudinal Data__  \n\nThe Wellbeing in Work data (`wellbeingwork3`) contains information on employees who were randomly assigned to one of three employment conditions:\n\n* control: No change to employment. Employees continue at 5 days a week, with standard allocated annual leave quota.    \n* unlimited_leave : Employees were given no limit to their annual leave, but were still expected to meet required targets as specified in their job description. \n* fourday_week: Employees worked a 4 day week for no decrease in pay, and were still expected to meet required targets as specified in their job description.\n\nWellbeing was was assessed at baseline (start of maintenance), 12 months post, 24 months post, and 36 months post.  \n\nThe researchers had two main questions: \n- Overall, did the participants' wellbeing stay the same or did it change?\n- Did the employment condition groups differ in the how wellbeing changed over the assessment period?   \n\nThe data is available, in **.rda** format, at [https://uoepsy.github.io/data/wellbeingwork3.rda](https://uoepsy.github.io/data/wellbeingwork3.rda). You can read it directly into your R environment using: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(url(\"https://uoepsy.github.io/data/wellbeingwork3.rda\"))\n```\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n  \n\n> Q: Overall, did the participants' wellbeing stay the same or did it change?  \n\n\nEach of our participants have measurements at 4 assessments. \nWe need to think about what this means for the **random effects** that we will include in our model (our **random effect structure**). Would we like our models to accommodate individuals to vary in their overall wellbeing, to vary in how they change in wellbeing over the course of the assessment period, or both?\n\nTo investigate whether wellbeing changed over the course of the assessments, or whether it stayed the same, we can fit and compare 2 models:  \n\n1. The \"null\" or \"intercept-only\" model. \n2. A model with wellbeing predicted by time point.  \n\nAnd we can then compare them in terms of model fit. As discussed in the lecture, there are lots of ways to assess inference in multilevel models. \n\nOur sample size here (180 participants, each with 4 observations) is reasonably large given the relative simplicity of our model. We might consider running a straightforward Likelihood Ratio Test using `anova(restricted_model, full_model)` to compare our two models. \n\n:::hints\n- **Remember, we shouldn't compare models with different random effect structures.**  \n- *(For now, don't worry too much about \"singular fits\". We'll talk more about how we might deal with them next week!)*\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-8' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\n\nThis is our null model:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm.null <- lmer(Wellbeing ~ 1 + (1 | ID), data=wellbeingwork3)\nsummary(m.null)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: Wellbeing ~ 1 + (1 | ID)\n   Data: wellbeingwork3\n\nREML criterion at convergence: 4395.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5195 -0.6051 -0.0456  0.5895  3.5966 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept)  4.82    2.195   \n Residual             22.48    4.741   \nNumber of obs: 720, groups:  ID, 180\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  40.0431     0.2408   166.3\n```\n:::\n:::\n\nWe can see the `4.82 / (4.82 + 22.48)`, or 0.18 of the total variance is attributable to participant-level variation. \n\nNow lets suppose we want to compare this null model with a model with an effect of `TimePoint` (to assess whether there is overall change over time).\nWhich model should we compare `m.null` to?  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodA <- lmer(Wellbeing ~ 1 + TimePoint + (1 + TimePoint | ID), data=wellbeingwork3)\nmodB <- lmer(Wellbeing ~ 1 + TimePoint + (1 | ID), data=wellbeingwork3)\n```\n:::\n\nA comparison between these `m.null` and `modA` will not be assessing the influence of _only_ the fixed effect of TimePoint. \n\nRemember, we shouldn't compare models with different random effect structures.   \n\nHowever, `modB` doesn't include our by-participant random effects of timepoint, so comparing this to `m.null` is potentially going to mis-attribute random deviations in participants' change to being an overall effect of timepoint.  \n\nIf we want to conduct a model comparison to isolate the effect of overall change over time (a fixed effect of `TimePoint`), we _might_ want to compare these two models:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm.base0 <- lmer(Wellbeing ~ 1 + (1 + TimePoint | ID), data=wellbeingwork3)\nm.base <- lmer(Wellbeing ~ 1 + TimePoint + (1 + TimePoint | ID), data=wellbeingwork3)\n```\n:::\n\nThe first of these models is a bit weird to think about - how can we have by-participant random deviations of `TimePoint` if we don't have a fixed effect of `TimePoint`? That makes very little sense. What it is actually fitting is a model where there is assumed to be __no overall effect__ of TimePoint. So the fixed effect is 0. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Straightforward LRT\nanova(m.base0, m.base)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: wellbeingwork3\nModels:\nm.base0: Wellbeing ~ 1 + (1 + TimePoint | ID)\nm.base: Wellbeing ~ 1 + TimePoint + (1 + TimePoint | ID)\n        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm.base0    5 4202.4 4225.2 -2096.2   4192.4                         \nm.base     6 4171.7 4199.2 -2079.8   4159.7 32.649  1  1.104e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\n\n> Q: Did the employment condition groups differ in the how wellbeing changed over the assessment period?   \n\n:::hints\n**Hint:** It helps to break it down. There are two questions here:  \n\n  1. do groups differ overall?  \n  2. do groups differ over time?  \n\nWe can begin to see that we're asking two questions about the `Condition` variable here: \"is there an effect of Condition?\" and \"Is there an interaction between TimePoint and Condition?\".  \n\nTry fitting two more models which incrementally build these levels of complexity, and compare them (perhaps to one another, perhaps to models from the previous question - think about what each comparison is testing!)  \n:::\n  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-9' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm.int <- lmer(Wellbeing ~ TimePoint + Condition + (TimePoint | ID), \n              data=wellbeingwork3)\nm.full <- lmer(Wellbeing ~ TimePoint*Condition + (TimePoint | ID), \n               data=wellbeingwork3)\n```\n:::\n\n\nWe're going to compare each model to the previous one to examine the improvement in fit due to inclusion of each parameter. \nWe could do this quickly with\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m.base0, m.base, m.int, m.full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: wellbeingwork3\nModels:\nm.base0: Wellbeing ~ 1 + (1 + TimePoint | ID)\nm.base: Wellbeing ~ 1 + TimePoint + (1 + TimePoint | ID)\nm.int: Wellbeing ~ TimePoint + Condition + (TimePoint | ID)\nm.full: Wellbeing ~ TimePoint * Condition + (TimePoint | ID)\n        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm.base0    5 4202.4 4225.2 -2096.2   4192.4                         \nm.base     6 4171.7 4199.2 -2079.8   4159.7 32.649  1  1.104e-08 ***\nm.int      8 4164.3 4200.9 -2074.2   4148.3 11.393  2   0.003358 ** \nm.full    10 4144.6 4190.4 -2062.3   4124.6 23.711  2  7.098e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n:::int \nConditions differed overall in wellbeing change $\\chi^2(2)=11.39, p = .003$  \nConditions differed in change over assessment period $\\chi^2(2)=23.71, p < .001$\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\n\n- Examine the parameter estimates and interpret them (i.e., what does each parameter represent?)\n- Make a graph of the model fit *and* the observed data.  \n\n:::hints\n**Hints:**  \n\n- We can get the fixed effects using `fixef(model)`, and we can also use `tidy(model)` from the **broom.mixed** package, and similar to `lm` models in DAPR2, we can pull out the bit of the `summary()` using `summary(model)$coefficients`.   \n- There are lots of ways you can visualise the model, try a couple: \n  1. Using the **effects** package, does this help: `as.data.frame(effect(\"TimePoint:Condition\", model))`  \n  2. Using `fitted(model)`\n  3. Using `augment()` from the **broom.mixed** package.  \n  4. **sjPlot**, as we used in DAPR2\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-10' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                                   Estimate Std. Error t value\n(Intercept)                          38.352      0.398  96.456\nTimePoint                            -0.023      0.325  -0.072\nConditionunlimited_leave             -0.018      0.562  -0.033\nConditionfourday_week                -0.260      0.562  -0.462\nTimePoint:Conditionunlimited_leave    1.357      0.460   2.951\nTimePoint:Conditionfourday_week       2.282      0.460   4.963\n```\n:::\n:::\n\n\n* `(Intercept)` ==> Wellbeing at baseline in 'control' group\n* `TimePoint`  ==> Slope of welleing change in 'control' group\n* `Conditionunlimited_leave` ==> baseline wellbeing difference from 'unlimited_leave' group relative to 'control' group\n* `Conditionfourday_week` ==> baseline wellbeing difference from 'fourday_week' group relative to 'control' group\n* `TimePoint:Conditionunlimited_leave`  ==> slope of wellbeing change in 'unlimited_leave' group relative to 'control' group\n* `TimePoint:Conditionfourday_week`  ==> slope of wellbeing change in 'fourday_week' group relative to 'control' group\n\n:::int\nCompared to the control group, wellbeing increased by 1.35 points/year more for employees with unlimited leave, and by 2.28 points/year for employees on the 4 day week.  \n:::\n\nTo visualise the model fitted values and observed data, there are various options to choose from. \n\n1. Using the `effect()` function (and then adding the means and SEs from the original data):  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nef <- as.data.frame(effect(\"TimePoint:Condition\", m.full))\n\nggplot(ef, aes(TimePoint, fit, color=Condition)) + \n  geom_line() +\n  stat_summary(data=wellbeingwork3, aes(y=Wellbeing), \n               fun.data=mean_se, geom=\"pointrange\", size=1) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n2. Using the `fitted()` function to extract and plot fitted values from the model: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(wellbeingwork3, aes(TimePoint, Wellbeing, color=Condition)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\", size=1) + \n  stat_summary(aes(y=fitted(m.full)), fun=mean, geom=\"line\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n3. Or using `augment()`:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(m.full) %>%\nggplot(., aes(TimePoint, Wellbeing, color=Condition)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\", size=1) + \n  stat_summary(aes(y=.fitted), fun=mean, geom=\"line\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n4. finally, __sjPlot__ can give us the model fitted values, but it's trickier to add on the observed means. We can add the raw data using `show.data=TRUE`, but that will make it a bit messier\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sjPlot)\nplot_model(m.full, type=\"int\")\n```\n\n::: {.cell-output-display}\n![](02_intromlm_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n## Repeated Measures: Basketball/HRV\n\nWhile the wellbeing example considers the groupings or 'clusters' of different LAAs, a more relate-able grouping in psychological research is that of several observations belonging to the same individual. One obvious benefit of this is that we can collect many more observations with fewer participants, and account for the resulting dependency of observations. \n\n:::frame\n\nRecall the data from the previous week, from an experiment in which heart rate variability (HRV) was measured for amateur basketball players when tasked with scoring a goal with varying levels and type of potential loss/reward.  \n\nA separate group of researchers conducted a replication of this experiment with 15 participants. There were some issues with the HRV measurements resulting in some missing data, and one participant being excluded completely (meaning a slightly unbalanced design in that 8 participants were in one condition and only 7 in the other).  \n\nYou can find the data at: [https://uoepsy.github.io/data/bball_replication.csv](https://uoepsy.github.io/data/bball_replication.csv)\nIt contains the following variables:  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"neootcnney\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#neootcnney .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#neootcnney .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#neootcnney .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#neootcnney .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#neootcnney .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#neootcnney .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#neootcnney .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#neootcnney .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#neootcnney .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#neootcnney .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#neootcnney .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#neootcnney .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#neootcnney .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#neootcnney .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#neootcnney .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#neootcnney .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#neootcnney .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#neootcnney .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#neootcnney .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#neootcnney .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#neootcnney .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#neootcnney .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#neootcnney .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#neootcnney .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#neootcnney .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#neootcnney .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#neootcnney .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#neootcnney .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#neootcnney .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#neootcnney .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#neootcnney .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#neootcnney .gt_left {\n  text-align: left;\n}\n\n#neootcnney .gt_center {\n  text-align: center;\n}\n\n#neootcnney .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#neootcnney .gt_font_normal {\n  font-weight: normal;\n}\n\n#neootcnney .gt_font_bold {\n  font-weight: bold;\n}\n\n#neootcnney .gt_font_italic {\n  font-style: italic;\n}\n\n#neootcnney .gt_super {\n  font-size: 65%;\n}\n\n#neootcnney .gt_two_val_uncert {\n  display: inline-block;\n  line-height: 1em;\n  text-align: right;\n  font-size: 60%;\n  vertical-align: -0.25em;\n  margin-left: 0.1em;\n}\n\n#neootcnney .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#neootcnney .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#neootcnney .gt_slash_mark {\n  font-size: 0.7em;\n  line-height: 0.7em;\n  vertical-align: 0.15em;\n}\n\n#neootcnney .gt_fraction_numerator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: 0.45em;\n}\n\n#neootcnney .gt_fraction_denominator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: -0.05em;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">stakes</td>\n<td class=\"gt_row gt_left\">Size of reward (points to be won/lost on a given trial). Ranges 1 to 20</td></tr>\n    <tr><td class=\"gt_row gt_left\">condition</td>\n<td class=\"gt_row gt_left\">Experimental Condition: Whether the participant was playing for monetary reward ('money') or for a place on the scoreboard ('kudos')</td></tr>\n    <tr><td class=\"gt_row gt_left\">sub</td>\n<td class=\"gt_row gt_left\">Participant Identifier</td></tr>\n    <tr><td class=\"gt_row gt_left\">throw</td>\n<td class=\"gt_row gt_left\">Whether the participant successfully completed the trial</td></tr>\n    <tr><td class=\"gt_row gt_left\">trial_no</td>\n<td class=\"gt_row gt_left\">Trial Number (1 to 20)</td></tr>\n    <tr><td class=\"gt_row gt_left\">hrv</td>\n<td class=\"gt_row gt_left\">Average Heart Rate Variability over the 10 seconds prior to throwing</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\nRecall that the research question was concerned with how the size and type of potential reward influence stress levels (as measured by heart rate variability):\n\n> How do the size and type of potential reward/loss interact to influence levels of stress? \n\nFit a multi-level model to examine the effects of size and type of reward on HRV, and their interaction. \n\n:::hints\n\nRemember to think about:  \n\n- what is our outcome variable of interest?\n- what are our predictor variables that we are interested in?\n    - these should be in the fixed effects part.    \n- what is the clustering?\n    - this should be the random effects `(1 | cluster)` part\n- does size of reward (`stakes`) vary within clusters, or between?\n    - if so, we might be able to fit a random slope of `stakes | cluster`. if not, then it doesn't make sense to do so.  \n- does type of reward (`condition`) vary within clusters, or between?\n      - if so, we might be able to fit a random slope of `condition | cluster`. if not, then it doesn't make sense to do so. \n\n\n_If you get an error about model convergence, consider changing the optimiser (see [above](02_intromlm.html#Estimation))_\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-11' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- lmer(hrv ~ stakes * condition + \n              (1 + stakes | sub), data = bballrep,\n            control = lmerControl(optimizer=\"bobyqa\"))\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: hrv ~ stakes * condition + (1 + stakes | sub)\n   Data: bballrep\nControl: lmerControl(optimizer = \"bobyqa\")\n\nREML criterion at convergence: 867\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6415 -0.6182 -0.0401  0.6038  2.7335 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n sub      (Intercept) 2.86473  1.6926        \n          stakes      0.01661  0.1289   -0.85\n Residual             0.87768  0.9368        \nNumber of obs: 288, groups:  sub, 15\n\nFixed effects:\n                      Estimate Std. Error t value\n(Intercept)            4.76028    0.61973   7.681\nstakes                 0.03215    0.04749   0.677\nconditionmoney        -0.24945    0.90583  -0.275\nstakes:conditionmoney -0.05519    0.06944  -0.795\n\nCorrelation of Fixed Effects:\n            (Intr) stakes cndtnm\nstakes      -0.851              \nconditinmny -0.684  0.582       \nstks:cndtnm  0.582 -0.684 -0.850\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\nWe now have a model, but we don't have any p-values, confidence intervals, or inferential criteria on which to draw conclusions.  \n\nIn the longitudinal study of wellbeing over time, we did a series of model comparisons, performing tests of the incremental inclusion of additional parameters. In the Basketball/HRV example we went straight for the full model. This is in part because the two research aims of the longitudinal example can be matched two models (one for the \"overall\" trajectory, and one looking at differences between groups), whereas the Basketball/HRV research question simply requires the `stakes*condition` interaction.  \n\nThere are some options here for you to choose from: you can either perform tests against the null that certain parameter estimates are equal to zero (i.e. testing the fixed effects), or you can fit a reduced model and conduct model comparisons between that and the full model (thereby isolating and testing the improvement in the model due to a certain parameter).  \n\nThere are different methods of implementing these in R, as detailed in the table below. Standard likelihood ratio tests require models to be fitted with ML, and can be less reliable when samples are small (at any level). Often, approximations of the degrees of freedom are preferable, in part because these allow models to be fitted with REML. The more computationally expensive bootstrapping approach is perhaps the most recommended approach as it can provide more accurate p-values for the likelihood ratio test, as well as confidence intervals for our estimates, but for larger models it can take a lot of time to compute. Additionally, when performing the bootstrap it is important to watch out for issues with convergence in the bootstrap iterations - it may indicate your model needs simplification.  \n\nMethod |  Model Comparison |  Parameter Estimation|\n|------:|--------:|------------:|\n| Likelihood Ratio Test | `anova(model1, model2)` |  |\n| Approximations to $ddf$ | Satterthwaite: `SATmodcomp(model2, model1)` from the __pbkrtest__ package.<br>Kenward-Rogers: `KRmodcomp(model2, model1)` from the __pbkrtest__ package  | Satterthwaite: load the __lmerTest__ package and re-fit your model (the summary output will then have p-values)  |\n| Parametric Bootstrap | `PBmodcomp(model2, model1)` from the __pbkrtest__ package | `confint(model, method=\"boot\")`|\n\n\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\nThis study is interested in whether the previously reported interaction between size (`stakes`) and type (`condition)` of reward on stress levels - measured by heart-rate variability (`hrv`) - replicates in their new sample.  \n\nPick a method of your choosing and perform a test of/provide an interval for the relevant effect of interest.  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-12' class=\"fa fa-hand-o-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\nIn this case we have $n=15$ participants (our level 2 sample size), and each participant has approximately 20 observations (but some have missingness). The sample size might be a bit small for standard likelihood ratio tests (i.e. comparing models fitted with ML rather than REML). We would be better off using models fitted with REML because they will provide more accurate estimates of the variance components (the `1+stakes|sub` bit), and so better estimates of the standard errors of the fixed effects. \n\nWe'll go through each approach here so you can see what it looks like. There's no *right* answer here.  \n\nIf we choose a model comparison approach, we need to isolate the interaction term, because that's what we're interested in: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_res <- lmer(hrv ~ stakes + condition + (1 + stakes | sub), data = bballrep,\n            control = lmerControl(optimizer=\"bobyqa\"))\nmod_full <- lmer(hrv ~ stakes * condition + (1 + stakes | sub), data = bballrep,\n            control = lmerControl(optimizer=\"bobyqa\"))\n```\n:::\n\n\nWe see that the standard likelihood ratio test refits the models with ML rather than REML\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(mod_res, mod_full)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nrefitting model(s) with ML (instead of REML)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nData: bballrep\nModels:\nmod_res: hrv ~ stakes + condition + (1 + stakes | sub)\nmod_full: hrv ~ stakes * condition + (1 + stakes | sub)\n         npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)\nmod_res     7 872.33 897.97 -429.17   858.33                     \nmod_full    8 873.62 902.93 -428.81   857.62 0.7111  1     0.3991\n```\n:::\n:::\n\n:::int\nInclusion of the interaction between size and type of reward was not found to improve model fit, as indicated by a likelihood ratio test ($\\chi^2(1) = 0.71, p = .399$). \n:::\n\nWe could instead perform the parametric bootstrap for this test instead. This requires us to remove any incomplete cases from the dataset first, and then re-fit the models: \n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pbkrtest)\nbballrep2 = na.omit(bballrep)\nmod_res <- lmer(hrv ~ stakes + condition + (1 + stakes | sub), data = bballrep2,\n            control = lmerControl(optimizer=\"bobyqa\"))\nmod_full <- lmer(hrv ~ stakes * condition + (1 + stakes | sub), data = bballrep2,\n            control = lmerControl(optimizer=\"bobyqa\"))\nPBmodcomp(mod_full, mod_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBootstrap test; time: 52.20 sec; samples: 1000; extremes: 468;\nlarge : hrv ~ stakes * condition + (1 + stakes | sub)\nhrv ~ stakes + condition + (1 + stakes | sub)\n         stat df p.value\nLRT    0.6122  1  0.4340\nPBtest 0.6122     0.4685\n```\n:::\n:::\n\n\n:::int\nInclusion of the interaction between size and type of reward was not found to improve model fit, as indicated by a parametric bootstrapped ($k=1000$) likelihood ratio test ($\\Delta 2loglik = 0.612, p = .469$). \n:::\n\n\nIf instead we choose the approximation for degrees of freedom, then generally speaking the Kenward Rogers approach is preferable as it is a little more conservative.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nKRmodcomp(mod_full, mod_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlarge : hrv ~ stakes * condition + (1 + stakes | sub)\nsmall : hrv ~ stakes + condition + (1 + stakes | sub)\n         stat     ndf     ddf F.scaling p.value\nFtest  0.6317  1.0000 12.9927         1   0.441\n```\n:::\n:::\n\n:::int\nInclusion of the interaction between size and type of reward was not found to improve model fit ($F(1, 13^*) = 0.63, p = .441$).  \n  \n$\\textrm{ }^*$: denominator degrees of freedom approximated using Kenward-Rogers method.  \n:::\n\nAlternatively, we can perform the tests on the fixed effects themselves. This is more like what you will remember from DAPR2, where we get a table of effects and we can interpret each one in turn. For now we'll just focus on the interaction term as that is the main one of interest.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lmerTest)\nmod_full <- lmer(hrv ~ stakes * condition + (1 + stakes| sub), data = bballrep,\n            control = lmerControl(optimizer=\"bobyqa\"))\nsummary(mod_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: hrv ~ stakes * condition + (1 + stakes | sub)\n   Data: bballrep\nControl: lmerControl(optimizer = \"bobyqa\")\n\nREML criterion at convergence: 867\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6415 -0.6182 -0.0401  0.6038  2.7335 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n sub      (Intercept) 2.86473  1.6926        \n          stakes      0.01661  0.1289   -0.85\n Residual             0.87768  0.9368        \nNumber of obs: 288, groups:  sub, 15\n\nFixed effects:\n                      Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)            4.76028    0.61973 13.08438   7.681 3.34e-06 ***\nstakes                 0.03215    0.04749 13.09616   0.677    0.510    \nconditionmoney        -0.24945    0.90583 13.00709  -0.275    0.787    \nstakes:conditionmoney -0.05519    0.06944 13.04372  -0.795    0.441    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) stakes cndtnm\nstakes      -0.851              \nconditinmny -0.684  0.582       \nstks:cndtnm  0.582 -0.684 -0.850\n```\n:::\n:::\n\n:::int\nThere was no significant interaction between size and type of reward ($\\beta = -0.06, SE = 0.07, t(13.04^*) = -0.8, p = .441$). \n\n$\\textrm{ }^*$: denominator degrees of freedom approximated using Satterthwaite method.  \n:::\n\nLastly, we could also opt to construct parametric bootstrapped confidence intervals around our fixed effect estimates: \n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconfint(mod_full, method=\"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            2.5 %      97.5 %\n.sig01                 1.01777802  2.41524811\n.sig02                -0.96252286 -0.61207542\n.sig03                 0.07907304  0.18089815\n.sigma                 0.86358573  1.02589783\n(Intercept)            3.50865914  6.14629755\nstakes                -0.06090850  0.12560977\nconditionmoney        -2.07035051  1.50523773\nstakes:conditionmoney -0.19634219  0.06820011\n```\n:::\n:::\n\n:::int\nThere was no significant interaction between size and type of reward ($\\beta = -0.06, \\text{ parametric bootstrapped 95\\% CI: } [-0.196, 0.068]$).  \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>",
    "supporting": [
      "02_intromlm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}