{
  "hash": "95682ebbc8351e94fae306b7c40f47bc",
  "result": {
    "markdown": "---\ntitle: 'Analysis Example: Repeated-measures'\nlink-citations: yes\ncode-fold: true\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\n---\n\n\n\n\n:::frame\n\nEach of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:  \n\n  - First the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated. \n  - Second, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\n  - Then, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in **lme4**. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals. \n  - Finally, we visualize and interpret our analysis.\n  \nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email [ug.ppls.stats@ed.ac.uk](mailto:ug.ppls.stats@ed.ac.uk). \n\n:::\n\n# Overview\n\nThe idea behind \"repeated measures\" is that the same variable is measured on the same set of subjects over two or more time periods or under different conditions.  \n\nThe data used for this worked example are simulated to represent data from 50 participants, each measured at 3 different time-points on an outcome variable of interest. This is a fairly simple design, leading from a question such as \"how does [dependent variable] change over time?\"\nYou might easily think of the 3 time points as 3 different experimental conditions instead (condition1, condition2, condition3) and ask \"how does [dv] change over depending on [independent variable]?\"\n\n\nThis is a very simple way to simulate repeated measures data structure (with long data). There are a good number of other approaches, but this will do for now as you may well be familiar with all the functions involved: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(347)\nlibrary(tidyverse)\nsimRPT <- tibble(\n  pid = factor(rep(paste(\"ID\", 1:50, sep=\"\"),each=3)),\n  ppt_int = rep(rnorm(50,0,10),each=3), # add some participantz random-ness\n  dv = rnorm(150,c(40,50,70),sd=10) + ppt_int,\n  iv = factor(rep(c(\"T1\", \"T2\", \"T3\"), each=1, 50))\n)\n```\n:::\n\n\n:::rtip\nIf you are unclear about any section of the code above, why not try running small bits of it in your console to see what it is doing?   \nFor instance, try running:\n\n- `paste(\"ID\", 1:50, sep=\"\")`  \n- `rep(paste(\"ID\", 1:50, sep=\"\"),each=3)`  \n- `factor(rep(paste(\"ID\", 1:50, sep=\"\"),each=3))`  \n\n:::\n\n\n# Data Wrangling\n\nBecause we simulated our data, it is already nice and tidy. Each observation is a row, and we have variable indicating participant id (`pid`).  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(simRPT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  pid   ppt_int    dv iv   \n  <fct>   <dbl> <dbl> <fct>\n1 ID1     -1.92  41.6 T1   \n2 ID1     -1.92  40.2 T2   \n3 ID1     -1.92  63.6 T3   \n4 ID2    -11.1   22.9 T1   \n5 ID2    -11.1   40.5 T2   \n6 ID2    -11.1   60.6 T3   \n```\n:::\n:::\n\n\n# Descriptives\nLet' see our summaries per time-point:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumRPT <- \n  simRPT %>%\n  group_by(iv) %>%\n  summarise(\n    n = n_distinct(pid),\n    mean.dv = round(mean(dv, na.rm=T),2),\n    sd.dv = round(sd(dv, na.rm=T),2)\n    )\nsumRPT\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  iv        n mean.dv sd.dv\n  <fct> <int>   <dbl> <dbl>\n1 T1       50    38.8  13.1\n2 T2       50    50.8  11.2\n3 T3       50    67.8  13.5\n```\n:::\n:::\n\nWe can make this a little prettier:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nkable(sumRPT) %>%\n  kable_styling(\"striped\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> iv </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> mean.dv </th>\n   <th style=\"text-align:right;\"> sd.dv </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> T1 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 38.84 </td>\n   <td style=\"text-align:right;\"> 13.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> T2 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 50.82 </td>\n   <td style=\"text-align:right;\"> 11.16 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> T3 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 67.81 </td>\n   <td style=\"text-align:right;\"> 13.48 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWell...we knew what the answer was going to be, but there we have it, our scores improve across the three administrations of our test.\n\n# Visualizations\nWe can construct some simple plots showing distribution of the outcome variable at each level of the independent variable (iv): \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT %>% \n  ggplot(aes(x = iv, y = dv)) + \n  geom_violin() + \n  geom_jitter(alpha=.5,width=.1,height=0) + \n  labs(x=\"Time\", y = \"Test Score\", \n       title=\"Scores across trials\", \n       subtitle = \"Violin Plots with (jittered) Observations\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSo what does this show? Essentially we are plotting all responses at each point in time. The points are `jittered` so that they are not all overlaid on one another. The areas marked at each time point are mirrored density plots (i.e. they show the distribution of the scores at each point in time). \n\nIf you want to get an intuitive sense of these plotted areas, look at them against the mean's and sd's per time point calculated above.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT %>% \n  ggplot(aes(as.numeric(iv), dv)) +  \n  stat_summary(fun.data = mean_cl_boot, geom=\"ribbon\", alpha=.3) + \n  stat_summary(fun.y = mean, geom=\"line\") + \n  labs(x=\"Time\", y = \"Test Score\", \n       title=\"Scores across trials\", \n       subtitle = \"Mean and Boostrapped 95% Confidence Intervals\")\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can also show each participants' trajectory over time, by using the `group` aesthetic mapping. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT %>%\n  ggplot(aes(x = iv, y = dv)) +\n  geom_point(size=3, alpha=.4)+\n  geom_line(aes(group=pid), alpha = .2) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n# Analysis\n\n## Equations\nWe're going to fit this model, and examine the change in `dv` associated with moving from time-point 1 to each subsequent time-point.  \nRecall that because `iv` is categorical with 3 levels, we're going to be estimating 2 ($3-1$) coefficients. \n\n$$\n\\begin{aligned}\n  \\operatorname{dv}_{i[j]} &= \\beta_{0i} + \\beta_1(\\operatorname{iv}_{\\operatorname{T2}_j}) + \\beta_2(\\operatorname{iv}_{\\operatorname{T3}_j}) + \\varepsilon_{i[j]} \\\\\n    \\beta_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\ \n    & \\text{for }\\operatorname{pid}\\text{ i = 1,} \\dots \\text{,I}\n\\end{aligned}\n$$\n\n\n\n## Fitting the models\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\n```\n:::\n\n\nHere we run an empty model so that we have something to compare our model which includes our iv. Other than to give us a reference model, we do not have a huge amount of interest in this.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm0 <- lmer(dv ~ 1 + (1 | pid), data = simRPT)\n```\n:::\n\n\nNext, we specify our model. Here we include a fixed effect of our predictor (group membership, `iv`), and a random effect of participant (`iv`) to take account of the fact we have three measurements per person.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- lmer(dv ~ 1 + iv + (1 | pid), data = simRPT)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: dv ~ 1 + iv + (1 | pid)\n   Data: simRPT\n\nREML criterion at convergence: 1144.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.52990 -0.57636 -0.02015  0.56073  2.50816 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n pid      (Intercept) 74.66    8.641   \n Residual             84.60    9.198   \nNumber of obs: 150, groups:  pid, 50\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   38.842      1.785   21.76\nivT2          11.976      1.840    6.51\nivT3          28.964      1.840   15.74\n\nCorrelation of Fixed Effects:\n     (Intr) ivT2  \nivT2 -0.515       \nivT3 -0.515  0.500\n```\n:::\n:::\n\n\nAnd we can compare our models.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pbkrtest)\nPBmodcomp(m1, m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBootstrap test; time: 57.86 sec; samples: 1000; extremes: 0;\nlarge : dv ~ 1 + iv + (1 | pid)\ndv ~ 1 + (1 | pid)\n         stat df   p.value    \nLRT    126.84  2 < 2.2e-16 ***\nPBtest 126.84     0.000999 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m0,m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: simRPT\nModels:\nm0: dv ~ 1 + (1 | pid)\nm1: dv ~ 1 + iv + (1 | pid)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm0    3 1285.9 1294.9 -639.94   1279.9                         \nm1    5 1163.0 1178.1 -576.52   1153.0 126.83  2  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nOK, so we can see that we appear to have a significant effect of our repeated factor here. Our parametric bootstrap LRT is in agreement here. \n\n:::frame\n__Comparison to `aov()`__\n\nUsing `anova()` to compare multilevel models will not give you a typical ANOVA output.  \nFor piece of mind, it can be useful to compare how we might do this in `aov()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2 <- aov(dv ~ iv + Error(pid), data = simRPT)\n```\n:::\n\n\nHere the term `Error(pid)` is specifying the within person error, or residual. This is what we are doing with our random effect `(1 | pid)` in `lmer()`\n\nAnd we can compare the model sums of squares from both approaches to see the equivalence:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nError: pid\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 49  15121   308.6               \n\nError: Within\n          Df Sum Sq Mean Sq F value Pr(>F)    \niv         2  21183   10591   125.2 <2e-16 ***\nResiduals 98   8291      85                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n   npar Sum Sq Mean Sq F value\niv    2  21183   10591  125.19\n```\n:::\n:::\n\n:::\n\n\n## Check model\n\nThe residuals look reasonably normally distributed, and there seems to be fairly constant variance across the linear predictor. We might be a little concerned about the potential tails of the plot below, at which residuals don't appear to have a mean of zero\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(m1, type = c(\"p\",\"smooth\"))\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nlibrary(lattice)\nqqmath(m1)\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-16-2.png){fig-align='center' width=672}\n:::\n:::\n\nRandom effects are (roughly) normally distributed:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrans <- as.data.frame(ranef(m1)$pid)\nggplot(rans, aes(sample = `(Intercept)`)) + \n  stat_qq() + stat_qq_line() +\n  labs(title=\"random intercept\")\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Visualise Model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sjPlot)\nplot_model(m1, type=\"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$iv\n```\n:::\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m1, type=\"re\") # an alternative: dotplot.ranef.mer(ranef(m1))\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-18-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Interpret model\n\n__Parametric bootstrap 95% CIs:__\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconfint(m1, method = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                2.5 %   97.5 %\n.sig01       5.999069 11.24815\n.sigma       7.941403 10.46011\n(Intercept) 35.397974 42.37131\nivT2         8.313544 15.62274\nivT3        25.286894 32.52241\n```\n:::\n:::\n\n\n__Case-resample bootstrap 95% CIs:__\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lmeresampler)\nbootmodel <- bootstrap(m1, fixef, type = \"case\", B = 999, resample = c(TRUE,FALSE))\nconfint(bootmodel, type = \"perc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  term        estimate lower upper type  level\n  <chr>          <dbl> <dbl> <dbl> <chr> <dbl>\n1 (Intercept)     38.8 35.8   42.0 perc   0.95\n2 ivT2            12.0  8.44  15.5 perc   0.95\n3 ivT3            29.0 25.5   32.6 perc   0.95\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- confint(bootmodel, type=\"perc\")\nres <- res %>% mutate_if(is.numeric,~round(.,2))\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  term        estimate lower upper type  level\n  <chr>          <dbl> <dbl> <dbl> <chr> <dbl>\n1 (Intercept)     38.8 35.8   42.0 perc   0.95\n2 ivT2            12.0  8.44  15.5 perc   0.95\n3 ivT3            29.0 25.5   32.6 perc   0.95\n```\n:::\n:::\n\n\n\nWriting up an interpretation of this is a bit clunky as we have abstract names for our variables like \"dv\" and \"iv\", but as a rough starting point: \n\n:::int\n\nChange in [dv] over [iv] was modeled using a linear mixed effects model, with a fixed effect of [iv] and a by-[pid] random intercepts. At baseline, scores on [dv] were estimated at 38.84 (cluster-resample bootstrap 95% CI: 35.79--42.01). Results indicated that, relative to time-point 1, scores at time-point 2 increased by 11.98 (8.44--15.54), and at time-point 3 had increased by 28.96 (25.48--32.6). \n\n\n:::\n\n",
    "supporting": [
      "example_01_repeated_measures_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}