{
  "hash": "54286434ec18af1017e1ebe3cdb2e2da",
  "result": {
    "markdown": "---\ntitle: \"Analysis Example 3: Many trials\"\nlink-citations: yes\ncode-fold: true\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\n---\n\n\n\n\n:::frame\n\nEach of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:  \n\n  - First the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated. \n  - Second, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\n  - Then, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in **lme4**. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals. \n  - Finally, we visualize and interpret our analysis.\n  \nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email [ug.ppls.stats@ed.ac.uk](mailto:ug.ppls.stats@ed.ac.uk). \n\n:::\n\n# Overview\nThis data comes from an undergraduate dissertation student. She ran an experiment looking at the way people's perception of the size of models influences the price they are willing to pay for products. Participants saw a series of pictures of a number of items of clothing. The images had been manipulated so that (a) all pictures were of the same model, and (b) the size of the model differed from a 6 to 16. In total participants saw 54 images. During the study, each picture was presented to participants with a sliding scale from 0 to 100 underneath. Participants simply had to drag the cursor to the appropriate point on the slide to indicate how much they would pay for the garment.\n\nThis data was collected using Qualtrics. The resultant output was a wide format data set where each participant (n=120) is a row and each item (n=54) is a column. Along with each of these questions were a series of demographic variables, and two short survey measures assessing participants attitude to thinness.\n\nThe main ideas we were interested in looking at were whether: \n\n(i) participants would pay more for garments on thinner models\n(ii) participants would pay more for items when the model size matched their actual size\n(iii) participants would pay more for items when the model size matched their ideal size\n(iv) the extent to which participants idealize thin figures would moderate (ii)\n\n\n# Data Wrangling\nUnlike some of our examples, there was some fairly serious data cleaning needed with this data set. So let's work through it.  \n\nThe data is available at [https://uoepsy.github.io/data/data_HA.csv](https://uoepsy.github.io/data/data_HA.csv)  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndf <- read_csv(\"https://uoepsy.github.io/data/data_HA.csv\")\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 116\n  Respons…¹ Gender   Age Dress…² Top_1…³ Botto…⁴ Dress…⁵ Botto…⁶ Top_6…⁷ Dress…⁸\n  <chr>      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 P_ID1001       1    22      45      24      30      30      20      17      15\n2 P_ID1002       1    20      30      19       9      52       0       5      16\n3 P_ID1003       1    21      30      12       4      18      20       8      12\n4 P_ID1004       1    21      39      30      30      45      25      20      25\n5 P_ID1005       1    23      10       5      15       7      15       5      20\n6 P_ID1006       1    43      40      30      45      60      35      25      30\n# … with 106 more variables: Dress_12...11 <dbl>, Bottom_12...12 <dbl>,\n#   Top_10...13 <dbl>, Top_8...14 <dbl>, Bottom_6...15 <dbl>,\n#   Bottom_8...16 <dbl>, Dress_14...17 <dbl>, Top_16...18 <dbl>,\n#   Bottom_6...19 <dbl>, Bottom_14...20 <dbl>, Top_8...21 <dbl>,\n#   Dress_8...22 <dbl>, Top_12...23 <dbl>, Top_14...24 <dbl>,\n#   Dress_16...25 <dbl>, Top_10...26 <dbl>, Top_14...27 <dbl>,\n#   Dress_8...28 <dbl>, Dress_16...29 <dbl>, Bottom_12...30 <dbl>, …\n# ℹ Use `colnames()` to see all variable names\n```\n:::\n:::\n\n\nFirst things first, let's use a handy package to change all our variable names to a nice easy \"snake_case\":\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(janitor)\ndf <- clean_names(df)\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 116\n  respons…¹ gender   age dress…² top_1…³ botto…⁴ dress…⁵ botto…⁶ top_6_9 dress…⁷\n  <chr>      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 P_ID1001       1    22      45      24      30      30      20      17      15\n2 P_ID1002       1    20      30      19       9      52       0       5      16\n3 P_ID1003       1    21      30      12       4      18      20       8      12\n4 P_ID1004       1    21      39      30      30      45      25      20      25\n5 P_ID1005       1    23      10       5      15       7      15       5      20\n6 P_ID1006       1    43      40      30      45      60      35      25      30\n# … with 106 more variables: dress_12_11 <dbl>, bottom_12_12 <dbl>,\n#   top_10_13 <dbl>, top_8_14 <dbl>, bottom_6_15 <dbl>, bottom_8_16 <dbl>,\n#   dress_14_17 <dbl>, top_16_18 <dbl>, bottom_6_19 <dbl>, bottom_14_20 <dbl>,\n#   top_8_21 <dbl>, dress_8_22 <dbl>, top_12_23 <dbl>, top_14_24 <dbl>,\n#   dress_16_25 <dbl>, top_10_26 <dbl>, top_14_27 <dbl>, dress_8_28 <dbl>,\n#   dress_16_29 <dbl>, bottom_12_30 <dbl>, dress_6_31 <dbl>,\n#   bottom_14_32 <dbl>, bottom_8_33 <dbl>, top_16_34 <dbl>, …\n# ℹ Use `colnames()` to see all variable names\n```\n:::\n:::\n\n\nOur next job is to cut out a few variables that we will not work with in this example. These are a set of questions asking about clothing preferences. They all end in `p` and appear at the end of the data set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf1 <- \n  df %>%\n  select(-ends_with(\"p\"))\n```\n:::\n\n\nNow we want to create scores for the two surveys scored using Likert-type scales. We're going to take the means of these scales as our scores:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# TI score\ndf1 <- \n  df1 %>%\n  select(contains(\"_tii\")) %>%\n  rowMeans(., na.rm=T) %>%\n  bind_cols(df1, tii_score = .)\n         \n# MA score\ndf1 <- \n  df1 %>%\n  select(contains(\"_mo\")) %>%\n  rowMeans(., na.rm=T) %>%\n  bind_cols(df1, ma_score = .)\n```\n:::\n\n\nNext, we need to make some changes to the coding of current and ideal size\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf1 <- \n  df1 %>%\n  mutate(\n    c.size = recode(current_size, 6, 8, 10, 12, 14, 16),\n    i.size = recode(ideal_size,  6, 8, 10, 12, 14, 16)\n  )\n```\n:::\n\n\nAlways sensible to check our changes:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf1 %>%\n  select(current_size, ideal_size, c.size, i.size)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 120 × 4\n   current_size ideal_size c.size i.size\n          <dbl>      <dbl>  <dbl>  <dbl>\n 1            3          2     10      8\n 2            1          1      6      6\n 3            2          1      8      6\n 4            2          1      8      6\n 5            3          2     10      8\n 6            4          3     12     10\n 7            3          2     10      8\n 8            2          2      8      8\n 9            5          3     14     10\n10            3          2     10      8\n# … with 110 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nExcellent, that has worked.\n\nOur next step (and this one is not strictly necessary) is that we are going to aggregate over the different types of top, bottoms and dresses. We could treat each individual garment of clothing as exactly that, but in this instance it was decided that this was not of interest, and to simplify the models, we would create scores for each broad category by size.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf1 <- \n  df1 %>%\n  mutate(top_S6 = rowMeans(.[names(df1)[grepl(\"top_6\",names(df1))]]),\n         top_S8 = rowMeans(.[names(df1)[grepl(\"top_8\",names(df1))]]),\n         top_S10 = rowMeans(.[names(df1)[grepl(\"top_10\",names(df1))]]),\n         top_S12 = rowMeans(.[names(df1)[grepl(\"top_12\",names(df1))]]),\n         top_S14 = rowMeans(.[names(df1)[grepl(\"top_14\",names(df1))]]),\n         top_S16 = rowMeans(.[names(df1)[grepl(\"top_16\",names(df1))]]),\n         bottom_S6 = rowMeans(.[names(df1)[grepl(\"bottom_6\",names(df1))]]),\n         bottom_S8 = rowMeans(.[names(df1)[grepl(\"bottom_8\",names(df1))]]),\n         bottom_S10 = rowMeans(.[names(df1)[grepl(\"bottom_10\",names(df1))]]),\n         bottom_S12 = rowMeans(.[names(df1)[grepl(\"bottom_12\",names(df1))]]),\n         bottom_S14 = rowMeans(.[names(df1)[grepl(\"bottom_14\",names(df1))]]),\n         bottom_S16 = rowMeans(.[names(df1)[grepl(\"bottom_16\",names(df1))]]),\n         dress_S6 = rowMeans(.[names(df1)[grepl(\"dress_6\",names(df1))]]),\n         dress_S8 = rowMeans(.[names(df1)[grepl(\"dress_8\",names(df1))]]),\n         dress_S10 = rowMeans(.[names(df1)[grepl(\"dress_10\",names(df1))]]),\n         dress_S12 = rowMeans(.[names(df1)[grepl(\"dress_12\",names(df1))]]),\n         dress_S14 = rowMeans(.[names(df1)[grepl(\"dress_14\",names(df1))]]),\n         dress_S16 = rowMeans(.[names(df1)[grepl(\"dress_16\",names(df1))]]),\n         )\n```\n:::\n\n\nAt this point, our next big step is to make the data long. But I am also going to make this a little more manageable by trimming out the variables we do not need. We want ID and age, gender is constant (all female sample), so we do not need this, and then we want the variables we have just created.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf2 <- \n  df1 %>%\n  select(response_id, age, 99:120)\n\ndf2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 120 × 24\n   response_id   age tii_s…¹ ma_sc…² c.size i.size top_S6 top_S8 top_S10 top_S12\n   <chr>       <dbl>   <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl>\n 1 P_ID1001       22    2.63    1.78     10      8  20.7    16.3    21.7   20   \n 2 P_ID1002       20    3       2.44      6      6   7.67   12.3    10     17.3 \n 3 P_ID1003       21    2.6     1.78      8      6  16.7    10.3     9     11.7 \n 4 P_ID1004       21    2.27    1.78      8      6  23.3    20      18.3   23.3 \n 5 P_ID1005       23    2.87    2.56     10      8   6.33   10.7    11      8.33\n 6 P_ID1006       43    2.73    2.22     12     10  28.3    25      41.7   30   \n 7 P_ID1007       55    2.93    1.89     10      8  23.3    28.3    23.3   23.3 \n 8 P_ID1008       20    3.03    2.11      8      8  21.3    20.7    19     23   \n 9 P_ID1009       48    2.7     2.89     14     10  45.7    20.3    26.7   57   \n10 P_ID1010       21    2.37    2        10      8  15.3    16.7    18.3   13.3 \n# … with 110 more rows, 14 more variables: top_S14 <dbl>, top_S16 <dbl>,\n#   bottom_S6 <dbl>, bottom_S8 <dbl>, bottom_S10 <dbl>, bottom_S12 <dbl>,\n#   bottom_S14 <dbl>, bottom_S16 <dbl>, dress_S6 <dbl>, dress_S8 <dbl>,\n#   dress_S10 <dbl>, dress_S12 <dbl>, dress_S14 <dbl>, dress_S16 <dbl>, and\n#   abbreviated variable names ¹​tii_score, ²​ma_score\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n```\n:::\n:::\n\n\nOK, now we need to get the data from wide to long format.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_long <- \n  df2 %>%\n  pivot_longer(top_S6:dress_S16, names_to = \"garment\",values_to = \"price\")\n\ndf_long\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,160 × 8\n   response_id   age tii_score ma_score c.size i.size garment    price\n   <chr>       <dbl>     <dbl>    <dbl>  <dbl>  <dbl> <chr>      <dbl>\n 1 P_ID1001       22      2.63     1.78     10      8 top_S6      20.7\n 2 P_ID1001       22      2.63     1.78     10      8 top_S8      16.3\n 3 P_ID1001       22      2.63     1.78     10      8 top_S10     21.7\n 4 P_ID1001       22      2.63     1.78     10      8 top_S12     20  \n 5 P_ID1001       22      2.63     1.78     10      8 top_S14     15.3\n 6 P_ID1001       22      2.63     1.78     10      8 top_S16     17  \n 7 P_ID1001       22      2.63     1.78     10      8 bottom_S6   21.7\n 8 P_ID1001       22      2.63     1.78     10      8 bottom_S8   18  \n 9 P_ID1001       22      2.63     1.78     10      8 bottom_S10  30  \n10 P_ID1001       22      2.63     1.78     10      8 bottom_S12  20  \n# … with 2,150 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nThis looks good, but we now need to have variables that code for size and item type.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_analysis <- \n  df_long %>%\n  separate(garment, c(\"item\", \"size\"), \"_S\")\n```\n:::\n\n\nAnd check....\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_analysis\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,160 × 9\n   response_id   age tii_score ma_score c.size i.size item   size  price\n   <chr>       <dbl>     <dbl>    <dbl>  <dbl>  <dbl> <chr>  <chr> <dbl>\n 1 P_ID1001       22      2.63     1.78     10      8 top    6      20.7\n 2 P_ID1001       22      2.63     1.78     10      8 top    8      16.3\n 3 P_ID1001       22      2.63     1.78     10      8 top    10     21.7\n 4 P_ID1001       22      2.63     1.78     10      8 top    12     20  \n 5 P_ID1001       22      2.63     1.78     10      8 top    14     15.3\n 6 P_ID1001       22      2.63     1.78     10      8 top    16     17  \n 7 P_ID1001       22      2.63     1.78     10      8 bottom 6      21.7\n 8 P_ID1001       22      2.63     1.78     10      8 bottom 8      18  \n 9 P_ID1001       22      2.63     1.78     10      8 bottom 10     30  \n10 P_ID1001       22      2.63     1.78     10      8 bottom 12     20  \n# … with 2,150 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nFinally, our last couple of steps. First, we want to calculate a couple of binary variables that code whether a give item being rated matches a participants actual or ideal size; second, we need to make our item variable a factor, and third, let's standardize our scale scores for idealization of thinness. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_analysis <- \n  df_analysis %>%\n  mutate(\n    c.match = factor(if_else(c.size == size, 1, 0)),\n    i.match = factor(if_else(i.size == size, 1, 0)),\n    sizefactor = factor(size, levels=c(\"6\",\"8\",\"10\",\"12\",\"14\",\"16\")),\n    size = scale(as.numeric(as.character(size))),\n    item = as.factor(item),\n    id = response_id,\n    tii_scorez = scale(tii_score),\n    ma_scorez = scale(ma_score)\n  )\n\ndf_analysis[,c(1,5:11)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,160 × 8\n   response_id c.size i.size item   size[,1] price c.match i.match\n   <chr>        <dbl>  <dbl> <fct>     <dbl> <dbl> <fct>   <fct>  \n 1 P_ID1001        10      8 top      -1.46   20.7 0       0      \n 2 P_ID1001        10      8 top      -0.878  16.3 0       1      \n 3 P_ID1001        10      8 top      -0.293  21.7 1       0      \n 4 P_ID1001        10      8 top       0.293  20   0       0      \n 5 P_ID1001        10      8 top       0.878  15.3 0       0      \n 6 P_ID1001        10      8 top       1.46   17   0       0      \n 7 P_ID1001        10      8 bottom   -1.46   21.7 0       0      \n 8 P_ID1001        10      8 bottom   -0.878  18   0       1      \n 9 P_ID1001        10      8 bottom   -0.293  30   1       0      \n10 P_ID1001        10      8 bottom    0.293  20   0       0      \n# … with 2,150 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n:::imp\nThere's a debate to be had about whether we should consider our `size` variable to be numeric or a factor. It could be argued that the sizes of clothing are distinct categories, and that the scale might not be regular (e.g. size 10 is not the same amount bigger than size 8 as size 8 is from size 6). On the other hand, clothing sizes can also be considered points on an underlying latent continuous variable, which might lead you to want to treat it as numeric. \nPersonally, I would want to know exactly how the participants were presented with the sizes - if they were shown the images and the size of the garment was made explicit for each item, then I would be inclined to consider them distinct categories. However, if participants were not explicitly aware of the size of each item, and it was only the size of the model they saw that varied in their size, I am tempted to treat it numerically. \n\n:::\n\n\n# Descriptives\nLet's look at the average price paid by item type and size:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_analysis %>%\n  group_by(size, item) %>%\n  summarize(\n    price = mean(price, na.rm=T)\n  ) %>%\n  arrange(item)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 18 × 3\n# Groups:   size [6]\n   size[,1] item   price\n      <dbl> <fct>  <dbl>\n 1   -1.46  bottom  26.1\n 2   -0.878 bottom  25.7\n 3   -0.293 bottom  23.7\n 4    0.293 bottom  24.0\n 5    0.878 bottom  24.1\n 6    1.46  bottom  22.5\n 7   -1.46  dress   28.2\n 8   -0.878 dress   27.3\n 9   -0.293 dress   26.2\n10    0.293 dress   27.3\n11    0.878 dress   25.8\n12    1.46  dress   26.5\n13   -1.46  top     18.6\n14   -0.878 top     18.1\n15   -0.293 top     20.0\n16    0.293 top     19.1\n17    0.878 top     19.2\n18    1.46  top     19.3\n```\n:::\n:::\n\n\nThis looks a lot like we are seeing difference, averaged across all participants, in the price they would pay for different types of garment, but not a lot of difference by size.\n\nWe can also calculate the ICC's\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\nm0 <- lmer(price ~ 1 + \n             (1|id) + (1|item),\n           data = df_analysis)\nICC <- as.data.frame(VarCorr(m0))\n```\n:::\n\n\nFor participant:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround((ICC[1,4]/sum(ICC[,4]))*100, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.99\n```\n:::\n:::\n\n\nAnd item:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround((ICC[2,4]/sum(ICC[,4]))*100, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14.36\n```\n:::\n:::\n\n\nSo we can see we have a lot of between person variation, and some between item variation in our data. This suggests that there is potential value in our level 2 predictors concerning both the items and between person characteristics.\n\n# Visualizations\n\nThere are too many ways to visualize this data! Here are just a few:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=c.size, y=price,col=sizefactor))+\n  stat_summary(geom=\"pointrange\")+\n  stat_summary(geom=\"path\")+\n  facet_grid(~item)+\n  labs(x=\"actual size\",y=\"price would pay\")\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=i.size, y=price,col=sizefactor))+\n  stat_summary(geom=\"pointrange\")+\n  stat_summary(geom=\"path\")+\n  facet_grid(~item)+\n  labs(x=\"ideal size\",y=\"price would pay\")\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-17-2.png){fig-align='center' width=672}\n:::\n:::\n\n\nRemember, however, that we had some research questions to consider! \n\n(i) participants would pay more for garments on thinner models\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=sizefactor, y=price))+\n  geom_violin()+\n  labs(x=\"item size\",y=\"price would pay\")\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n(ii) participants would pay more for items when the model size matched their actual size\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=factor(c.match), y=price))+\n  geom_violin()+\n  labs(x=\"item size matches actual size\",y=\"price would pay\")\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n(iii) participants would pay more for items when the model size matched their ideal size\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=factor(i.match), y=price))+\n  geom_violin()+\n  labs(x=\"item size matches ideal size\",y=\"price would pay\")\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n(iv) the extent to which participants idealize thin figures would moderate (ii)\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df_analysis, aes(x=tii_scorez, y=price))+\n  stat_summary(geom=\"pointrange\",aes(group=id))+ # want a mean per participant, rather than each individual point\n  facet_grid(~c.match)\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\n  labs(x=\"thinness idealization score\",y=\"price would pay\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$x\n[1] \"thinness idealization score\"\n\n$y\n[1] \"price would pay\"\n\nattr(,\"class\")\n[1] \"labels\"\n```\n:::\n:::\n\n\n\n# Analysis\n## Equations\n\n:::imp\n\nWhy `item` as a fixed effect and not by-item random intercepts (e.g.`(1 | item)`)? It is debatable how you decide to treat item here. It could be argued that the different item types (dress/top/bottom, etc) represent a sample from some broader population of garment types, and as such should be modeled as random effects (especially given that we are not interested in specific parameter estimates for differences between item types).  \n\nHowever, we only have 3 different types of item, and it is important to remember that having `(1|item)` will involve estimating variance components based on these. Variance estimates will be less stable with such a small number of groups. There's no hard rule to follow here about \"how many groups is enough\" (some people suggest 5 or 6 at least), but personally I would be inclined to use item as a fixed effect. \n\nWe should also consider the possibility that certain items should be less desirable to purchase when in a smaller/bigger size. It may be that size differences are more salient, or more influential on our outcome variable, for certain types of item over others. This would involve adding the interaction between size and item type\n\n:::  \n\n\n\n$$\n\\begin{aligned}\n  \\operatorname{price}_{i[j]}  =& \\beta_{0i} + \n  \\beta_{1i}(\\operatorname{item-size}_j) + \n  \\beta_{1}(\\operatorname{item-type}_j) + \\\\\n  & \\beta_{2}(\\operatorname{item-size}_j \\times \\operatorname{item-type}_j) + \\\\\n  & \\beta_{3i}(\\operatorname{matches-actual-size}_j) + \\\\\n  & \\beta_{4}(\\operatorname{matches-ideal-size}_j) + \\varepsilon_{i[j]}\\\\\n  \\qquad \\\\\n  \n  \\beta_{0i} &= \\gamma_{00} + \\gamma_{01}(\\operatorname{thin-idealisation-score}_i) + \\zeta_{0i} \\\\\n  \\beta_{1i} &= \\gamma_{10} + \\zeta_{1i}\\\\\n  \\beta_{3i} &= \\gamma_{30} + \\gamma_{31}(\\operatorname{thin-idealisation-score}_i)\\\\\n  & \\text{for participant i = 1, } \\dots \\text{, I} \\\\\n\\end{aligned}\n$$\n\n\n## Fitting the models\n\nWe're going to want to do lots of model comparisons, and for those we need all our models to be fitted on the same data. We're going to use these variables:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_analysis <-\n  df_analysis %>%\n  filter(\n    !is.na(size),\n    !is.na(item),\n    !is.na(c.match),\n    !is.na(i.match),\n    !is.na(tii_scorez),\n    !is.na(id),\n    !is.na(price)\n  )\n```\n:::\n\n\n\n\n\nFirst, the effect of size. We're going to treat size as a numeric variable here, in part because it makes our models less complex. \nIt also allows us to model by-participant random effects of size (you can think of this as modeling participants as varying in the amount to which size influences the amount that they are prepared to pay).  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm0 <- lmer(price ~ 1 + item + \n             (1+size|id),\n           data = df_analysis)\nm1 <- lmer(price ~ 1 + item + size +\n             (1 + size|id),\n           data = df_analysis)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item + size + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14045.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.5003 -0.5885 -0.0396  0.5259  5.1435 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.130   7.882         \n          size         2.371   1.540    -0.07\n Residual             33.570   5.794         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  24.3845     0.7517  32.439\nitemdress     2.6468     0.3081   8.590\nitemtop      -5.3352     0.3073 -17.360\nsize         -0.4893     0.1887  -2.593\n\nCorrelation of Fixed Effects:\n          (Intr) itmdrs itemtp\nitemdress -0.204              \nitemtop   -0.205  0.500       \nsize      -0.051  0.000  0.001\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m0, m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm0: price ~ 1 + item + (1 + size | id)\nm1: price ~ 1 + item + size + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)  \nm0    7 14065 14104 -7025.3    14051                       \nm1    8 14060 14105 -7022.0    14044 6.6082  1    0.01015 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe interaction between size and item:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2 <- lmer(price ~ 1 +  item * size +\n             (1+size|id),\n           data = df_analysis)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14026.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.5043 -0.5804 -0.0377  0.5095  5.1433 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.135   7.883         \n          size         2.392   1.547    -0.07\n Residual             33.240   5.765         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.3870     0.7514  32.454\nitemdress        2.6449     0.3066   8.626\nitemtop         -5.3370     0.3058 -17.451\nsize            -1.1062     0.2587  -4.277\nitemdress:size   0.4740     0.3071   1.543\nitemtop:size     1.3689     0.3058   4.477\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   itmdr:\nitemdress   -0.203                            \nitemtop     -0.204  0.500                     \nsize        -0.038  0.002  0.002              \nitemdrss:sz  0.001 -0.003 -0.002 -0.591       \nitemtop:siz  0.001 -0.002 -0.002 -0.594  0.500\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m1,m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm1: price ~ 1 + item + size + (1 + size | id)\nm2: price ~ 1 + item * size + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm1    8 14060 14105 -7022.0    14044                         \nm2   10 14043 14100 -7011.7    14023 20.613  2  3.341e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\nWhat about the effect of item size matching your current size:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm3 <- lmer(price ~ 1 +  item * size + c.match +\n             (1+size|id),\n           data = df_analysis)\nsummary(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14023.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4754 -0.5995 -0.0312  0.5075  5.1647 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.145   7.883         \n          size         2.317   1.522    -0.08\n Residual             33.233   5.765         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.2782     0.7537  32.214\nitemdress        2.6431     0.3066   8.621\nitemtop         -5.3374     0.3058 -17.454\nsize            -1.0747     0.2580  -4.166\nc.match1         0.6620     0.3494   1.895\nitemdress:size   0.4736     0.3071   1.542\nitemtop:size     1.3689     0.3058   4.477\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 itmdr:\nitemdress   -0.202                                   \nitemtop     -0.203  0.500                            \nsize        -0.048  0.002  0.002                     \nc.match1    -0.076 -0.003 -0.001  0.064              \nitemdrss:sz  0.001 -0.003 -0.002 -0.592  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.595  0.000  0.500\n```\n:::\n:::\n\n\nCompare models for current size match:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m2,m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm2: price ~ 1 + item * size + (1 + size | id)\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)  \nm2   10 14043 14100 -7011.7    14023                       \nm3   11 14042 14104 -7009.9    14020 3.5856  1    0.05828 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nOr your ideal size:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm4 <- lmer(price ~ 1 + item * size + c.match + i.match +\n             (1+size|id),\n           data = df_analysis)\nsummary(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14021.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4705 -0.5911 -0.0355  0.5049  5.1828 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.171   7.885         \n          size         2.281   1.510    -0.08\n Residual             33.244   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.2167     0.7556  32.050\nitemdress        2.6439     0.3066   8.622\nitemtop         -5.3369     0.3058 -17.450\nsize            -1.0264     0.2606  -3.938\nc.match1         0.5972     0.3539   1.688\ni.match1         0.4308     0.3650   1.180\nitemdress:size   0.4736     0.3071   1.542\nitemtop:size     1.3685     0.3058   4.475\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 itmdr:\nitemdress   -0.202                                          \nitemtop     -0.203  0.500                                   \nsize        -0.058  0.002  0.002                            \nc.match1    -0.064 -0.003 -0.001  0.038                     \ni.match1    -0.069  0.002  0.001  0.156 -0.160              \nitemdrss:sz  0.001 -0.003 -0.002 -0.586 -0.001  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.500\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00383895 (tol = 0.002, component 1)\n```\n:::\n:::\n\n\nCompare models for ideal size match:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m3,m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\n   npar   AIC   BIC  logLik deviance Chisq Df Pr(>Chisq)\nm3   11 14042 14104 -7009.9    14020                    \nm4   12 14042 14110 -7009.2    14018 1.399  1     0.2369\n```\n:::\n:::\n\n\nFixed effects for thin ideals:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm5 <- lmer(price ~ 1 + item * size + c.match + i.match + tii_scorez + \n             (1+size|id),\n           data = df_analysis)\nsummary(m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 +  \n    size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14020.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4719 -0.5907 -0.0357  0.5059  5.1829 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.695   7.918         \n          size         2.279   1.510    -0.08\n Residual             33.245   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)    24.21667    0.75848  31.928\nitemdress       2.64389    0.30664   8.622\nitemtop        -5.33684    0.30584 -17.450\nsize           -1.02641    0.26060  -3.939\nc.match1        0.59704    0.35388   1.687\ni.match1        0.43085    0.36497   1.181\ntii_scorez     -0.07229    0.73246  -0.099\nitemdress:size  0.47367    0.30714   1.542\nitemtop:size    1.36846    0.30582   4.475\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 t_scrz itmdr:\nitemdress   -0.201                                                 \nitemtop     -0.202  0.500                                          \nsize        -0.058  0.002  0.002                                   \nc.match1    -0.064 -0.003 -0.001  0.038                            \ni.match1    -0.068  0.002  0.001  0.156 -0.160                     \ntii_scorez   0.000  0.000 -0.001  0.001  0.003 -0.001              \nitemdrss:sz  0.001 -0.003 -0.002 -0.587 -0.001  0.000  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.000  0.500\n```\n:::\n:::\n\n\nCompare models for thin ideal:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m4,m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\nm5: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)\nm4   12 14042 14110 -7009.2    14018                     \nm5   13 14044 14118 -7009.2    14018 0.0099  1     0.9208\n```\n:::\n:::\n\n\nDo they interact?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm6 <- lmer(price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match*tii_scorez + \n             (1+size|id),\n           data = df_analysis)\nsummary(m6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match *  \n    tii_scorez + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14019.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4672 -0.5966 -0.0323  0.5021  5.1910 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.679   7.917         \n          size         2.281   1.510    -0.08\n Residual             33.243   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         24.20683    0.75845  31.916\nitemdress            2.64336    0.30663   8.621\nitemtop             -5.33608    0.30584 -17.448\nsize                -1.02537    0.26062  -3.934\nc.match1             0.56650    0.35506   1.595\ni.match1             0.51739    0.37448   1.382\ntii_scorez          -0.01563    0.73458  -0.021\nitemdress:size       0.47423    0.30713   1.544\nitemtop:size         1.36867    0.30581   4.476\nc.match1:tii_scorez -0.37423    0.36191  -1.034\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 t_scrz itmdr: itmtp:\nitemdress   -0.201                                                        \nitemtop     -0.202  0.500                                                 \nsize        -0.056  0.002  0.002                                          \nc.match1    -0.063 -0.003 -0.001  0.037                                   \ni.match1    -0.070  0.002  0.002  0.153 -0.173                            \ntii_scorez  -0.001  0.000  0.000  0.001 -0.003  0.016                     \nitemdrss:sz  0.001 -0.003 -0.002 -0.586 -0.001  0.001  0.000              \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.000  0.500       \nc.mtch1:t_s  0.013  0.002 -0.002 -0.004  0.082 -0.224 -0.076 -0.002 -0.001\n```\n:::\n:::\n\n\nAnd let's just compare all at once, just for fun:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(m0,m1,m2,m3,m4,m5,m6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_analysis\nModels:\nm0: price ~ 1 + item + (1 + size | id)\nm1: price ~ 1 + item + size + (1 + size | id)\nm2: price ~ 1 + item * size + (1 + size | id)\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\nm5: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 + size | id)\nm6: price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match * tii_scorez + (1 + size | id)\n   npar   AIC   BIC  logLik deviance   Chisq Df Pr(>Chisq)    \nm0    7 14065 14104 -7025.3    14051                          \nm1    8 14060 14105 -7022.0    14044  6.6082  1    0.01015 *  \nm2   10 14043 14100 -7011.7    14023 20.6131  2  3.341e-05 ***\nm3   11 14042 14104 -7009.9    14020  3.5856  1    0.05828 .  \nm4   12 14042 14110 -7009.2    14018  1.3990  1    0.23690    \nm5   13 14044 14118 -7009.2    14018  0.0099  1    0.92076    \nm6   14 14045 14125 -7008.7    14017  1.0720  1    0.30048    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## Check model(s)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lattice)\nlibrary(gridExtra)\ngrid.arrange(\n  plot(m1, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m2, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m3, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m4, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m5, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m6, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  ncol=3\n)\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-35-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\ngrid.arrange(\n  qqmath(m1),\n  qqmath(m2),\n  qqmath(m3),\n  qqmath(m4),\n  qqmath(m5),\n  qqmath(m6),\n  ncol=3\n)\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-35-2.png){fig-align='center' width=672}\n:::\n:::\n\n\nI might be a little concerned about our assumptions here. The QQplots look a little off in the tails, however, the histograms of residuals make it look okay:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-36-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nFor peace of mind, we could re-do the model comparisons with parametric bootstrapped model comparison for more reliable conclusions. This _will_ assume that the model specified distribution of residuals ($\\varepsilon \\sim N(0, \\sigma_\\varepsilon)$) holds in the population\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pbkrtest)\nPBmodcomp(m1, m0)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           stat df    p.value\nLRT    6.605558  1 0.01016610\nPBtest 6.605558 NA 0.01098901\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nPBmodcomp(m2, m1)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           stat df      p.value\nLRT    20.61468  2 3.338708e-05\nPBtest 20.61468 NA 9.990010e-04\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nPBmodcomp(m3, m2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           stat df    p.value\nLRT    3.585967  1 0.05826951\nPBtest 3.585967 NA 0.07092907\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nPBmodcomp(m4, m3)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           stat df   p.value\nLRT    1.399085  1 0.2368768\nPBtest 1.399085 NA 0.2317682\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nPBmodcomp(m5, m4)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n             stat df   p.value\nLRT    0.00153228  1 0.9687753\nPBtest 0.00153228 NA 0.9670330\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nPBmodcomp(m6, m5)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           stat df   p.value\nLRT    1.072739  1 0.3003275\nPBtest 1.072739 NA 0.2857143\n```\n:::\n:::\n\n\n\n\n\n\n# Visualise model(s)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsjPlot::plot_model(m6)\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-50-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndotplot.ranef.mer(ranef(m6))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$id\n```\n:::\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-51-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sjPlot)\nplot_model(m6, type = \"pred\")$size\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-52-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m6, type = \"pred\")$c.match\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-52-2.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m6, type = \"pred\")$i.match\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-52-3.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m6, type = \"pred\", terms = c(\"c.match\",\"tii_scorez [-1,0,1]\")) +\n   geom_path()\n```\n\n::: {.cell-output-display}\n![](example_03_many_trials_files/figure-html/unnamed-chunk-52-4.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n# Interpret model(s)\n\n:::int\n\nThe amount that participants indicated they would pay for a garment was modeled using multi-level linear regression models, with by-participant random intercepts and effects of garment size. After adjusting for effects on our outcome due to the garment-type (dress/top/bottom), inclusion of garment size as a fixed predictor was found to improve model fit (Parametric Bootstrap Likelihood Ratio = 6.61, p = 0.011). The effect of garment-size was found to differ between garment-types (inclusion of interaction term LRT 20.61, p <.001). After controlling for garment-type, -size and their interaction, neither the garments' matching participants' actual or ideal size, nor the extent to which participants idealized thin figures were found to predict the price they would pay, and the predicted interaction between actual-size matching and idealization of thin figures was not evidenced. Results of the full model are shown in Table 1. \n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntab_model(m6, show.p = F, title=\"Table 1: Model results. Please note that 95% CIs are not bootstrapped\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Table 1: Model results. Please note that 95% CIs are not bootstrapped</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">price</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">24.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">22.72&nbsp;&ndash;&nbsp;25.69</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">item [dress]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.64</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.04&nbsp;&ndash;&nbsp;3.24</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">item [top]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;5.34</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;5.94&nbsp;&ndash;&nbsp;-4.74</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">size</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.54&nbsp;&ndash;&nbsp;-0.51</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">c match [1]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.57</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.13&nbsp;&ndash;&nbsp;1.26</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">i match [1]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.52</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.22&nbsp;&ndash;&nbsp;1.25</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tii scorez</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.46&nbsp;&ndash;&nbsp;1.42</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">item [dress] * size</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.47</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.13&nbsp;&ndash;&nbsp;1.08</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">item [top] * size</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.77&nbsp;&ndash;&nbsp;1.97</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">c match [1] * tii scorez</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.08&nbsp;&ndash;&nbsp;0.34</td>\n</tr>\n<tr>\n<td colspan=\"3\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">33.24</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>id</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">62.68</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>11</sub> <sub>id.size</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">2.28</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&rho;<sub>01</sub> <sub>id</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">-0.08</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.66</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>id</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">120</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">2130</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.106 / 0.697</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "example_03_many_trials_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}