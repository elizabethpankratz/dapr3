{"title":"Analysis Example: Exploratory Factor Analysis","markdown":{"yaml":{"title":"Analysis Example: Exploratory Factor Analysis","link-citations":"yes","code-fold":true,"params":{"SHOW_SOLS":true,"TOGGLE":true}},"headingText":"Intro","containsRefs":false,"markdown":"\n```{r setup, include=F}\nknitr::opts_chunk$set(message = F, warning = F, fig.align = 'center')\n```\n\n:::frame\n\nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email [ug.ppls.stats@ed.ac.uk](mailto:ug.ppls.stats@ed.ac.uk). \n\n:::\n\n```{r echo=FALSE}\nset.seed(3)\n```\n\n\n\nThis is a quick demonstration of one way of dealing with these tasks. It is by no means the only correct way. There is a substantial level of subjectivity in _Exploratory Factor Analysis_ and the method involves repeated evaluation and re-evaluation of the model in light of the extracted factors and their conceptual relationships with the analysed items. In other words, a good EFA requires you to get your hands dirty.\n\n:::frame\n__Data: Work Pressures Survey__  \n\nThe Work Pressures Survey (WPS) data is available at the following link:\n[https://uoepsy.github.io/data/WPS_data.csv](https://uoepsy.github.io/data/WPS_data.csv).  \nThe data contains responses from 946 workers from a variety of companies to the Work Pressures Survey. You can look at the survey taken by the study participants at the following [link: https://uoepsy.github.io/data/WPS_data_codebook.pdf](https://uoepsy.github.io/data/WPS_data_codebook.pdf)\n\nWe will be performing a factor analysis of the main section of this survey (Job1 to Job50).\n\n:::\n\n# Read in Data\n\nRead the WPS data into R. Make sure to take a look at the variable names and data structure.\n```{r}\nlibrary(tidyverse)\ndf <- read.csv(\"https://uoepsy.github.io/data/WPS_data.csv\")\nhead(df)\n```\n\nVariable names - Option 1:\n```{r}\nnames(df)\n```\n\nVariable names - Option 2:\n```{r eval=FALSE}\ncolnames(df)\n```\n\nData structure - Option 1:\n```{r}\nstr(df)\n```\n\nData structure - Option 2:\n```{r}\nglimpse(df)\n```\n\n# Sanity Checks  \n\nProduce a table of summary statistics for the variables in the data.\n```{r}\ndf %>%\n    summarise(across(everything(), \n                     list(M = mean, SD = sd, MIN = min, MAX = max))) %>%\n    pivot_longer(everything())\n```\n\nWe can see that there are a few missing values in some variables.\n\nIf you were to analyse this data for a research project hopefully leading to a paper, you would probably want to perform sanity check on the variables, such as check if everyone is an adult (assuming this was a requirement for partaking of the study).\n\nCheck whether all participants in the study are adults.\n\n```{r}\nunique(df$doby)\n```\n\nThe data look like a bit of a mess.. Some participants have the full year of birth, some only the last 2 digits. Let’s only extract the last 2 digits from all rows then.\n\nLet's use the `str_sub()` function to take only the last 2 characters.\n```{r}\ndf <- df %>%\n    mutate(doby = str_sub(doby, -2, -1))\n```\nIt seems like it's now a character rather than a number:\n```{r}\nclass(df$doby)\n```\nLet's make it a number again:\n```{r}\ndf$doby <- as.numeric(df$doby)\n```\n\n\nVisualise the distribution of birth year.\nDo we notice anything strange?  \n```{r}\nggplot(df, aes(x = doby)) + \n    geom_histogram(color = 'white')\n```\nOr a dotplot if you prefer:\n```{r}\nggplot(df, aes(x = doby)) + \n    geom_dotplot(dotsize = 0.6, binwidth = 1, fill = 'dodgerblue', color = NA)\n```\n\nA year of birth equal to −1 doesn't make any sense and, since we only want to keep adults, we will remove the rows in the data set having a year of birth equal to -1.\n\nIn the meantime, we will also remove those participants who don't have a value for `doby`.\n```{r}\ndf <- df %>%\n    filter(!is.na(doby) | doby > 0)\n\nhist(df$doby)\n```\nThat looks much better!\n\nNormally, you'd want to check other variables too.\nFor now, because we are focusing on EFA, we'll just assume that the other variables are okay.\n\n# Subset\n\nRemember that the only variables we are interested in for our EFA are the `job1` to `job50` variables. We need to subset the data set to only include those variables.\n\n```{r}\ndf <- df %>%\n    select(job1:job50)\n```\n\nCreate a table of descriptive summary statistics for each variable.\n```{r}\nlibrary(psych)\ndescribe(df)\n```\n\nSome of the variables appear to have values of 0, −1, as well as values larger than 7, even though all the questionnaire items are on a 7-point Likert scale. \n\nGet rid of infeasible values:\n```{r}\ndf[df < 1 | df > 7] <- NA\n```\n\n# Descriptives & Visualising  \n\nLet's now look at the score distributions per item and the correlations between pairs of items.\n\nSometimes easier to use subsets of ten variables each time. For example, look at the pairwise plots of the first 10 variables, then the next 10, and so on. \n\nThere's a lot here to look at. the bottom triangle shows the scatterplots for pairs of variables. Because we have lots of data, and everything is likert data (1-7), the points themselves don't tell us much, but we can eyeball the lines to look at the relationships. And we can look in the top triangle to see these too. It's also good to take a look at the diagonals, which show the distributions of each item. This will help inform us about what type of correlations and factor extraction we might use.  \n```{r}\npairs.panels(df[, 1:10])\npairs.panels(df[, 11:20])\npairs.panels(df[, 21:30])\npairs.panels(df[, 31:40])\npairs.panels(df[, 41:50])\n```\n\nAs you can see, while some of the items have pretty much bell-shaped distributions, some others are massively skewed (looking at you `job49`) or close to uniform (`job9`). \nAt this stage, you'd want to have a closer look at the wording of these troublesome items and see if you can spot any methodological issues that might account for these distributions. \nIf the items look fine, you might want to consider alternative correlation coefficients (e.g., polychoric correlations) that might be more suitable to items with weird distributions. \nFor now, let’s stick to Pearson's correlation (r). Since we have NAs in the data, let's just use complete observations.\n\n\nCompute the correlation matrix of the variables.\n\nInstead of looking at the $50 \\times 50$ matrix of correlations, look at the distribution of correlation coefficients from the lower triangular part of the matrix.\n\nOption 1:\n```{r}\nR <- cor(df, use = \"complete.obs\")\n```\n\nOption 2:\n```{r}\nR <- cor(na.omit(df))\n```\n\n```{r}\nhist(R[lower.tri(R)])\n```\n\nIf you want to be a little fancier, you can categorise the coefficients into negligible, weak, moderate, and strong correlations and plot a bar plot like this:\n\n```{r}\nRc <- cut(abs(R), \n          breaks = c(0, .2, .5, .7, 1), \n          labels = c(\"negligible\", \"weak\", \"moderate\", \"strong\"))\n\nbarplot(table(Rc[lower.tri(Rc)]))\n```\n\nAs we can see, most of the correlations are negligible and many are weak. There are some moderate and strong relationships in the data. This suggests that there might be multiple independent factors.\n\n# Suitability for FA  \n\nCheck if the correlations are sufficient for EFA with Bartlett's test of sphericity and if the sample was adequate with KMO.\n```{r}\ncortest.bartlett(R, \n                 n = sum(complete.cases(df))) # we have 917 complete cases\n```\n\n```{r}\nKMO(R)\n```\n\nA significant Bartlett's test of sphericity means that our correlation matrix is _not_ proportional to an identity matrix (a matrix with only 1s on the diagonal and 0s everywhere else). This is exactly what we want, so we're happy!\n\nLikewise, the sampling adequacy is pretty good. All items have a measure of sampling adequacy (MSA) in the $>.7$ \"middling\" region and the overall KMO is bordering on the $>.9$ \"marvellous\" level (I kid you not).\n\nGiven these results, we can merrily factor-analyse!\n\n# Number of Factors  \n\nIn order to decide how many factors to use, look at the suggestions given by parallel analysis and MAP.\n\n```{r}\nfa.parallel(df, fa = 'fa')\n```\n\n```{r}\nVSS(df)\n```\n\nSince parallel analysis (suggesting 11 factor) tends to overextract and MAP (suggesting 7 factors) can sometimes underextract, it is reasonable to look at solutions with 7-10 factors.\nHowever, looking at the scree plot, it might be reasonable to cast a glance on a 5- or 6-factor solution.\n\n# Perform EFA\n\nFit a factor analysis model to the data using 10 factors.\nSince there is no good reason to expect the factors to be uncorrelated (orthogonal), let's use the oblimin rotation.  \n\n```{r}\nm_10f <- fa(df, nfactors = 10, rotate = \"oblimin\", fm = \"ml\")\n```\n\nPrint loadings sorted according to loadings\n```{r}\nfa.sort(m_10f)\n```\n\nOK, 10 factors looks like way too many as the last 2 have very few substantive loadings (>.33). Let’s look at a smaller solution, e.g. 9 or 8 factors and see if it’s still the case...\n\n```{r}\nm_9f <- fa(df, nfactors = 9, rotate = \"oblimin\", fm = \"ml\")\nm_8f <- fa(df, nfactors = 8, rotate = \"oblimin\", fm = \"ml\")\n```\n\nIt was the case and even the 9-factor solution has only 1 substantive loading on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off:\nWe can see that a few items don’t have any loadings larger than our .33 cut-off:\n```{r}\n# get loadings\nx <- m_9f$loadings\nwhich(rowSums(x < .33) == 9)\n```\n\nIt was the case and even the 8-factor solution has only 2 substantive loadings on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off:\n\n```{r}\n# get loadings\nx <- m_8f$loadings\nwhich(rowSums(x < .33) == 8)\n```\n\nHere is when we would go back to the item wordings and try to see why these items might not really correlate with any other items. For instance, `job11` (\"I regularly discuss problems at work with my colleagues.\") might be ambiguous: does it mean that there are often problems or that if there are problems, I discuss them regularly?\n\nFor argument's sake, let's say, all of these identified items are deemed problematic so we should remove them:\n\n```{r}\ncols_to_remove <- names(which(rowSums(x < .33) == 8))\ndf2 <- df[ , !names(df) %in% cols_to_remove]\n```\n\nCheck parallel analysis and MAP again.\n\n```{r}\nfa.parallel(df2, fa = 'fa')\n```\n\n```{r}\nVSS(df2)\n```\n\nFit an 8-factor model to the new dataset.\n\n```{r}\nm_8f <- fa(df2, nfactors = 8, rotate = \"oblimin\", fm = \"ml\")\nfa.sort(m_8f)\n```\n\nWe still only get 2 substantive loadings on the last factor, while we want at least 3. This also happens with the 7- and 6-factor solutions. But once we hit the 5-factor solution, we find a better structure:\n\n```{r}\nm_5f <- fa(df2, nfactors = 5, rotate = \"oblimin\", fm = \"ml\")\nfa.sort(m_5f)\n```\n\nAlso notice that the 8-factor solution accounted for 49% of the variance and the 5-factor one explains 41%. That is not a huge drop considering that, by choosing the 5-factor over the 8-factor solution, we reduce the dimensionality of the data (number of variables we have to deal with) by further 3 dimensions!\n\nLooking at the loadings, we can see that only 4 items have substantial cross-loadings (on exactly 2 factors), which is not terrible.\n\nGlance at the factor correlations of this final model, we see that only factor 1 and 5 are weakly-to-moderately correlated, which is not too bad! It allows us to claim that the factors (except for one) are largely independent of each other. This model accounts for about 41% of the variance.\n\nAt this stage, we would go to the individual items, look at which factors load on which items, and try to figure out what is the common theme linking these items. For instance, let’s look at the factor ML5. I would start by looking at the items with the highest loadings, i.e., items 44, 4, 33, and 24. They all have three things in common: they address fairness, openness, and promotions/pay rises. Since we have multiple themes going on here, let’s look at the items with loadings in the .4-.6 range. A stronger theme of fair acknowledgement of performance emerges. Not all of the lower-loading items chime with this theme terribly well, but those that do not tend to have cross-loadings with other factor. I would therefore be reasonable confident that the factor taps into something that could be called \"Fair recognition\" (apparently this is referred to in the OrgPsych jargon as \"Procedural justice\").\n\n\n<!-- Formatting -->\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"example2_01_EFA.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.38","toc_float":true,"theme":["united","assets/style-labs.scss"],"code-copy":false,"title":"Analysis Example: Exploratory Factor Analysis","link-citations":"yes","params":{"SHOW_SOLS":true,"TOGGLE":true}},"extensions":{"book":{"multiFile":true}}}}}