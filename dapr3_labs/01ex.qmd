---
title: "Week 1 Exercises: Regression Refresher"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
library(ggdist)
xaringanExtra::use_panelset()
qcounter <- function(){
  if(!exists("qcounter_i")){
    qcounter_i <<- 1
  }else{
    qcounter_i <<- qcounter_i + 1
  }
  qcounter_i
}
```

# Workplace Pride


```{r}
#| include: false
ss=round(runif(1,1e3,1e5))
set.seed(ss)
set.seed(19872)
n_groups = 16
gp = c(3,rep(1,15))
gp = gp/sum(gp)
g = c(rep(1,30),unlist(lapply(2:16, function(x) rep(x,sample(3*(3:6),1)))))
g = sample(1:n_groups,size=300,replace=T,prob=gp)
g = g[order(g)]
getxn = function(v){
  xx=rep(floor(v/3),3)
  idx = sample(1:3,1)
  xx[idx] = xx[idx] + (v %% 3)
  x = c(rep(0,xx[1]),rep(1,xx[2]),rep(2,xx[3]))
  return(x)
}
x = unlist(lapply(table(g), function(x) getxn(x)))
x[g==1] = rbinom(sum(g==1),2,.2)

b = rbinom(n_groups,1,.5)[g]
c = rnorm(length(g),x,1)

re = MASS::mvrnorm(n_groups, mu=c(0,0),Sigma=matrix(c(1,.5,.5,1),nrow=2))
re0 = re[,1][g]
rex = re[,2][g]
lp = (0 + re0) +  -2*c + (1 + rex) * x + b
y = rnorm(length(g), mean = lp, sd = 1)
#y_bin = rbinom(N, size = 1, prob = plogis(lp))
df=data.frame(x=letters[x+1],c, g = factor(g), b,y)


# jobsat ~ age + job_type + coll_supp + manag_support + (1|dept)

# perceived support ~ time in organisation + role(A/B/C) + (1|dept)



# q1
# roles B and C feel much less supported!  
lm(y~x,df) |> broom::tidy()
# oh.. actually that could be due to age differences.. 
with(df,boxplot(c~x))
with(df,plot(y~c))
lm(y~c+x,df) |> broom::tidy()

# q2
# do roles differ in their perceived support?
anova(
  lm(y~c,df),
  lm(y~c+x,df)
)

# q3.. but departments may well differ in their support. some department might be nice to work in, some less so. 
# in observational data like this - we need to be careful about having mistaking department differences as something else. 
# for instance in dept 1 we happen to have a lot more A than B or C. so if dept 1 happens to be a very nice department (which it does), then our current model comparing A, B and C is going to think group A feel very supported (when actually it's just that the A's that we have are from generally happy dept)
ggplot(df,aes(x=x))+geom_bar()+facet_wrap(~g)
with(df,boxplot(y~g))

# what can we do? well, we can control for dept too!
lm(y~c+x,df) |> broom::tidy()
lm(y~c+g+x,df) |> broom::tidy()
anova(
  lm(y~c+g,df),
  lm(y~c+g+x,df)
)
lm(y~c+g+x,df) |> broom::tidy()
#lme4::lmer(y~c+x+(1|g),df) |> broom::tidy()

# okay, cool!


# so we're starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on.. 

# describe the data in more detail:
# - how many ppts, from how many depts?
nrow(df)
length(table(df$g))
# - how many ppts on average from each dept? (min, max?)
df |> count(g) |> summarise(min=min(n),max=max(n),median=median(n))
# - average age of ppts?
mean(df$c)
# - how many depts are b vs not b? 
df |> count(g,b) |> count(b)

# overall average y
mean(df$y)
sd(df$y)
# how much of y variation is due to dept? (ICC)
ICC::ICCbare(g,y,df)




# what if i want to know if, beyond differences due to age and job roles, does the departments' XX influence perceived support?
anova(
  lm(y~c+g+x,df),
  lm(y~c+g+x+b,df)
)
lm(y~c+g+x+b,df) |> broom::tidy()



```

:::frame
__Data: jsup.csv__

- employees from various departments (some are virtual departments, some are office based). 
- employees are either role A, B, or C. (A tends to have less responsibility, C is more managerial)
- also have their length of employment. sometimes new employees come straight in at role C, but a lot of them come in at A and work up. 
- Measured their 'pride in the workplace'

```{r}
#| echo: false
jsup <- df |>
  transmute(role = x, employment_length = c, dept = g, virtual = b, wp = y)
tibble(
  variable = names(jsup),
  description = ""
) |> gt::gt()
```



:::



`r qbegin(qcounter())`
Read in the data and provide some descriptive statistics.  


::: {.callout-tip collapse="true"}
#### Hints

Don't remember how to do descriptives? Think back to previous courses - it's time for some means, standard deviations, mins and maxes. For categorical variables we can do counts or proportions. 

We've seen various functions such as `summary()`, and also `describe()` from the **psych** package.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
library(tidyverse) # for data wrangling
library(psych) 

jsup |> 
  select(employment_length, wp) |> 
  describe()

table(jsup$role)
table(jsup$dept)
table(jsup$virtual)
```

`r solend()`

`r qbegin(qcounter())`
Are there differences in 'workplace-pride' between people in different roles?   


::: {.callout-tip collapse="true"}
#### Hints

does y [continuous variable] differ by x [three groups]? `lm(y ~ x)`?  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
mod1 <- lm(wp ~ role, data = jsup)
```

Rather than doing `summary(model)` - I'm just going to pull out a tidy data.frame of the coefficients, standard errors, t-statistics and p-values.  
It's the same information, just neater
```{r}
library(broom)
tidy(mod1)
```

It looks like people in roles B and C report a lot _less_ pride in the workplace, compared to people in role A.  

`r solend()`

`r qbegin(qcounter())`
Is it something about the roles that make people report differences in workplace-pride, or is it possibly just that people who are newer to the company tend to feel more pride than those who have been there for a while (they're all jaded), and the people in role A tend to be much newer to the company (making it _look_ like people in role A take more pride). In other words, if we were to compare people in role A vs role B vs role C but holding constant their `employment_length`, we might see something different?   


::: {.callout-tip collapse="true"}
#### Hints

so we want to _adjust_ for how long people have been part of the company.. 

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
mod2 <- lm(wp ~ employment_length + role, data = jsup)
tidy(mod2)
```

Note that there are no significant differences in `wp` between roles B or C compared to A, after adjusting for employment length.  

If we plot the data to show all these variables together, we can kind of see why! Given the pattern of `wp` against `employment_length`, the `wp` for different roles are pretty much where we would expect them to be if role doesn't make any difference (i.e., if role doesn't shift your `wp` up or down). 

```{r}
ggplot(jsup, aes(x=employment_length,y=wp,col=role))+
  geom_point(size=3,alpha=.3)
```


`r solend()`


`r qbegin(qcounter())`
Do roles differ in their workplace-pride, when adjusting for time in the company?  


::: {.callout-tip collapse="true"}
#### Hints

Note this is not a question about _specific_ group differences. It is about whether, overall, the `role` groups differ.  So it's wanting to test the _joint_ effect of the two additional parameters we've just added to our model. (hint hint model comparison!)

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
mod2a <- lm(wp ~ employment_length, data = jsup)
mod2 <- lm(wp ~ employment_length + role, data = jsup)

anova(mod2a, mod2)
```


`r solend()`



`r qbegin(qcounter())`
Let's take a step back. We've got `r nrow(jsup)` people in our dataset, from `r n_distinct(jsup$dept)` departments. 

Departments may well differ in the general amount of workplace-pride people report. People love to say that they work in TODO, but other departments might not elicit such pride. 
We need to be careful not to mistake department differences as something else (like differences due to the job role). 

make a couple of plots

- how many each role in each department?
- workplace pride by department




`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
ggplot(jsup, aes(x = role)) + 
  geom_bar()+
  facet_wrap(~dept)
```

In this case, it looks like most of the departments have similar numbers of each role, apart from department TODO, where we've got _loads_ more of role A, and very few role C..  
Note also that department TODO is, on average, full of employees who take a lot of pride in their work. Is this due to the high proportion of roles? or is the effect of role we're seeing more due to differences in departments? 


```{r}
ggplot(jsup, aes(x = dept, y = wp)) +
  geom_boxplot()
```

Even if we had perfectly equal numbers of roles in each department, we're also adjusting for other things such as `employment_length`, and our model the extent to which this differs by department can have trickle-on effects on our coefficient of interest (the `role` coefficients).  

`r solend()`


`r qbegin(qcounter())`
Adjusting for both length of employment _and_ department, are there differences in 'workplace-pride' between the different roles?   

::: {.callout-tip collapse="true"}
#### Hints

Can you make some plots 
:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
mod3 <- lm(wp ~ employment_length + dept + role, data = jsup)
summary(mod3)
```

In a way, adding predictors to our model is kind of like splitting up our plots by that predictor to see the patterns. This becomes more and more difficult (/impossible) as we get more variables, but right now we can split the data into all the constituent parts. 

The association between `wp` and `employment_length` is clear in all these little sub-plots - there's a downward trend. The department differences can be seen too: department 1 is generally a bit higher, departments 5 and 9 a bit lower, and so on. By default, the model captures these coefficients as 'differences from the reference group', so most of the coefficients are negative because they're mostly lower than department 1. 

Seeing the role differences is a bit harder in this plot, but think about what you would expect to see if there were no differences in roles (i.e. imagine if they were all in role A). Take for instance department 2 - for people in role C, for their employment length we would expect their `wp` to be lower if they were in role A. Likewise for those in role B. Across all these departments, the people in role B and C (green and blue dots respectively) are a bit higher than we would expect. This is what the model coefficients tell us!  

```{r}
ggplot(jsup, aes(x = employment_length, y = wp, col = role)) +
  geom_point(size=3,alpha=.4)+
  facet_wrap(~dept)
```

`r solend()`



`r qbegin(qcounter())`
So we're starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on..  

Let's try to describe our sample in a bit more detail. 

- how many participants do we have, and from how many departments?
- how many participants are there, on average, from each department? what is the minimum and maximum?
- what is the average employment length for our participants?
- how many departments are 'virtual departments' vs office-based?  
- what is the overall average reported workplace-pride? 
- how much variation in workplace-pride is due to differences between departments?  


::: {.callout-tip collapse="true"}
#### Hints

The first lot of these questions can be answered using things like `count()`, `summary()`, `table()`, `mean()`, `min()` etc. See [1: Clustered Data #determining-sample-sizes](https://uoepsy.github.io/lmm/01_clustered.html#determining-sample-sizes){target="_blank"}

For the last one, we can use the ICC! See [1: Clustered Data #icc](https://uoepsy.github.io/lmm/01_clustered.html#icc---quantifying-clustering-in-an-outcome-variable){target="_blank"}

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
# - how many participants do we have, and from how many departments?
nrow(jsup)
length(table(jsup$dept))
# - how many ppts on average from each dept? (min, max?)
jsup |> count(dept) |> summarise(min=min(n),max=max(n),median=median(n))
# - average employment length of ppts?
mean(jsup$employment_length)
# - how many depts are virtual vs office based?
jsup |> group_by(virtual) |>
  summarise(
    ndept = n_distinct(dept)
  )

# overall average wp
mean(jsup$wp)
sd(jsup$wp)
# how much of y variation is due to dept? (ICC)
ICC::ICCbare(x = dept, y = wp, data = jsup)
```


`r solend()`

`r qbegin(qcounter())`
What if I would like to know if, adjusting for differences due to employment length and roles, the workplace-pride differs between people working in virtual-departments compared to office-based ones?  


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Let's add the `virtual` predictor to our model. Note that we don't actually get a coefficient here - it is giving us an `NA`!  
```{r}
mod4 <- lm(wp ~ employment_length + dept + role + virtual, data = jsup)

summary(mod4)
```

So what is happening? If we think about it, if we separate out "differences due to departments" then there is nothing left to compare between departments that are virtual vs office based.
Adding the between-department predictor of `virtual` doesn't explain anything more - the residual sums of squares doesn't decrease at all:  
```{r}
anova(
  lm(wp ~ employment_length + dept + role, data = jsup),
  lm(wp ~ employment_length + dept + role + virtual, data = jsup)
)
```

Another way of thinking about this: knowing average workplace-pride for the department that someone is in tells me what to expect about that person's workplace pride. But once I know their department's average workplace-pride, knowing whether it is 'virtual' or 'office-based' doesn't tell me anything new, for the very fact that the virtual/office-based distinction comes from comparing department averages.  

But we're not really interested in departments specifically! What would be nice would be if we can look at the relevant effects of interest (things like `role` and `virtual`), but then just think of the department differences as just some sort of random variation. So we want to think of departments in a similar way to how we think of our individual *employees* - they vary randomly around what we expect - only they're at a different _level_ of observation.  


`r solend()`



