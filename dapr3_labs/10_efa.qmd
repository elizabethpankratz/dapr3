---
title: "10. Exploratory Factor Analysis (EFA): Part 1"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(tidyverse)
library(patchwork)
library(effects)
library(knitr)
library(kableExtra)
library(xaringanExtra)
xaringanExtra::use_panelset()
library(lavaan)
library(semPlot)
# knitr::opts_chunk$set(cache = TRUE)
options(digits=3, scipen = 3)
.pp <- function(command,top=3,bottom=-3,l=FALSE) {
  t <- capture.output(eval(command))
  ln <- length(t)
  if (class(l)!='logical') {
    i=0
    for (n in l) {
      if (i>0) {
        cat("...",sep="\n")
      }
      i=i+1
      if (length(n)==1 && (i == 1 || i == length(l))) {
        if (n<0) {
          s <- n+1+ln
          n <- c(s:ln)
        } else {
          n <- c(1:n)
        }
      }
      if (!(0 %in% n)) {
        cat(t[n],sep="\n")
      }
    }
  } else {
    if (top != 0) {
      cat(t[1:top],sep="\n")
    }
    cat("...",sep="\n")
    if (bottom !=0) {
      bottom <- bottom+1+ln
      cat(t[bottom:ln],sep="\n")
    }
  }
}

qcounter <- function(){
  if(!exists("qcounter_i")){
    qcounter_i <<- 1
  }else{
    qcounter_i <<- qcounter_i + 1
  }
  qcounter_i
}
```



:::lo
**Relevant packages**

+ psych
+ GPArotation

::: 

# PCA vs FA  

Where **PCA** aims to summarise a set of measured variables into a set of orthogonal (uncorrelated) components as linear combinations (a weighted average) of the measured variables, **Factor Analysis (FA)** assumes that the relationships between a set of measured variables can be explained by a number of underlying *latent factors*.   
  
Note how the directions of the arrows in @fig-pcafa are different between PCA and FA - in PCA, each component $C_i$ is the weighted combination of the observed variables $y_1, ...,y_n$, whereas in FA, each measured variable $y_i$ is seen as *generated by* some latent factor(s) $F_i$ plus some unexplained variance $u_i$.   

It might help to read the $\lambda$s as beta-weights ($b$, or $\beta$), because that's all they really are. 
The equation $y_i = \lambda_{1i} F_1 + \lambda_{2i} F_2 + u_i$ is just our way of saying that the variable $y_i$ is the manifestation of some amount ($\lambda_{1i}$) of an underlying factor $F_1$, some amount ($\lambda_{2i}$) of some other underlying factor $F_2$, and some error ($u_i$). 

```{r}
#| label: fig-pcafa
#| echo: false
#| fig-cap: "Path diagrams for PCA and FA"
#| out-width: "1000px"
knitr::include_graphics("images/pcaefa/pca_efa.png")
```

In **_Exploratory_ Factor Analysis (EFA)**, we are starting with no hypothesis about either the number of latent factors or about the specific relationships between latent factors and measured variables (known as the *factor structure*). Typically, all variables will load on all factors, and a transformation method such as a rotation (we'll cover this in more detail below) is used to help make the results more easily interpretable.^[When we have some clear hypothesis about relationships between measured variables and latent factors, we might want to impose a specific factor structure on the data (e.g., items 1 to 10 all measure social anxiety, items 11 to 15 measure health anxiety, and so on). When we impose a specific factor structure, we are doing **Confirmatory Factor Analysis (CFA)**. This is not covered in this course, but it's important to note that in practice EFA is not wholly "exploratory" (your theory *will* influence the decisions you make) nor is CFA wholly "confirmatory" (in which you will inevitably get tempted to explore how changing your factor structure might improve fit).] 


# Suitability of items for EFA

There are various ways of assessing the suitability of our items for exploratory factor analysis, and most of them rely on examining the observed correlations between items.  

:::statbox
__Look at the correlation matrix__  

Use a function such as `cor` or `corr.test(data)` (from the **psych** package) to create the correlation matrix.  

:::

:::statbox
__Bartlett's Test__  

The function `cortest.bartlett(cor(data), n = nrow(data))` conducts "Bartlett's test". This tests against the null that the correlation matrix is proportional to the identity matrix (a matrix of all 0s except for 1s on the diagonal).  

  - Null hypothesis: observed correlation matrix is equivalent to the identity matrix  
  - Alternative hypothesis: observed correlation matrix is not equivalent to the identity matrix.  
  

`r optbegin("What is the identity matrix?", olabel=FALSE)`
The "Identity matrix" is a matrix of all 0s except for 1s on the diagonal.  
e.g. for a 3x3 matrix:  
$$
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{bmatrix}
$$
If a correlation matrix looks like this, then it means there is __no__ shared variance between the items, so it is not suitable for factor analysis
`r optend()`
:::

:::statbox
__Kaiser, Meyer, Olkin Measure of Sampling Adequacy__  

You can check the "factorability" of the correlation matrix using `KMO(data)` (also from **psych**!).  

- Rules of thumb: 
    - $0.8 < MSA < 1$: the sampling is adequate
    - $MSA <0.6$: sampling is not adequate 
    - $MSA \sim 0$: large partial correlations compared to the sum of correlations. Not good for FA  
    
`r optbegin("Kaiser's suggested cuts", toggle=params$TOGGLE)`
These are Kaiser's corresponding adjectives suggested for each level of the KMO:  

- 0.00 to 0.49 "unacceptable"  
- 0.50 to 0.59 "miserable"  
- 0.60 to 0.69 "mediocre"  
- 0.70 to 0.79 "middling"  
- 0.80 to 0.89 "meritorious"  
- 0.90 to 1.00 "marvelous"  

`r optend()`
:::

:::statbox
__Check for linearity__  

It also makes sense to check for linearity of relationships prior to conducting EFA. EFA is all based on correlations, which assume the relations we are capturing are linear.  

You can check linearity of relations using `pairs.panels(data)` (also from **psych**), and you can view the histograms on the diagonals, allowing you to check univariate normality (which is usually a good enough proxy for multivariate normality). 

:::



# Exercises: Conduct Problems  


:::frame
__Data: Conduct Problems__  

A researcher is developing a new brief measure of Conduct Problems. She has collected data from n=450 adolescents on 10 items, which cover the following behaviours:  

1. Stealing
1. Lying
1. Skipping school
1. Vandalism
1. Breaking curfew
1. Threatening others
1. Bullying
1. Spreading malicious rumours
1. Using a weapon 
1. Fighting

Your task is to use the dimension reduction techniques you learned about in the lecture to help inform how to organise the items she has developed into subscales.  

The data can be found at https://uoepsy.github.io/data/conduct_probs.csv 

:::

## 1. Check Suitability

`r qbegin(qcounter())`
Read in the dataset from [https://uoepsy.github.io/data/conduct_probs.csv](https://uoepsy.github.io/data/conduct_probs.csv).  
The first column is clearly an ID column, and it is easiest just to discard this when we are doing factor analysis.  
  
Create a correlation matrix for *the items*.  
Inspect the items to check their suitability for exploratory factor analysis.   


`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
```{r}
library(psych)
df <- read.csv("https://uoepsy.github.io/data/conduct_probs.csv")
# discard the first column
df <- df[,-1]

corr.test(df)  

cortest.bartlett(cor(df), n=450)

KMO(df)  

pairs.panels(df)
```
or alternatively, if you want a ggplot based approach:
```{r message=FALSE}
library(GGally)
ggpairs(data=df, diag=list(continuous="density"), axisLabels="show")
```
`r solend()`

## 2. How many factors?

`r qbegin(qcounter())`
How many dimensions should be retained? This question can be answered in the same way as we did above for PCA. 
  
Use a scree plot, parallel analysis, and MAP test to guide you.   
You can use `fa.parallel(data, fm = "fa")` to conduct both parallel analysis and view the scree plot!   
`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
```{r}
fa.parallel(df, fa = "fa")
```
In this case the scree plot has a kink at the third factor, so we probably want to retain 2 factors.  
  
We can conduct the MAP test using `VSS(data)`.
```{r}
VSS(df, plot = FALSE, n = ncol(df))$map
```
The MAP test suggests retaining 2 factors.  
`r solend()`

## 3. Perform EFA

Now we need to perform the factor analysis. But there are two further things we need to consider, and they are:  

a) whether we want to apply a __rotation__ to our factor loadings, in order to make them easier to interpret, and  
b) how do we want to extract our factors (it turns out there are loads of different approaches!). 


:::statbox
**Rotations?** 

Rotations are so called because they transform our loadings matrix in such a way that it can make it more easy to interpret. You can think of it as a transformation applied to our loadings in order to optimise interpretability, by maximising the loading of each item onto one factor, while minimising its loadings to others. We can do this by simple rotations, but maintaining our axes (the factors) as perpendicular (i.e., uncorrelated) as in @fig-rot2, or we can allow them to be transformed beyond a rotation to allow the factors to correlate (@fig-rot3). 
```{r}
#| label: fig-rot1
#| fig-cap: "No rotation"
#| echo: false
knitr::include_graphics("images/pcaefa/rot1.png")
```

```{r}
#| label: fig-rot2
#| fig-cap: "Orthogonal rotation"
#| echo: false
knitr::include_graphics("images/pcaefa/rot2.png")
```

```{r}
#| label: fig-rot3
#| fig-cap: "Oblique rotation"
#| echo: false
knitr::include_graphics("images/pcaefa/rot3.png")
```
In our path diagram of the model (@fig-efarot), all the factor loadings remain present, but some of them become negligible. We can also introduce the possible correlation between our factors, as indicated by the curved arrow between $F_1$ and $F_2$. 

```{r}
#| label: fig-efarot
#| fig-cap: "Path diagrams for EFA with rotation"
#| out-width: "1000px"
#| echo: false
knitr::include_graphics("images/pcaefa/efa_rot.png")
```

:::

:::frame
**Factor Extraction**  

PCA (using eigendecomposition) is itself a method of extracting the different dimensions from our data. However, there are lots more available for factor analysis. 

You can find a lot of discussion about different methods both in the help documentation for the `fa()` function from the psych package: 

>Factoring method fm="minres" will do a minimum residual as will fm="uls". Both of these use a first derivative. fm="ols" differs very slightly from "minres" in that it minimizes the entire residual matrix using an OLS procedure but uses the empirical first derivative. This will be slower. fm="wls" will do a weighted least squares (WLS) solution, fm="gls" does a generalized weighted least squares (GLS), fm="pa" will do the principal factor solution, fm="ml" will do a maximum likelihood factor analysis. fm="minchi" will minimize the sample size weighted chi square when treating pairwise correlations with different number of subjects per pair. fm ="minrank" will do a minimum rank factor analysis. "old.min" will do minimal residual the way it was done prior to April, 2017 (see discussion below). fm="alpha" will do alpha factor analysis as described in Kaiser and Coffey (1965)

And there are lots of discussions both in papers and on [forums](https://stats.stackexchange.com/questions/50745/best-factor-extraction-methods-in-factor-analysis). 

As you can see, this is a complicated issue, but when you have a large sample size, a large number of variables, for which you have similar communalities, then the extraction methods tend to agree. For now, don't fret too much about the factor extraction method.^[(It's a *bit* like the optimiser issue in the multi-level model block)]

:::


`r qbegin(qcounter())`
Use the function `fa()` from the **psych** package to conduct and EFA to extract 2 factors (this is what *we* suggest based on the various tests above, but *you* might feel differently - the ideal number of factors is subjective!). Use a suitable rotation (`rotate = ?`) and extraction method (`fm = ?`).  
```{r}
#| eval: false
conduct_efa <- fa(data, nfactors = ?, rotate = ?, fm = ?)
```

`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
For example, you could choose an oblimin rotation to allow factors to correlate and use minres as the extraction method.  
```{r}
conduct_efa <- fa(df, nfactors=2, rotate='oblimin', fm="minres")
```
`r solend()`

## 4. Inspect

We can simply print the name of our model in order to see a lot of information. Let's go through it in pieces.   

:::statbox

__Loadings__  
```{r}
#| echo: false
.pp(conduct_efa, l=list(1:15))
```

Factor loading's, like PCA loading's, show the relationship of each measured variable to each factor. They range between -1.00 and 1.00
Larger absolute values represent stronger relationship between measured variable and factor.  

- The columns that (depending upon estimation method) might be called `MR`/`ML`/`PC` are the factors. The number assigned to is arbitrary, and they might not always be in a numeric order (this has to do with a rotated solution). Typically, the numbering maps to how much variance each factor account for. 
- __h2:__ This is the "communality", which is how much variance in the item is explained by the factors. It is calculated as the sum of the squared loadings.  
- __u2:__ This is $1 - h2$. It is the residual variance, or the "uniqueness" for that item (i.e. the amount left unexplained).  
- __com:__ This is the "Item complexity". It tells us how much a given item reflects a single factor (vs being "more complex" in that it represents multiple factors). It equals one if an item loads only on one factor, 2 if evenly loads on two factors, etc.  

You can get these on their own using
```{r}
#| eval: false
conduct_efa$loadings
```

:::

:::statbox
__Variance Accounted For__  
```{r}
#| echo: false
.pp(conduct_efa, l=list(16:21))
```

Below the factor loadings, we have a familiar set of measures of the variance in the data accounted for by each factor. This is very similar to what we saw with PCA.  

- SS loadings: The sum of the squared loadings. The eigenvalues.  
- Proportion Var: how much of the overall variance the factor accounts for out of all the variables. 
- Cumulative Var: cumulative sum of Proportion Var.
- Proportion Explained: relative amount of variance explained ($\frac{\text{Proportion Var}}{\text{sum(Proportion Var)}}$.
- Cumulative Proportion: cumulative sum of Proportion Explained.

You can get these on their own using
```{r}
#| eval: false
conduct_efa$Vaccounted
```

:::

:::statbox
__Factor Correlations__  
```{r}
#| echo: false
.pp(conduct_efa, l=list(22:28))
```

Whether we see this section will depend if we have run a factor analysis with $\geq 2$ factors and a rotation.  

- `factor correlations`: shows the correlation matrix between the factors. 
- `mean item complexity`: shows the mean of the `com` column from the loadings above.  

You can get these on their own using
```{r}
#| eval: false
conduct_efa$Phi
```

:::


:::statbox
__Tests, Fit Indices etc__  

We also get a whole load of other stuff that can sometimes be useful. These include: a test of an hypothesis that the 2 factors are sufficient; information on the number of observations; fit indices such as RMSEA, TLI RMSR etc; and measures of factor score adequacy (we'll get to talking about factor scores next week).
```{r}
#| echo: false
.pp(conduct_efa, l=list(29:48))
```



:::

`r qbegin(qcounter())`
Inspect the loadings (`conduct_efa$loadings`) and give the factors you extracted labels based on the patterns of loadings.  
  
Look back to the description of the items, and suggest a name for your factors  
`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
You can inspect the loadings using:
```{r}
print(conduct_efa$loadings, sort=TRUE)
```
We can see that the first five items have high loadings for one factor and the second five items have high loadings for the other.  
  
The first five items all have in common that they are non-aggressive forms of conduct problems, while the last five items are all aggressive behaviours. We could, therefore, label our factors: ‘non-aggressive’ and ‘aggressive’ conduct problems.
`r solend()`

`r qbegin(qcounter())`
How correlated are your factors?  

We can inspect the factor correlations (if we used an oblique rotation) using:
```{r}
#| eval: false
conduct_efa$Phi
```
`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
```{r}
conduct_efa$Phi
```
We can see here that there is a moderate correlation between the two factors. An oblique rotation would be appropriate here. 
`r solend()`

## 5. Write-up 

`r qbegin(qcounter())`
Drawing on your previous answers and conducting any additional analyses you believe would be necessary to identify an optimal factor structure for the 10 conduct problems, write a brief text that summarises your method and the results from your chosen optimal model.
`r qend()`
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
The main principles governing the reporting of statistical results are transparency and reproducibility (i.e., someone should be able to reproduce your analysis based on your description).

An example summary would be:

:::int 

First, the data were checked for their suitability for factor analysis. Normality was checked using visual inspection of histograms, linearity was checked through the inspection of the linear and lowess lines for the pairwise relations of the variables, and factorability was confirmed using a KMO test, which yielded an overall KMO of $.87$ with no variable KMOs $<.50$. 
An exploratory factor analysis was conducted to inform the structure of a new conduct problems test. Inspection of a scree plot alongside parallel analysis (using principal components analysis; PA-PCA) and the MAP test were used to guide the number of factors to retain. All three methods suggested retaining two factors; however, a one-factor and three-factor solution were inspected to confirm that the two-factor solution was optimal from a substantive and practical perspective, e.g., that it neither blurred important factor distinctions nor included a minor factor that would be better combined with the other in a one-factor solution. These factor analyses were conducted using minres extraction and (for the two- and three-factor solutions) an oblimin rotation, because it was expected that the factors would correlate. Inspection of the factor loadings and correlations reinforced that the two-factor solution was optimal: both factors were well-determined, including 5 loadings $>|0.3|$ and the one-factor model blurred the distinction between different forms of conduct problems. 
The factor loadings are provided in @tbl-loadingtab^[You should provide the table of factor loadings. It is conventional to omit factor loadings $<|0.3|$; however, be sure to ensure that you mention this in a table note.]. Based on the pattern of factor loadings, the two factors were labelled 'aggressive conduct problems' and 'non-aggressive conduct problems'. These factors had a  correlation of $r=.43$. Overall, they accounted for 57% of the variance in the items, suggesting that a two-factor solution effectively summarised the variation in the items.


```{r}
#| label: tbl-loadingtab
#| echo: false
#| tbl-cap: "Factor Loadings"


loadings = unclass(conduct_efa$loadings)
loadings = round(loadings, 3)
loadings[abs(loadings) < 0.3] = NA
options(knitr.kable.NA = '')
knitr::kable(loadings, digits = 2)
```

:::


`r solend()`

# PCA & EFA Comparison Exercise

`r qbegin(qcounter())`
Using the same data, conduct a PCA using the `principal()` function.  
  
What differences do you notice compared to your EFA?  
  
Do you think a PCA or an EFA is more appropriate in this particular case?
`r qend()` 
`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
We can use:
```{r}
principal(df, nfactors=2)
```
We can see that while the loadings differ somewhat between the EFA and the PCA, the overall pattern is quite similar. This is not always the case, especially when the item communalities are low.  
  
In terms of which method is more appropriate, arguably EFA would be more appropriate in this case because our researcher wishes to measure a theoretical construct (conduct problems), rather than simply reduce the dimensions of her data.
`r solend()`



<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>