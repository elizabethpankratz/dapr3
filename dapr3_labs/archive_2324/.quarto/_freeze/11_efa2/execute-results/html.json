{
  "hash": "a0f962352682aa9080a274139bce3fd6",
  "result": {
    "markdown": "---\ntitle: \"11. EFA 2\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n:::lo\n**Relevant packages**\n\n+ tidyverse\n+ psych\n+ GPArotation\n\n::: \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n# Practical Issues with EFA\n\n:::frame\n__Data: pgpets.csv__  \n\nA pet food company has conducted a questionnaire on the internet ($n = 620$) to examine whether owning a pet influences low mood. They asked 16 questions on a Likert scale (1-7, detailed below) followed by a simple Yes/No question concerning whether the respondent owned a pet.   \nThere are lots of questions, and the researchers don't really know much about the theory of mood disorders, but they think that they are likely picking up on multiple different types of \"low mood\". They want to conduct a factor analysis to examine this, and then plan on investigating the group differences (pet owners vs not pet owners) on the factor scores.  \n\nThe data is available at https://uoepsy.github.io/data/pgpets.csv  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> QuestionNumber </th>\n   <th style=\"text-align:left;\"> Over the last 2 weeks, how much have you had/have you been... </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> item1 </td>\n   <td style=\"text-align:left;\"> Little interest or pleasure in doing things? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item2 </td>\n   <td style=\"text-align:left;\"> Feeling down, depressed, or hopeless? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item3 </td>\n   <td style=\"text-align:left;\"> Trouble falling or staying asleep, or sleeping too much? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item4 </td>\n   <td style=\"text-align:left;\"> Feeling tired or having little energy? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item5 </td>\n   <td style=\"text-align:left;\"> Poor appetite or overeating? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item6 </td>\n   <td style=\"text-align:left;\"> Feeling bad about yourself - or that you are a failure or have let yourself or your family down? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item7 </td>\n   <td style=\"text-align:left;\"> Reading the newspaper or watching television? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item8 </td>\n   <td style=\"text-align:left;\"> Moving or speaking so slowly that other people could have noticed? Or the opposite - being so fidgety or restless that you have been moving around a lot more than usual? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item9 </td>\n   <td style=\"text-align:left;\"> A lack of motivation to do anything at all? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item10 </td>\n   <td style=\"text-align:left;\"> Feeling nervous, anxious or on edge? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item11 </td>\n   <td style=\"text-align:left;\"> Not being able to stop or control worrying? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item12 </td>\n   <td style=\"text-align:left;\"> Worrying too much about different things? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item13 </td>\n   <td style=\"text-align:left;\"> Trouble relaxing? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item14 </td>\n   <td style=\"text-align:left;\"> Being so restless that it is hard to sit still? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item15 </td>\n   <td style=\"text-align:left;\"> Becoming easily annoyed or irritable? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item16 </td>\n   <td style=\"text-align:left;\"> Feeling afraid as if something awful might happen? </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\nRead the data into R.  \nCreate a new object in R that contains a subset the data. It should include all variables except for the participant ID and the variable corresponding to whether or not they have a pet (we're going to come back to these later on).  \nIn this new object, change the names of the columns to match the question number, rather than the question itself (see the data description above). This will be easier to work with.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nCheck the output of the code `paste0(\"item\", 1:10)`. Consider this code in combination with another function: `names(data)`. How could you combine the two codes to assign the new names to the current variable names?  \n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-1' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-1', 'sol-start-1')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-1\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(psych)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npgpets <- read_csv(\"https://uoepsy.github.io/data/pgpets.csv\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnames(pgpets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"little_interest_or_pleasure_in_doing_things\"                                                                                                                          \n [2] \"feeling_down_depressed_or_hopeless\"                                                                                                                                   \n [3] \"trouble_falling_or_staying_asleep_or_sleeping_too_much\"                                                                                                               \n [4] \"feeling_tired_or_having_little_energy\"                                                                                                                                \n [5] \"poor_appetite_or_overeating\"                                                                                                                                          \n [6] \"feeling_bad_about_yourself_or_that_you_are_a_failure_or_have_let_yourself_or_your_family_down\"                                                                        \n [7] \"trouble_concentrating_on_things_such_as_reading_the_newspaper_or_watching_television\"                                                                                 \n [8] \"moving_or_speaking_so_slowly_that_other_people_could_have_noticed_or_the_opposite_being_so_fidgety_or_restless_that_you_have_been_moving_around_a_lot_more_than_usual\"\n [9] \"a_lack_of_motivation_to_do_anything_at_all\"                                                                                                                           \n[10] \"feeling_nervous_anxious_or_on_edge\"                                                                                                                                   \n[11] \"not_being_able_to_stop_or_control_worrying\"                                                                                                                           \n[12] \"worrying_too_much_about_different_things\"                                                                                                                             \n[13] \"trouble_relaxing\"                                                                                                                                                     \n[14] \"being_so_restless_that_it_is_hard_to_sit_still\"                                                                                                                       \n[15] \"becoming_easily_annoyed_or_irritable\"                                                                                                                                 \n[16] \"feeling_afraid_as_if_something_awful_might_happen\"                                                                                                                    \n[17] \"do_you_own_a_pet\"                                                                                                                                                     \n[18] \"ppt_id\"                                                                                                                                                               \n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- pgpets %>% \n    select(-ppt_id, -do_you_own_a_pet)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnames(df) <- paste0(\"item\", 1:ncol(df))\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  item1 item2 item3 item4 item5 item6 item7 item8 item9 item10 item11 item12\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n1     5     5     5     4     6     7     4     3     6      4      4      5\n2     4     4     3     5     3     5     2     4     4      3      3      5\n3     5     5     5     5     3     7     5     5     6      5      5      5\n4     4     5     5     6     4     5     4     6     7      6      6      4\n5     2     1     3     3     3     3     5     4     2      3      3      3\n6     6     4     6     5     5     4     3     5     6      5      4      4\n# ℹ 4 more variables: item13 <dbl>, item14 <dbl>, item15 <dbl>, item16 <dbl>\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\nVisualise the items (this might be the histograms of all marginal distributions, or a scatterplot matrix, or both).  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThe function `multi.hist()` from the __psych__ package can be pretty useful if we're just wanting the distributions. Things like `pairs.panels()` can get pretty chaotic when we have lots of variables, so you might need to use that on subsets.  \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-2' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(psych)\nmulti.hist(df)\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nThe data have 6 variables, so we will create two plots each focusing on 8 at a time:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npairs.panels(df[, 1:8])\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=80%}\n:::\n\n```{.r .cell-code}\npairs.panels(df[, 9:16])\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-10-2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\nCompute the correlation matrix for the items, and assess the suitability for factor analysis, using the Bartlett test and the Kaiser-Meyer-Olkin factor adequacy.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nLook back in last week's lab to see how Bartlett & KMO are conducted in R\n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-3' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncordf = cor(df)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncortest.bartlett(cordf, n = nrow(df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$chisq\n[1] 3008\n\n$p.value\n[1] 0\n\n$df\n[1] 120\n```\n:::\n:::\n\n:::int\nBartlett's test indicates that the correlation matrix is proportionally different from the identity matrix ($\\chi^2 (120) = 3008, p<.001$), suggesting our correlations are significantly different from zero. \n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nKMO(cordf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cordf)\nOverall MSA =  0.9\nMSA for each item = \n item1  item2  item3  item4  item5  item6  item7  item8  item9 item10 item11 \n  0.90   0.91   0.93   0.90   0.92   0.89   0.40   0.92   0.88   0.91   0.90 \nitem12 item13 item14 item15 item16 \n  0.92   0.94   0.88   0.90   0.91 \n```\n:::\n:::\n\n\n:::int\nThe KMO for individual items are mainly \"meritorious\" or \"marvelous\". The only item that may need further investigation is item 7, having an \"unacceptable\" KMO. \nThe overall measure of sampling adequacy is 0.90, which suggests we have suitable data to perform a factor analysis\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\nDetermine how many factors you will extract.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nAs always, there are lots of methods to help you decide, but the ultimate decision is yours.  \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-4' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\nUsing parallel analysis:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfa.parallel(df, fa = 'fa')\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n```\n:::\n:::\n\n\nUsing Velicer's Minimum Average Partial:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nVSS(df)\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.67  with  3  factors\nVSS complexity 2 achieves a maximimum of 0.86  with  8  factors\n\nThe Velicer MAP achieves a minimum of 0.01  with  2  factors \nBIC achieves a minimum of  -477  with  2  factors\nSample Size adjusted BIC achieves a minimum of  -195  with  2  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof  chisq     prob sqresid  fit  RMSEA  BIC SABIC complex\n1 0.66 0.00 0.035 104 1014.1 4.0e-149    12.1 0.66 0.1188  345   676     1.0\n2 0.66 0.81 0.012  89   94.8  3.2e-01     6.8 0.81 0.0101 -477  -195     1.2\n3 0.67 0.80 0.020  75   75.2  4.7e-01     6.5 0.82 0.0015 -407  -169     1.3\n4 0.64 0.81 0.028  62   60.4  5.3e-01     5.9 0.83 0.0000 -338  -141     1.3\n5 0.63 0.82 0.042  50   38.1  8.9e-01     5.2 0.85 0.0000 -283  -125     1.3\n6 0.64 0.84 0.058  39   28.4  8.9e-01     4.4 0.88 0.0000 -222   -99     1.3\n7 0.62 0.84 0.076  29   18.8  9.3e-01     4.0 0.89 0.0000 -168   -76     1.4\n8 0.63 0.86 0.089  20    9.6  9.7e-01     3.7 0.89 0.0000 -119   -55     1.4\n  eChisq   SRMR eCRMS eBIC\n1 1880.5 0.1124 0.121 1212\n2   73.0 0.0221 0.026 -499\n3   55.9 0.0194 0.025 -426\n4   40.9 0.0166 0.023 -358\n5   25.1 0.0130 0.020 -296\n6   16.1 0.0104 0.018 -235\n7    9.2 0.0078 0.016 -177\n8    4.4 0.0054 0.013 -124\n```\n:::\n:::\n\n:::int\nBoth parallel analysis and Velicer’s Minimum Average Partial suggested retaining 2 factors.\n:::\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\nChoosing an appropriate estimation method and rotation, perform a factor analysis to extract the desired number of factors (based on your answer to the previous question).  \n\nIf you get an error, you may need to install the \"GPArotation\" package: `install.packages(\"GPArotation\")`.\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-5' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\nWe probably shouldn't use MLE as an estimation method here, because we're going to be treating what looks like some sort of Likert data (ordinal, responses of 1-7) as if it is continuous.  \nLet's use `minres` here.  \n\nFinally, do we have any reason to think that the factors we are going to extract are orthogonal? Given what the questions look to be evaluating, it's hard to see distinctly unrelated constructs within the 16 items. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npgmod <- fa(df, nfactors = 2, rotate = \"oblimin\", fm = \"minres\")\npgmod\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFactor Analysis using method =  minres\nCall: fa(r = df, nfactors = 2, rotate = \"oblimin\", fm = \"minres\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n         MR1   MR2     h2   u2 com\nitem1   0.45 -0.02 0.1947 0.81 1.0\nitem2   0.54 -0.05 0.2685 0.73 1.0\nitem3   0.50  0.44 0.6071 0.39 2.0\nitem4   0.75  0.04 0.5871 0.41 1.0\nitem5   0.44 -0.12 0.1678 0.83 1.1\nitem6   0.81 -0.02 0.6464 0.35 1.0\nitem7   0.01  0.03 0.0012 1.00 1.4\nitem8   0.57 -0.02 0.3112 0.69 1.0\nitem9   0.84 -0.03 0.6921 0.31 1.0\nitem10  0.01  0.68 0.4669 0.53 1.0\nitem11 -0.05  0.63 0.3778 0.62 1.0\nitem12  0.05  0.41 0.1887 0.81 1.0\nitem13  0.07  0.51 0.2933 0.71 1.0\nitem14 -0.03  0.77 0.5818 0.42 1.0\nitem15 -0.04  0.65 0.4033 0.60 1.0\nitem16  0.01  0.59 0.3579 0.64 1.0\n\n                       MR1  MR2\nSS loadings           3.23 2.92\nProportion Var        0.20 0.18\nCumulative Var        0.20 0.38\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\n With factor correlations of \n     MR1  MR2\nMR1 1.00 0.39\nMR2 0.39 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  120  with the objective function =  4.91 with Chi Square =  3008\ndf of  the model are 89  and the objective function was  0.16 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  620 with the empirical chi square  73  with prob <  0.89 \nThe total n.obs was  620  with Likelihood Chi Square =  94.8  with prob <  0.32 \n\nTucker Lewis Index of factoring reliability =  0.997\nRMSEA index =  0.01  and the 90 % confidence intervals are  0 0.025\nBIC =  -477\nFit based upon off diagonal values = 0.99\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.94 0.92\nMultiple R square of scores with factors          0.88 0.85\nMinimum correlation of possible factor scores     0.77 0.69\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n::: {.callout-note collapse=\"true\"}\n#### EFA output\n\n\\newcommand{\\item}[1]{ \\text{Item}_{#1} }\n\\newcommand{\\fact}[1]{ \\text{Factor}_{#1} }\n\\newcommand{\\e}[1]{ \\epsilon_{#1} }\n\\newcommand{\\LL}[2]{ {\\lambda_{#1,#2}} }\n\nIf we think about a factor analysis being a set of regressions (convention in factor analysis is to use $\\LL{}{}$ instead of $\\beta$), then we can think of a given item being the manifestation of some latent factors, plus a bit of randomness (or 'stray causes'):\n\n\\begin{aligned}\n\\item{1}  &= \\LL{1}{1} \\cdot \\fact{1} + \\LL{2}{1} \\cdot \\fact{2} + u_{1} \\\\\n\\item{2}  &= \\LL{1}{2} \\cdot \\fact{1} + \\LL{2}{2} \\cdot \\fact{2} + u_{2} \\\\\n&\\vdots \\\\\n\\item{16} &= \\LL{1}{16} \\cdot \\fact{1} + \\LL{2}{16} \\cdot \\fact{2} + u_{16}\n\\end{aligned}\n\nAs you can see from the above, the 16 different items all stem from the same two factors ($\\fact{1}, \\fact{2}$), plus some item-specific errors ($u_{1}, \\dots, u_{16}$). The $\\LL{}{}$ terms are called factor loadings, or loadings in short\n\n__Communality__ is sum of the squared factor loadings for each item.  \n\nIntuitively, for each row, the two $\\LL{}{}$s tell us how much each item depends on the two factors shared by the 16 items. The sum of the squared loadings tells us how much of one item's information is due to the shared factors.\n\nThe communality is a bit like the $R^2$ (the proportion of variance of an item that is explained by the factor structure). And the standardised loadings are the proportion of variance in an item explained by each factor after accounting for other other factors.  \n\n\nThe __Uniqueness__ of each item is simply $1 - \\text{communality}$.  \nThis is the leftover bit; the variance in each item that is left unexplained by the latent factors (this could be specific variance, or it could be error variance. the one thing we know is, it's not common variance).  \n\n_Side note: this is what sets Factor Analysis apart from PCA, which is the linear combination of total variance (including error) in all our items. FA allows some of the variance to be shared by the underlying factors, and considers the remainder to be unique to the individual items (or, in another, error in how each item measures the construct)._\n\nThe __Complexity__ of an item corresponds to how well an item reflects a _single_ underlying construct. Specifically, it is ${(\\sum \\lambda_i^2)^2}/{\\sum \\lambda_i^4}$, where $\\lambda_i$ is the loading on to the $i^{th}$ factor. It will be equal to 1 for an item which loads _only_ on one factor, and 2 if it loads evenly on to two factors, and so on. \n\n:::rtip\nIn R, we will often see these estimats under specific columns:  \n\n+ __h2__ = item communality  \n+ __u__  = item uniqueness  \n+ __com__ = item complexity\n\n:::\n\n:::\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n\nUsing `fa.sort()`, examine the loadings of each item onto the factors, along with communalities, uniqueness and complexity scores.  \n\n\n- Do all factors load on 3+ items at a salient level?\n- Do all items have at least one loading above a salient cut off?\n- Are there any Heywood cases (communalities or standardised loadings $\\geq1$)? \n- Should we perhaps remove some complex items? \n- Does the solution account for an acceptable level of variance?  \n- Is the factor structure (items that load on to each factor) coherent, and does it make theoretical sense?  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-6' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfa.sort(pgmod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFactor Analysis using method =  minres\nCall: fa(r = df, nfactors = 2, rotate = \"oblimin\", fm = \"minres\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n         MR1   MR2     h2   u2 com\nitem9   0.84 -0.03 0.6921 0.31 1.0\nitem6   0.81 -0.02 0.6464 0.35 1.0\nitem4   0.75  0.04 0.5871 0.41 1.0\nitem8   0.57 -0.02 0.3112 0.69 1.0\nitem2   0.54 -0.05 0.2685 0.73 1.0\nitem3   0.50  0.44 0.6071 0.39 2.0\nitem1   0.45 -0.02 0.1947 0.81 1.0\nitem5   0.44 -0.12 0.1678 0.83 1.1\nitem14 -0.03  0.77 0.5818 0.42 1.0\nitem10  0.01  0.68 0.4669 0.53 1.0\nitem15 -0.04  0.65 0.4033 0.60 1.0\nitem11 -0.05  0.63 0.3778 0.62 1.0\nitem16  0.01  0.59 0.3579 0.64 1.0\nitem13  0.07  0.51 0.2933 0.71 1.0\nitem12  0.05  0.41 0.1887 0.81 1.0\nitem7   0.01  0.03 0.0012 1.00 1.4\n\n                       MR1  MR2\nSS loadings           3.23 2.92\nProportion Var        0.20 0.18\nCumulative Var        0.20 0.38\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\n With factor correlations of \n     MR1  MR2\nMR1 1.00 0.39\nMR2 0.39 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  120  with the objective function =  4.91 with Chi Square =  3008\ndf of  the model are 89  and the objective function was  0.16 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  620 with the empirical chi square  73  with prob <  0.89 \nThe total n.obs was  620  with Likelihood Chi Square =  94.8  with prob <  0.32 \n\nTucker Lewis Index of factoring reliability =  0.997\nRMSEA index =  0.01  and the 90 % confidence intervals are  0 0.025\nBIC =  -477\nFit based upon off diagonal values = 0.99\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.94 0.92\nMultiple R square of scores with factors          0.88 0.85\nMinimum correlation of possible factor scores     0.77 0.69\n```\n:::\n:::\n\n\n- Both factors load on 3+ items at a salient level. \n- All except item7 has loadings $>0.3$. \n- There are no Heywood cases.\n- Item 3 loads quite highly on both factors (high complexity) \n- The solution explains 38% of the variance.  \n- The coherence of the factor structure will require us to look back at the questions themselves. We'll not do this right now, but do that later on.  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\nIf you think any items should be removed, do so now, and perform the factor analysis once more.  \n\nReally, this starts the whole process again, so we'll have to go through our steps to get to our new factor model on the reduced set of items.  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-7' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  remove items</button></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\nWe're going to remove that problematic item 7 (which seems to be about \"reading the newspaper and watching tv\"), as well as item 3 (which seems to be about sleepiness, and relates to both factors quite highly).  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf2 <- df %>% \n    select(-item7,-item3)\n```\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-8' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  assess factorability</button></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\n\nAs before we removed items 3 and 7, these all look fine:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncortest.bartlett(cor(df2), n = nrow(df2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$chisq\n[1] 2516\n\n$p.value\n[1] 0\n\n$df\n[1] 91\n```\n:::\n\n```{.r .cell-code}\nKMO(cor(df2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cor(df2))\nOverall MSA =  0.88\nMSA for each item = \n item1  item2  item4  item5  item6  item8  item9 item10 item11 item12 item13 \n  0.90   0.92   0.88   0.91   0.87   0.91   0.85   0.89   0.89   0.91   0.92 \nitem14 item15 item16 \n  0.86   0.89   0.90 \n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-9' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  how many factors?</button></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\nBoth parallel analysis and MAP suggest 2:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfa.parallel(df2, fa = 'fa')\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n```\n:::\n\n```{.r .cell-code}\nVSS(df2)\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-20-2.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.73  with  3  factors\nVSS complexity 2 achieves a maximimum of 0.83  with  8  factors\n\nThe Velicer MAP achieves a minimum of 0.01  with  2  factors \nBIC achieves a minimum of  -342  with  2  factors\nSample Size adjusted BIC achieves a minimum of  -139  with  2  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq     prob sqresid  fit RMSEA  BIC SABIC complex\n1 0.62 0.00 0.046  77 983.7 2.8e-157    10.9 0.62 0.138  489   733     1.0\n2 0.73 0.81 0.015  64  69.6  2.9e-01     5.6 0.81 0.012 -342  -139     1.1\n3 0.73 0.80 0.024  52  51.3  5.0e-01     5.3 0.81 0.000 -283  -118     1.2\n4 0.71 0.81 0.039  41  34.4  7.6e-01     4.7 0.84 0.000 -229   -99     1.2\n5 0.67 0.81 0.056  31  21.9  8.9e-01     4.3 0.85 0.000 -177   -79     1.3\n6 0.64 0.81 0.075  22  13.5  9.2e-01     3.9 0.86 0.000 -128   -58     1.3\n7 0.71 0.82 0.100  14   4.9  9.9e-01     4.0 0.86 0.000  -85   -41     1.4\n8 0.64 0.83 0.149   7   2.3  9.4e-01     3.4 0.88 0.000  -43   -20     1.5\n   eChisq   SRMR eCRMS eBIC\n1 1857.56 0.1283 0.139 1362\n2   50.68 0.0212 0.025 -361\n3   34.68 0.0175 0.023 -300\n4   21.55 0.0138 0.021 -242\n5   12.82 0.0107 0.018 -186\n6    6.65 0.0077 0.016 -135\n7    2.50 0.0047 0.012  -88\n8    0.88 0.0028 0.010  -44\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-10' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  conduct and inspect EFA</button></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npgmod2 <- fa(df2, nfactors = 2, rotate = \"oblimin\", fm = \"minres\")\npgmod2$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nLoadings:\n       MR1    MR2   \nitem1   0.438       \nitem2   0.531       \nitem4   0.743       \nitem5   0.431 -0.113\nitem6   0.806       \nitem8   0.564       \nitem9   0.837       \nitem10         0.676\nitem11         0.629\nitem12         0.408\nitem13         0.509\nitem14         0.766\nitem15         0.639\nitem16         0.593\n\n                 MR1   MR2\nSS loadings    2.894 2.644\nProportion Var 0.207 0.189\nCumulative Var 0.207 0.396\n```\n:::\n\n```{.r .cell-code}\nfa.sort(pgmod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFactor Analysis using method =  minres\nCall: fa(r = df2, nfactors = 2, rotate = \"oblimin\", fm = \"minres\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n         MR1   MR2   h2   u2 com\nitem9   0.84 -0.01 0.70 0.30 1.0\nitem6   0.81  0.00 0.65 0.35 1.0\nitem4   0.74  0.06 0.59 0.41 1.0\nitem8   0.56 -0.01 0.31 0.69 1.0\nitem2   0.53 -0.03 0.27 0.73 1.0\nitem1   0.44 -0.02 0.19 0.81 1.0\nitem5   0.43 -0.11 0.16 0.84 1.1\nitem14 -0.02  0.77 0.58 0.42 1.0\nitem10  0.02  0.68 0.47 0.53 1.0\nitem15 -0.02  0.64 0.40 0.60 1.0\nitem11 -0.03  0.63 0.38 0.62 1.0\nitem16  0.03  0.59 0.36 0.64 1.0\nitem13  0.08  0.51 0.29 0.71 1.0\nitem12  0.06  0.41 0.19 0.81 1.0\n\n                       MR1  MR2\nSS loadings           2.89 2.64\nProportion Var        0.21 0.19\nCumulative Var        0.21 0.40\nProportion Explained  0.52 0.48\nCumulative Proportion 0.52 1.00\n\n With factor correlations of \n     MR1  MR2\nMR1 1.00 0.35\nMR2 0.35 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  91  with the objective function =  4.1 with Chi Square =  2516\ndf of  the model are 64  and the objective function was  0.11 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  620 with the empirical chi square  50.7  with prob <  0.89 \nThe total n.obs was  620  with Likelihood Chi Square =  69.6  with prob <  0.29 \n\nTucker Lewis Index of factoring reliability =  0.997\nRMSEA index =  0.012  and the 90 % confidence intervals are  0 0.028\nBIC =  -342\nFit based upon off diagonal values = 0.99\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.93 0.91\nMultiple R square of scores with factors          0.87 0.83\nMinimum correlation of possible factor scores     0.75 0.66\n```\n:::\n:::\n\n\n- Both factors load on 3+ items at a salient level. \n- All items have a loading $>0.3$. \n- There are no Heywood cases.\n- No items have high loadings on multiple factors (complexity is low for all items)\n- The solution explains 40% of the variance.  \n\nThis looks much better!  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n::: {.callout-note collapse=\"true\"}\n#### Reliability \n\n<!-- parallel tests -->\n\n<!-- test-retest reliability   -->\n<!-- split-half reliability   -->\n<!-- cronbach's alpha   -->\n<!-- mcdonald's omega   -->\n<!-- inter-rater reliability   -->\n<!-- intra-class correlations!    -->\n<!-- - link back to MLM   -->\n\n<!-- attenuation for measurement error -->\n\n__Measurement Error & Reliability__  \n\nYou will often find research that foregoes the measurement model by taking a scale score (i.e., the sum or mean of a set of likert-type questions). For instance, think back to our exercises on path mediation, where \"Health Locus of Control\" was measured as the \"average score on a set of items relating to perceived control over ones own health\". In doing so, we make the assumption that these variables provide measurements of the underlying latent construct **without error**.  \nIn fact, if we think about it a little, in our simple regression framework $y = \\beta_0 + \\beta_1x_1 + ... + \\beta_kx_k + \\varepsilon$ all our predictor variables $x_1$ to $x_k$ are assumed to be measured without error - it is only our outcome $y$ that our model considers to have some randomness included (the $\\varepsilon$). This seems less problematic if our variables are representing something that is quite easily and reliably measured (time, weight, height, age, etc.), but it seems inappropriate when we are concerned with something more abstract. For instance, two people both scoring 11 on the Generalised Anxiety Disorder 7 (GAD-7) scale does not necessarily mean that they have _identical_ levels of anxiety.  \n  \nThe inconsistency with which an observed variable reflects the underlying construct that we consider it to be measuring is termed the *reliability*.  \n\n:::frame\n**Reliability: A silly example** \n\nSuppose I'm trying to weigh [my dog](https://photos.app.goo.gl/f26FrRDyJxTvXvGS9). I have a set of scales, and I put him on the scales. He weighs in at 13.53kg. \nI immediately do it again, and the scales this time say 13.41kg. I do it again. 13.51kg, and again, 13.60kg. \nWhat is happening? Is Dougal's weight (Dougal is the dog, by the way) randomly fluctuating by 100g? Or are my scales just a bit inconsistent, and my observations contain measurement error?  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nI take him to the vets, where they have a much better set of weighing scales, and I do the same thing (measure him 4 times). The weights are 13.47, 13.49, 13.48, 13.48.  \nThe scales at the vets are clearly *more __reliable__*. We still don't know Dougal's *true* weight, but we are better informed to estimate it if we go on the measurements from the scales at the vet.^[Of course this all assuming that the scales aren't completely miscalibrated] \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=80%}\n:::\n:::\n\n:::\n\nAnother way to think about reliability is to consider the idea that more error means less reliability: \n$$\\text{observations = truth + error}$$  \n\n\nThere are different types of reliability:  \n\n- **test re-test reliability:** correlation between values over repeated measurements. \n- **alternate-form reliability:** correlation between scores on different forms/versions of a test (we might want different versions to avoid practice effects). \n- **Inter-rater reliability:** correlation between values obtained from different raters. \n- **split-half reliability:** correlation between scores of two equally sized subsets of items. \n\nThe form of reliability we are going to be most concerned with here is known as **Internal Consistency**. This is the extent to which items within a scale are correlated with one another. There are two main measures of this:\n\n  \n\n__Alpha & Omega__  \n\n**Cronbach's $\\alpha$** ranges from 0 to 1 (higher is better). You can get this using the `alpha()` function from the **psych** package. The formula is:\n\n$$\n\\begin{aligned}\n\\text{Cronbach's } \\alpha &= \\frac{n \\cdot \\overline{cov(ij)}}{\\overline{\\sigma^2_i} + (n-1) \\cdot \\overline{cov(ij)}}  \\\\\n\\\\\n\\text{where}:  & \\qquad\n& n = \\text{number of items} \\\\\n& \\overline{cov(ij)} = \\text{average covariance between item-pairs}  \\\\\n& \\overline{\\sigma^2_i} = \\text{average item variance}  \\\\\n\\end{aligned}\n$$\n\n**McDonald's Omega ($\\omega$)** is substantially more complicated, but avoids the limitation that Cronbach's alpha which assumes that all items are equally related to the construct. You can get it using the `omega()` function from the **psych** package. If you want more info about it then the help docs (`?omega()`) are a good place to start. \n\n:::\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\nUsing the relevant function, obtain alpha for the set of items in each factor from your final factor analysis model of low mood. \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-11' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\nThe first factor has high loadings for items 1 to 9 (we have excluded 3 and 7). \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnames(df2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"item1\"  \"item2\"  \"item4\"  \"item5\"  \"item6\"  \"item8\"  \"item9\"  \"item10\"\n [9] \"item11\" \"item12\" \"item13\" \"item14\" \"item15\" \"item16\"\n```\n:::\n\n```{.r .cell-code}\nalpha(select(df2, item1:item9))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nReliability analysis   \nCall: alpha(x = select(df2, item1:item9))\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.82      0.81     0.8      0.37 4.2 0.01    4 0.98     0.35\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.79  0.82  0.84\nDuhachek  0.80  0.82  0.84\n\n Reliability if an item is dropped:\n      raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nitem1      0.82      0.81    0.80      0.41 4.2    0.010 0.022  0.43\nitem2      0.81      0.79    0.78      0.39 3.9    0.011 0.024  0.35\nitem4      0.77      0.76    0.75      0.35 3.2    0.013 0.016  0.31\nitem5      0.82      0.81    0.80      0.42 4.3    0.010 0.020  0.43\nitem6      0.76      0.75    0.74      0.34 3.0    0.013 0.015  0.30\nitem8      0.80      0.79    0.78      0.38 3.8    0.011 0.023  0.35\nitem9      0.76      0.75    0.73      0.33 3.0    0.014 0.014  0.30\n\n Item statistics \n        n raw.r std.r r.cor r.drop mean  sd\nitem1 620  0.54  0.57  0.44   0.40  4.0 1.1\nitem2 620  0.61  0.63  0.52   0.48  4.0 1.2\nitem4 620  0.79  0.77  0.75   0.68  4.0 1.5\nitem5 620  0.50  0.54  0.40   0.36  4.0 1.1\nitem6 620  0.83  0.80  0.79   0.72  4.1 1.7\nitem8 620  0.64  0.65  0.56   0.51  4.0 1.2\nitem9 620  0.85  0.82  0.82   0.74  3.9 1.8\n\nNon missing response frequency for each item\n         1    2    3    4    5    6    7 miss\nitem1 0.01 0.07 0.26 0.33 0.23 0.08 0.01    0\nitem2 0.02 0.09 0.22 0.34 0.23 0.09 0.02    0\nitem4 0.06 0.10 0.20 0.28 0.20 0.11 0.06    0\nitem5 0.01 0.07 0.24 0.36 0.24 0.06 0.01    0\nitem6 0.07 0.12 0.17 0.22 0.21 0.13 0.08    0\nitem8 0.02 0.09 0.23 0.30 0.27 0.07 0.02    0\nitem9 0.13 0.12 0.15 0.20 0.17 0.14 0.10    0\n```\n:::\n\n```{.r .cell-code}\nalpha(select(df2, item10:item16))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nReliability analysis   \nCall: alpha(x = select(df2, item10:item16))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n      0.81       0.8    0.78      0.37 4.1 0.012    4 0.89     0.37\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.78  0.81  0.83\nDuhachek  0.78  0.81  0.83\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nitem10      0.77      0.77    0.74      0.35 3.3    0.014 0.0072  0.35\nitem11      0.78      0.78    0.75      0.37 3.5    0.013 0.0085  0.37\nitem12      0.81      0.80    0.78      0.41 4.1    0.012 0.0035  0.41\nitem13      0.79      0.79    0.76      0.38 3.7    0.013 0.0077  0.41\nitem14      0.76      0.75    0.72      0.34 3.1    0.015 0.0045  0.35\nitem15      0.78      0.77    0.75      0.36 3.4    0.013 0.0072  0.35\nitem16      0.78      0.78    0.75      0.37 3.5    0.013 0.0077  0.37\n\n Item statistics \n         n raw.r std.r r.cor r.drop mean  sd\nitem10 620  0.74  0.73  0.67   0.61  4.0 1.4\nitem11 620  0.69  0.69  0.61   0.55  4.0 1.3\nitem12 620  0.54  0.56  0.43   0.38  4.0 1.2\nitem13 620  0.62  0.63  0.53   0.48  3.9 1.2\nitem14 620  0.79  0.77  0.74   0.66  3.9 1.5\nitem15 620  0.69  0.69  0.62   0.56  4.0 1.3\nitem16 620  0.67  0.67  0.60   0.54  4.0 1.2\n\nNon missing response frequency for each item\n          1    2    3    4    5    6    7 miss\nitem10 0.04 0.10 0.22 0.27 0.24 0.08 0.04    0\nitem11 0.04 0.08 0.19 0.33 0.24 0.10 0.03    0\nitem12 0.01 0.09 0.24 0.32 0.25 0.08 0.01    0\nitem13 0.03 0.08 0.25 0.35 0.19 0.10 0.01    0\nitem14 0.06 0.11 0.22 0.27 0.20 0.10 0.05    0\nitem15 0.03 0.10 0.24 0.31 0.20 0.10 0.03    0\nitem16 0.02 0.09 0.23 0.30 0.25 0.08 0.01    0\n```\n:::\n:::\n\n:::int\nCronbach's $\\alpha$ of 0.82 and 0.81 for the two factors and suggests high internal consistency. \n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<!-- :::frame -->\n<!-- You can't test the structural model if the measurement model is bad -->\n\n<!-- if you test the relationships between a set of latent factors, and they are not reliably measured by the observed items, then this error propagates up to influence the fit of the model.   -->\n<!-- To test the measurement model, it is typical to *saturate* the structural model (i.e., allow all the latent variables to correlate with one another). This way any misfit is due to the measurement model.   -->\n\n<!-- ::: -->\n\n<!-- what can we __do__ with this knowledge?   -->\n<!-- attenuation due to measurement error -->\n<br>\n\n# Replicability \n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\nSplit the dataset in half, and assess the replicability of your factor structure of low mood by examining the factor congruence in scores on each subset of the data. \n\n__Hint:__ see the lectures! \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-12' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nset1 <- df2 %>%\n  sample_frac(.5) # randomly select one half\nset2 <- anti_join(df2, set1) # select the non-matching cases\n\nres1 <- fa(set1, nfactors = 2, rotate = \"oblimin\")\nres2 <- fa(set2, nfactors = 2, rotate = \"oblimin\")\nfa.congruence(res1, res2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      MR1 MR2\nMR1  0.99   0\nMR2 -0.01   1\n```\n:::\n:::\n\n\nWe can see there is a high level of factor congruence across the two subsets of data.  \n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n# Factor Scores\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\nExtract the factor scores for each factor of low-mood from your model, and attach them to original dataset (the one which has information on pet ownership).  \nThen, conduct a $t$-test to examine whether the pet-owners differ from non-pet-owners in their levels of each factor of low mood.  \n\nAs a bonus, can you come up with some description of the two factors? you will have to look back to what the items represent (i.e. the questions that each item is asking. \n\n::: {.callout-note collapse=\"true\"}\n#### reminder of questions\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"aioomaxdhf\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#aioomaxdhf table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#aioomaxdhf thead, #aioomaxdhf tbody, #aioomaxdhf tfoot, #aioomaxdhf tr, #aioomaxdhf td, #aioomaxdhf th {\n  border-style: none;\n}\n\n#aioomaxdhf p {\n  margin: 0;\n  padding: 0;\n}\n\n#aioomaxdhf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#aioomaxdhf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#aioomaxdhf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#aioomaxdhf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#aioomaxdhf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#aioomaxdhf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#aioomaxdhf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#aioomaxdhf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#aioomaxdhf .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#aioomaxdhf .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#aioomaxdhf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#aioomaxdhf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#aioomaxdhf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#aioomaxdhf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#aioomaxdhf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#aioomaxdhf .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#aioomaxdhf .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#aioomaxdhf .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#aioomaxdhf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#aioomaxdhf .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#aioomaxdhf .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#aioomaxdhf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#aioomaxdhf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#aioomaxdhf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#aioomaxdhf .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#aioomaxdhf .gt_left {\n  text-align: left;\n}\n\n#aioomaxdhf .gt_center {\n  text-align: center;\n}\n\n#aioomaxdhf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#aioomaxdhf .gt_font_normal {\n  font-weight: normal;\n}\n\n#aioomaxdhf .gt_font_bold {\n  font-weight: bold;\n}\n\n#aioomaxdhf .gt_font_italic {\n  font-style: italic;\n}\n\n#aioomaxdhf .gt_super {\n  font-size: 65%;\n}\n\n#aioomaxdhf .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#aioomaxdhf .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#aioomaxdhf .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#aioomaxdhf .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#aioomaxdhf .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#aioomaxdhf .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#aioomaxdhf .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"QuestionNumber\">QuestionNumber</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Over the last 2 weeks, how much have you had/have you been...\">Over the last 2 weeks, how much have you had/have you been...</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item1</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Little interest or pleasure in doing things?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item2</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Feeling down, depressed, or hopeless?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item3</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">~~Trouble falling or staying asleep, or sleeping too much?~~</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item4</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Feeling tired or having little energy?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item5</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Poor appetite or overeating?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item6</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Feeling bad about yourself - or that you are a failure or have let yourself or your family down?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item7</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">~~Reading the newspaper or watching television?~~</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item8</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Moving or speaking so slowly that other people could have noticed? Or the opposite - being so fidgety or restless that you have been moving around a lot more than usual?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item9</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">A lack of motivation to do anything at all?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item10</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Feeling nervous, anxious or on edge?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item11</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Not being able to stop or control worrying?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item12</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Worrying too much about different things?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item13</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Trouble relaxing?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item14</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Being so restless that it is hard to sit still?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item15</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Becoming easily annoyed or irritable?</td></tr>\n    <tr><td headers=\"QuestionNumber\" class=\"gt_row gt_left\">item16</td>\n<td headers=\"Over the last 2 weeks, how much have you had/have you been...\" class=\"gt_row gt_left\">Feeling afraid as if something awful might happen?</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-13' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-13', 'sol-start-13')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-13\" style=\"display: none;\">\n\n\n\nIt looks like all the items 1-9 (excluding items 3 and 7, which aren't in our factor model in the end) are all about lower mood or lack of energy - i.e. 'depression'.  \nThe latter items that load onto the second factor (items 10-16) all seem related to 'anxiety'.  \n\nSo we can use the estimated factor scores as a representation of peoples' relative standings on those underlying latent variables of 'depression' and 'anxiety', and we can then look at whether people who own a pet significantly differ on those two constructs from those who don't own a pet!  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npgpets <- \n  pgpets %>% \n    mutate(\n      depression = pgmod2$scores[,1],\n      anxiety = pgmod2$scores[,2],\n      pet = factor(do_you_own_a_pet)\n    )\n\nt.test(pgpets$depression ~ pgpets$pet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  pgpets$depression by pgpets$pet\nt = 1, df = 600, p-value = 0.3\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.0691  0.2273\nsample estimates:\nmean in group 0 mean in group 1 \n         0.0375         -0.0416 \n```\n:::\n\n```{.r .cell-code}\nggplot(pgpets, aes(x=pet, y=depression))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=80%}\n:::\n\n```{.r .cell-code}\nt.test(pgpets$anxiety~pgpets$pet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  pgpets$anxiety by pgpets$pet\nt = 4, df = 597, p-value = 0.00004\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 0.159 0.444\nsample estimates:\nmean in group 0 mean in group 1 \n          0.143          -0.158 \n```\n:::\n\n```{.r .cell-code}\nggplot(pgpets, aes(x=pet, y=anxiety))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](11_efa2_files/figure-html/unnamed-chunk-27-2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>",
    "supporting": [
      "11_efa2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/panelset-0.2.6/panelset.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/panelset-0.2.6/panelset.js\"></script>\r\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}