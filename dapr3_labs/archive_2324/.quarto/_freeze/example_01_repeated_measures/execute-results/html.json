{
  "hash": "9020a75020e8bce387aa1bd33563b9f9",
  "result": {
    "markdown": "---\ntitle: 'Analysis Walkthrough 1'\ncode-fold: true\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\n---\n\n\n\n\n:::frame\n\nEach of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:  \n\n  - First the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated. \n  - Second, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\n  - Then, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in **lme4**. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals. \n  - Finally, we visualize and interpret our analysis.\n  \nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email [ppls.psych.stats@ed.ac.uk](mailto:ppls.psych.stats@ed.ac.uk). \n\n:::\n\n# Overview\n\n:::frame\nThese data are simulated to represent data from a fake experiment, in which participants were asked to drive around a route in a 30mph zone. Each participant completed the route 3 times (i.e. \"repeated measures\"), but each time they were listening to different audio (either speech, classical music or rap music). Their average speed across the route was recorded. \nThis is a fairly simple design, that we might use to ask \"how is the type of audio being listened to associated with driving speeds?\" \n\nThe data are available at [https://uoepsy.github.io/data/drivingmusicwithin.csv](https://uoepsy.github.io/data/drivingmusicwithin.csv).  \n:::\n\nThe design here is a 'repeated measures' design. The idea behind \"repeated measures\" is that the same variable is measured on the same set of subjects over two or more time periods or under different conditions. You might easily think of a question and design in which the 3 music conditions are instead 3 time points (e.g. age 60, 70, and 80). \n\n\n::: {.callout-note collapse=\"true\"}\n#### How we simulated the data\n\nThis is a very simple way to simulate repeated measures data structure (with long data). There are a good number of other approaches, but this will do for now as you may well be familiar with all the functions involved: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(347)\nlibrary(tidyverse)\nsimRPT <- tibble(\n  pid = factor(rep(paste(\"ID\", 1:50, sep=\"\"),each=3)),\n  ppt_int = rep(rnorm(50,0,5),each=3), # some participant-level random intercepts\n  speed = rnorm(150,c(29,34,30),sd=4) + ppt_int,\n  music = factor(rep(c(\"rap\", \"classical\", \"speech\"), each=1, 50))\n) %>% select(-ppt_int)\n```\n:::\n\n\n:::rtip\nIf you are unclear about any section of the code above, why not try running small bits of it in your console to see what it is doing?   \nFor instance, try running:\n\n- `paste(\"ID\", 1:50, sep=\"\")`  \n- `rep(paste(\"ID\", 1:50, sep=\"\"),each=3)`  \n- `factor(rep(paste(\"ID\", 1:50, sep=\"\"),each=3))`  \n\n:::\n\n:::\n\n\n# Data Wrangling\n\nBecause we simulated our data, it is already nice and tidy. Each observation is a row, and we have variable indicating participant id (`pid`).  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(simRPT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  pid   speed music    \n  <fct> <dbl> <fct>    \n1 ID1    29.4 rap      \n2 ID1    29.9 classical\n3 ID1    27.2 speech   \n4 ID2    21.1 rap      \n5 ID2    29.1 classical\n6 ID2    25.1 speech   \n```\n:::\n:::\n\n\n# Descriptives\nLet' see our summaries per time-point:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumRPT <- \n  simRPT %>%\n  group_by(music) %>%\n  summarise(\n    n = n_distinct(pid),\n    mean.speed = round(mean(speed, na.rm=T),2),\n    sd.speed = round(sd(speed, na.rm=T),2)\n    )\nsumRPT\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  music         n mean.speed sd.speed\n  <fct>     <int>      <dbl>    <dbl>\n1 classical    50       34.2     5.16\n2 rap          50       28.5     6.05\n3 speech       50       29.0     6.19\n```\n:::\n:::\n\nWe can make this a little prettier:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nkable(sumRPT) %>%\n  kable_styling(\"striped\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> music </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> mean.speed </th>\n   <th style=\"text-align:right;\"> sd.speed </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> classical </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 34.25 </td>\n   <td style=\"text-align:right;\"> 5.16 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rap </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 28.46 </td>\n   <td style=\"text-align:right;\"> 6.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> speech </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 29.04 </td>\n   <td style=\"text-align:right;\"> 6.19 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWell...we knew what the answer was going to be (because we simulated it), but there we have it - the speeds are highest for classical music, and lowest for rap.  \n\n# Visualizations\nWe can construct some simple plots showing distribution of the outcome variable (speed) at each level of the independent variable (music): \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT %>% \n  ggplot(aes(x = music, y = speed)) + \n  geom_violin() + \n  geom_jitter(alpha=.5,width=.1,height=0) + \n  labs(x=\"Audio\", y = \"Speed (mph)\", \n       title=\"Speeds while listening to different audio\", \n       subtitle = \"Violin Plots with (jittered) Observations\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSo what does this show? Essentially we are plotting all speeds in each condition. The points are `jittered` so that they are not all overlaid on one another. The areas marked at each condition are mirrored density plots (i.e. they show the distribution of the speeds in each condition). \n\nIf you want to get an intuitive sense of these plotted areas, look at them against the mean's and sd's per condition calculated above.\n\nWe can also show each participants' specific changes between conditions, by using the `group` aesthetic mapping.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT %>%\n  ggplot(aes(x = music, y = speed)) +\n  geom_point(size=3, alpha=.4)+\n  geom_line(aes(group=pid), alpha = .2) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n# Analysis\n\n## Equations\nWe're going to fit the model below, and examine the change in speed associated with moving from speech (our reference level) to both classical, and rap conditions.   \nRecall that because `music` is categorical with 3 levels, we're going to be estimating 2 ($3-1$) coefficients.  \n\n\n\\begin{aligned}\n&\\text{for trial }j \\text{ from participant } i \\\\\n  \\operatorname{speed}_{i[j]} =& \\beta_{0i} + \\beta_1(\\operatorname{music}_{\\operatorname{classical}_j}) + \\beta_2(\\operatorname{music}_{\\operatorname{rap}_j}) + \\varepsilon_{i[j]} \\\\\n    \\beta_{0i} =& \\gamma_{00} + \\zeta_{0i} \\\\ \n\\end{aligned}\n\n\n\n## Fitting the models\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\n```\n:::\n\n\nHere we run an empty model so that we have something to compare our model which includes our independent variable. Other than to give us a reference model, we do not have a huge amount of interest in this. It includes no predictors, but a random intercept by participant (`pid`) to take account of the fact we have three measurements per person. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm0 <- lmer(speed ~ 1 + (1 | pid), data = simRPT)\n```\n:::\n\n\nNext, add a fixed effect of our predictor (music condition, `music`). \nFirst though, we'll want to re-level it so that \"speech\" is the reference level (because that's what we said we wanted). \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimRPT <-\n  simRPT %>%\n  mutate(\n    music = fct_relevel(factor(music), \"speech\")\n  )\n\nm1 <- lmer(speed ~ 1 + music + (1 | pid), data = simRPT)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: speed ~ 1 + music + (1 | pid)\n   Data: simRPT\n\nREML criterion at convergence: 895.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.47567 -0.56300 -0.01549  0.54691  2.42387 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n pid      (Intercept) 20.32    4.508   \n Residual             13.54    3.679   \nNumber of obs: 150, groups:  pid, 50\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     29.0408     0.8229  35.290\nmusicclassical   5.2048     0.7358   7.073\nmusicrap        -0.5858     0.7358  -0.796\n\nCorrelation of Fixed Effects:\n            (Intr) msccls\nmusicclsscl -0.447       \nmusicrap    -0.447  0.500\n```\n:::\n:::\n\n\nAnd we can compare our models. A Kenward-Rogers F ratio suggests that we appear to have a significant differences in speeds between conditions. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pbkrtest)\nKRmodcomp(m1, m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlarge : speed ~ 1 + music + (1 | pid)\nsmall : speed ~ 1 + (1 | pid)\n       stat   ndf   ddf F.scaling   p.value    \nFtest 37.53  2.00 98.00         1 7.913e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\n<!-- ::: {.callout-note collapse=\"true\"} -->\n<!-- #### Comparison to `aov()` -->\n\n<!-- Using `anova()` to compare multilevel models will not give you a typical ANOVA output.   -->\n<!-- For piece of mind, it can be useful to compare how we might do this in `aov()` -->\n\n<!-- ```{r} -->\n<!-- m2 <- aov(speed ~ music + Error(pid), data = simRPT) -->\n<!-- ``` -->\n\n<!-- Here the term `Error(pid)` is specifying the within person error, or residual. This is what we are doing with our random effect `(1 | pid)` in `lmer()` -->\n\n<!-- And we can compare the model sums of squares from both approaches to see the equivalence: -->\n\n<!-- ```{r} -->\n<!-- summary(m2) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- anova(m1) -->\n<!-- ``` -->\n<!-- ::: -->\n\n\n## Check model\n\nThe residuals look reasonably normally distributed, and there seems to be fairly constant variance across the linear predictor. We might be a little concerned about the potential tails of the plot below, at which residuals don't appear to have a mean of zero\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(m1, type = c(\"p\",\"smooth\"))\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nlibrary(lattice)\nqqmath(m1)\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-11-2.png){fig-align='center' width=672}\n:::\n:::\n\nRandom effects are (roughly) normally distributed:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrans <- as.data.frame(ranef(m1)$pid)\nggplot(rans, aes(sample = `(Intercept)`)) + \n  stat_qq() + stat_qq_line() +\n  labs(title=\"random intercept\")\n```\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Visualise Model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sjPlot)\nplot_model(m1, type=\"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$music\n```\n:::\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\ndotplot.ranef.mer(ranef(m1)) # an alternative: plot_model(m1, type=\"re\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pid\n```\n:::\n\n::: {.cell-output-display}\n![](example_01_repeated_measures_files/figure-html/unnamed-chunk-13-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Interpret model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(parameters)\nmodel_parameters(m1, ci_method = \"kr\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Fixed Effects\n\nParameter         | Coefficient |   SE |         95% CI |     t |    df |      p\n--------------------------------------------------------------------------------\n(Intercept)       |       29.04 | 0.82 | [27.40, 30.68] | 35.29 | 85.44 | < .001\nmusic [classical] |        5.20 | 0.74 | [ 3.74,  6.66] |  7.07 | 98.00 | < .001\nmusic [rap]       |       -0.59 | 0.74 | [-2.05,  0.87] | -0.80 | 98.00 | 0.428 \n\n# Random Effects\n\nParameter           | Coefficient |   SE |       95% CI\n-------------------------------------------------------\nSD (Intercept: pid) |        4.51 | 0.56 | [3.53, 5.75]\nSD (Residual)       |        3.68 | 0.26 | [3.20, 4.23]\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nA very quick (bare-bones) write-up:  \n\n:::int\n\nAverage driving speeds (mph) across audio conditions was modeled using a linear mixed effects model, with a fixed effect of condition (speech/rap/classical, treatment coded with 'speech' as the reference level) and a by-participant random intercepts. The model was fitted using in Rv4.3.0 using the lme4 package with the default optimiser. Confidence intervals and p-values were obtained using the Kenward-Rogers approximation for denominator degrees of freedom. \n\nResults show a significant difference in driving speeds between audio conditions ($F(2,98)=37.5304157, p< 0.05$). Specifically, relative to the speech condition (in which the estimated driving speed was 29.04mph), listening to classical music was associated with increased driving speeds of 5.2mph ($\\beta=5.2,SE=0.74,t(98)=7.07,p<0.05$). There was no significant difference between speech and rap ($\\beta=-0.59,SE=0.74,p= 0.428$). Participant-level variation in driving speeds was estimated to have a standard deviation of 4.51mph. The pattern of results are shown in @fig-finplot\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Driving speeds across different audio-conditions. Grey indicates raw data (grouped by participant), and red points show model estimated speed for each condition with 95% confidence intervals](example_01_repeated_measures_files/figure-html/fig-finplot-1.png){#fig-finplot fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n:::\n\n",
    "supporting": [
      "example_01_repeated_measures_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}