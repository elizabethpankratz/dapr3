{"title":"3. Assumptions and Diagnostics | Centering","markdown":{"yaml":{"title":"3. Assumptions and Diagnostics | Centering","params":{"SHOW_SOLS":true,"TOGGLE":true}},"headingText":"Exercises: Assumptions & Diagnostics","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(effects)\nlibrary(knitr)\nlibrary(kableExtra)\n```\n\n\n\n:::frame\n__Data: Wellbeing Across Scotland__  \n\nFor these next set of exercises we continue with our recurring study in which researchers want to look at the relationship between time spent outdoors and mental wellbeing, across all of Scotland. Data is collected from 20 of the Local Authority Areas and is accessible at [https://uoepsy.github.io/data/LAAwellbeing.csv](https://uoepsy.github.io/data/LAAwellbeing.csv).  \n```{r echo=FALSE, message=FALSE,warning=FALSE}\nlibrary(gt)\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\ntibble(variable=names(scotmw),\n       description=c(\"Participant ID\",\"Participant Name\",\"Local Authority Area\",\"Self report estimated number of hours per week spent outdoors\",\"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\",\"LAA Population Density (people per square km)\")\n) %>% gt()\n```\n:::\n\n`r qbegin(\"1\")`\nThe code below will read in the data and fit the model with by-LAA random intercepts and slopes of outdoor time. \n```{r message=F,warning=F}\nlibrary(tidyverse)\nlibrary(lme4)\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\nrs_model <- lmer(wellbeing ~ 1 + outdoor_time + (1 + outdoor_time | laa), data = scotmw)\n```\n\n1. Plot the residuals vs fitted values, and assess the extend to which the assumption holds that the residuals are zero mean.\n2. Construct a scale-location plot. This is where the square-root of the absolute value of the standardised residuals is plotted against the fitted values, and allows you to more easily assess the assumption of constant variance. \n  - Optional: can you create the same plot using ggplot, starting with the `augment()` function from the __broom.mixed__ package?  \n  \n::: {.callout-tip collapse=\"true\"}\n#### Hints\n`plot(model)` will give you this plot, but you might want to play with the `type = c(......)` argument to get the smoothing line\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nplot(rs_model, type=c(\"p\",\"smooth\"))\n```\nAs we can see, the mean value of the residuals is quite close to zero, right the way across the fitted values. This is good. \n\n::: {.callout-note}\nTo change labels for the x and y axes, add the following arguments to the plot() function:\n\n- `xlab = \"Fitted values\"`\n- `ylab = \"Residuals\"`\n:::\n\n```{r}\nplot(rs_model,\n     form = sqrt(abs(resid(.))) ~ fitted(.),\n     type = c(\"p\",\"smooth\"))\n```\n\nIn this plot we can see that the variance of the residuals is fairly constant across the fitted values. There is a slight dip at the lower end. We can see this in the previous plot too - all the points at the LHS of the plot are slightly more tightly grouped around the line. This is not enough to worry me, personally.  \n\n```{r}\nlibrary(broom.mixed)\naugment(rs_model) %>%\n  mutate(\n    sqrtr = sqrt(abs(.resid))\n  ) %>%\n  ggplot(aes(x=.fitted, y=sqrtr)) + \n  geom_point() +\n  geom_smooth()\n```\n\n::: {.callout-note}\nTo remove the confidence bands (in grey) from the smoothed line, you can change the last command to:\n\n`geom_smooth(se = FALSE)`\n:::\n\n`r solend()`\n\n\n`r qbegin(\"2\")`\nExamine the normality of both the level 1 and level 2 residuals.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n  - Use `hist()` if you like, or `qqnorm(residuals)` followed by `qqline(residuals)`\n  - Extracting the level 2 residuals (the random effects) can be difficult. `ranef(model)` will get you some of the way.\n  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n__Level 1__  \n\n```{r}\nhist(resid(rs_model))\nqqnorm(resid(rs_model))\nqqline(resid(rs_model))\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n\n__Indexing random effects__  \n\nThe output of `ranef()` is a type of data container called \"list\". The list includes different named slots and you can find the names as follows: \n\n```{r}\nnames(ranef(rs_model))\n```\n\nYou have a named slot for each group in your lmer specification. In this case, we only specified `laa` as grouping. To access the random effects for the specific group, type `ranef(model)` followed by `$groupname`\n\n```{r}\nranef(rs_model)$laa\n```\n\nYou will have multiple columns, one for each random effect.\n\nYou can get the random intercepts by laa, by selecting the first column as follows:\n\n```{r}\nranef(rs_model)$laa[, 1]\n```\n\nRespectively, for the random slopes by laa, you select the second column as follows:\n\n```{r}\nranef(rs_model)$laa[, 2]\n```\n\n:::\n\n\n__Level 2__  \n```{r}\nqqnorm(ranef(rs_model)$laa[, 1], main = \"Random intercept\")\nqqline(ranef(rs_model)$laa[, 1])\n\nqqnorm(ranef(rs_model)$laa[, 2], main = \"Random slope\")\nqqline(ranef(rs_model)$laa[, 2])\n```\n\nThe normality of the residuals at both levels looks pretty decent here. This is especially good given that we only actually have 20 clusters (the LAAs). We have quite a small sample at this level.  \n\n`r solend()`\n\n\n\n`r qbegin(\"3\")`\n1. Which person in the dataset has the greatest influence on our model?  \n2. For which person is the model fit the worst (i.e., who has the highest residual?)\n3. Which _LAA_ has the greatest influence on our model?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- as well as `hlm_influence()` in the __HLMdiag__ package there is another nice function, `hlm_augment()`\n- we can often end up in confusion because the $i^{th}$ observation inputted to our model (and therefore the $i^{th}$ observation of `hlm_influence()` output) **might not be** the $i^{th}$ observation in our original dataset - there may be missing data! (Luckily, we have no missing data in this dataset). \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(HLMdiag)\nl1_inf <- hlm_influence(rs_model,level=1)\ndotplot_diag(l1_inf$cooksd, cutoff=\"internal\")+\n  ylim(0,.15)\n```\nGreatest influence:\n```{r}\nhlm_augment(rs_model, level=1) %>% arrange(desc(cooksd))\nscotmw[74, ]\n```\n```{r}\n#| echo: false\n#| out-width: \"100px\"\n#| fig-align: \"center\"\nknitr::include_graphics(\"images/intro/willie.jpg\")\n```\n\nHighest residual: \n```{r}\nhlm_augment(rs_model, level=1) %>% arrange(desc(abs(.resid)))\nscotmw[64, ]\n```\n\nMost influential LAA: \n```{r}\nhlm_augment(rs_model, level=\"laa\") %>% arrange(desc(cooksd))\n```\n\n`r solend()`\n\n\n`r qbegin(\"4\")`\n\n1. Looking at the random effects, which LAA shows the least benefit to wellbeing as outdoor time increases, and which shows the greatest benefit?  \n2. What is the estimated wellbeing for people from City of Edinburgh with zero hours of outdoor time per week, and what is their associated increases in wellbeing for every hour per week increase in outdoor time?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nIt looks like the residents of Midlothian have the least improvement, and the Western Isles (Na h-Eileanan Siar) show the most increases of wellbeing with outdoor time. We can see this from the LAA-random slopes of outdoor time:  \n```{r}\nranef(rs_model)\n```\nWe can get the cluster-specific coefficients either by adding the `fixef()` and `ranef()` together, or using `coef()`:  \n```{r}\ncoef(rs_model)\n```\n```{r}\ncoef(rs_model)$laa[\"City of Edinburgh\",]\n```\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Exercises: Centering in the MLM\n\n\n::: {.callout-note collapse=\"true\"}\n## Centering & Scaling in LM\n\nWe have some data from a study investigating how perceived persuasiveness of a speaker is influenced by the rate at which they speak.  \n```{r}\ndap2 <- read_csv(\"https://uoepsy.github.io/data/dapr2_2122_report1.csv\")\n```\n\nWe can fit a simple linear regression (one predictor) to evaluate how speech rate (variable `sp_rate` in the dataset) influences perceived persuasiveness (variable `persuasive` in the dataset). There are various ways in which we can transform the predictor variable `sp_rate`, which in turn can alter the interpretation of some of our estimates:  \n\n:::panelset\n:::panel\n#### Raw X\n```{r}\nm1 <- lm(persuasive ~ sp_rate, data = dap2)\nsummary(m1)$coefficients\n```\n\nThe intercept and the coefficient for speech rate are interpreted as:  \n\n- `(Intercept)`: A audio clip of someone speaking at zero phones per second is estimated as having an average persuasive rating of `r coefficients(m1)[1] %>% round(.,2)`.  \n- `sp_rate`: For every increase of one phone per second, perceived persuasiveness is estimated to decrease by `r coefficients(m1)[2] %>% round(.,2)`.  \n\n:::\n:::panel\n#### Mean-Centered X\n\nWe can mean center our predictor and fit the model again: \n```{r}\ndap2 <- dap2 %>% mutate(sp_rate_mc = sp_rate - mean(sp_rate))\nm2 <- lm(persuasive ~ sp_rate_mc, data = dap2)\nsummary(m2)$coefficients\n```\n- `(Intercept)`: A audio clip of someone speaking at the __mean__ phones per second is estimated as having an average persuasive rating of `r coefficients(m2)[1] %>% round(.,2)`.  \n- `sp_rate_mc`: For every increase of one phone per second, perceived persuasiveness is estimated to decrease by `r coefficients(m2)[2] %>% round(.,2)`.  \n\n:::\n:::panel\n#### Standardised X\n\nWe can _standardise_ our predictor and fit the model yet again: \n\n```{r}\ndap2 <- dap2 %>% mutate(sp_rate_z = scale(sp_rate))\nm3 <- lm(persuasive ~ sp_rate_z, data = dap2)\nsummary(m3)$coefficients\n```\n- `(Intercept)`: A audio clip of someone speaking at the __mean__ phones per second is estimated as having an average persuasive rating of `r coefficients(m3)[1] %>% round(.,2)`.  \n- `sp_rate_z`: For every increase of one __standard deviation__ in phones per second, perceived persuasiveness is estimated to decrease by `r coefficients(m3)[2] %>% round(.,2)`. \n\nRemember that the `scale(sp_rate)` is subtracting the mean from each value, then dividing those by the standard deviation. \nThe standard deviation of `dap2$sp_rate` is:\n```{r}\nsd(dap2$sp_rate)\n```\nso in our variable `dap2$sp_rate_z`, a change of `r sd(dap2$sp_rate) %>% round(.,2)` gets scaled to be a change of 1 (because we are dividing by `sd(dap2$sp_rate)`).  \n```{r}\ncoef(m1)[2] * sd(dap2$sp_rate)\ncoef(m3)[2]\n```\n\n:::\n:::\n\nNote that these models are identical. When we conduct a model comparison between the 3 models, the residual sums of squares is identical for all models: \n```{r}\nanova(m1,m2,m3)\n```\n\nWhat changes when you center or scale a predictor in a standard regression model (one fitted with `lm()`)?  \n\n- The variance explained by the predictor remains exactly the same\n- The intercept will change to be the estimated mean outcome where that predictor is \"0\". Scaling and centering changes what \"0\" represents, thereby changing this estimate (the significance test will therefore also change because the intercept now has a different meaning)\n- The slope of the predictor will change according to any scaling (e.g. if you divide your predictor by 10, the slope will multiply by 10). \n- The **test** of the slope of the predictor remains exactly the same.  \n\n:::\n\n:::frame\n__Data: Hangry__\n\nThe study is interested in evaluating whether hunger influences peoples' levels of irritability (i.e., \"the hangry hypothesis\"), and whether this is different for people following a diet that includes fasting. 81 participants were recruited into the study. Once a week for 5 consecutive weeks, participants were asked to complete two questionnaires, one assessing their level of hunger, and one assessing their level of irritability. The time and day at which participants were assessed was at a randomly chosen hour between 7am and 7pm each week. 46 of the participants were following a five-two diet (five days of normal eating, 2 days of fasting), and the remaining 35 were following no specific diet.  \n\nThe data are available at: [https://uoepsy.github.io/data/hangry.csv](https://uoepsy.github.io/data/hangry.csv).  \n\n```{r}\n#| echo: false\nhangry<-read_csv(\"https://uoepsy.github.io/data/hangry.csv\") %>% mutate(fivetwo=factor(fivetwo))\ntibble(\n    variable = names(hangry),\n    description = c(\"Score on irritability questionnaire (0:100)\",\n                    \"Score on hunger questionnaire (0:100)\",\n                    \"Participant\",\n                    \"Whether the participant follows the five-two diet\")\n) %>% knitr::kable()\n```\n\n:::\n\n`r qbegin(1)`\nRead carefully the description of the study above, and try to write out (in `lmer` syntax) an appropriate model to test the research aims.  \ne.g.:  \n```{}\noutcome ~ explanatory variables + (???? | grouping)\n```\nTry to think about the maximal random effect structure (i.e. everything that can vary by-grouping is estimated as doing so). \n\nTo help you think through the steps to get from a description of a research study to a model specification, think about your answers to the following questions. \n\nQ: What is our outcome variable?  \nQ: What are our explanatory variables?  \nQ: Is there any grouping (or \"clustering\") of our data that we consider to be a random sample? If so, what are the groups?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- The research is looking at how hunger influences irritability, and whether this is different for people on the fivetwo diet.\n- We can split our data in to groups of each participant. We can also split it into groups of each diet. Which of these groups have we randomly sampled? Do we have a random sample of participants? Do we have a random sample of diets? Another way to think of this is \"if i repeated the experiment, what these groups be different?\"\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nOur outcome is irritability here, because it is the thing that we are trying to explain through peoples' hunger levels and diets.  \n\n```{r}\n#| eval: false\nlmer(irritability ~  explanatory variables + (???? | grouping))\n```\n\nWe are interested in the effect of hunger on irritability, and whether this effect is different for the five-two diet. \nSo we are interested in the interaction: \n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (???? | grouping))\n```\n(remember that `hunger + diet + hunger:diet` is just a more explicit way of writing `hunger*diet`). \n\nIf we did this experiment again, would we have different participants?  \nYes. If we did this experiment again, would we have different diets? No, because we're interested in the specific differences between the five-two diet and no dieting. This means we will likely want to by-participant random deviations (e.g. the `( ... | participant)` bit in `lmer`). But we won't have by-diet random effects `(1 | diet)` because the diet differences are the specific differences that we wish to test.  \n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (???? | participant))\n```\n\nThinking about what __can__ be modelled as randomly varying between participants, we have some options:\n\n1. participants vary in how irritable they are on average   \n(the intercept, `1 | participant`)\n2. participants vary in how much hunger influences their irritability   \n(the effect of hunger, `hunger | participant`)\n3. participants vary in how much diet influences irritability   \n(the effect of diet, `diet | participant`)\n4. participants vary in how much diet effects hunger's influence on irritability   \n(the interaction between diet and hunger, `diet:hunger | participant`)\n\nWe can vary 1 and 2, but not 3 and 4. This is because each participant is _either_ following the five-two diet _or_ they are not. So for a _single_ participant, we can't assess \"the effect diet has\" on anything, because we haven't seen that participant under different diets. if we try to plot a single participants' data, we can see that it is impossible for us to assess \"the effect of diet\":\n```{r}\n#| echo: false\n#| fig-height: 2.5\nhangry %>% filter(ppt == \"N1p2\") %>%\n    ggplot(., aes(x=fivetwo, y=q_irritability))+\n    geom_point()+\n    geom_smooth(method=\"lm\",se=F)+\n    scale_x_discrete(drop=FALSE)+\n  labs(title=\"The 'effect of diet' for a single\\nparticipant from the Hangry study\",subtitle=\"cannot be defined\")\n```\n\nBy contrast, we __can__ vary the intercept and the effect of hunger, because each participant has multiple values of irritability, and multiple different observations of hunger. We can think about a single participant's \"effect of hunger on irritability\" and how we might fit a line to their data:\n```{r}\n#| echo: false\n#| fig-height: 2.5\nhangry %>% filter(ppt == \"N1p2\") %>%\n    ggplot(., aes(x=q_hunger, y=q_irritability))+\n    geom_point()+\n    geom_smooth(method=\"lm\",se=F)+\n  labs(title=\"The 'effect of hunger' for a single\\nparticipant from the Hangry study\")\n```\n\n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (1 + hunger | participant))\n```\n\n`r solend()`\n\n::: {.callout-note collapse=\"true\"}\n## Total, Within, Between\n\nRecall our research aim: \n\n> **... whether hunger influences peoples' levels of irritability (i.e., \"the hangry hypothesis\")**, and whether this is different for people following a diet that includes fasting.  \n\nForgetting about any differences due to diet, let's just think about the relationship between irritability and hunger. How should we interpret this research aim?  \nWas it: \n\na. \"Are people more irritable if they are, __on average__, more hungry __than other people__?\"  \nb. \"Are people more irritable if they are, __for them__, more hungry __than they usually are__?\"  \nc. Some combination of both a. and b.   \n\nThis is just one demonstration of how the statistical methods we use can constitute an integral part of our development of a research project, and part of the reason that data analysis for scientific cannot be so easily outsourced after designing the study and collecting the data.  \n\nAs our data currently is currently stored, the relationship between `irritability` and the raw scores on the hunger questionnaire `q_hunger` represents some 'total effect' of hunger on irritability. This is a bit like interpretation __c.__ above - it's a composite of both the 'within' ( __b.__ ) and 'between' ( __a.__ ) effects. The problem with this is that the 'total effect' isn't necessarily all that meaningful. It may tell us that 'being higher on the hunger questionnaire is associated with being more irritable', but how can we apply this information? It is not specifically about the comparison between hungry people and less hungry people, and nor is it about how person i changes when they are more hungry than usual. It is both these things smushed together.  \n\nTo disaggregate the 'within' and 'between' effects of hunger on irritability, we can group-mean center. For 'between', we are interested in how irritability is related to the average hunger levels of a participant, and for 'within', we are asking how irritability is related to a participants' _relative levels_ of hunger (i.e., how far above/below their average hunger level they are.).  \n\n:::\n\n\n`r qbegin(2)`\nAdd to the data these two columns: \n\n1. a column which contains the average hungriness score for each participant.\n2. a column which contains the deviation from each person's hunger score to that person's average hunger score. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\nYou'll find `group_by() %>% mutate()` very useful here. \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nhangry <- \n    hangry %>% group_by(ppt) %>%\n        mutate(\n            avg_hunger = mean(q_hunger),\n            hunger_gc = q_hunger - avg_hunger\n        )\nhead(hangry)\n```\n`r solend()`\n\n`r qbegin(3)`\nFor each of the new variables you just added, plot the irritability scores against those variables.  \n\n- Does it look like hungry people are more irritable than less hungry people?  \n- Does it look like when people are more hungry than normal, they are more irritable? \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWe might find it easier to look at a plot where each participant is represented as their mean plus an indication of their range of irritability scores:  \n```{r fig.asp=.5}\nggplot(hangry,aes(x=avg_hunger,y=q_irritability))+\n    stat_summary(geom=\"pointrange\")\n```\nThere appears to be a slight positive relationship between a persons' average hunger and their irritability scores. \n\nIt is harder to tell what the relationship is between participant-centered hunger and irritability, because there are a lot of different lines (one for each participant). To make it easier to get an idea of what's happening, we'll make the plot fit a simple lm() (a straight line) for each participants' data:  \n\n```{r include=FALSE}\n# ggplot(hangry,aes(x=hunger_gc,y=q_irritability, group=ppt))+\n#   geom_point(alpha = .2) + \n#   geom_smooth(method=lm, se=FALSE, lwd=.2)\n```\n\n```{r}\nggplot(hangry,aes(x=hunger_gc,y=q_irritability, color=ppt)) +\n  geom_point(alpha = .2) + \n  geom_smooth(method=lm, se=FALSE, lwd=.2) +\n  theme(legend.position = 'none')\n```\n\nI think there might be a positive trend in here, in that participants tend to be higher irritability when they are higher (for them) on the hunger score. \n`r solend()`\n\n`r qbegin(4)`\nWe have taken the raw hunger scores and separated them into two parts (raw hunger scores = participants' average hunger score + observation level deviations from those averages), that represent two different aspects of the relationship between hunger and irritability.  \n\nAdjust your model specification to include these two separate variables as predictors, instead of the raw hunger scores.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `hunger * diet` could be replaced by `(hunger1 + hunger2) * diet`, thereby allowing each aspect of hunger to interact with diet. \n- We can only put one of these variables in the random effects `(1 + hunger | participant)`. Recall that above we discussed how we cannot have `(diet | participant)`, because \"an effect of diet\" makes no sense for a single participant (they are either on the diet or they are not, so there is no 'effect'). Similarly, each participant has only one value for their average hungriness.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(lme4)\nhangrywb <- lmer(q_irritability ~ (avg_hunger + hunger_gc)* fivetwo + \n                (1 + hunger_gc | ppt), \n                data = hangry,\n                control = lmerControl(optimizer=\"bobyqa\"))\n```\n`r solend()`\n\n`r qbegin(5)`\nHopefully, you have fitted a model similar to the below:  \n```{r}\nhangrywb <- lmer(q_irritability ~ (avg_hunger + hunger_gc) * fivetwo + \n                (1 + hunger_gc | ppt), data = hangry,\n            control = lmerControl(optimizer=\"bobyqa\"))\n```\n\nBelow, we have obtained p-values using the Kenward Rogers Approximation of $df$ for the test of whether the fixed effects are zero, so we can see the significance of each estimate.  \n\nProvide an answer for each of these questions:\n\n1. For those following no diet, is there evidence to suggest that people who are _on average_ more hungry are more irritable?\n2. Is there evidence to suggest that this is different for those following the five-two diet? In what way?\n3. Do people following no diet tend to be more irritable when they are more hungry than they usually are? \n4. Is there evidence to suggest that this is different for those following the five-two diet? In what way?\n5. __(Trickier:)__ What does the `fivetwo` coefficient represent? \n\n```{r}\n#| echo: false\nlibrary(parameters)\nmodel_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE) |>\n  print_html()\n```\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n**1: For those following no diet, is there evidence to suggest that people who are _on average_ more hungry are more irritable?**  \nA: 'No diet' is the reference level of the five-two variable, and because we have an interaction, that means the `avg_hunger` coefficient will provide the relevant estimate. There is no evidence ($p>.05$) to suggest that when not dieting, hungrier people are more irritable than less hungry people. \n\n\n**2: Is there evidence to suggest that this is different for those following the five-two diet? In what way?**  \nA: This is the interaction between `avg_hunger:fivetwo1`. We can see that, for every increase of 1 in average hunger, irritability is estimated to increase by 0.47 more for those in the five-two diet than it does for those following no diet.  \nThese units are still in terms of the original scale (i.e. 0 to 100). \n\n\n**3: Do people following no diet tend to be more irritable when they are more hungry than they usually are?** \nA: This is the estimate for the coefficient of `hunger_gc`. For people following no diet, there is an estimated 0.19 increase in irritability for every 1 unit more hungry they become. \n\n**4: Is there evidence to suggest that this is different for those following the five-two diet? In what way?**\nA: This effect of a 1 unit change on within-person hunger increasing irritability is increased for those who are following the five-two diet by an additional 0.38\n\n**5: What does the `fivetwo1` coefficient represent?** \nA: This represents the group difference of irritability between those on the five-two diet vs those not dieting, for someone who has an average hunger score of 0. \n\n`r solend()`\n\n`r qbegin(6)`\nConstruct two plots showing the two model estimated interactions. Think about your answers to the previous question, and check that they match with what you are seeing in the plots (do not underestimate the utility of this activity for helping understanding!).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis isn't as difficult as it sounds. the sjPlot package can do it in one line of code!\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(sjPlot)\nplot_model(hangrywb, type = \"int\")[[1]]\n```\nWe saw in the model coefficients that for the reference level of `fivetwo`, the \"No Diet\" group, there was no association between how hungry a person is _on average_ and their irritability. This is the red line we see in the plot above. \nWe also saw the interaction `avg_hunger:fivetwo1` indicates that irritability is estimated to increase by 0.47 more for those in the five-two diet than it does for those following no diet. So the blue line is should be going up more steeply than the red line (which is flat). And it is! \n\n```{r}\nplot_model(hangrywb, type = \"int\")[[2]]\n```\nFrom the coefficient of `hunger_gc` we get the estimated amount by which irritability increases for every 1 more hungry that a person becomes (when they're on \"No Diet\"). This is the slope of the red line. \nThe interaction `hunger_gc:fivetwo1` gave us the adjustment to get from the red line to the blue line. It is positive and significant, which matches with the fact that the blue line is clearly steeper in this plot. \n\n`r solend()`\n\n`r qbegin(7)`\nProvide tests or confidence intervals for the parameters of interest, and write-up the results.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Remember: some options for inference\n\n\n|                  | df approximations                                                  | likelihood-based                                                    | \n| ---------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------- | \n| tests or CIs for model parameters | `library(parameters)`<br>`model_parameters(model, ci_method=\"kr\")` | `confint(model, type=\"profile\")`                                    | \n| model comparison<br><small>(different fixed effects, same random effects)</small> | `library(pbkrtest)`<br>`KRmodcomp(model1,model0)`                  | `anova(model0,model)`                                               |\n|                  | fit models with `REML=TRUE`.<br>good option for small samples      | fit models with `REML=FALSE`.<br>needs large N at both levels (40+) | \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(parameters)\nmodel_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE)\n```\n\n```{r}\n#| include: false\nres = as.data.frame(model_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE))\nres[,2:8] <- apply(res[,2:8],2,function(x) round(x,2))\nres[,9] <- format.pval(res[,9],digits=1, eps=.001)\nres[,9][!grepl(\"<\",res[,9])] <- paste0(\"=\",res[,9][!grepl(\"<\",res[,9])])\nres\n```\n\nTo investigate the association between irritability and hunger, and whether this relationship is different depending on whether or not participants are on a restricted diet such as the five-two, a multilevel linear model was fitted.  \nTo disaggregate between the differences in irritability due to people being in general more/less hungry, and those due to people being more/less hungry than usual for them, irritability was regressed onto both participants' average hunger scores their relative hunger levels. Both of these were allowed to interact with whether or not participants were on the five-two diet. Random intercepts and slopes of relative-hunger level were included for participants. The model was fitting with restricted maximum likelihood estimation with the **lme4** package (Bates et al., 2015), using the _bobyqa_ optimiser from the **lme4**. $P$-values were obtained using Wald tests with Kenward-Roger approximation of denominator degrees of freedom.  \n\nResults indicate that for people on no diet, being more hungry than normal was associated with greater irritability ($\\beta = `r res[3,2]`,\\ SE = `r res[3,3]`,\\ t(`r res[3,7]`) = `r res[3,8]`,\\ p`r res[3,9]`$), and that this was increased for those following the five-two diet ($\\beta = `r res[6,2]`,\\ SE = `r res[6,3]`,\\ t(`r res[6,7]`) = `r res[6,8]`,\\ p`r res[6,9]`$). \nAlthough for those not on a specific diet there was no evidence for an association between irritability and being generally a more hungry person ($p`r res[2,9]`$), there a significant interaction was found between average hunger and being on the five-two diet ($\\beta = `r res[5,2]`,\\ SE = `r res[5,3]`,\\ t(`r res[5,7]`) = `r res[5,8]`,\\ p`r res[5,9]`$), suggesting that when dieting, hungrier people tend to be more irritable than less hungry people.  \nResults suggest that the 'hangry hypothesis' may occur _within_ people (when a person is more hungry than they usually are, they tend to be more irritable), but not necessarily between hungry/less hungry people. Dieting was found to increase the association of both between-person hunger and within-person hunger with irritability.  \n`r solend()`\n\n\n:::statbox\n__Other within-group transformations__  \n\nAs well as within-group mean centering a predictor (like we have done above), we can within-group _standardise_ a predictor. This would disagregate within and between effects, but interpretation would of the within effect would be the estimated change in $y$ associated with being 1 standard deviation higher in $x$ _for that group_.  \n\n:::\n<br>\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(effects)\nlibrary(knitr)\nlibrary(kableExtra)\n```\n\n\n# Exercises: Assumptions & Diagnostics\n\n:::frame\n__Data: Wellbeing Across Scotland__  \n\nFor these next set of exercises we continue with our recurring study in which researchers want to look at the relationship between time spent outdoors and mental wellbeing, across all of Scotland. Data is collected from 20 of the Local Authority Areas and is accessible at [https://uoepsy.github.io/data/LAAwellbeing.csv](https://uoepsy.github.io/data/LAAwellbeing.csv).  \n```{r echo=FALSE, message=FALSE,warning=FALSE}\nlibrary(gt)\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\ntibble(variable=names(scotmw),\n       description=c(\"Participant ID\",\"Participant Name\",\"Local Authority Area\",\"Self report estimated number of hours per week spent outdoors\",\"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\",\"LAA Population Density (people per square km)\")\n) %>% gt()\n```\n:::\n\n`r qbegin(\"1\")`\nThe code below will read in the data and fit the model with by-LAA random intercepts and slopes of outdoor time. \n```{r message=F,warning=F}\nlibrary(tidyverse)\nlibrary(lme4)\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\nrs_model <- lmer(wellbeing ~ 1 + outdoor_time + (1 + outdoor_time | laa), data = scotmw)\n```\n\n1. Plot the residuals vs fitted values, and assess the extend to which the assumption holds that the residuals are zero mean.\n2. Construct a scale-location plot. This is where the square-root of the absolute value of the standardised residuals is plotted against the fitted values, and allows you to more easily assess the assumption of constant variance. \n  - Optional: can you create the same plot using ggplot, starting with the `augment()` function from the __broom.mixed__ package?  \n  \n::: {.callout-tip collapse=\"true\"}\n#### Hints\n`plot(model)` will give you this plot, but you might want to play with the `type = c(......)` argument to get the smoothing line\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nplot(rs_model, type=c(\"p\",\"smooth\"))\n```\nAs we can see, the mean value of the residuals is quite close to zero, right the way across the fitted values. This is good. \n\n::: {.callout-note}\nTo change labels for the x and y axes, add the following arguments to the plot() function:\n\n- `xlab = \"Fitted values\"`\n- `ylab = \"Residuals\"`\n:::\n\n```{r}\nplot(rs_model,\n     form = sqrt(abs(resid(.))) ~ fitted(.),\n     type = c(\"p\",\"smooth\"))\n```\n\nIn this plot we can see that the variance of the residuals is fairly constant across the fitted values. There is a slight dip at the lower end. We can see this in the previous plot too - all the points at the LHS of the plot are slightly more tightly grouped around the line. This is not enough to worry me, personally.  \n\n```{r}\nlibrary(broom.mixed)\naugment(rs_model) %>%\n  mutate(\n    sqrtr = sqrt(abs(.resid))\n  ) %>%\n  ggplot(aes(x=.fitted, y=sqrtr)) + \n  geom_point() +\n  geom_smooth()\n```\n\n::: {.callout-note}\nTo remove the confidence bands (in grey) from the smoothed line, you can change the last command to:\n\n`geom_smooth(se = FALSE)`\n:::\n\n`r solend()`\n\n\n`r qbegin(\"2\")`\nExamine the normality of both the level 1 and level 2 residuals.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n  - Use `hist()` if you like, or `qqnorm(residuals)` followed by `qqline(residuals)`\n  - Extracting the level 2 residuals (the random effects) can be difficult. `ranef(model)` will get you some of the way.\n  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n__Level 1__  \n\n```{r}\nhist(resid(rs_model))\nqqnorm(resid(rs_model))\nqqline(resid(rs_model))\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n\n__Indexing random effects__  \n\nThe output of `ranef()` is a type of data container called \"list\". The list includes different named slots and you can find the names as follows: \n\n```{r}\nnames(ranef(rs_model))\n```\n\nYou have a named slot for each group in your lmer specification. In this case, we only specified `laa` as grouping. To access the random effects for the specific group, type `ranef(model)` followed by `$groupname`\n\n```{r}\nranef(rs_model)$laa\n```\n\nYou will have multiple columns, one for each random effect.\n\nYou can get the random intercepts by laa, by selecting the first column as follows:\n\n```{r}\nranef(rs_model)$laa[, 1]\n```\n\nRespectively, for the random slopes by laa, you select the second column as follows:\n\n```{r}\nranef(rs_model)$laa[, 2]\n```\n\n:::\n\n\n__Level 2__  \n```{r}\nqqnorm(ranef(rs_model)$laa[, 1], main = \"Random intercept\")\nqqline(ranef(rs_model)$laa[, 1])\n\nqqnorm(ranef(rs_model)$laa[, 2], main = \"Random slope\")\nqqline(ranef(rs_model)$laa[, 2])\n```\n\nThe normality of the residuals at both levels looks pretty decent here. This is especially good given that we only actually have 20 clusters (the LAAs). We have quite a small sample at this level.  \n\n`r solend()`\n\n\n\n`r qbegin(\"3\")`\n1. Which person in the dataset has the greatest influence on our model?  \n2. For which person is the model fit the worst (i.e., who has the highest residual?)\n3. Which _LAA_ has the greatest influence on our model?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- as well as `hlm_influence()` in the __HLMdiag__ package there is another nice function, `hlm_augment()`\n- we can often end up in confusion because the $i^{th}$ observation inputted to our model (and therefore the $i^{th}$ observation of `hlm_influence()` output) **might not be** the $i^{th}$ observation in our original dataset - there may be missing data! (Luckily, we have no missing data in this dataset). \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(HLMdiag)\nl1_inf <- hlm_influence(rs_model,level=1)\ndotplot_diag(l1_inf$cooksd, cutoff=\"internal\")+\n  ylim(0,.15)\n```\nGreatest influence:\n```{r}\nhlm_augment(rs_model, level=1) %>% arrange(desc(cooksd))\nscotmw[74, ]\n```\n```{r}\n#| echo: false\n#| out-width: \"100px\"\n#| fig-align: \"center\"\nknitr::include_graphics(\"images/intro/willie.jpg\")\n```\n\nHighest residual: \n```{r}\nhlm_augment(rs_model, level=1) %>% arrange(desc(abs(.resid)))\nscotmw[64, ]\n```\n\nMost influential LAA: \n```{r}\nhlm_augment(rs_model, level=\"laa\") %>% arrange(desc(cooksd))\n```\n\n`r solend()`\n\n\n`r qbegin(\"4\")`\n\n1. Looking at the random effects, which LAA shows the least benefit to wellbeing as outdoor time increases, and which shows the greatest benefit?  \n2. What is the estimated wellbeing for people from City of Edinburgh with zero hours of outdoor time per week, and what is their associated increases in wellbeing for every hour per week increase in outdoor time?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nIt looks like the residents of Midlothian have the least improvement, and the Western Isles (Na h-Eileanan Siar) show the most increases of wellbeing with outdoor time. We can see this from the LAA-random slopes of outdoor time:  \n```{r}\nranef(rs_model)\n```\nWe can get the cluster-specific coefficients either by adding the `fixef()` and `ranef()` together, or using `coef()`:  \n```{r}\ncoef(rs_model)\n```\n```{r}\ncoef(rs_model)$laa[\"City of Edinburgh\",]\n```\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Exercises: Centering in the MLM\n\n\n::: {.callout-note collapse=\"true\"}\n## Centering & Scaling in LM\n\nWe have some data from a study investigating how perceived persuasiveness of a speaker is influenced by the rate at which they speak.  \n```{r}\ndap2 <- read_csv(\"https://uoepsy.github.io/data/dapr2_2122_report1.csv\")\n```\n\nWe can fit a simple linear regression (one predictor) to evaluate how speech rate (variable `sp_rate` in the dataset) influences perceived persuasiveness (variable `persuasive` in the dataset). There are various ways in which we can transform the predictor variable `sp_rate`, which in turn can alter the interpretation of some of our estimates:  \n\n:::panelset\n:::panel\n#### Raw X\n```{r}\nm1 <- lm(persuasive ~ sp_rate, data = dap2)\nsummary(m1)$coefficients\n```\n\nThe intercept and the coefficient for speech rate are interpreted as:  \n\n- `(Intercept)`: A audio clip of someone speaking at zero phones per second is estimated as having an average persuasive rating of `r coefficients(m1)[1] %>% round(.,2)`.  \n- `sp_rate`: For every increase of one phone per second, perceived persuasiveness is estimated to decrease by `r coefficients(m1)[2] %>% round(.,2)`.  \n\n:::\n:::panel\n#### Mean-Centered X\n\nWe can mean center our predictor and fit the model again: \n```{r}\ndap2 <- dap2 %>% mutate(sp_rate_mc = sp_rate - mean(sp_rate))\nm2 <- lm(persuasive ~ sp_rate_mc, data = dap2)\nsummary(m2)$coefficients\n```\n- `(Intercept)`: A audio clip of someone speaking at the __mean__ phones per second is estimated as having an average persuasive rating of `r coefficients(m2)[1] %>% round(.,2)`.  \n- `sp_rate_mc`: For every increase of one phone per second, perceived persuasiveness is estimated to decrease by `r coefficients(m2)[2] %>% round(.,2)`.  \n\n:::\n:::panel\n#### Standardised X\n\nWe can _standardise_ our predictor and fit the model yet again: \n\n```{r}\ndap2 <- dap2 %>% mutate(sp_rate_z = scale(sp_rate))\nm3 <- lm(persuasive ~ sp_rate_z, data = dap2)\nsummary(m3)$coefficients\n```\n- `(Intercept)`: A audio clip of someone speaking at the __mean__ phones per second is estimated as having an average persuasive rating of `r coefficients(m3)[1] %>% round(.,2)`.  \n- `sp_rate_z`: For every increase of one __standard deviation__ in phones per second, perceived persuasiveness is estimated to decrease by `r coefficients(m3)[2] %>% round(.,2)`. \n\nRemember that the `scale(sp_rate)` is subtracting the mean from each value, then dividing those by the standard deviation. \nThe standard deviation of `dap2$sp_rate` is:\n```{r}\nsd(dap2$sp_rate)\n```\nso in our variable `dap2$sp_rate_z`, a change of `r sd(dap2$sp_rate) %>% round(.,2)` gets scaled to be a change of 1 (because we are dividing by `sd(dap2$sp_rate)`).  \n```{r}\ncoef(m1)[2] * sd(dap2$sp_rate)\ncoef(m3)[2]\n```\n\n:::\n:::\n\nNote that these models are identical. When we conduct a model comparison between the 3 models, the residual sums of squares is identical for all models: \n```{r}\nanova(m1,m2,m3)\n```\n\nWhat changes when you center or scale a predictor in a standard regression model (one fitted with `lm()`)?  \n\n- The variance explained by the predictor remains exactly the same\n- The intercept will change to be the estimated mean outcome where that predictor is \"0\". Scaling and centering changes what \"0\" represents, thereby changing this estimate (the significance test will therefore also change because the intercept now has a different meaning)\n- The slope of the predictor will change according to any scaling (e.g. if you divide your predictor by 10, the slope will multiply by 10). \n- The **test** of the slope of the predictor remains exactly the same.  \n\n:::\n\n:::frame\n__Data: Hangry__\n\nThe study is interested in evaluating whether hunger influences peoples' levels of irritability (i.e., \"the hangry hypothesis\"), and whether this is different for people following a diet that includes fasting. 81 participants were recruited into the study. Once a week for 5 consecutive weeks, participants were asked to complete two questionnaires, one assessing their level of hunger, and one assessing their level of irritability. The time and day at which participants were assessed was at a randomly chosen hour between 7am and 7pm each week. 46 of the participants were following a five-two diet (five days of normal eating, 2 days of fasting), and the remaining 35 were following no specific diet.  \n\nThe data are available at: [https://uoepsy.github.io/data/hangry.csv](https://uoepsy.github.io/data/hangry.csv).  \n\n```{r}\n#| echo: false\nhangry<-read_csv(\"https://uoepsy.github.io/data/hangry.csv\") %>% mutate(fivetwo=factor(fivetwo))\ntibble(\n    variable = names(hangry),\n    description = c(\"Score on irritability questionnaire (0:100)\",\n                    \"Score on hunger questionnaire (0:100)\",\n                    \"Participant\",\n                    \"Whether the participant follows the five-two diet\")\n) %>% knitr::kable()\n```\n\n:::\n\n`r qbegin(1)`\nRead carefully the description of the study above, and try to write out (in `lmer` syntax) an appropriate model to test the research aims.  \ne.g.:  \n```{}\noutcome ~ explanatory variables + (???? | grouping)\n```\nTry to think about the maximal random effect structure (i.e. everything that can vary by-grouping is estimated as doing so). \n\nTo help you think through the steps to get from a description of a research study to a model specification, think about your answers to the following questions. \n\nQ: What is our outcome variable?  \nQ: What are our explanatory variables?  \nQ: Is there any grouping (or \"clustering\") of our data that we consider to be a random sample? If so, what are the groups?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- The research is looking at how hunger influences irritability, and whether this is different for people on the fivetwo diet.\n- We can split our data in to groups of each participant. We can also split it into groups of each diet. Which of these groups have we randomly sampled? Do we have a random sample of participants? Do we have a random sample of diets? Another way to think of this is \"if i repeated the experiment, what these groups be different?\"\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nOur outcome is irritability here, because it is the thing that we are trying to explain through peoples' hunger levels and diets.  \n\n```{r}\n#| eval: false\nlmer(irritability ~  explanatory variables + (???? | grouping))\n```\n\nWe are interested in the effect of hunger on irritability, and whether this effect is different for the five-two diet. \nSo we are interested in the interaction: \n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (???? | grouping))\n```\n(remember that `hunger + diet + hunger:diet` is just a more explicit way of writing `hunger*diet`). \n\nIf we did this experiment again, would we have different participants?  \nYes. If we did this experiment again, would we have different diets? No, because we're interested in the specific differences between the five-two diet and no dieting. This means we will likely want to by-participant random deviations (e.g. the `( ... | participant)` bit in `lmer`). But we won't have by-diet random effects `(1 | diet)` because the diet differences are the specific differences that we wish to test.  \n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (???? | participant))\n```\n\nThinking about what __can__ be modelled as randomly varying between participants, we have some options:\n\n1. participants vary in how irritable they are on average   \n(the intercept, `1 | participant`)\n2. participants vary in how much hunger influences their irritability   \n(the effect of hunger, `hunger | participant`)\n3. participants vary in how much diet influences irritability   \n(the effect of diet, `diet | participant`)\n4. participants vary in how much diet effects hunger's influence on irritability   \n(the interaction between diet and hunger, `diet:hunger | participant`)\n\nWe can vary 1 and 2, but not 3 and 4. This is because each participant is _either_ following the five-two diet _or_ they are not. So for a _single_ participant, we can't assess \"the effect diet has\" on anything, because we haven't seen that participant under different diets. if we try to plot a single participants' data, we can see that it is impossible for us to assess \"the effect of diet\":\n```{r}\n#| echo: false\n#| fig-height: 2.5\nhangry %>% filter(ppt == \"N1p2\") %>%\n    ggplot(., aes(x=fivetwo, y=q_irritability))+\n    geom_point()+\n    geom_smooth(method=\"lm\",se=F)+\n    scale_x_discrete(drop=FALSE)+\n  labs(title=\"The 'effect of diet' for a single\\nparticipant from the Hangry study\",subtitle=\"cannot be defined\")\n```\n\nBy contrast, we __can__ vary the intercept and the effect of hunger, because each participant has multiple values of irritability, and multiple different observations of hunger. We can think about a single participant's \"effect of hunger on irritability\" and how we might fit a line to their data:\n```{r}\n#| echo: false\n#| fig-height: 2.5\nhangry %>% filter(ppt == \"N1p2\") %>%\n    ggplot(., aes(x=q_hunger, y=q_irritability))+\n    geom_point()+\n    geom_smooth(method=\"lm\",se=F)+\n  labs(title=\"The 'effect of hunger' for a single\\nparticipant from the Hangry study\")\n```\n\n```{r}\n#| eval: false\nlmer(irritability ~  hunger + diet + hunger:diet + (1 + hunger | participant))\n```\n\n`r solend()`\n\n::: {.callout-note collapse=\"true\"}\n## Total, Within, Between\n\nRecall our research aim: \n\n> **... whether hunger influences peoples' levels of irritability (i.e., \"the hangry hypothesis\")**, and whether this is different for people following a diet that includes fasting.  \n\nForgetting about any differences due to diet, let's just think about the relationship between irritability and hunger. How should we interpret this research aim?  \nWas it: \n\na. \"Are people more irritable if they are, __on average__, more hungry __than other people__?\"  \nb. \"Are people more irritable if they are, __for them__, more hungry __than they usually are__?\"  \nc. Some combination of both a. and b.   \n\nThis is just one demonstration of how the statistical methods we use can constitute an integral part of our development of a research project, and part of the reason that data analysis for scientific cannot be so easily outsourced after designing the study and collecting the data.  \n\nAs our data currently is currently stored, the relationship between `irritability` and the raw scores on the hunger questionnaire `q_hunger` represents some 'total effect' of hunger on irritability. This is a bit like interpretation __c.__ above - it's a composite of both the 'within' ( __b.__ ) and 'between' ( __a.__ ) effects. The problem with this is that the 'total effect' isn't necessarily all that meaningful. It may tell us that 'being higher on the hunger questionnaire is associated with being more irritable', but how can we apply this information? It is not specifically about the comparison between hungry people and less hungry people, and nor is it about how person i changes when they are more hungry than usual. It is both these things smushed together.  \n\nTo disaggregate the 'within' and 'between' effects of hunger on irritability, we can group-mean center. For 'between', we are interested in how irritability is related to the average hunger levels of a participant, and for 'within', we are asking how irritability is related to a participants' _relative levels_ of hunger (i.e., how far above/below their average hunger level they are.).  \n\n:::\n\n\n`r qbegin(2)`\nAdd to the data these two columns: \n\n1. a column which contains the average hungriness score for each participant.\n2. a column which contains the deviation from each person's hunger score to that person's average hunger score. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\nYou'll find `group_by() %>% mutate()` very useful here. \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nhangry <- \n    hangry %>% group_by(ppt) %>%\n        mutate(\n            avg_hunger = mean(q_hunger),\n            hunger_gc = q_hunger - avg_hunger\n        )\nhead(hangry)\n```\n`r solend()`\n\n`r qbegin(3)`\nFor each of the new variables you just added, plot the irritability scores against those variables.  \n\n- Does it look like hungry people are more irritable than less hungry people?  \n- Does it look like when people are more hungry than normal, they are more irritable? \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWe might find it easier to look at a plot where each participant is represented as their mean plus an indication of their range of irritability scores:  \n```{r fig.asp=.5}\nggplot(hangry,aes(x=avg_hunger,y=q_irritability))+\n    stat_summary(geom=\"pointrange\")\n```\nThere appears to be a slight positive relationship between a persons' average hunger and their irritability scores. \n\nIt is harder to tell what the relationship is between participant-centered hunger and irritability, because there are a lot of different lines (one for each participant). To make it easier to get an idea of what's happening, we'll make the plot fit a simple lm() (a straight line) for each participants' data:  \n\n```{r include=FALSE}\n# ggplot(hangry,aes(x=hunger_gc,y=q_irritability, group=ppt))+\n#   geom_point(alpha = .2) + \n#   geom_smooth(method=lm, se=FALSE, lwd=.2)\n```\n\n```{r}\nggplot(hangry,aes(x=hunger_gc,y=q_irritability, color=ppt)) +\n  geom_point(alpha = .2) + \n  geom_smooth(method=lm, se=FALSE, lwd=.2) +\n  theme(legend.position = 'none')\n```\n\nI think there might be a positive trend in here, in that participants tend to be higher irritability when they are higher (for them) on the hunger score. \n`r solend()`\n\n`r qbegin(4)`\nWe have taken the raw hunger scores and separated them into two parts (raw hunger scores = participants' average hunger score + observation level deviations from those averages), that represent two different aspects of the relationship between hunger and irritability.  \n\nAdjust your model specification to include these two separate variables as predictors, instead of the raw hunger scores.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `hunger * diet` could be replaced by `(hunger1 + hunger2) * diet`, thereby allowing each aspect of hunger to interact with diet. \n- We can only put one of these variables in the random effects `(1 + hunger | participant)`. Recall that above we discussed how we cannot have `(diet | participant)`, because \"an effect of diet\" makes no sense for a single participant (they are either on the diet or they are not, so there is no 'effect'). Similarly, each participant has only one value for their average hungriness.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(lme4)\nhangrywb <- lmer(q_irritability ~ (avg_hunger + hunger_gc)* fivetwo + \n                (1 + hunger_gc | ppt), \n                data = hangry,\n                control = lmerControl(optimizer=\"bobyqa\"))\n```\n`r solend()`\n\n`r qbegin(5)`\nHopefully, you have fitted a model similar to the below:  \n```{r}\nhangrywb <- lmer(q_irritability ~ (avg_hunger + hunger_gc) * fivetwo + \n                (1 + hunger_gc | ppt), data = hangry,\n            control = lmerControl(optimizer=\"bobyqa\"))\n```\n\nBelow, we have obtained p-values using the Kenward Rogers Approximation of $df$ for the test of whether the fixed effects are zero, so we can see the significance of each estimate.  \n\nProvide an answer for each of these questions:\n\n1. For those following no diet, is there evidence to suggest that people who are _on average_ more hungry are more irritable?\n2. Is there evidence to suggest that this is different for those following the five-two diet? In what way?\n3. Do people following no diet tend to be more irritable when they are more hungry than they usually are? \n4. Is there evidence to suggest that this is different for those following the five-two diet? In what way?\n5. __(Trickier:)__ What does the `fivetwo` coefficient represent? \n\n```{r}\n#| echo: false\nlibrary(parameters)\nmodel_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE) |>\n  print_html()\n```\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n**1: For those following no diet, is there evidence to suggest that people who are _on average_ more hungry are more irritable?**  \nA: 'No diet' is the reference level of the five-two variable, and because we have an interaction, that means the `avg_hunger` coefficient will provide the relevant estimate. There is no evidence ($p>.05$) to suggest that when not dieting, hungrier people are more irritable than less hungry people. \n\n\n**2: Is there evidence to suggest that this is different for those following the five-two diet? In what way?**  \nA: This is the interaction between `avg_hunger:fivetwo1`. We can see that, for every increase of 1 in average hunger, irritability is estimated to increase by 0.47 more for those in the five-two diet than it does for those following no diet.  \nThese units are still in terms of the original scale (i.e. 0 to 100). \n\n\n**3: Do people following no diet tend to be more irritable when they are more hungry than they usually are?** \nA: This is the estimate for the coefficient of `hunger_gc`. For people following no diet, there is an estimated 0.19 increase in irritability for every 1 unit more hungry they become. \n\n**4: Is there evidence to suggest that this is different for those following the five-two diet? In what way?**\nA: This effect of a 1 unit change on within-person hunger increasing irritability is increased for those who are following the five-two diet by an additional 0.38\n\n**5: What does the `fivetwo1` coefficient represent?** \nA: This represents the group difference of irritability between those on the five-two diet vs those not dieting, for someone who has an average hunger score of 0. \n\n`r solend()`\n\n`r qbegin(6)`\nConstruct two plots showing the two model estimated interactions. Think about your answers to the previous question, and check that they match with what you are seeing in the plots (do not underestimate the utility of this activity for helping understanding!).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis isn't as difficult as it sounds. the sjPlot package can do it in one line of code!\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(sjPlot)\nplot_model(hangrywb, type = \"int\")[[1]]\n```\nWe saw in the model coefficients that for the reference level of `fivetwo`, the \"No Diet\" group, there was no association between how hungry a person is _on average_ and their irritability. This is the red line we see in the plot above. \nWe also saw the interaction `avg_hunger:fivetwo1` indicates that irritability is estimated to increase by 0.47 more for those in the five-two diet than it does for those following no diet. So the blue line is should be going up more steeply than the red line (which is flat). And it is! \n\n```{r}\nplot_model(hangrywb, type = \"int\")[[2]]\n```\nFrom the coefficient of `hunger_gc` we get the estimated amount by which irritability increases for every 1 more hungry that a person becomes (when they're on \"No Diet\"). This is the slope of the red line. \nThe interaction `hunger_gc:fivetwo1` gave us the adjustment to get from the red line to the blue line. It is positive and significant, which matches with the fact that the blue line is clearly steeper in this plot. \n\n`r solend()`\n\n`r qbegin(7)`\nProvide tests or confidence intervals for the parameters of interest, and write-up the results.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Remember: some options for inference\n\n\n|                  | df approximations                                                  | likelihood-based                                                    | \n| ---------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------- | \n| tests or CIs for model parameters | `library(parameters)`<br>`model_parameters(model, ci_method=\"kr\")` | `confint(model, type=\"profile\")`                                    | \n| model comparison<br><small>(different fixed effects, same random effects)</small> | `library(pbkrtest)`<br>`KRmodcomp(model1,model0)`                  | `anova(model0,model)`                                               |\n|                  | fit models with `REML=TRUE`.<br>good option for small samples      | fit models with `REML=FALSE`.<br>needs large N at both levels (40+) | \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(parameters)\nmodel_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE)\n```\n\n```{r}\n#| include: false\nres = as.data.frame(model_parameters(hangrywb, ci_method = \"kr\", ci_random = FALSE))\nres[,2:8] <- apply(res[,2:8],2,function(x) round(x,2))\nres[,9] <- format.pval(res[,9],digits=1, eps=.001)\nres[,9][!grepl(\"<\",res[,9])] <- paste0(\"=\",res[,9][!grepl(\"<\",res[,9])])\nres\n```\n\nTo investigate the association between irritability and hunger, and whether this relationship is different depending on whether or not participants are on a restricted diet such as the five-two, a multilevel linear model was fitted.  \nTo disaggregate between the differences in irritability due to people being in general more/less hungry, and those due to people being more/less hungry than usual for them, irritability was regressed onto both participants' average hunger scores their relative hunger levels. Both of these were allowed to interact with whether or not participants were on the five-two diet. Random intercepts and slopes of relative-hunger level were included for participants. The model was fitting with restricted maximum likelihood estimation with the **lme4** package (Bates et al., 2015), using the _bobyqa_ optimiser from the **lme4**. $P$-values were obtained using Wald tests with Kenward-Roger approximation of denominator degrees of freedom.  \n\nResults indicate that for people on no diet, being more hungry than normal was associated with greater irritability ($\\beta = `r res[3,2]`,\\ SE = `r res[3,3]`,\\ t(`r res[3,7]`) = `r res[3,8]`,\\ p`r res[3,9]`$), and that this was increased for those following the five-two diet ($\\beta = `r res[6,2]`,\\ SE = `r res[6,3]`,\\ t(`r res[6,7]`) = `r res[6,8]`,\\ p`r res[6,9]`$). \nAlthough for those not on a specific diet there was no evidence for an association between irritability and being generally a more hungry person ($p`r res[2,9]`$), there a significant interaction was found between average hunger and being on the five-two diet ($\\beta = `r res[5,2]`,\\ SE = `r res[5,3]`,\\ t(`r res[5,7]`) = `r res[5,8]`,\\ p`r res[5,9]`$), suggesting that when dieting, hungrier people tend to be more irritable than less hungry people.  \nResults suggest that the 'hangry hypothesis' may occur _within_ people (when a person is more hungry than they usually are, they tend to be more irritable), but not necessarily between hungry/less hungry people. Dieting was found to increase the association of both between-person hunger and within-person hunger with irritability.  \n`r solend()`\n\n\n:::statbox\n__Other within-group transformations__  \n\nAs well as within-group mean centering a predictor (like we have done above), we can within-group _standardise_ a predictor. This would disagregate within and between effects, but interpretation would of the within effect would be the estimated change in $y$ associated with being 1 standard deviation higher in $x$ _for that group_.  \n\n:::\n<br>\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"03_assumptcent.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.340","toc_float":true,"theme":["united","assets/style-labs.scss"],"link-citations":true,"code-copy":false,"title":"3. Assumptions and Diagnostics | Centering","params":{"SHOW_SOLS":true,"TOGGLE":true}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}