{"title":"5. Recap & Practice Datasets","markdown":{"yaml":{"title":"5. Recap & Practice Datasets","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"Flashcards: `lm` to `lmer`","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(effects)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\n```\n\n\n\n\n```{r}\n#| echo: false\nrequire(patchwork)\nsource(\"plottingmixedmods.R\")\nrandom_intercept_model = mod2\nrandom_slopes_model = mod3\nb1 <- fixef(mod3) %>% round(3)\nu1 <- ranef(mod3)$subject %>% round(3)\nsu <- as.data.frame(VarCorr(mod3))[, 5] %>% round(3)\ns <- sigma(mod3) %>% round(3)\n```\n\n\nIn a simple linear regression, there is only considered to be one source of random variability: any variability left unexplained by a set of predictors (which are modelled as fixed estimates) is captured in the model residuals.  \n  \nMulti-level (or 'mixed-effects') approaches involve modelling more than one source of random variability - as well as variance resulting from taking a random sample of observations, we can identify random variability across different groups of observations. For example, if we are studying a patient population in a hospital, we would expect there to be variability across the our sample of patients, but also across the doctors who treat them.  \n  \nWe can account for this variability by allowing the outcome to be lower/higher for each group (a random intercept) and by allowing the estimated effect of a predictor vary across groups (random slopes).  \n  \n:::blue\nBefore you expand each of the boxes below, think about how comfortable you feel with each concept.  \nThis content is very cumulative, which means often going back to try to isolate the place which we need to focus efforts in learning. \n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Simple Linear Regression\n\n:::frame\n**Formula:**  \n  \n+ $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$  \n  \n**R command:**  \n  \n+ `lm(outcome ~ predictor, data = dataframe)`  \n  \n*Note:* this is the same as `lm(outcome ~ 1 + predictor, data = dataframe)`. The `1 +` is always there unless we specify otherwise (e.g., by using `0 +`).\n\n:::\n\n\n```{r}\n#| echo: false\nplot_data + plot_lm\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Clustered (multi-level) data\n\nWhen our data is clustered (or 'grouped') such that datapoints are no longer independent, but belong to some grouping such as that of multiple observations from the same subject, we have multiple sources of random variability. A simple regression does not capture this.  \n\nIf we separate out our data to show an individual plot for each grouping (in this data the grouping is by subjects), we can see how the fitted regression line from `lm()` is assumed to be the same for each group.  \n  \n```{r}\n#| echo: false\n#| fig-height: 10\nplot_lm_fac\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Random intercepts\n\nBy including a random-intercept term, we are letting our model estimate random variability around an average parameter (represented by the fixed effects) for the clusters.\n\n:::frame \n\n**Formula:**  \nLevel 1:  \n  \n+ $y_{ij} = \\beta_{0i} + \\beta_{1i} x_{ij} + \\epsilon_{ij}$  \n  \nLevel 2:  \n  \n+ $\\beta_{0i} = \\gamma_{00} + \\zeta_{0i}$   \n\nWhere the expected values of $\\zeta_{0}$, and $\\epsilon$ are 0, and their variances are $\\sigma_{0}^2$ and $\\sigma_\\epsilon^2$ respectively. We will further assume that these are normally distributed.\n\nWe can now see that the intercept estimate $\\beta_{0i}$ for a particular group $i$ is represented by the combination of a mean estimate for the parameter ($\\gamma_{00}$) and a random effect for that group ($\\zeta_{0i}$).\n\n**R command:**  \n  \n+ `lmer(outcome ~ predictor + (1 | grouping), data = dataframe)`  \n  \n:::\n\nNotice how the fitted line of the random intercept model has an adjustment for each subject.  \nEach subject's line has been moved up or down accordingly. \n\n```{r}\n#| echo: false\n#| fig-height: 8\n#| fig-width: 12\n#| out-width: \"100%\"\nplot_lm_fac + plot_ri_fac\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Shrinkage\n\nIf you think about it, we might have done a similar thing to the random intercept with the tools we already had at our disposal, by using `lm(y~x+subject)`.\nThis would give us a coefficient for the difference between each subject and the reference level intercept, or we could extend this to `lm(y~x*subject)` to give us an adjustment to the slope for each subject.  \n  \nHowever, the estimate of these models will be slightly different:  \n\n```{r}\n#| echo: false\nplot_shrinkage\n```\n\n**Why?** One of the benefits of multi-level models is that our cluster-level estimates are shrunk towards the average depending on a) the level of across-cluster variation and b) the number of datapoints in clusters. \n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Random slopes\n\n:::frame \n\n**Formula:**  \nLevel 1:  \n  \n+ $y_{ij} = \\beta_{0i} + \\beta_{1i} x_{ij} + \\epsilon_{ij}$  \n  \nLevel 2:  \n  \n+ $\\beta_{0i} = \\gamma_{00} + \\zeta_{0i}$  \n+ $\\beta_{1i} = \\gamma_{10} + \\zeta_{1i}$  \n\nWhere the expected values of $\\zeta_0$, $\\zeta_1$, and $\\epsilon$ are 0, and their variances are $\\sigma_{0}^2$, $\\sigma_{1}^2$, $\\sigma_\\epsilon^2$ respectively. We will further assume that these are normally distributed.\n\nAs with the intercept $\\beta_{0i}$, the slope of the predictor $\\beta_{1i}$ is now modelled by a mean $\\gamma_{10}$ and a random effect for each group ($\\zeta_{1i}$). \n\n\n**R command:** \n  \n+ `lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)`  \n  \n*Note:* this is the same as `lmer(outcome ~ predictor + (predictor | grouping), data = dataframe)` . Like in the fixed-effects part, the `1 +` is assumed in the random-effects part.\n\n:::\n\n```{r}\n#| echo: false\n#| fig-height: 8\n#| fig-width: 12\nplot_ri_fac + plot_rs_fac\n```\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Model parameters: Fixed effects\n\nThe plot below show the fitted values for each subject from the random slopes model `lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)`  \n\n```{r}\n#| echo: false\nplot_rs\n```\n\nThe thick green line shows the fixed intercept and slope around which the groups all vary randomly.  \n\nThe *fixed effects* are the parameters that define the thick green line, and we can extract them using the `fixef()` function:\n\nThese are the overall intercept and slope. Think of these as the estimated intercept and slope for the average group.  \n```{r}\nfixef(random_slopes_model)\n```\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Model parameters: Variance components\n\nAs well as estimating the fixed effects, multilevel models are also defined by the \"variance components\". These are the variances and covariances of the random effects. \n\ni.e. how much do groups vary in around the fixed intercept? and around the fixed slope? Do groups with higher intercepts also have higher slopes (this is the correlation).  \n\n```{r}\n#| echo: false\nplot_rs / (pltints + pltslops)\n```\n\nWe can extract these using the `VarCorr()` function, and we can also see them in the \"random effects\" part of the `summary()` output from a model.  \n\n```{r}\nVarCorr(random_slopes_model)\n```\n\n:::imp\nRemember, variance is just standard deviation squared!  \n:::\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Group-specific random effects\n\nThe plots below show the fitted values for each subject from each model that we have gone through in these expandable boxes (simple linear regression, random intercept, and random intercept & slope): \n\n```{r}\n#| echo: false\n#| fig-width: 12\nplotdata2<-\n  ggplot(dat, aes(x=x1,y=outcome, col=subject))+\n  geom_point(alpha=0.5)+geom_path(alpha=0.5)+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)+\n  labs(title=\"- The data (by subject) - \", y=\"y\", x=\"x\")+\n  NULL\n\n#(plot_data + plotdata2 ) / (plot_lm2 + plot_ri + plot_rs)\nplot_lm2 + plot_ri + plot_rs\n```\n\nIn the random-intercept model (center panel), the differences from each of the subjects' intercepts to the fixed intercept (thick green line) have mean 0 and standard deviation $\\sigma_0$.  The standard deviation (and variance, which is $\\sigma_0^2$) is what we see in the random effects part of our model summary (or using the `VarCorr()` function).  \n\n```{r}\n#| echo: false\n#| out-width: \"400px\"\nknitr::include_graphics(\"images/varcors.PNG\")\n```\n\nIn the random-slope model (right panel), the same is true for the differences from each subjects' slope to the fixed slope. \nWe can extract the deviations for each group from the fixed effect estimates using the `ranef()` function.  \n  \nThese are the deviations from the overall intercept ($\\widehat \\gamma_{00} = `r b1[1]`$) and slope ($\\widehat \\gamma_{10} = `r b1[2]`$) for each subject $i$.  \n```{r}\nranef(random_slopes_model)\n```\n::: \n\n\n\n::: {.callout-note collapse=\"true\"}\n## Group-specific coefficients\n\nWe can see the estimated intercept and slope for each subject $i$ specifically, using the `coef()` function.  \n\n```{r}\ncoef(random_slopes_model)\n```\n\nNotice that the above are the fixed effects + random effects estimates, i.e. the overall intercept and slope + deviations for each subject.\n\n```{r}\ncbind(\n  int = fixef(random_slopes_model)[1] + \n    ranef(random_slopes_model)$subject[,1],\n  slope = fixef(random_slopes_model)[2] + \n    ranef(random_slopes_model)$subject[,2]\n)\n```\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Assumptions, Influence\n\nIn the simple linear model $\\color{red}{y} = \\color{blue}{\\beta_0 + \\beta_1(x)} + \\varepsilon$, we distinguished between the systematic model part $\\beta_0 + \\beta_1(x)$, around which observations randomly vary (the $\\varepsilon$ part) - i.e. $\\color{red}{\\text{outcome}} = \\color{blue}{\\text{model}} + \\text{error}$.  \n\nIn the multi-level model, our random effects are another source of random variation - $\\color{red}{\\text{outcome}} = \\color{blue}{\\text{model}} + \\text{group_error} + \\text{individual_error}$. As such, random effects are another form of residual, and our assumptions of zero mean constant variance apply at both levels of residuals (see @fig-assump).   \n\n```{r}\n#| echo: false\n#| label: fig-assump\n#| fig-cap: \"The black dashed lines show our model assumptions.\"\nknitr::include_graphics(\"images/assump.png\")\n```\n\n- We can assess these normality of both `resid(model)` and `ranef(model)` by constructing plots using functions such as `hist()`, `qqnorm()` and `qqline()`.   \n- We can also use `plot(model, type=c(\"p\",\"smooth\"))` to give us our residuals vs fitted plot (smooth line should be horizontal at approx zero, showing zero mean).  \n- `plot(model, form = sqrt(abs(resid(.))) ~ fitted(.), type = c(\"p\",\"smooth\"))` will give us our scale-location plot (smooth line should be horizontal, showing constant variance).  \n\nWe can also use the `check_model()` function from the __performance__ package to get lots of info at once:  \n```{r}\nlibrary(performance)\ncheck_model(random_slopes_model)\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Inference\n\n|                  | df approximations                                                  | likelihood-based                                                    | case-based bootstrap |\n| ---------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------- | -------------------- |\n| tests or CIs for model parameters | `library(parameters)`<br>`model_parameters(model, ci_method=\"kr\")` | `confint(model, type=\"profile\")`                                    |`library(lmeresampler)`<br>`bootstrap(model, .f=fixef, type=\"case\", B = 2000, resample = c(??,??))`                      | \n| model comparison<br><small>(different fixed effects, same random effects)</small> | `library(pbkrtest)`<br>`KRmodcomp(model1,model0)`                  | `anova(model0,model)`                                               |                      |\n|                  | fit models with `REML=TRUE`.<br>good option for small samples      | fit models with `REML=FALSE`.<br>needs large N at both levels (40+) | takes time, needs careful thought about which levels to resample, but means we can relax distributional assumptions (e.g. about normality of residuals)                     |\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Visualising Model Fitted values\n\nThe model fitted (or \"model predicted\") values can be obtained using `predict()` (returning just the values) or `broom.mixed::augment()` (returning the values attached to the data that is inputted to the model).   \n\nTo plot, them, we would typically like to plot the fitted values for each group (e.g. subject)\n\n```{r}\nlibrary(broom.mixed)\naugment(random_slopes_model) %>%\n  ggplot(.,aes(x=x1, y=.fitted, group=subject))+\n  geom_line()\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Visualising Fixed Effects\n\nIf we want to plot the fixed effects from our model, we have to do something else. Packages like __sjPlot__ make it incredibly easy (but sometimes _too_ easy), so a nice option is to use the __effects__ package to construct a dataframe of the linear prediction accross the values of a predictor, plus standard errors and confidence intervals. We can then pass this to `ggplot()`, giving us all the control over the aesthetics.  \n\n```{r}\n#| eval: false\n# a quick option:  \nlibrary(sjPlot)\nplot_model(random_slopes_model, type = \"eff\")\n```\n\n\n```{r}\n# when you want more control\nlibrary(effects)\nef <- as.data.frame(effect(term=\"x1\",mod=random_slopes_model))\nggplot(ef, aes(x=x1,y=fit, ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Plotting random effects\n\nThe quick and easy way to plot your random effects is to use the `dotplot.ranef.mer()` function in `lme4`. \n\n```{r}\nrandoms <- ranef(random_slopes_model, condVar=TRUE)\ndotplot.ranef.mer(randoms)\n```\n\n<!-- `r optbegin(\"Completely optional - extracting them for plotting in ggplot\", olabel=FALSE, toggle=params$TOGGLE)` -->\n<!-- Sometimes, however, we might want to have a bit more control over our plotting, we can extract the estimates and correlations for each subject:   -->\n<!-- ```{r} -->\n<!-- #we can get the random effects: -->\n<!-- #(note that we use $subject because there might be other groupings, and the ranef() function will give us a list, with one element for each grouping variable) -->\n<!-- randoms <- -->\n<!--   ranef(random_slopes_model)$subject %>% -->\n<!--   mutate(subject = row.names(.)) %>%  # the subject IDs are stored in the rownames, so lets add them as a variable -->\n<!--   pivot_longer(cols=1:2, names_to=\"term\",values_to=\"estimate\") # finally, let's reshape it for plotting -->\n\n<!-- #and the same for the standard errors (from the arm package): -->\n<!-- randoms_se <- -->\n<!--   arm::se.ranef(random_slopes_model)$subject %>% -->\n<!--   as.data.frame() %>% -->\n<!--   mutate(subject = row.names(.)) %>% -->\n<!--   pivot_longer(cols=1:2, names_to=\"term\",values_to=\"se\") -->\n\n<!-- # join them together: -->\n<!-- ranefs_plotting <- left_join(randoms, randoms_se) -->\n\n<!-- # it's easier for plotting if we -->\n<!-- ggplot(ranefs_plotting, aes(y=subject, x=estimate))+ -->\n<!--   geom_errorbarh(aes(xmin=estimate-2*se, xmax=estimate+2*se))+ -->\n<!--   facet_wrap(~term, scales=\"free_x\") -->\n\n<!-- ``` -->\n\n<!-- `r optend()` -->\n\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Nested and Crossed structures\n\nThe same principle we have seen for one level of clustering can be extended to clustering at different levels (for instance, observations are clustered within subjects, which are in turn clustered within groups). \n\nConsider the example where we have observations for each student in every class within a number of schools:  \n\n```{r}\n#| echo: false\n#| out-width: \"1200px\"\nknitr::include_graphics(\"images/structure_nestednew.png\")\n```\n\n**Question:** Is \"Class 1\" in \"School 1\" the same as \"Class 1\" in \"School 2\"?  \n  \nNo.  \nThe classes in one school are distinct from the classes in another **even though they are named the same**.  \n  \nThe classes-within-schools example is a good case of **nested random effects** - one factor level (one group in a grouping varible) appears *only within* a particular level of another grouping variable.  \n  \nIn R, we can specify this using:  \n  \n`(1 | school) + (1 | class:school)`  \n  \nor, more succinctly:  \n  \n`(1 | school/class)`  \n\nConsider another example, where we administer the same set of tasks at multiple time-points for every participant.  \n  \n**Question:** Are tasks nested within participants?  \n  \nNo.  \nTasks are seen by multiple participants (and participants see multiple tasks).  \n  \nWe could visualise this as the below:  \n```{r}\n#| echo: false\n#| out-width: \"400px\"\nknitr::include_graphics(\"images/structure_crossednew.png\")\n```\n\nIn the sense that these are not nested, they are **crossed** random effects.  \n  \nIn R, we can specify this using:  \n\n`(1 | subject) + (1 | task)`  \n\n:::blue\n**Nested vs Crossed**  \n\n*Nested:* Each group belongs uniquely to a higher-level group.   \n\n*Crossed:* Not-nested. \n\n:::\n\nNote that in the schools and classes example, had we changed data such that the classes had unique IDs (e.g., see below), then the structures `(1 | school) + (1 | class)` and `(1 | school/class)` would give the same results.  \n```{r}\n#| echo: false\n#| out-width: \"1200px\"\nknitr::include_graphics(\"images/structure_nestedlabnew.png\")\n```\n\n:::\n\n---\n\n::: {.callout-tip collapse=\"true\" icon=false appearance=\"simple\"}\n## MLM in a nutshell\n\nMLM allows us to model effects in the linear model as _varying_ between groups. Our coefficients we remember from simple linear models (the $\\beta$'s) are modelled as a distribution that has an overall mean around which our groups vary. We can see this in @fig-unlmm, where both the intercept and the slope of the line are modelled as varying by-groups. @fig-unlmm shows the overall line in blue, with a given group's line in green.  \n\n\n```{r}\n#| label: fig-unlmm\n#| fig-cap: \"Multilevel Model. Each group (e.g. the group in the green line) deviates from the overall fixed effects (the blue line), and the individual observations (green points) deviate from their groups line\" \n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics('images/un_lmm.png')\n```\n\nThe formula notation for these models involves separating out our effects $\\beta$ into two parts: the overall effect $\\gamma$ + the group deviations $\\zeta_i$:  \n\n$$\n\\begin{align}\n& \\text{for observation }j\\text{ in group }i \\\\\n\\quad \\\\\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}}\\color{black} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1i} \\cdot x_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{\\beta_{1i}}\\color{black} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\quad \\\\\n& \\text{Where:} \\\\\n& \\gamma_{00}\\text{ is the population intercept, and }\\color{orange}{\\zeta_{0i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{00} \\\\\n& \\gamma_{10}\\text{ is the population slope, and }\\color{orange}{\\zeta_{1i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{10} \\\\\n\\end{align}\n$$\n\nThe group-specific deviations $\\zeta_{0i}$ from the overall intercept are assumed to be normally distributed with mean $0$ and variance $\\sigma_0^2$. Similarly, the deviations $\\zeta_{1i}$ of the slope for group $i$ from the overall slope are assumed to come from a normal distribution with mean $0$ and variance $\\sigma_1^2$. The correlation between random intercepts and slopes is $\\rho = \\text{Cor}(\\zeta_{0i}, \\zeta_{1i}) = \\frac{\\sigma_{01}}{\\sigma_0 \\sigma_1}$:\n\n$$\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix} \n\\sim N\n\\left(\n    \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \n    \\begin{bmatrix} \n        \\sigma_0^2 & \\rho \\sigma_0 \\sigma_1 \\\\\n        \\rho \\sigma_0 \\sigma_1 & \\sigma_1^2\n    \\end{bmatrix}\n\\right)\n$$\n\nThe random errors, independently from the random effects, are assumed to be normally distributed with a mean of zero  \n$$\n\\epsilon_{ij} \\sim N(0, \\sigma_\\epsilon^2)\n$$\n\nWe fit these models using the R package __lme4__, and the function `lmer()`. \nThink of it like building your linear model `lm(y ~ 1 + x)`, and then allowing effects (i.e. things on the right hand side of the `~` symbol) to vary by the grouping of your data. We specify these by adding `(vary these effects | by these groups)` to the model: \n```{r}\n#| echo: false\nread_csv(\"https://uoepsy.github.io/data/toyexample.csv\") %>% \n  transmute(\n    x = round(hrs_week,2),\n    y = round(R_AGE,1),\n    obs = paste0(\"child_\",as.numeric(as.factor(toy))),\n    group = paste0(\"school_\",as.numeric(as.factor(toy_type)))\n  ) -> df\n```\n```{r}\nlibrary(lme4)\nm1 <- lmer(y ~ x + (1 + x | group), data = df)\nsummary(m1)\n```\n\n```{r}\n#| echo: false\nb1 <- fixef(m1) %>% round(3)\nu1 <- ranef(m1)$group %>% round(3)\nsu <- as.data.frame(VarCorr(m1))[, 5] %>% round(3)\ns <- sigma(m1) %>% round(3)\n```\n\nThe summary of the `lmer` output returns estimated values for\n\nFixed effects:\n\n- $\\widehat \\gamma_{00} = `r b1[1]`$ \n- $\\widehat \\gamma_{10} = `r b1[2]`$\n\nVariability of random effects:\n\n- $\\widehat \\sigma_{0} = `r su[1]`$\n- $\\widehat \\sigma_{1} = `r su[2]`$\n\nCorrelation of random effects:\n\n- $\\widehat \\rho = `r su[3]`$\n\nResiduals:\n\n- $\\widehat \\sigma_\\epsilon = `r su[4]`$\n\n:::\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Practice Datasets Weeks 4 and 5\n\nBelow are various datasets on which you can try out your new-found modelling skills. Read the descriptions carefully, keeping in mind the explanation of how the data is collected and the research question that motivates the study design.  \nAll datasets with hierarchical structures that we have seen in DAPR3 can be found [here](05b_lmmdatasets.html){target=\"_blank\"}. \n\n::: {.callout-note collapse=\"true\"}\n#### Practice 1: Music and Driving \n\nThese data are simulated to represent data from a fake experiment, in which participants were asked to drive around a route in a 30mph zone. Each participant completed the route 3 times (i.e. \"repeated measures\"), but each time they were listening to different audio (either speech, classical music or rap music). Their average speed across the route was recorded. \nThis is a fairly simple design, that we might use to ask **\"how is the type of audio being listened to associated with driving speeds?\"** \n\nThe data are available at [https://uoepsy.github.io/data/drivingmusicwithin.csv](https://uoepsy.github.io/data/drivingmusicwithin.csv).  \n\n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/drivingmusicwithin.csv\")),\n  description = c(\"Participant Identifier\",\"Avg Speed Driven on Route (mph)\",\"Music listened to while driving (classical music / rap music / spoken word)\")\n) |> gt::gt()\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 2: CBT and Stress\n\nThese data are simulated to represent data from 50 participants, each measured at 3 different time-points (pre, during, and post) on a measure of stress. Participants were randomly allocated such that half received some cognitive behavioural therapy (CBT) treatment, and half did not. This study is interested in assessing **whether the two groups (control vs treatment) differ in how stress changes across the 3 time points**. \n\nThe data are available at [https://uoepsy.github.io/data/stressint.csv](https://uoepsy.github.io/data/stressint.csv).  \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/stressint.csv\")),\n  description = c(\"Participant Identifier\",\"Stress (range 0 to 100)\",\"Time (pre/post/during)\",\n                  \"Whether participant is in the CBT group or control group\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 3: Erm.. I don't believe you\n\nThese data are simulated to represent data from 30 participants who took part in an experiment designed to investigate **whether fluency of speech influences how believable an utterance is perceived to be**.  \n\nEach participant listened to the same 20 statements, with 10 being presented in fluent speech, and 10 being presented with a disfluency (an \"erm, ...\"). Fluency of the statements was counterbalanced such that 15 participants heard statements 1 to 10 as fluent and 11 to 20 as disfluent, and the remaining 15 participants heard statements 1 to 10 as disfluent, and 11 to 20 as fluent. The order of the statements presented to each participant was random. Participants rated each statement on how believable it is on a scale of 0 to 100.  \n\nThe data are available at [https://uoepsy.github.io/data/erm_belief.csv](https://uoepsy.github.io/data/erm_belief.csv). \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/erm_belief.csv\")),\n  description = c(\"Participant Identifier\",\"Trial number\", \"Statement identifier\", \"Condition (fluent v disfluent)\", \"belief rating (0-100)\", \"Statement\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 4: Cognitive Aging\n\nThese data are simulated to represent a large scale international study of cognitive aging, for which data from 17 research centers has been combined. The study team are interested in **whether different cognitive domains have different trajectories as people age**. Do all cognitive domains decline at the same rate? Do some decline more steeply, and some less? The literature suggests that scores on cognitive ability are predicted by educational attainment, so they would like to control for this.  \n\nEach of the 17 research centers recruited a minimum of 14 participants (Median = 21, Range 14-29) at age 45, and recorded their level of education (in years). Participants were then tested on 5 cognitive domains: processing speed, spatial visualisation, memory, reasoning, and vocabulary. Participants were contacted for follow-up on a further 9 occasions (resulting in 10 datapoints for each participant), and at every follow-up they were tested on the same 5 cognitive domains. Follow-ups were on average 3 years apart (Mean = 3, SD = 0.8). \n\nThe data are available at [https://uoepsy.github.io/data/cogdecline.csv](https://uoepsy.github.io/data/cogdecline.csv). \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/cogdecline.csv\")),\n  description = c(\"Center ID\",\"Participant Identifier\",\"Educational attainment (years of education)\",\"Age at visit (years)\",\n                  \"Score on Processing Speed domain task\",\n                  \"Score on Spatial Visualisation domain task\",\n                  \"Score on Memory domain task\",\n                  \"Score on Reasoning domain task\",\n                  \"Score on Vocabulary domain task\"\n                  )\n) |> gt::gt()\n```\n\n:::\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(effects)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\n```\n\n\n\n# Flashcards: `lm` to `lmer`\n\n```{r}\n#| echo: false\nrequire(patchwork)\nsource(\"plottingmixedmods.R\")\nrandom_intercept_model = mod2\nrandom_slopes_model = mod3\nb1 <- fixef(mod3) %>% round(3)\nu1 <- ranef(mod3)$subject %>% round(3)\nsu <- as.data.frame(VarCorr(mod3))[, 5] %>% round(3)\ns <- sigma(mod3) %>% round(3)\n```\n\n\nIn a simple linear regression, there is only considered to be one source of random variability: any variability left unexplained by a set of predictors (which are modelled as fixed estimates) is captured in the model residuals.  \n  \nMulti-level (or 'mixed-effects') approaches involve modelling more than one source of random variability - as well as variance resulting from taking a random sample of observations, we can identify random variability across different groups of observations. For example, if we are studying a patient population in a hospital, we would expect there to be variability across the our sample of patients, but also across the doctors who treat them.  \n  \nWe can account for this variability by allowing the outcome to be lower/higher for each group (a random intercept) and by allowing the estimated effect of a predictor vary across groups (random slopes).  \n  \n:::blue\nBefore you expand each of the boxes below, think about how comfortable you feel with each concept.  \nThis content is very cumulative, which means often going back to try to isolate the place which we need to focus efforts in learning. \n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Simple Linear Regression\n\n:::frame\n**Formula:**  \n  \n+ $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$  \n  \n**R command:**  \n  \n+ `lm(outcome ~ predictor, data = dataframe)`  \n  \n*Note:* this is the same as `lm(outcome ~ 1 + predictor, data = dataframe)`. The `1 +` is always there unless we specify otherwise (e.g., by using `0 +`).\n\n:::\n\n\n```{r}\n#| echo: false\nplot_data + plot_lm\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Clustered (multi-level) data\n\nWhen our data is clustered (or 'grouped') such that datapoints are no longer independent, but belong to some grouping such as that of multiple observations from the same subject, we have multiple sources of random variability. A simple regression does not capture this.  \n\nIf we separate out our data to show an individual plot for each grouping (in this data the grouping is by subjects), we can see how the fitted regression line from `lm()` is assumed to be the same for each group.  \n  \n```{r}\n#| echo: false\n#| fig-height: 10\nplot_lm_fac\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Random intercepts\n\nBy including a random-intercept term, we are letting our model estimate random variability around an average parameter (represented by the fixed effects) for the clusters.\n\n:::frame \n\n**Formula:**  \nLevel 1:  \n  \n+ $y_{ij} = \\beta_{0i} + \\beta_{1i} x_{ij} + \\epsilon_{ij}$  \n  \nLevel 2:  \n  \n+ $\\beta_{0i} = \\gamma_{00} + \\zeta_{0i}$   \n\nWhere the expected values of $\\zeta_{0}$, and $\\epsilon$ are 0, and their variances are $\\sigma_{0}^2$ and $\\sigma_\\epsilon^2$ respectively. We will further assume that these are normally distributed.\n\nWe can now see that the intercept estimate $\\beta_{0i}$ for a particular group $i$ is represented by the combination of a mean estimate for the parameter ($\\gamma_{00}$) and a random effect for that group ($\\zeta_{0i}$).\n\n**R command:**  \n  \n+ `lmer(outcome ~ predictor + (1 | grouping), data = dataframe)`  \n  \n:::\n\nNotice how the fitted line of the random intercept model has an adjustment for each subject.  \nEach subject's line has been moved up or down accordingly. \n\n```{r}\n#| echo: false\n#| fig-height: 8\n#| fig-width: 12\n#| out-width: \"100%\"\nplot_lm_fac + plot_ri_fac\n```\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Shrinkage\n\nIf you think about it, we might have done a similar thing to the random intercept with the tools we already had at our disposal, by using `lm(y~x+subject)`.\nThis would give us a coefficient for the difference between each subject and the reference level intercept, or we could extend this to `lm(y~x*subject)` to give us an adjustment to the slope for each subject.  \n  \nHowever, the estimate of these models will be slightly different:  \n\n```{r}\n#| echo: false\nplot_shrinkage\n```\n\n**Why?** One of the benefits of multi-level models is that our cluster-level estimates are shrunk towards the average depending on a) the level of across-cluster variation and b) the number of datapoints in clusters. \n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Random slopes\n\n:::frame \n\n**Formula:**  \nLevel 1:  \n  \n+ $y_{ij} = \\beta_{0i} + \\beta_{1i} x_{ij} + \\epsilon_{ij}$  \n  \nLevel 2:  \n  \n+ $\\beta_{0i} = \\gamma_{00} + \\zeta_{0i}$  \n+ $\\beta_{1i} = \\gamma_{10} + \\zeta_{1i}$  \n\nWhere the expected values of $\\zeta_0$, $\\zeta_1$, and $\\epsilon$ are 0, and their variances are $\\sigma_{0}^2$, $\\sigma_{1}^2$, $\\sigma_\\epsilon^2$ respectively. We will further assume that these are normally distributed.\n\nAs with the intercept $\\beta_{0i}$, the slope of the predictor $\\beta_{1i}$ is now modelled by a mean $\\gamma_{10}$ and a random effect for each group ($\\zeta_{1i}$). \n\n\n**R command:** \n  \n+ `lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)`  \n  \n*Note:* this is the same as `lmer(outcome ~ predictor + (predictor | grouping), data = dataframe)` . Like in the fixed-effects part, the `1 +` is assumed in the random-effects part.\n\n:::\n\n```{r}\n#| echo: false\n#| fig-height: 8\n#| fig-width: 12\nplot_ri_fac + plot_rs_fac\n```\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Model parameters: Fixed effects\n\nThe plot below show the fitted values for each subject from the random slopes model `lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)`  \n\n```{r}\n#| echo: false\nplot_rs\n```\n\nThe thick green line shows the fixed intercept and slope around which the groups all vary randomly.  \n\nThe *fixed effects* are the parameters that define the thick green line, and we can extract them using the `fixef()` function:\n\nThese are the overall intercept and slope. Think of these as the estimated intercept and slope for the average group.  \n```{r}\nfixef(random_slopes_model)\n```\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Model parameters: Variance components\n\nAs well as estimating the fixed effects, multilevel models are also defined by the \"variance components\". These are the variances and covariances of the random effects. \n\ni.e. how much do groups vary in around the fixed intercept? and around the fixed slope? Do groups with higher intercepts also have higher slopes (this is the correlation).  \n\n```{r}\n#| echo: false\nplot_rs / (pltints + pltslops)\n```\n\nWe can extract these using the `VarCorr()` function, and we can also see them in the \"random effects\" part of the `summary()` output from a model.  \n\n```{r}\nVarCorr(random_slopes_model)\n```\n\n:::imp\nRemember, variance is just standard deviation squared!  \n:::\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Group-specific random effects\n\nThe plots below show the fitted values for each subject from each model that we have gone through in these expandable boxes (simple linear regression, random intercept, and random intercept & slope): \n\n```{r}\n#| echo: false\n#| fig-width: 12\nplotdata2<-\n  ggplot(dat, aes(x=x1,y=outcome, col=subject))+\n  geom_point(alpha=0.5)+geom_path(alpha=0.5)+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)+\n  labs(title=\"- The data (by subject) - \", y=\"y\", x=\"x\")+\n  NULL\n\n#(plot_data + plotdata2 ) / (plot_lm2 + plot_ri + plot_rs)\nplot_lm2 + plot_ri + plot_rs\n```\n\nIn the random-intercept model (center panel), the differences from each of the subjects' intercepts to the fixed intercept (thick green line) have mean 0 and standard deviation $\\sigma_0$.  The standard deviation (and variance, which is $\\sigma_0^2$) is what we see in the random effects part of our model summary (or using the `VarCorr()` function).  \n\n```{r}\n#| echo: false\n#| out-width: \"400px\"\nknitr::include_graphics(\"images/varcors.PNG\")\n```\n\nIn the random-slope model (right panel), the same is true for the differences from each subjects' slope to the fixed slope. \nWe can extract the deviations for each group from the fixed effect estimates using the `ranef()` function.  \n  \nThese are the deviations from the overall intercept ($\\widehat \\gamma_{00} = `r b1[1]`$) and slope ($\\widehat \\gamma_{10} = `r b1[2]`$) for each subject $i$.  \n```{r}\nranef(random_slopes_model)\n```\n::: \n\n\n\n::: {.callout-note collapse=\"true\"}\n## Group-specific coefficients\n\nWe can see the estimated intercept and slope for each subject $i$ specifically, using the `coef()` function.  \n\n```{r}\ncoef(random_slopes_model)\n```\n\nNotice that the above are the fixed effects + random effects estimates, i.e. the overall intercept and slope + deviations for each subject.\n\n```{r}\ncbind(\n  int = fixef(random_slopes_model)[1] + \n    ranef(random_slopes_model)$subject[,1],\n  slope = fixef(random_slopes_model)[2] + \n    ranef(random_slopes_model)$subject[,2]\n)\n```\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Assumptions, Influence\n\nIn the simple linear model $\\color{red}{y} = \\color{blue}{\\beta_0 + \\beta_1(x)} + \\varepsilon$, we distinguished between the systematic model part $\\beta_0 + \\beta_1(x)$, around which observations randomly vary (the $\\varepsilon$ part) - i.e. $\\color{red}{\\text{outcome}} = \\color{blue}{\\text{model}} + \\text{error}$.  \n\nIn the multi-level model, our random effects are another source of random variation - $\\color{red}{\\text{outcome}} = \\color{blue}{\\text{model}} + \\text{group_error} + \\text{individual_error}$. As such, random effects are another form of residual, and our assumptions of zero mean constant variance apply at both levels of residuals (see @fig-assump).   \n\n```{r}\n#| echo: false\n#| label: fig-assump\n#| fig-cap: \"The black dashed lines show our model assumptions.\"\nknitr::include_graphics(\"images/assump.png\")\n```\n\n- We can assess these normality of both `resid(model)` and `ranef(model)` by constructing plots using functions such as `hist()`, `qqnorm()` and `qqline()`.   \n- We can also use `plot(model, type=c(\"p\",\"smooth\"))` to give us our residuals vs fitted plot (smooth line should be horizontal at approx zero, showing zero mean).  \n- `plot(model, form = sqrt(abs(resid(.))) ~ fitted(.), type = c(\"p\",\"smooth\"))` will give us our scale-location plot (smooth line should be horizontal, showing constant variance).  \n\nWe can also use the `check_model()` function from the __performance__ package to get lots of info at once:  \n```{r}\nlibrary(performance)\ncheck_model(random_slopes_model)\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Inference\n\n|                  | df approximations                                                  | likelihood-based                                                    | case-based bootstrap |\n| ---------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------- | -------------------- |\n| tests or CIs for model parameters | `library(parameters)`<br>`model_parameters(model, ci_method=\"kr\")` | `confint(model, type=\"profile\")`                                    |`library(lmeresampler)`<br>`bootstrap(model, .f=fixef, type=\"case\", B = 2000, resample = c(??,??))`                      | \n| model comparison<br><small>(different fixed effects, same random effects)</small> | `library(pbkrtest)`<br>`KRmodcomp(model1,model0)`                  | `anova(model0,model)`                                               |                      |\n|                  | fit models with `REML=TRUE`.<br>good option for small samples      | fit models with `REML=FALSE`.<br>needs large N at both levels (40+) | takes time, needs careful thought about which levels to resample, but means we can relax distributional assumptions (e.g. about normality of residuals)                     |\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Visualising Model Fitted values\n\nThe model fitted (or \"model predicted\") values can be obtained using `predict()` (returning just the values) or `broom.mixed::augment()` (returning the values attached to the data that is inputted to the model).   \n\nTo plot, them, we would typically like to plot the fitted values for each group (e.g. subject)\n\n```{r}\nlibrary(broom.mixed)\naugment(random_slopes_model) %>%\n  ggplot(.,aes(x=x1, y=.fitted, group=subject))+\n  geom_line()\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Visualising Fixed Effects\n\nIf we want to plot the fixed effects from our model, we have to do something else. Packages like __sjPlot__ make it incredibly easy (but sometimes _too_ easy), so a nice option is to use the __effects__ package to construct a dataframe of the linear prediction accross the values of a predictor, plus standard errors and confidence intervals. We can then pass this to `ggplot()`, giving us all the control over the aesthetics.  \n\n```{r}\n#| eval: false\n# a quick option:  \nlibrary(sjPlot)\nplot_model(random_slopes_model, type = \"eff\")\n```\n\n\n```{r}\n# when you want more control\nlibrary(effects)\nef <- as.data.frame(effect(term=\"x1\",mod=random_slopes_model))\nggplot(ef, aes(x=x1,y=fit, ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Plotting random effects\n\nThe quick and easy way to plot your random effects is to use the `dotplot.ranef.mer()` function in `lme4`. \n\n```{r}\nrandoms <- ranef(random_slopes_model, condVar=TRUE)\ndotplot.ranef.mer(randoms)\n```\n\n<!-- `r optbegin(\"Completely optional - extracting them for plotting in ggplot\", olabel=FALSE, toggle=params$TOGGLE)` -->\n<!-- Sometimes, however, we might want to have a bit more control over our plotting, we can extract the estimates and correlations for each subject:   -->\n<!-- ```{r} -->\n<!-- #we can get the random effects: -->\n<!-- #(note that we use $subject because there might be other groupings, and the ranef() function will give us a list, with one element for each grouping variable) -->\n<!-- randoms <- -->\n<!--   ranef(random_slopes_model)$subject %>% -->\n<!--   mutate(subject = row.names(.)) %>%  # the subject IDs are stored in the rownames, so lets add them as a variable -->\n<!--   pivot_longer(cols=1:2, names_to=\"term\",values_to=\"estimate\") # finally, let's reshape it for plotting -->\n\n<!-- #and the same for the standard errors (from the arm package): -->\n<!-- randoms_se <- -->\n<!--   arm::se.ranef(random_slopes_model)$subject %>% -->\n<!--   as.data.frame() %>% -->\n<!--   mutate(subject = row.names(.)) %>% -->\n<!--   pivot_longer(cols=1:2, names_to=\"term\",values_to=\"se\") -->\n\n<!-- # join them together: -->\n<!-- ranefs_plotting <- left_join(randoms, randoms_se) -->\n\n<!-- # it's easier for plotting if we -->\n<!-- ggplot(ranefs_plotting, aes(y=subject, x=estimate))+ -->\n<!--   geom_errorbarh(aes(xmin=estimate-2*se, xmax=estimate+2*se))+ -->\n<!--   facet_wrap(~term, scales=\"free_x\") -->\n\n<!-- ``` -->\n\n<!-- `r optend()` -->\n\n::: \n\n::: {.callout-note collapse=\"true\"}\n## Nested and Crossed structures\n\nThe same principle we have seen for one level of clustering can be extended to clustering at different levels (for instance, observations are clustered within subjects, which are in turn clustered within groups). \n\nConsider the example where we have observations for each student in every class within a number of schools:  \n\n```{r}\n#| echo: false\n#| out-width: \"1200px\"\nknitr::include_graphics(\"images/structure_nestednew.png\")\n```\n\n**Question:** Is \"Class 1\" in \"School 1\" the same as \"Class 1\" in \"School 2\"?  \n  \nNo.  \nThe classes in one school are distinct from the classes in another **even though they are named the same**.  \n  \nThe classes-within-schools example is a good case of **nested random effects** - one factor level (one group in a grouping varible) appears *only within* a particular level of another grouping variable.  \n  \nIn R, we can specify this using:  \n  \n`(1 | school) + (1 | class:school)`  \n  \nor, more succinctly:  \n  \n`(1 | school/class)`  \n\nConsider another example, where we administer the same set of tasks at multiple time-points for every participant.  \n  \n**Question:** Are tasks nested within participants?  \n  \nNo.  \nTasks are seen by multiple participants (and participants see multiple tasks).  \n  \nWe could visualise this as the below:  \n```{r}\n#| echo: false\n#| out-width: \"400px\"\nknitr::include_graphics(\"images/structure_crossednew.png\")\n```\n\nIn the sense that these are not nested, they are **crossed** random effects.  \n  \nIn R, we can specify this using:  \n\n`(1 | subject) + (1 | task)`  \n\n:::blue\n**Nested vs Crossed**  \n\n*Nested:* Each group belongs uniquely to a higher-level group.   \n\n*Crossed:* Not-nested. \n\n:::\n\nNote that in the schools and classes example, had we changed data such that the classes had unique IDs (e.g., see below), then the structures `(1 | school) + (1 | class)` and `(1 | school/class)` would give the same results.  \n```{r}\n#| echo: false\n#| out-width: \"1200px\"\nknitr::include_graphics(\"images/structure_nestedlabnew.png\")\n```\n\n:::\n\n---\n\n::: {.callout-tip collapse=\"true\" icon=false appearance=\"simple\"}\n## MLM in a nutshell\n\nMLM allows us to model effects in the linear model as _varying_ between groups. Our coefficients we remember from simple linear models (the $\\beta$'s) are modelled as a distribution that has an overall mean around which our groups vary. We can see this in @fig-unlmm, where both the intercept and the slope of the line are modelled as varying by-groups. @fig-unlmm shows the overall line in blue, with a given group's line in green.  \n\n\n```{r}\n#| label: fig-unlmm\n#| fig-cap: \"Multilevel Model. Each group (e.g. the group in the green line) deviates from the overall fixed effects (the blue line), and the individual observations (green points) deviate from their groups line\" \n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics('images/un_lmm.png')\n```\n\nThe formula notation for these models involves separating out our effects $\\beta$ into two parts: the overall effect $\\gamma$ + the group deviations $\\zeta_i$:  \n\n$$\n\\begin{align}\n& \\text{for observation }j\\text{ in group }i \\\\\n\\quad \\\\\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}}\\color{black} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1i} \\cdot x_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{\\beta_{1i}}\\color{black} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\quad \\\\\n& \\text{Where:} \\\\\n& \\gamma_{00}\\text{ is the population intercept, and }\\color{orange}{\\zeta_{0i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{00} \\\\\n& \\gamma_{10}\\text{ is the population slope, and }\\color{orange}{\\zeta_{1i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{10} \\\\\n\\end{align}\n$$\n\nThe group-specific deviations $\\zeta_{0i}$ from the overall intercept are assumed to be normally distributed with mean $0$ and variance $\\sigma_0^2$. Similarly, the deviations $\\zeta_{1i}$ of the slope for group $i$ from the overall slope are assumed to come from a normal distribution with mean $0$ and variance $\\sigma_1^2$. The correlation between random intercepts and slopes is $\\rho = \\text{Cor}(\\zeta_{0i}, \\zeta_{1i}) = \\frac{\\sigma_{01}}{\\sigma_0 \\sigma_1}$:\n\n$$\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix} \n\\sim N\n\\left(\n    \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \n    \\begin{bmatrix} \n        \\sigma_0^2 & \\rho \\sigma_0 \\sigma_1 \\\\\n        \\rho \\sigma_0 \\sigma_1 & \\sigma_1^2\n    \\end{bmatrix}\n\\right)\n$$\n\nThe random errors, independently from the random effects, are assumed to be normally distributed with a mean of zero  \n$$\n\\epsilon_{ij} \\sim N(0, \\sigma_\\epsilon^2)\n$$\n\nWe fit these models using the R package __lme4__, and the function `lmer()`. \nThink of it like building your linear model `lm(y ~ 1 + x)`, and then allowing effects (i.e. things on the right hand side of the `~` symbol) to vary by the grouping of your data. We specify these by adding `(vary these effects | by these groups)` to the model: \n```{r}\n#| echo: false\nread_csv(\"https://uoepsy.github.io/data/toyexample.csv\") %>% \n  transmute(\n    x = round(hrs_week,2),\n    y = round(R_AGE,1),\n    obs = paste0(\"child_\",as.numeric(as.factor(toy))),\n    group = paste0(\"school_\",as.numeric(as.factor(toy_type)))\n  ) -> df\n```\n```{r}\nlibrary(lme4)\nm1 <- lmer(y ~ x + (1 + x | group), data = df)\nsummary(m1)\n```\n\n```{r}\n#| echo: false\nb1 <- fixef(m1) %>% round(3)\nu1 <- ranef(m1)$group %>% round(3)\nsu <- as.data.frame(VarCorr(m1))[, 5] %>% round(3)\ns <- sigma(m1) %>% round(3)\n```\n\nThe summary of the `lmer` output returns estimated values for\n\nFixed effects:\n\n- $\\widehat \\gamma_{00} = `r b1[1]`$ \n- $\\widehat \\gamma_{10} = `r b1[2]`$\n\nVariability of random effects:\n\n- $\\widehat \\sigma_{0} = `r su[1]`$\n- $\\widehat \\sigma_{1} = `r su[2]`$\n\nCorrelation of random effects:\n\n- $\\widehat \\rho = `r su[3]`$\n\nResiduals:\n\n- $\\widehat \\sigma_\\epsilon = `r su[4]`$\n\n:::\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Practice Datasets Weeks 4 and 5\n\nBelow are various datasets on which you can try out your new-found modelling skills. Read the descriptions carefully, keeping in mind the explanation of how the data is collected and the research question that motivates the study design.  \nAll datasets with hierarchical structures that we have seen in DAPR3 can be found [here](05b_lmmdatasets.html){target=\"_blank\"}. \n\n::: {.callout-note collapse=\"true\"}\n#### Practice 1: Music and Driving \n\nThese data are simulated to represent data from a fake experiment, in which participants were asked to drive around a route in a 30mph zone. Each participant completed the route 3 times (i.e. \"repeated measures\"), but each time they were listening to different audio (either speech, classical music or rap music). Their average speed across the route was recorded. \nThis is a fairly simple design, that we might use to ask **\"how is the type of audio being listened to associated with driving speeds?\"** \n\nThe data are available at [https://uoepsy.github.io/data/drivingmusicwithin.csv](https://uoepsy.github.io/data/drivingmusicwithin.csv).  \n\n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/drivingmusicwithin.csv\")),\n  description = c(\"Participant Identifier\",\"Avg Speed Driven on Route (mph)\",\"Music listened to while driving (classical music / rap music / spoken word)\")\n) |> gt::gt()\n```\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 2: CBT and Stress\n\nThese data are simulated to represent data from 50 participants, each measured at 3 different time-points (pre, during, and post) on a measure of stress. Participants were randomly allocated such that half received some cognitive behavioural therapy (CBT) treatment, and half did not. This study is interested in assessing **whether the two groups (control vs treatment) differ in how stress changes across the 3 time points**. \n\nThe data are available at [https://uoepsy.github.io/data/stressint.csv](https://uoepsy.github.io/data/stressint.csv).  \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/stressint.csv\")),\n  description = c(\"Participant Identifier\",\"Stress (range 0 to 100)\",\"Time (pre/post/during)\",\n                  \"Whether participant is in the CBT group or control group\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 3: Erm.. I don't believe you\n\nThese data are simulated to represent data from 30 participants who took part in an experiment designed to investigate **whether fluency of speech influences how believable an utterance is perceived to be**.  \n\nEach participant listened to the same 20 statements, with 10 being presented in fluent speech, and 10 being presented with a disfluency (an \"erm, ...\"). Fluency of the statements was counterbalanced such that 15 participants heard statements 1 to 10 as fluent and 11 to 20 as disfluent, and the remaining 15 participants heard statements 1 to 10 as disfluent, and 11 to 20 as fluent. The order of the statements presented to each participant was random. Participants rated each statement on how believable it is on a scale of 0 to 100.  \n\nThe data are available at [https://uoepsy.github.io/data/erm_belief.csv](https://uoepsy.github.io/data/erm_belief.csv). \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/erm_belief.csv\")),\n  description = c(\"Participant Identifier\",\"Trial number\", \"Statement identifier\", \"Condition (fluent v disfluent)\", \"belief rating (0-100)\", \"Statement\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### Practice 4: Cognitive Aging\n\nThese data are simulated to represent a large scale international study of cognitive aging, for which data from 17 research centers has been combined. The study team are interested in **whether different cognitive domains have different trajectories as people age**. Do all cognitive domains decline at the same rate? Do some decline more steeply, and some less? The literature suggests that scores on cognitive ability are predicted by educational attainment, so they would like to control for this.  \n\nEach of the 17 research centers recruited a minimum of 14 participants (Median = 21, Range 14-29) at age 45, and recorded their level of education (in years). Participants were then tested on 5 cognitive domains: processing speed, spatial visualisation, memory, reasoning, and vocabulary. Participants were contacted for follow-up on a further 9 occasions (resulting in 10 datapoints for each participant), and at every follow-up they were tested on the same 5 cognitive domains. Follow-ups were on average 3 years apart (Mean = 3, SD = 0.8). \n\nThe data are available at [https://uoepsy.github.io/data/cogdecline.csv](https://uoepsy.github.io/data/cogdecline.csv). \n\n```{r echo=FALSE}\ntibble(\n  variable = names(read_csv(\"https://uoepsy.github.io/data/cogdecline.csv\")),\n  description = c(\"Center ID\",\"Participant Identifier\",\"Educational attainment (years of education)\",\"Age at visit (years)\",\n                  \"Score on Processing Speed domain task\",\n                  \"Score on Spatial Visualisation domain task\",\n                  \"Score on Memory domain task\",\n                  \"Score on Reasoning domain task\",\n                  \"Score on Vocabulary domain task\"\n                  )\n) |> gt::gt()\n```\n\n:::\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"05_recap.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.340","toc_float":true,"theme":["united","assets/style-labs.scss"],"link-citations":true,"code-copy":false,"title":"5. Recap & Practice Datasets","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}