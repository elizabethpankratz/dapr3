---
title: "Analysis Example: Cross-sectional multi-level"
link-citations: yes
code-fold: true
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---
```{r setup, include=F}
knitr::opts_chunk$set(message = F, warning = F, fig.align = 'center')
```

:::frame

Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:  

  - First the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated. 
  - Second, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.
  - Then, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in **lme4**. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals. 
  - Finally, we visualize and interpret our analysis.
  
Please note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email [ug.ppls.stats@ed.ac.uk](mailto:ug.ppls.stats@ed.ac.uk). 

:::

# Overview
OK, in this example we are keeping with Tom's home territory of organisational psychology. This data set was provided by Dr. David Hughes, from Manchester Business School. It is a subset of a larger data set that has been published on. 

- OrgID: organisation ID
- Sex: 0= female, 1=male
- Mot: self-rated motivation
- Perf: boss rated performance
- PubPri: 0= public, 1=private 
- Region: geographical location, 1=Wales, 2=England, 3=Scotland
- Size: number of employees 1= <20, 2=21-50, 3=50-100, 4=100-250, 5=251-500, 6=500-1,000, 7=1,000+

Here we are going to be looking at predicting employee performance from self-motivation, and investigating whether this effect is consistent across organisation. We will also look at whether the fact an organisation is public or private accounts for variation in model intercepts and slopes.

# Data Wrangling

This data set is available at [https://uoepsy.github.io/data/MLM_Org.csv](https://uoepsy.github.io/data/MLM_Org.csv).  

```{r}
library(tidyverse)
perform <- read_csv("https://uoepsy.github.io/data/MLM_Org.csv")
perform %>%
  filter(OrgID == "Org1")
```
Here we can see the first 10 employees in `Org1`. Look here at the values that are constant across the organisation, and those that vary by person.

# Descriptives

Given our data structure, it likely makes most sense for us to look at the averages across organisations.

```{r}
summarytab <- 
  perform %>%
  group_by(OrgID) %>%
  summarise(
    N = n_distinct(Perform),
    Mean.Perf = round(mean(Perform, na.rm=T),2),
    SD.Perf = round(sd(Perform, na.rm=T),2),
    Mean.Motiv = round(mean(Mot, na.rm=T),2),
    SD.Motiv = round(sd(Mot, na.rm=T),2)
    )
```

```{r}
library(kableExtra)
kable(summarytab) %>%
  kable_styling("striped")
```

Note the different numbers of employees we have across organisation. Clearly this will mean the information provided by each organisation will vary.

# Visualisations

Next, we can visualize the relationship between motivation and performance within each organisation. 

```{r}
perform %>%
  ggplot(aes(x=Mot, y=Perform, group = OrgID)) +
  geom_point(size = 2, alpha= .75) +
  geom_smooth(method = "lm") +
  labs(x="Motivation", y="Performance") +
  facet_wrap(~OrgID)
```

What we see here is A LOT of variability. Not only do the intercepts change, so does the steepness and direction of the slopes.

# Analysis

## Equations

Our model will take the structure specified below. However, we may also want to discuss whether public/private moderates the _within_ effect of motivation, or the _between_ effect of motivation, in which case we would need to separate out the group mean motivation and the group-mean centered motivation. 
$$
\begin{align}
\operatorname{Perform}_{ij} &= \beta_{0i} + \beta_{1i}(\operatorname{Motivation}_j) + \varepsilon_{ij}\\
\beta_{0i} &= \gamma_{00} + \zeta_{0i} \\
\beta_{1i} &= \gamma_{10} + \gamma_{11}(\operatorname{isPrivate}_i) + \zeta_{0i} \\
& \text{for OrgID i = 1,} \dots \text{,I}
\end{align}
$$

## Fitting the models
As we have in many of our examples, let's run an empty model, and look at the ICC for the grouping variable organisation. 

```{r}
library(lme4)
# Empty model
m0 <- lmer(Perform ~ 1 + 
             (1 | OrgID),
           data = perform)
summary(m0)
```

```{r}
# ICC
varM0 <- as.data.frame(VarCorr(m0))
varM0
```

```{r}
round((varM0[1,4]/sum(varM0[,4]))*100,2)
```

So, around 24% of the variance in our data is at the grouping level, meaning around 76% is at the person level. So clearly we have scope here for explanatory variables of both types.

To begin, we add motivation as a fixed effect:

```{r}
# Fixed effect for motivation
m1 <- lmer(Perform ~ 1 + Mot +
             (1 | OrgID),
           data = perform)
summary(m1)
```

From this, we can calculate the reduction in the residual variance, or the PRV:

```{r}
# PRV - how much residual variance does motivation account for
m1_sum <- summary(m1)
varM1 <- as.data.frame(m1_sum$varcor)
varM1
```

```{r}
round(((varM0[2,4]-varM1[2,4])/varM0[2,4])*100,2)
```

Not bad, so there is a 12.5% reduction in level 1 residual variance from the inclusion of motivation. The coefficient is positive, which is what we would hope to see, motivated employees have better performance.

We will do all of our model comparisons in one go at the end of our model building, so let's continue. Next, is a random slope (as evidenced by our plots above) for motivation.

```{r}
# Random slope
m2 <- lmer(Perform ~ 1 + Mot +
             (1 + Mot | OrgID),
           data = perform)
summary(m2)
```

And now we can look to compare the set of models before adding the predictors:

```{r}
anova(m0, m1, m2)
```

In each case, adding the additional parameters has improved our model, so we will keep them all.

Our big interest here is in whether organisations being public or private changes the relationship of motivation to performance. For this, we will want to include the cross level interaction between `Mot` and `PubPri`. 

```{r}
m3 <- lmer(Perform ~ 1 + Mot + PubPri + Mot*PubPri +
             (1 + Mot | OrgID),
           data = perform)
summary(m3)
```

The *t*-values here are pretty small. This doesn't look like the added effects have contributed much to our model. 
```{r}
# model comparison
anova(m2,m3)
```

And indeed our model comparison suggests not. But wait a minute, we forgot about something....

...we need to center our predictors.

Let's create variables which are the group mean motivation, and the group-mean centered motivation. 

```{r}
perform <- 
  perform %>%
  group_by(OrgID) %>%
  mutate(
    Mot_m = mean(Mot, na.rm=T),
    Mot_c = Mot - mean(Mot, na.rm=T)
  ) %>% ungroup
```

And re-run the models:

```{r}
m4 <- lmer(Perform ~ 1 + Mot_m + Mot_c +
             (1 + Mot_c | OrgID),
           data = perform)
m5 <- lmer(Perform ~ 1 + Mot_m + Mot_c + PubPri + Mot_c*PubPri +
             (1 + Mot_c | OrgID),
           data = perform)
anova(m4,m5)
summary(m5)
```
What do you notice about the results? Spend a little bit of time comparing the effects (fixed and random) and see the changes that result from centering a variable. Remember that our interpretation of the conditional main effects is the effect of a predictor on the outcome when the interacting variable = 0. Zero for Mot_c is average motivation, and zero for PubPri is public sector. So for every unit increase in motivation within a public centre organisation, performance increases by 1.77 units.



# Check model

I might be a little concerned about homoscedasticity here. The variance is a bit narrower at the tail ends:
```{r}
library(lattice)
plot(m5, sqrt(abs(resid(.)))~fitted(.), type = c("p","smooth"))
qqmath(m5)
dotplot.ranef.mer(ranef(m5))
```

```{r}
library(robustlmm)
m5r <- rlmer(Perform ~ 1 + Mot_m + Mot_c + PubPri + Mot_c*PubPri +
             (1 + Mot_c | OrgID),
           data = perform)
```


# Visualise model

```{r}
library(sjPlot)
plot_model(m5, type="pred",terms=c("Mot_m"))
plot_model(m5, type="pred", terms=c("Mot_c","PubPri"))
```

# Interpret model



