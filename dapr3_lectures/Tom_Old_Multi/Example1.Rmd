---
title: "Analysis Example 1: Repeated-measures"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
  html_notebook:
    code_folding: show
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float: yes
---

# Overview
Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way. First the data is introduced. For the purpose of these tutorials, I will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated. Second, the structure of the data is discussed so that we can more easily see what data structure the design creates, and how this aligns to the variables in the data. Third, we translate the research questions into formal equations, and then `lmer()` code. Finally, we will follow those through for our example data.

## Data structure
So...I did not have a simple repeated measures ANOVA study to hand, so I decided we would just simulate our data. We will simulate 50 participants completing a task (`DV`) at 3 points in time (`IV`).

## Equations

# Analysis

```{r}
library(tidyverse)
library(lme4)
library(kableExtra)
```


## Tidy data
Well, the beauty of simulating data is this is exactly how I want it! So for now, we have no additional tidying to do.

```{r}
simRPT <- tibble(
  ID = factor(rep(paste("ID", 1:50, sep=""),each=3)) ,
  DV = rnorm(150,c(40,50,70),sd=c(4, 7, 5)),
  IV = factor(rep(c("T1", "T2", "T3"), each=1,50))
)

head(simRPT)
```

This is a very simple way to simulate repeated measures data structure (with long data). There are a good number of other approaches, but this will do as a place-holder so I can show you the model. I will replace this once I have time to find a good example.

## Describe
Let' see our summaries per time point:

```{r}
sumRPT <- 
  simRPT %>%
  group_by(IV) %>%
  summarise(
    N = n_distinct(ID),
    Mean.DV = round(mean(DV, na.rm=T),2),
    SD.DV = round(sd(DV, na.rm=T),2)
    )
```

```{r}
kable(sumRPT) %>%
  kable_styling("striped")
```

Well...we knew what the answer was going to be, but there we have it, our scores improve across the three administrations of our test.

## Visualize
As this is a nice simple example, let's add a new plot - the violin plot. Here is the code and plot:

```{r}
simRPT %>% 
  ggplot(aes(IV, DV)) + 
  geom_violin() + 
  geom_jitter(alpha=.5,width=.1,height=0) + 
  labs(x="Time", y = "Test Score", 
       title="Scores across trials", 
       subtitle = "Violin Plots with (jittered) Observations")
```

So what does this show? Essentially we are plotting all responses at each point in time. The points are `jittered` so that they are not all overlaid on one another. The areas marked at each time point are mirrored density plots (i.e. they show the distribution of the scores at each point in time). 

If you want to get an intuitive sense of these plotted areas, look at them against the mean's and sd's per time point calculated above.

```{r}
simRPT %>% 
  ggplot(aes(as.numeric(IV), DV)) +  
  stat_summary(fun.data = mean_cl_boot, geom="ribbon", alpha=.3) + 
  stat_summary(fun.y = mean, geom="line") + 
  labs(x="Time", y = "Test Score", 
       title="Scores across trials", 
       subtitle = "Mean and Boostrapped 95% Confidence Intervals")
```


## Run models
Here we run an empty model so that we have something to compare our model which includes our IV. Other than to give us a reference model, we do not have a huge amount of interest in this.

```{r}
m0 <- lmer(DV ~ 1 +
             (1 | ID), 
           data = simRPT
           )
```

Next, we specify our model. Here we include a fixed effect of our predictor (group membership, `IV`), and a random effect of participant (`IV`) to take account of the fact we have three measurements per person.

```{r}
m1 <- lmer(DV ~ 1 + IV +
             (1 | ID), 
           data = simRPT
           )
summary(m1)
```

And we can compare our models:

```{r}
anova(m0,m1)
```

OK, so we can see that we appear to have a significant effect of our repeated factor here. But this does not look like a typical ANOVA output. For piece of mind, it can be useful to compare models.

## Comparison to `aov()`
```{r}
m2 <- aov(DV ~ IV + Error(ID/IV), data = simRPT)
```

Here the term `Error(ID/IV)` is specifying the within person error, or residual. This is what we are doing with our random effect (`(1 | ID)`) in `lmer()`

And we can compare the model sums of squares from both approaches to see the equivalence:

```{r}
summary(m2)
```

```{r}
anova(m1)
```