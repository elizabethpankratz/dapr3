---
title: "<b>Centering Predictors<br>Generalisations</b>"
subtitle: "Data Analysis for Psychology in R 3"
author: "Josiah King"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: jk_libs/libs
    css: 
      - xaringan-themer.css
      - jk_libs/tweaks.css
    nature:
      beforeInit: "jk_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
params: 
    finalcompile: FALSE
editor_options:
  chunk_output_type: console
---



```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(patchwork)
library(lme4)

options(htmltools.dir.version = FALSE)
options(digits=4,scipen=2)
options(knitr.table.format="html")

xaringanExtra::use_share_again()
xaringanExtra::use_xaringan_extra(c("tile_view","animate_css","tachyons"))
xaringanExtra::use_extra_styles(
  mute_unhighlighted_code = FALSE
)

knitr::opts_chunk$set(
  dev = "svg",
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.asp=.8
)
theme_set(
    theme_minimal() + 
    theme(text = element_text(size=20))
)
source("jk_source/jk_presfuncs.R")

library(xaringanthemer)
style_mono_accent(
  base_color = "#88B04B", # DAPR3 
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  code_font_size = "0.7rem",
  extra_css = list(".scroll-output" = list("height"="90%","overflow-y"="scroll"))
)
```

class: inverse, center, middle


<h2>Part 1: Back to the start</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Centering Predictors</h2>
<h2 style="text-align: left;opacity:0.3;">Extra Slides (optional): GLMM</h2>  

<h2 style="text-align: left;">https://www.menti.com/al7vqejztmg1</h2>
<h2 style="text-align: left;">or menti.com code: 4669 8678</h2>

---
# Research Question

> **How do reaction times change with increasing sleep deprivation?** <span style="opacity:.4">An international study, in which institutions in 20 countries each studied 18 participants over 10 days. Information was also captured on two known predictors of reaction time - age, and whether or not participants regularly consume caffeine.</span>  


???
- so we have a straightforward research question.  
- how do reaction times change as days without sleep increases? - we're going to ignore the context right now, and just use this as a starting point for a broad view of what we've looked at so far in dapr3  

---
# lm: a line

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide1.PNG")
```

???
- our relationship is RT predicted by Days without sleep
- we can fit a simple regression model where we are estimating two parameters, an interept and slope  
- beta 0 is the intercept - the average RT at day 0
- beta 1 is the slope - the amount by which RT increases with every day of no sleep


---
# lm: a line (2)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide13.PNG")
```

???
- this is fine if we have just measured a person with 2 days of no sleep, and another person with 5 days of no sleep, another with 3 days, etc.  
- because my reaction time is not dependent upon Tom's, or Emma's, or Umberto's etc. 

---
# lm: a line (3)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide2.PNG")
```

???
- but instead, let's suppose our design involves measuring people over time. 
- for each person, we have measured their RT with 1 day of no sleep, 2 days of no sleep, etc.. 
- now all these observations from me are related to one another. they're all high because i have slow reaction times
- for tom, his are all low - i.e. quick.  


---
# lm: lines and differences between them

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide3.PNG")
```

???
- in week1 we saw how we might try and model the differences between people directly  
- we'd get out loads more coefficients for the differences between a set of things that we are not specifically interested in. 
- the coefficients are the estimated adjustments to get from Tom's RT to my RT
- we'd rather think of the variation in RT between me and Tom as just some random variation that would be different if the experiment we repeated (because you would have different participants rather than me and Tom).  

---
# lmer: lines with a distribution of intercepts

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide4.PNG")
```

???
- multilevel models allow us to think in that way  
- they allow us to have parts of our model, e.g. the intercept in this plot, as a distribution. 
- we have a fixed value around which peoples' own intercepts vary
- so the fixed value is here. to get to mine, we need to add a bit, because i'm slower than the average person
- to get to Tom's we subtract a bit, because he's faster than the average person

- and the model estimates this fixed value, and the standard deviation of people's differences from that value  

---
# lmer: lines with a distribution of intercepts (2)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide5.PNG")
```

???
- So our intercept now is the combination of a fixed intercept, and random people-level variance around that intercept.
- we can get out these specific bits for me, for Tom, but we think of our model as really being the estimated variance in all of these. 


---
# lmer: lines with a distribution of intercepts (3)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide6.PNG")
```

???
- and this one the model is allowing for people do have different intercepts _only_. 
- Note they all have the same slope. 
- so the model thinks that my RT increases by some amount for every day of no sleep, and this is the same amount for Tom, and for everyone. 

---
# lmer: lines with a distribution of intercepts (4)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide7.PNG")
```

???
- So we the association between RT and Days of no sleep is just one fixed number
- it's only in the fixed effects part of the model syntax

---
# lmer: and with a distribution of slopes

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide8.PNG")
```


???
- but it doesn't have to be.
- we can say that the association between RT and days of no sleep _also_ varies between people.  
- i can cope with no sleep, so my RT doesn't get that much slower
- Tom can't. he needs his sleep. his RT gets a lot slower as he has more days of no sleep  


---
# lmer: and with a distribution of slopes (2)

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide9.PNG")
```

???
- and really, just like the intercept is now a distribution
- the slope is now a distribution.
  - there's an overall average slope
  - and people vary a bit around that. 
  - so Tom's RT goes up a lot more (he's above the average slope) - the T here
  - my RT doesn't go up as much - i'm below the average slope. the J here
  - and they are the little additions we make above the overall slope, in order to get to each persons own slope

---
# fixed and random

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide10.PNG")
```

???
- 95% of the time, research is interested in the fixed part. Describes the average group. 
  - Fixed effects estimates are the bits we test  
  - Random effects provide context

---
# nested: distributions of distributions 

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide11.PNG")
```

???
- we can extend the MLM approach to have more levels  
- so here we have some higher level grouping - Tom and I are both in Psychology, we also measured people in Linguistics, in Engineering, in Philosophy, etc.  
- around the overall average person from the average department
  - some departments have higher RT, some lower RT
  - psychology are really slow
  - engineering are really fast
- and _within_ those, people vary around the department 
  - i'm slower for psychology
  - Tom's quicker for psychology


---
# crossed: distributions and distributions

```{r echo=FALSE, out.height="600px"}
knitr::include_graphics("jk_img_sandbox/rt_example/Slide12.PNG")
```

???
- it's much harder to visualise the idea of crossed random effects in these figures, but i'm giving it a go  
- suppose we tested people's RT on lots of different tasks
  - the dropping & catching a ruler
  - pressing a button when they see a light
  - pressing a button when they hear a sound
  - etc
- we've got rid of the department stuff here, so no nesting. 
- in the coloured points you can see three tasks I did every day, and Tom did the same 3 tasks, etc. 
- we might expect these tasks to be vary in how quick people perform them. 
  - e.g. people press buttons quicker when they see a light vs hear a sound
  - pink task tend to be quick than the blue task. 
- we can model this variation as task-level differences, alongside person-level differences  
- intercept is now the RT for average person, on average task
  - to get to my estimated blue task intercept, we need to
  - add the "josiah is a slow person" bit
  - add the "blue task is a slow task" bit  

---
# https://www.menti.com/al7vqejztmg1

<div style='position: relative; padding-bottom: 56.25%; padding-top: 35px; height: 0; overflow: hidden;'><iframe sandbox='allow-scripts allow-same-origin allow-presentation' allowfullscreen='true' allowtransparency='true' frameborder='0' height='315' src='https://www.mentimeter.com/app/presentation/alp53d3no62krstg7ei7vp2tpixykaxe/ujrfj2ujz5fh/embed' style='position: absolute; top: 0; left: 0; width: 100%; height: 100%;' width='420'></iframe></div>
---
# model building 

> How do reaction times change with increasing sleep deprivation? An international study, in which institutions in 20 countries each studied 18 participants over 10 days. Information was also captured on two known predictors of reaction time - age, and whether or not participants regularly consume caffeine.

???
okay, let's return to our research question and design, so we can see this in action  
- note we don't have the multiple tasks here, and we also have countries not departments of the uni

---
# model building 

> How do reaction times change with increasing sleep deprivation? <span style="opacity:.4">An international study, in which institutions in 20 countries each studied 18 participants over 10 days.</span>Information was also captured on two known predictors of reaction time - age, and whether or not participants regularly consume caffeine.

<br><br>

- The research question tells us our fixed effects.  
- <span style="opacity:.4">The design tells us our grouping structure</span>
- <span style="opacity:.4">The random effects are additional levels of complexity that we _may_ be able to fit in order to better represent the world.</span>  

???
- so what are we interested in here? if you were to imagine this being a news headline, what part of it are we going to focus on
- READ
- reaction time and days of sleep deprivation  
- READ
- we are _also_ aware that there are things we _know_ contribute to reaction times, age and caffeine, and so we may want to control for those  

--

```{r eval=FALSE}
Reaction ~ Age + Caff + Days
```

???
which gives us something like this  


---
# model building 

> <span style="opacity:.4">How do reaction times change with increasing sleep deprivation?</span> An international study, in which institutions in 20 countries each studied 18 participants over 10 days.<span style="opacity:.4">Information was also captured on two known predictors of reaction time - age, and whether or not participants regularly consume caffeine.</span>

<br><br>

- The research question tells us our fixed effects.  
- The design tells us our grouping structure
- <span style="opacity:.4">The random effects are additional levels of complexity that we _may_ be able to fit in order to better represent the world.</span>  

```{r eval=FALSE}
Reaction ~ Age + Caff + Days + (_____ | Country/Subject)
```

???
- to decide _if_ and _what_ grouping structure we want to take into account, we need to know about the design
- READ
- we know each person is measured over 10 days
- so we have 10 datapoints for each person
- and the people in groups of 18 coming from 20 different countries  
- so we have people nested in countries


---
# model building 

> How do reaction times change with increasing sleep deprivation? An international study, in which institutions in 20 countries each studied 18 participants over 10 days. Information was also captured on two known predictors of reaction time - age, and whether or not participants regularly consume caffeine.

<br><br>

- The research question tells us our fixed effects.  
- The design tells us our grouping structure
- The random effects are additional levels of complexity that we _may_ be able to fit in order to better represent the world.

```{r eval=FALSE}
Reaction ~ Age + Caff + Days + (????? | Country/Subject)
```


???
- the last bit is really where the difficulty comes in
- what should we model as varying by these groups?  
- it's not a clear answer here. it depends on how much data we have, and how much variability there is in our data   
  
---
class: center, middle

# in RStudio...  

???
so let's have a go!  

---
# maximal structure

- everything that _can (theoretically)_ vary by grouping structure is modelled as doing so

```{r eval=FALSE}
Reaction ~ Age + Caff + Days + 
  (1 + Age + Caff + Days | Country) + 
  (1 + Days | Country:Subject)
```

- Simplify until model converges
  - Remember that you have a choice of optimizers (algorithms to try and find a converging model)
    ```{r eval=FALSE}
    control = lmerControl(optimizer = ???)
    ```


---
# how to simplify

Look for:

- Variances/standard deviations of 0 (or very small, e.g. `3.56e-05`)  
- Correlations of -1 or 1 

```{r eval=FALSE}
# to extract random effects
VarCorr(model)
```

- You might argue that random effects of focal predictors are more important than random effects of covariates  
- You will be faced with _subjective_ choices
  - which simplification can you most easily accept?  
  
---
# a note on random effect correlations

- If you remove a correlation between random effects, e.g.:

```{r eval=FALSE}
(1 + Days || Country)
```

- be sure that you're comfortable accepting this simplification

- try plotting the random effects from the model without the correlation. 
  - setting `(1 + Days || Country)` doesn't _prevent_ a correlation between the _estimated_ random effects.
  - it just tries to _describe_ the pattern with two **uncorrelated** distributions 
  
.pull-left[
Model Parameters
```{r echo=FALSE, fig.asp=.4}
fulldat <- read_csv("../../../data/countrysleep.csv")
m2 = lmer(Reaction ~ 1 + Days + 
           (1 + Days || Country),
         control=lmerControl(optimizer="bobyqa"), REML=TRUE,
         data = fulldat)
dd <- as.data.frame(ranef(m2)$Country)
sim = MASS::mvrnorm(n=1e5,mu=c(0,0), Sigma = diag(2) * as.data.frame(VarCorr(m2))[1:2,5]^2)
sim = as.data.frame(sim)
names(sim) = names(dd)

plotmod = ggplot(dd, aes(x=`(Intercept)`,y=Days))+
  #geom_point()+
  geom_density_2d(data=sim) + 
  xlim(-40,40) + ylim(-4,4)
plotran = ggplot(dd, aes(x=`(Intercept)`,y=Days))+
  geom_point()+
  xlim(-40,40) + ylim(-4,4)
ploti = ggplot(data=tibble(x=-40:40),aes(x=x))+
  stat_function(geom="line",fun=~dnorm(.x, mean=0,sd=as.data.frame(VarCorr(m2))[1,5]),lwd=1) + theme_void()
plots = ggplot(data=tibble(x=-4:4),aes(x=x))+
  stat_function(geom="line",fun=~dnorm(.x, mean=0,sd=as.data.frame(VarCorr(m2))[2,5]),lwd=1) +ylim(0,1) + coord_flip() + theme_void()
library(patchwork)
(ploti + plot_spacer()) / (plotmod + plots) +
  plot_layout(heights = c(1, 4),widths = c(1,1))
```
]
.pull-right[
Random effect estimates 
```{r echo=FALSE, fig.asp=.4}
(plot_spacer() + plot_spacer()) / (plotran + plot_spacer()) +
  plot_layout(heights = c(1, 4),widths = c(1,1))
```

]

---
# a note on random effect correlations (2)

- If you remove a correlation between random effects, e.g.:

```{r eval=FALSE}
(1 + Days || Country)
```

- be sure that you're comfortable accepting this simplification

- try plotting the individual cluster `lm()` lines  
  
.pull-left[
Individual `lm()` for each cluster:  
```{r fig.asp=.3}
ggplot(fulldat, aes(x=Days,y=Reaction,group=Country))+
  geom_smooth(method=lm,se=F)
```
]

---
# Summary

- think of the multilevel model `lmer()` as an extension of the simple linear model `lm()`  

- the multilevel model allow us to let parts of our model _vary by_ some grouping.  

  - i.e. different intercepts and/or slopes for each group
  
- the most straightforward approach to building these models: 

  1. start with most complex model  
  2. simplify until the model converges  




---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Back to the start</h2>
<h2>Part 2: Centering Predictors</h2>
<h2 style="text-align: left;opacity:0.3;">Extra Slides (optional): GLMM</h2>

---
# Centering

.pull-left[
Suppose we have a variable for which the mean is 100.  
```{r echo=FALSE, fig.asp=.8}
set.seed(57)
dat <- tibble(
  iq = 100+(scale(rnorm(200,100,15))[,1]*15)
)
dat$iq2 = dat$iq-100
dat$iq3 = dat$iq-120
dat$iq4 = (dat$iq-100)/15
ggplot(dat, aes(x=iq))+geom_histogram(binwidth = 2)+
  geom_rect(ymin=0,ymax=1, xmin=99.5,xmax=100.5, fill="red")+
  labs(x="IQ")
```
]
--
.pull-right[
We can re-center this so that the mean becomes zero:
```{r echo=FALSE,fig.asp=.8}
ggplot(dat, aes(x=iq2))+geom_histogram(binwidth = 2)+
  geom_rect(ymin=0,ymax=1, xmin=-0.5,xmax=0.5, fill="red")+
  geom_vline(xintercept=0)+
  labs(x="IQ - 100")
```

]

---
count:false
# Centering

.pull-left[
Suppose we have a variable for which the mean is 100.  
```{r echo=FALSE,fig.asp=.8}
ggplot(dat, aes(x=iq))+geom_histogram(binwidth = 2)+
  geom_rect(ymin=0,ymax=1, xmin=99.5,xmax=100.5, fill="red")+
  labs(x="IQ")
```
]
.pull-right[
We can re-center this so that _any_ value becomes zero:
```{r echo=FALSE,fig.asp=.8}
ggplot(dat, aes(x=iq3))+geom_histogram(binwidth = 2)+
  geom_vline(xintercept=0)+
  geom_rect(ymin=0,ymax=1, xmin=-19.5,xmax=-20.5, fill="red")+
  labs(x="IQ - 120")
```

]
???
- now really this isn't doing anything much. we're simply sliding the whole distribution left or right, thereby changing what the number "zero" means in the context of the variable. we can have zero as the mean, as 120, as any number we like. 

---
# Scaling

.pull-left[
Suppose we have a variable for which the mean is 100.  
The standard deviation is 15
```{r echo=FALSE, fig.asp=.8}
ggplot(dat, aes(x=iq))+geom_histogram(binwidth = 2)+
  geom_rect(ymin=0,ymax=1, xmin=99.5,xmax=100.5, fill="red")+
  labs(x="IQ")
```
]

???
- if we consider also the spread of the distribution, the standard deviation, then we can do something called standardisation

--
.pull-right[
We can scale this so that a change in 1 is equivalent to a change in 1 standard deviation:

```{r echo=FALSE, fig.asp=.8}
ggplot(dat, aes(x=iq4))+geom_histogram(binwidth = (2/15))+
  geom_rect(ymin=0,ymax=1, xmin=-0.5/15,xmax=0.5/15, fill="red")+
  geom_vline(xintercept=0)+
  labs(x="(IQ - 100) / 15")
```

]

???
- this is just mean centereing and then dividing by the standard deviation. 
- note that the shape of the distribution doesn't change, but the scale of the x axis does. 
- so what used to be a move of 15, going from 100 to 115, is now represented as a move of 1. 

---
# Centering predictors in LM

.pull-left[
```{r include=F}
library(lme4)
set.seed(934)
df <- tibble(
  x = rnorm(200,4,1),
  y = pmax(0.1,.3+.5*x + rnorm(200))
)
```

```{r}
m1 <- lm(y~x,data=df)
m2 <- lm(y~scale(x, center=T,scale=F),data=df)
m3 <- lm(y~scale(x, center=T,scale=T),data=df)
m4 <- lm(y~I(x-5), data=df)
```
]

???
- let's first think about how we can center or scale our predictors in a simple regression model. 
- i've used the scale function here, where you can set scale and center to be TRUE/FALSE, so we can mean center but not scale etc. 
- now, we can do whatever we like to our predictor here. these are all linear transformations. the relative distances between each value remain the same. 




---
count: false
# Centering predictors in LM

.pull-left[
```{r}
m1 <- lm(y~x,data=df)
m2 <- lm(y~scale(x, center=T,scale=F),data=df)
m3 <- lm(y~scale(x, center=T,scale=T),data=df)
m4 <- lm(y~I(x-5), data=df)
```
```{r}
anova(m1,m2,m3,m4)
```
]

???
- and it doesn't do anything to our model fit whatsoever. - the effect of our predictor on our outcome variable is EXACTLY the same.  
- we can see this here, a model comparison is showing the residual sums of squares as being identical. 

--

.pull-right[
```{r echo=FALSE, fig.align="center"}
set.seed(934)
df <- tibble(
  x = rnorm(200,4,1),
  y = pmax(0.1,.3+.5*x + rnorm(200))
)

mod = lm(y~x,df)
p1 = ggplot(df, aes(x=x,y=y))+geom_point()+
  geom_smooth(method="lm")+
  geom_smooth(method="lm",fullrange=T,lty="dotted")+
  #ylim(0,max(df$y))+
  geom_segment(x=0,xend=0,y=0,yend=max(df$y))+
  geom_segment(x=0,xend=max(df$x),y=0,yend=0)+
  geom_point(data=tibble(x=0,y=coef(mod)[1]),size=4)+
  labs(title="Raw X")+
  scale_x_continuous(limits=c(0,7),breaks=0:7)

mod = lm(y~scale(x,scale=F),df)
p2 = ggplot(df, aes(x=x,y=y))+geom_point()+
  geom_smooth(method="lm")+
  geom_smooth(method="lm",fullrange=T,lty="dotted")+
  #ylim(0,max(df$y))+
  geom_segment(x=mean(df$x),xend=mean(df$x),y=0,yend=max(df$y))+
  geom_segment(x=0,xend=max(df$x),y=0,yend=0)+
  geom_point(data=tibble(x=mean(df$x),y=coef(mod)[1]),size=4)+
  scale_x_continuous(limits=c(0,7),breaks=map_dbl(seq(4,-4), ~mean(df$x)-.),
                     labels=seq(-4,4))+
  labs(title="Mean centered X")
  
  
mod = lm(y~scale(x),df)
p3 = ggplot(df, aes(x=x,y=y))+geom_point()+
  geom_smooth(method="lm")+
  geom_smooth(method="lm",fullrange=T,lty="dotted")+
  #ylim(0,max(df$y))+
  geom_segment(x=mean(df$x),xend=mean(df$x),y=0,yend=max(df$y))+
  geom_segment(x=0,xend=30,y=0,yend=0)+
  geom_point(data=tibble(x=mean(df$x),y=coef(mod)[1]),size=4)+
  scale_x_continuous(limits=c(0,7),
                     breaks=c(mean(df$x)-(2*sd(df$x)), mean(df$x)-sd(df$x), 
                              mean(df$x), 
                              mean(df$x)+sd(df$x), mean(df$x)+(2*sd(df$x))),
                     labels=c(-2,-1,0,1,2))+
  labs(title="Scaled X")



mod = lm(y~x,df %>% mutate(x=x-5))
p4 = ggplot(df, aes(x=x,y=y))+geom_point()+
  geom_smooth(method="lm")+
  geom_smooth(method="lm",fullrange=T,lty="dotted")+
  #ylim(0,max(df$y))+
  geom_segment(x=5,xend=5,y=0,yend=max(df$y))+
  geom_segment(x=0,xend=30,y=0,yend=0)+
  geom_point(data=tibble(x=5,y=coef(mod)[1]),size=4)+
  scale_x_continuous(limits=c(0,7),breaks=0:7, labels=c(0:7)-5)+
  labs(title="x-5")
p1 + p2 + p3 + p4 
```
]

???
- so what's the point in doing it? well, it changes how we interpret some of our parameters. 
- remember that our intercept is the estimated mean y when our predictors are zero. 
- given that centering our predictor changes what "zero" is, then we can center predictors to make our intercept the estimated y for the mean value of x. 
- likewise, scaling our predictors changes the interpretation of our coefficient from the estimated change in y associated with a 1 unit increase in x, to the estimated change associated with a 1 STANDARD DEVIATION increase in X. And this may be preferable, especially if, for instance you've got some predictor where 1 unit isn't very useful 

---
# Big Fish Little Fish

```{r eval=FALSE, echo=FALSE}
set.seed(667)
doit<-1
while(doit){
  df<-as.data.frame(c())
  Ngroups = round(rnorm(1,10,0))
  NperGroup = rdunif(Ngroups, 10, 20)
  N = sum(NperGroup)
  dd<-MASS::mvrnorm(n=Ngroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
  igs = map(seq_along(NperGroup), ~rep(.,NperGroup[.])) %>% unlist
  xxm = rnorm(Ngroups,0,1)
  xxm = rdunif(Ngroups, 2, 10)
  xxm = map(1:Ngroups, ~rep(xxm[.], NperGroup[.])) %>% unlist
  xgc = map(1:Ngroups, ~rnorm(NperGroup[.], 0, 3)) %>% unlist
  #xx = map(1:Ngroups, ~rep(rnorm(1,3,.6), NperGroup[.]))%>% unlist
  xx = xxm+xgc 
  l2p = sample(1:4, Ngroups, replace=T)
  l2p = map(1:Ngroups, ~rep(l2p[.], NperGroup[.])) %>% unlist
  
  e = rnorm(N, sd = 1)
    
  y = 0 +
      dd[igs,1]+
      -3*xxm+
      2*xgc + 
      dd[igs,2]*xgc +
      0*l2p +
      e
  d = data.frame(y,xxm,xgc,igs,l2p)
  df<-rbind(df,d)
  
  lmer(y ~ xxm + xgc + l2p + (1+xgc | igs), data =df,
       control=lmerControl(optimizer = "bobyqa")) -> m 
  print(VarCorr(m))
  
  t1 = attributes(VarCorr(m)[[1]])$stddev
  t2 = attributes(VarCorr(m)[[1]])$correlation
  
  if(!isSingular(m)){
    doit <- 0
  }
}

df %>% transmute(
  pond = paste0("pond_",igs),
  tyoe = l2p,
  self_esteem = round(3+scale(y)[,1]*.6,2),
  fish_weight = round(31+scale(xxm+xgc)[,1]*11),
) -> bflp
write.csv(bflp, "../../uoepsy/data/bflp.csv", row.names=F)
```

```{r echo=FALSE, fig.asp=.7, fig.align="center"}
bflp <- read_csv("https://uoepsy.github.io/data/bflp.csv")
library(ggforce)
library(ggfx)
ggplot(bflp, aes(x=fish_weight, y=self_esteem))+
  geom_point()+
  #geom_line(aes(group=pond))+
  geom_smooth(method="lm")+
  labs(x="Fish Weight (kg)",y="Self Esteem Scale (1-5)")+
  geom_mark_ellipse(aes(label = "BIG FISH",filter = fish_weight > 60),
                    con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE)+
  geom_mark_ellipse(aes(label = "LITTLE FISH",filter = fish_weight == 5),
                    con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE)+
  geom_mark_ellipse(aes(label = "MEDIUM FISH", filter = (pond == "pond_6" & fish_weight==34)),con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE)+
  ylim(1,5)
```

data available at https://uoepsy.github.io/data/bflp.csv  


???
- now in the single level case, centering and scaling does very little, and thats because however we shift or scale the x-axis here, the distribution remains identically shaped. 
- so this is a silly example, we're measuring the self-esteem of some fish, and seeing if bigger fish have higher self esteem.  
- no matter how we transform 'fish_weight', this is always a little fish, this is always a big fish, and this is always a medium sized fish. 

---
# Things are different with multi-level data 

```{r echo=FALSE, fig.asp=.7, fig.align="center"}
ggplot(bflp, aes(x=fish_weight, y=self_esteem))+
  with_blur(geom_point(),sigma=3)+
  with_blur(geom_line(aes(group=pond),alpha=.5),sigma=3)+
  geom_point(data=filter(bflp, pond=="pond_6"))+
  geom_line(data=filter(bflp, pond=="pond_6"))+
  #geom_smooth(method="lm")+
  labs(x="Fish Weight (kg)",y="Self Esteem Scale (1-5)")+
  with_blur(geom_mark_ellipse(aes(label = "BIG FISH",filter = fish_weight > 60),
                    con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE),sigma=3)+
  with_blur(geom_mark_ellipse(aes(label = "LITTLE FISH",filter = fish_weight == 5),
                    con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE),sigma=3)+
  geom_mark_ellipse(aes(label = "BIG FISH, LITTLE POND", filter = (pond == "pond_6" & fish_weight==34)),con.arrow = arrow(ends = "last",length = unit(0.5, "cm")),
                    show.legend = FALSE)+
  ylim(1,5)
```

???
- but as soon as we have clusters in our data, as soon as we have multiple levels, then something cool happens. 
- how we think about these observations suddenly has another dimension.
- it's no longer as simple as "big fish medium fish little fish", but fish are large or small FOR THE POND IN WHICH THEY LIVE. 
- so our medium fish is still, in some ways, a "medium fish", but in terms of the pond in which it lives, it is the biggest fish. 
- and we might have another fish in our dataset which is exactly the same weight, but which is a SMALL fish FOR ITS POND
- the reason i'm using this silly example is that thinking of this as the idea of "big fish little pond" can be quite a good starting point, and in education research there is even a concept of "the big fish little pond effect" which is exactly this same concept, only instead of fish in ponds we have children in schools, and instead of weight on the x axis, we have education attainment. 
- so a child who scores close to the overall mean, if they are the top of their class, they feel great! 



---
# Multiple means

.pull-left[
__Grand mean__

```{r echo=FALSE, fig.asp=.8}
ggplot(bflp, aes(x=fish_weight, y=self_esteem, col=pond))+
  geom_point(alpha=.4)+
  labs(x="Fish Weight (kg)",y="Self Esteem Scale (1-5)")+
  guides(color="none")+
  geom_vline(xintercept=mean(bflp$fish_weight),lty="dotted", lwd=1)
```
]

???
- this idea of being a "big fish for the pond you're in", may well be the thing we're actually interested in! 
- i'm not interested in whether sharks have more self esteem than minnows (tiny fish).  
- i'm interested in whether fish who are big _relative to_ those around them, have higher self esteem.  

- you'll start to have noticed a pattern here, in that when we're talking about multilevel models, pretty much everything is at multiple levels. we talked last week about multiple levels of residuals, influence happening at multiple levels etc. 
- well guess what, we now have means at multiple levels. 
- we have our grand mean, that's simply the average of all of these values

--

.pull-right[
__Group means__

```{r echo=FALSE, fig.asp=.8}
bflp %>% group_by(pond) %>% summarise(s=sd(fish_weight), fish_weight = mean(fish_weight), self_esteem = mean(self_esteem)) %>% ungroup -> sdff
ggplot(bflp, aes(x=fish_weight, y=self_esteem, group=pond, col=pond))+
  geom_point(alpha=.4)+
  geom_point(data=sdff,size=4)+
  #geom_errorbarh(data=sdff,aes(xmin=fish_weight-(2*s), xmax=fish_weight+(2*s)))+
  labs(x="Fish Weight (kg)",y="Self Esteem Scale (1-5)")+
  guides(color="none")
```
]

???
- and then we have our group means, which are the means for each group. that's these bigger points here. 

---
# Group-mean centering

.pull-left[
<center>__ $x_{ij} - \bar{x}_i$ __</center><br>
```{r echo=FALSE}
bflp %>% group_by(pond) %>%
  mutate(
    xbar = mean(fish_weight),
    xbari = fish_weight - mean(fish_weight)
  ) -> bflpdat
ggplot(bflpdat, aes(x=xbari, y=self_esteem,color=pond)) +
  geom_point()+
  geom_line(aes(group=pond), alpha=.2)+
  geom_vline(xintercept=0, lty="dotted",lwd=1)+
  labs(x="Fish weight difference from pond average (kg)",y="Self Esteem Scale (1-5)")+
  guides(color="none")
```
]

???
- and what having all these means means is that we can mean-center, but instead of centering all our values around the one overall grand mean, we can center each groups values around that group mean. 
- and what we get out of this is a variable that represents something slightly different from what we had. - we now have something that shows the amount that an observation is higher or lower than its group average.
- so with these values we get something that shows if a fish is 5kg heavier, or 3kg lighter etc, THAN THE AVERAGE FOR ITS POND. 
- And what we're looking at here is the WITHIN effect. 
- that is, "within a given group how does being higher on x for that group influence scores on y?" 


---
# Group-mean centering

```{r include=FALSE}
bflp %>% group_by(pond) %>% summarise(s=sd(fish_weight), fish_weight = mean(fish_weight), self_esteem = mean(self_esteem)) %>% ungroup -> sdff

bind_rows(
  sdff %>% mutate(t=0),
  sdff %>% mutate(t=1,fish_weight=0)) -> sdff

bind_rows(bflp %>% mutate(t=0),
          bflp %>% group_by(pond) %>% 
            mutate(m=mean(fish_weight),fish_weight=fish_weight-m, t=1) %>% ungroup
) -> bflpa
```
```{r eval=FALSE, include=FALSE}
library(gganimate)
ggplot(bflpa, aes(x=fish_weight, y=self_esteem,color=pond)) +
  geom_point(alpha=.7)+
  geom_line(aes(group=pond), alpha=.1)+
  geom_point(data=sdff,size=4)+
  #geom_errorbarh(data=sdff,aes(x=0,xmin=0-(2*s), xmax=0+(2*s)), alpha=.5)+
  labs(x="Fish weight",y="Self Esteem Scale (1-5)")+
  guides(color="none") +
  transition_states(t) -> p

anim_save("jk_img_sandbox/center.gif", p)
```
<br>
```{r echo=FALSE, fig.align="center"}
knitr::include_graphics("jk_img_sandbox/center.gif")
```

???
- but we've lost something, right?
- when we center on the group means, we're lining up all our groups so that the means are all zero. 
- what was the biggest fish in the data, is actually not as big (relative to its pond average) as this other fish here. 
- we have removed information that is contained in the raw scores. 

---
# Group-mean centering

.pull-left[
<center>__ $x_{ij} - \bar{x}_i$ __</center><br>
```{r echo=FALSE}
bflp %>% group_by(pond) %>%
  mutate(
    xbar = mean(fish_weight),
    xbari = fish_weight - mean(fish_weight)
  ) -> bflpdat
ggplot(bflpdat, aes(x=xbari, y=self_esteem,color=pond)) +
  geom_point()+
  geom_line(aes(group=pond), alpha=.2)+
  geom_vline(xintercept=0, lty="dotted",lwd=1)+
  labs(x="Fish weight difference from pond average (kg)",y="Self Esteem Scale (1-5)")+
  guides(color="none")
```
]

.pull-right[
<center>__ $\bar{x}_i$ __</center><br>
```{r echo=FALSE}
ggplot(bflpdat, aes(x=xbar, y=self_esteem,color=pond)) +
  stat_summary(geom="pointrange")+
  #geom_point(alpha=.4)+
  #geom_line(aes(group=patient), alpha=.4)+
  labs(x="Pond Average fish weight (kg)",y="Self Esteem Scale (1-5)")+
  guides(color="none")
```
]

???
- but we can put it back! we jsut need to know the values for the group means. 
- and we have them! 
- and in fact, when we start thinking about these group means, we realise that we're looking at another part of the same question. 
- we're looking at the between-group effect. 
- now these are measured at the group-level, because these are the group averages, and what we're looking at here is the relationship between our outcome and the group-mean of x.

- so "if you're a fish from a pond which has a higher average weight of fish, you'll tend to have lower self esteem"
- whereas the ponds with an average weight of fish that is lower, the fish in those ponds tend to have higher self esteem. 

- but this is now separated from the fact that WITHIN each pond, the heavier a fish is, the more self esteem they have

---
# Disaggregating within & between

.pull-left[
**RE model**  
$$
\begin{align}
y_{ij} &= \beta_{0i} + \beta_{1}(x_j) + \varepsilon_{ij} \\
\beta_{0i} &= \gamma_{00} + \zeta_{0i} \\
... \\
\end{align}
$$


```{r}
rem <- lmer(self_esteem ~ fish_weight + 
              (1 | pond), data=bflp)
```

]

???
- so what are we going to do with group-mean centering in our multilevel model?

- well this is the kind of model we have been fitting so far.  
- we have self esteem being predicted by fish_weight, and then we have a random intercept for each pond. So some ponds have higher self-esteem, some lower, and we're assuming ponds' self esteem to be normally distributed around the fixed center. 

--

.pull-right[
**Within-between model**  
$$
\begin{align}
y_{ij} &= \beta_{0i} + \beta_{1}(\bar{x}_i) + \beta_2(x_{ij} - \bar{x}_i)+ \varepsilon_{ij} \\
\beta_{0i} &= \gamma_{00} + \zeta_{0i} \\
... \\
\end{align}
$$

```{r}
bflp <- 
  bflp %>% group_by(pond) %>%
    mutate(
      fw_pondm = mean(fish_weight),
      fw_pondc = fish_weight - mean(fish_weight)
    ) %>% ungroup

wbm <- lmer(self_esteem ~ fw_pondm + fw_pondc + 
              (1 | pond), data=bflp)
fixef(wbm)
```

]

???
- and take a minute to think about how we split our raw x scores up into two pieces. 
- we can get back to the original weight of any fish by using the average weight of that fishes pond, plus the relative difference from that average to the fish. 
- so it's just additive. and we can put both these new variables into our model and get estimates of these different effects!  

---
# Disaggregating within & between

.pull-left[
```{r echo=FALSE, fig.asp=.8, fig.align="center"}
broom.mixed::augment(wbm) %>%
  ggplot(.,aes(x=fw_pondm, y=self_esteem, group=pond))+
  geom_point() + #geom_line(alpha=.2) +
  geom_abline(intercept=fixef(wbm)[1], slope=fixef(wbm)[2]) -> p1

broom.mixed::augment(wbm) %>%
  ggplot(.,aes(x=fw_pondc, y=self_esteem, group=pond))+
  geom_point() + #geom_line(alpha=.2) +
  geom_abline(intercept=fixef(wbm)[1]+(fixef(wbm)[2]*mean(bflp$fw_pondm)), slope=fixef(wbm)[3]) -> p2

broom.mixed::augment(wbm) %>%
  ggplot(.,aes(x=fw_pondc + fw_pondm, y=.fitted, group=pond))+
  geom_point() + geom_line(alpha=.2) -> p3

(p1+p2)/p3
```
]

.pull-right[
**Within-between model**  
$$
\begin{align}
y_{ij} &= \beta_{0i} + \beta_{1}(\bar{x}_i) + \beta_2(x_{ij} - \bar{x}_i)+ \varepsilon_{ij} \\
\beta_{0i} &= \gamma_{00} + \zeta_{0i} \\
... \\
\end{align}
$$

```{r}
bflp <- 
  bflp %>% group_by(pond) %>%
    mutate(
      fw_pondm = mean(fish_weight),
      fw_pondc = fish_weight - mean(fish_weight)
    ) %>% ungroup

wbm <- lmer(self_esteem ~ fw_pondm + fw_pondc + 
              (1 | pond), data=bflp)
fixef(wbm)
```


]

???
so what we are estimating now is the separate contributing effects on self esteem of 
  - "being a bigger fish FOR YOUR POND" and 
  - "being from a pond that has bigger fish". 

 

---
# A more realistic example

```{r eval=FALSE, echo=FALSE}
library(lme4)
set.seed(77)
doit<-1
while(doit){
  Ngroup2s = 10
  dd2<-MASS::mvrnorm(n=Ngroup2s, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
  cor(dd2)
  i = 2
  df<-as.data.frame(c())
  for(i in 1:Ngroup2s){
    Ngroups = round(rnorm(1,10,0))
    Nxgroups = 2
    
    #NperGroup = rep(Nxgroups*nrep,Ngroups)
    NperGroup = rdunif(Ngroups, 5, 10)*Nxgroups
    N = sum(NperGroup)
    
    dd<-MASS::mvrnorm(n=Ngroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    ddb<-MASS::mvrnorm(n=Ngroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    ddx<-MASS::mvrnorm(n=Nxgroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    
    igs = map(seq_along(NperGroup), ~rep(.,NperGroup[.])) %>% unlist
    xgs = map(1:Ngroups, ~rep(1:Nxgroups,NperGroup[.]/Nxgroups)) %>% unlist
    #x = map(1:Ngroups, ~rep(1:NperGroup[.],Nxgroups)) %>% unlist
    xxm = rnorm(Ngroups,50,10)
    xxm = map(1:Ngroups, ~rep(xxm[.], NperGroup[.])) %>% unlist
    xgc = map(1:Ngroups, ~rnorm(NperGroup[.], 0, 3)) %>% unlist
    #xx = map(1:Ngroups, ~rep(rnorm(1,3,.6), NperGroup[.]))%>% unlist
    xx = xxm+xgc 
    
    l2p = sample(0:1, Ngroups, replace=T)
    l2p = map(1:Ngroups, ~rep(l2p[.], NperGroup[.])) %>% unlist
    
    l3p = i %% 2
    e = rnorm(N, sd = 15)
    
    y = 0 +
      dd[igs,1]+
      dd2[i,1]+
      #ddx[xgs, 1] + 
      -3*xxm+
      #-.05*(xx2 %in% c(1,2,4))*xgc+
      +4*xgc + 
      dd[igs,2]*xgc +
      #ddb[igs,2]*xxm + 
      1*dd2[i,2]*xxm +
      -3*l2p*xgc +
      2*l3p +
      e
    d = data.frame(y,xxm,xgc,igs,xgs,i, l2p,l3p)
    #ggplot(d,aes(x=x,y=y,group=factor(igs)))+facet_wrap(~xgs)+geom_path()
    d$ng2 = i
    df<-rbind(df,d)
  }
  df %>% filter(xgs == 1) %>%
  lmer(y ~ xxm + xgc + l2p + l3p + (1+xgc | ng2/igs), data =.,
       control=lmerControl(optimizer = "bobyqa")) -> m 
  print(VarCorr(m))
  t1 = attributes(VarCorr(m)[[1]])$stddev
  t2 = attributes(VarCorr(m)[[1]])$correlation
  t3 = attributes(VarCorr(m)[[2]])$stddev
  t4 = attributes(VarCorr(m)[[2]])$correlation
  
  if(!isSingular(m) & all(t1 != 0) & !(t2[lower.tri(t2)] %in% c(0,1,-1)) & all(t3 != 0) & !(t4[lower.tri(t4)] %in% c(0,1,-1)) ){
    doit <- 0
  }
}

df %>% filter(xgs==1) %>% transmute(
  alcunits = round(8+(scale(y)[,1]*4)),
  gad = xxm + xgc,
  gad = round(8+(scale(gad)[,1]*3)),
  center = ng2,
  ppt = igs,
  group = l2p,
  urb_rural = l3p
) %>% filter(center %in% c(2:5,8)) %>% 
  mutate(center=paste0("C",center),
         ppt = paste0("C",center,"_",ppt)) -> alcgad
write.csv(alcgad, "../../uoepsy/data/alcgad.csv", row.names=F)
```

.pull-left[
A research study investigates how anxiety is associated with drinking habits. Data was collected from 50 participants. Researchers administered the generalised anxiety disorder (GAD-7) questionnaire to measure levels of anxiety over the past week, and collected information on the units of alcohol participants had consumed within the week. Each participant was observed on 10 different occasions. 
]
.pull-right[
```{r echo=FALSE, fig.asp=.7}
alcgad <- read_csv("https://uoepsy.github.io/data/alcgad.csv") %>% mutate(interv = group)
ggplot(alcgad, aes(x=gad, y=alcunits,color=factor(ppt))) +
  geom_point(alpha=.4)+
  labs(x="Generalised Anxiety Disorder (GAD-7)",y="Units of Alcohol in previous 7 days")+
  guides(color="none")
```

data available at https://uoepsy.github.io/data/alcgad.csv 
]
???
- okay, let's think of a more realistic example. 
- let's suppose we are studying the relationship between anxiety and alcohol use, and we have multiple observations for each participant.  


---
# A more realistic example

.pull-left[
Is being more nervous (than you usually are) associated with higher consumption of alcohol?
]
.pull-right[
```{r echo=FALSE, fig.asp=.8}
alcgad %>% group_by(ppt) %>% mutate(gadm=mean(gad),gadmc=gad-gadm) %>%
ggplot(., aes(x=gadmc, y=alcunits)) +
  geom_point(alpha=.4)+
  labs(x="Generalised Anxiety Disorder (GAD-7)\n relative to participant average",y="Units of Alcohol in previous 7 days")+
  geom_smooth(method="lm",se=F)+
  guides(color="none")
```
]

???
- so we can really ask two separate questions here. 
- we can talk about the within effect. 
- if you are more nervous FOR YOU, do you drink more?

---
# A more realistic example

.pull-left[
Is being generally more nervous (relative to others) associated with higher consumption of alcohol?
]
.pull-right[
```{r echo=FALSE, fig.asp=.8}
alcgad %>% group_by(ppt) %>% mutate(gadm=mean(gad),gadmc=gad-gadm) %>%
ggplot(., aes(x=gadm, y=alcunits)) +
  geom_smooth(method="lm",se=F)+
  stat_summary(aes(group=ppt),geom="pointrange")+
  labs(x="Generalised Anxiety Disorder (GAD-7)\nparticipant average",y="Units of Alcohol in previous 7 days")+
  guides(color="none")
```
]

???
- and then we can think about the between effect.  
- this is like asking "is being a more anxious person associated with higher levels of alcohol consumption?"

---
# Modelling within & between effects

.pull-left[
```{r}
alcgad <- 
  alcgad %>% group_by(ppt) %>% 
  mutate(
    gadm=mean(gad),
    gadmc=gad-gadm
  )
alcmod <- lmer(alcunits ~ gadm + gadmc + 
                 (1 + gadmc | ppt), 
               data=alcgad,
               control=lmerControl(optimizer = "bobyqa"))
```
]
.pull-right[
```{r}
summary(alcmod)
```

]

???
- and just like the bigfish little pond, we can separate out the group mean and the deviations from the group mean. 
- so this is whether a person is more anxious than usual, and their overall mean anxiety score.  
- the more anxious you are FOR you, the more you drink
- the more anxious you are ON AVERAGE, the less you drink


---
# Modelling within & between interactions

.pull-left[
```{r}
alcmod <- lmer(alcunits ~ (gadm + gadmc)*interv + 
                 (1 | ppt), 
               data=alcgad,
               control=lmerControl(optimizer = "bobyqa"))
```
]
.pull-right[
```{r}
summary(alcmod)
```
]

???
- now another cool thing we can do is fit interactions with these specific effects. 
- so imagine we are testing whether some intervention is aimed to prevent people from using alcohol to "calm their nerves", and we have a group who have the intervention, and a group who don't. 
- the interaction between the intervention and the between effect doesn't make much difference. 
- but for the within effect it does. 
- so you can think of this as the intervention doesn't influence the extent to which more nervous people drink less. 
- but it does influence the extent to which people drink when they are more nervous FOR THEM


---
# Total effect

.pull-left[
```{r}
alcmod2 <- lmer(alcunits ~ gad + (1 | ppt), 
                data=alcgad,
                control=lmerControl(optimizer = "bobyqa"))
```
]
.pull-right[
```{r}
summary(alcmod2)
```
]

???
- Now that we've discussed the idea of these within & between effects, it raises a question. 
- what exactly are we modeling when we didn't separate them out? 
- what is the meaning of this effect here? 
- This effect represents regression of alcohol consumption on anxiety, pooling over all participants, and it's kind of a weighted composite effect of these within & between relations.  
- Now this might be perfectly sufficient for things like making predictions from your model, the location of this effect is a bit unclear 
  - where is the change? within or between? well, it's kind of both. 
- but really, the substantive and theoretically meaningful questions we have are more often about the specific effects that happen within or between groups, and this total effect doesn't really represent either.  

---
# Within & Between effects

```{r include=FALSE}
library(lme4)
set.seed(86)
doit<-1
while(doit){
  Ngroup2s = 10
  dd2<-MASS::mvrnorm(n=Ngroup2s, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
  cor(dd2)
  i = 2
  df<-as.data.frame(c())
  for(i in 1:Ngroup2s){
    Ngroups = round(rnorm(1,10,0))
    Nxgroups = 2
    
    #NperGroup = rep(Nxgroups*nrep,Ngroups)
    NperGroup = rdunif(Ngroups, 5, 10)*Nxgroups
    N = sum(NperGroup)
    
    dd<-MASS::mvrnorm(n=Ngroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    ddb<-MASS::mvrnorm(n=Ngroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    ddx<-MASS::mvrnorm(n=Nxgroups, mu = c(0,0), Sigma = matrix(c(1,0,0,1),byrow = T, nrow=2))
    
    igs = map(seq_along(NperGroup), ~rep(.,NperGroup[.])) %>% unlist
    xgs = map(1:Ngroups, ~rep(1:Nxgroups,NperGroup[.]/Nxgroups)) %>% unlist
    #x = map(1:Ngroups, ~rep(1:NperGroup[.],Nxgroups)) %>% unlist
    xxm = rnorm(Ngroups,50,10)
    xxm = map(1:Ngroups, ~rep(xxm[.], NperGroup[.])) %>% unlist
    xgc = map(1:Ngroups, ~rnorm(NperGroup[.], 0, 3)) %>% unlist
    #xx = map(1:Ngroups, ~rep(rnorm(1,3,.6), NperGroup[.]))%>% unlist
    xx = xxm+xgc 
    
    l2p = sample(1:4, Ngroups, replace=T, prob = c(.2,.5,.3,.1))
    l2p = map(1:Ngroups, ~rep(l2p[.], NperGroup[.])) %>% unlist
    
    l3p = i %% 2
    e = rnorm(N, sd = 15)
    
    y = 0 +
      dd[igs,1]+
      dd2[i,1]+
      #ddx[xgs, 1] + 
      -5*xxm+
      #-.05*(xx2 %in% c(1,2,4))*xgc+
      -6*xgc + 
      dd[igs,2]*xgc +
      #ddb[igs,2]*xxm + 
      1*dd2[i,2]*xxm +
      -3*l2p + 
      2*l3p +
      e
    d = data.frame(y,xxm,xgc,igs,xgs,i, l2p,l3p)
    #ggplot(d,aes(x=x,y=y,group=factor(igs)))+facet_wrap(~xgs)+geom_path()
    d$ng2 = i
    df<-rbind(df,d)
  }
  df %>% filter(xgs == 1) %>%
  lmer(y ~ xxm + xgc + l2p + l3p + (1+xgc | ng2/igs), data =.,
       control=lmerControl(optimizer = "bobyqa")) -> m 
  print(VarCorr(m))
  t1 = attributes(VarCorr(m)[[1]])$stddev
  t2 = attributes(VarCorr(m)[[1]])$correlation
  t3 = attributes(VarCorr(m)[[2]])$stddev
  t4 = attributes(VarCorr(m)[[2]])$correlation
  
  if(!isSingular(m) & all(t1 != 0) & !(t2[lower.tri(t2)] %in% c(0,1,-1)) & all(t3 != 0) & !(t4[lower.tri(t4)] %in% c(0,1,-1)) ){
    doit <- 0
  }
}

df %>% filter(xgs==1) %>% transmute(
  tgu = 8+(scale(y)[,1]*4),
  phys = round(xxm + xgc),
  hospital = ng2,
  patient = igs,
  prioritylevel = l2p,
  private = l3p
) %>% filter(hospital%in%c(5,6)) %>% 
  mutate(hospital=paste0("Hospital_",hospital),
patient = paste0(hospital,patient))-> tgudat

ggplot(tgudat, aes(x=phys, y=tgu,color=patient)) +
  geom_point(alpha=.4)+
  geom_smooth(aes(group=patient), method="lm",se=F,alpha=.4)+
  labs(x="Daily amount of Physiotherapy\n(minutes)", y="Time Get up and Go test (seconds)")+
  guides(color="none") -> p1

ggplot(bflp, aes(x=fish_weight, y=self_esteem))+
  geom_point()+
  geom_smooth(aes(group=pond),method="lm",se=F,alpha=.4)+
  labs(x="Fish Weight (kg)",y="Self Esteem Scale (1-5)")+
  ylim(1,5) -> p2

ggplot(alcgad, aes(x=gad, y=alcunits,color=factor(ppt))) +
  geom_point(alpha=.4)+
  geom_smooth(aes(group=ppt), method="lm",se=F,alpha=.4)+
  labs(x="Generalised Anxiety Disorder (GAD-7)",y="Units of Alcohol in previous 7 days")+
  guides(color="none") -> p3
```

.pull-left[
```{r echo=FALSE, fig.asp=.8}
p2
```
]
.pull-right[
```{r echo=FALSE, fig.asp=.8}
p3
```
]

???
- so here are the two examples we've just seen
- one last thing to note is that these within & between effects don't have to counteract one another. 
- these examples both had the within effect going one way, and the between effect going the other. 
- so when we plot the group lines like this, we see the lines going up, and you move across these lines tend to be starting lower.


---
count:false
# Within & Between effects

.pull-left[
```{r echo=FALSE, fig.asp=.8}
p1
```
]
???
- but that doesn't have to be the case, we can think of how both are in the same direction. 


--

.pull-right[
```{r echo=FALSE}
tgudat %>% group_by(patient) %>% mutate(physm= mean(phys),physc = phys-physm) %>% ungroup %>%
ggplot(., aes(x=physc, y=tgu,color=patient)) +
  geom_point()+
  geom_line(aes(group=patient), alpha=.4)+
  #geom_smooth(method="lm",se=F,alpha=.1)+
  labs(x="Daily amount of Physiotherapy\n(minutes relative to patient average)", y="TUG")+
  guides(color="none") ->p1

tgudat %>% group_by(patient) %>% mutate(physm= mean(phys),physc = phys-physm) %>% ungroup %>%
ggplot(., aes(x=physm, y=tgu,color=patient)) +
  #geom_point(alpha=.4)+
  #geom_line(aes(group=patient), alpha=.4)+
  stat_summary(geom="pointrange")+
  labs(x="Average daily amount of Physiotherapy\n(minutes)", y="TUG")+
  guides(color="none") -> p2
p1 / p2
```
]

???
- in this example, if you do more physio than you usually do, then your test time goes down, 
- if you do, on average, more physio than other people, then your test time tends to be lower. 

---
# Summary

- Applying the same linear transformation to a predictor (e.g. grand-mean centering, or standardising) makes __no difference__ to our model or significance tests
  - but it may change the meaning and/or interpretation of our parameters

- When data are clustered, we can apply group-level transformations, e.g. __group-mean centering.__ 

- Group-mean centering our predictors allows us to disaggregate __within__ from __between__ effects.  
  - allowing us to ask the theoretical questions that we are actually interested in




---
class: inverse, center, middle, animated, rotateInDownLeft

# End

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Back to the start</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Centering Predictors</h2>
<h2>Extra Slides (optional): GLMM</h2>

???
we're now going to talk about the generalised multilevel model.  
up til now, all of the outcome variables that we have been studying have been continuous.  
the generalised model allows us to also study outcomes that follow different distributions. 
we're going to look specifically about the logistic model as a means of studying binary outcomes - that is, outcomes that are comprised of two distinct categories. 



---
# lm() and glm()

.pull-left[
### lm()  
$$
\begin{align}
& \color{red}{y} = \color{blue}{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)} + \mathbf{\boldsymbol{\varepsilon}}\\
\end{align}
$$ 
]

???
let's first just think back to our single level linear model.
in this model is the outcome variable, y, is modelled as the weighted linear combination of our predictor variables, plus some random error

---
count:false
# lm() and glm()

.pull-left[
### lm()  
$$
\begin{align}
& \color{red}{y} = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
\end{align}
$$ 
]
???
we can write this list of explanatory variables and betas as X the matrix of predictors, and beta, the vector of coefficients. 


---
count:false
# lm() and glm()

.pull-left[
### lm()  
$$
\begin{align}
& \color{red}{y} = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
& \text{where } -\infty \leq \color{red}{y} \leq \infty \\
\end{align}
$$ 

]

???
now in this model, the outcome variable itself, y, is modelled directly as X beta plus the error term. 
and because x beta is simply defining a straight line (or, when we have lots more predictors, we extend this idea to more dimensions, but the logic is the same - the straight line model is a model of y. and straight lines just extend infinitely, so y, in these models, can be any value

--

.pull-right[
### &nbsp;

$$
\begin{align}
\color{red}{??} = & \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
\end{align}
$$ 
]
???
but we don't have to use this model to model the outcome variable DIRECTLY. 

---
count:false
# lm() and glm()

.pull-left[
### lm()  
$$
\begin{align}
& \color{red}{y} = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
& \text{where } -\infty \leq \color{red}{y} \leq \infty \\
\end{align}
$$ 

]

.pull-right[
### glm()

$$
\begin{align}
\color{red}{ln \left( \frac{p}{1-p} \right) } & = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
& \text{where } 0 \leq p \leq 1 \\
\end{align}
$$ 
]
???
when faced with an outcome variable that is binary, either 0 or 1, like "correct" or "incorrect", fitting a straight line to these values would mean we end up with predicted values outside the possible range of probability (e.g. below 0 or greater than 1).  
what we can do, however, is model something such as the log-odds, which are a way of translating probabilities to be unbounded from negative infinity to infinity

---
count:false
# lm() and glm()

.pull-left[
### lm()  
$$
\begin{align}
& \color{red}{y} = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
& \text{where } -\infty \leq \color{red}{y} \leq \infty \\
\end{align}
$$ 

]

.pull-right[
### glm()

$$
\begin{align}
\color{red}{ln \left( \frac{p}{1-p} \right) } & = \color{blue}{\underbrace{\beta_0 + \beta_1(x_1) + ... + \beta_k(x_k)}_{\mathbf{X \boldsymbol{\beta}}}} + \boldsymbol{\varepsilon} \\
& \text{where } 0 \leq p \leq 1 \\
\end{align}
$$ 

glm() is the __generalised__ linear model. 

we can specify the link function to model outcomes with different distributions.  
this allows us to fit models such as the _logistic_ regression model:
```{}
glm(y~x, family = binomial(link="logit"))
```
]
???
so what we are doing here is not modelling the outcome directly, but modeling it by specifying some relation between the linear prediction (this bit in blue) and the observed outcome variable. and in this case we have the logit link. 

---
# logistic regression visualised

.pull-left[
### continuous outcome
<br><br>
```{r echo=FALSE, fig.asp=.7}
set.seed(94)
tibble(
  x=rnorm(200,10,3),
  y=2*x+rnorm(200,0,5)
) %>% lm(y~x,data=.) -> mod
ggplot(broom::augment(mod), aes(x=x,y=y))+
  geom_point()
```
]
.pull-right[
### binary outcome
<br><br>
```{r echo=FALSE, fig.asp=.7}
set.seed(35)
tibble(
  x=rnorm(200,0,3),
  y=rbinom(200, size = 1, prob = plogis(.45*x))
) %>% glm(y~x,data=.,family=binomial) -> mod1
ggplot(broom::augment(mod1), aes(x=x,y=y))+
  geom_point() +
  #geom_smooth(method="glm",method.args=list(family=binomial),se=F, fullrange=T)+
  #geom_smooth(method="lm",se=F)+
  #geom_smooth(method="lm",se=F,fullrange=T)+
  #labs(y="probability")+
  xlim(0,12)+
  NULL
```
]
???
let's visualise this idea then. we have a continuous outcome on the left plot and a binary outcome on the right one. 

---
count:false
# logistic regression visualised

.pull-left[
### linear regression
we model __y__ directly as linear combination of one or more predictor variables 
```{r echo=FALSE, fig.asp=.7}
ggplot(broom::augment(mod), aes(x=x,y=y))+
  geom_point() +
  geom_smooth(method="lm",se=F,fullrange=T)
```
]
.pull-right[
### logistic regression
__probability__ is _not_ linear..  
but we can model it indirectly  
```{r echo=FALSE, fig.asp=.7}
ggplot(broom::augment(mod1), aes(x=x,y=y))+
  geom_point() +
  geom_smooth(method="glm",method.args=list(family=binomial),se=F, fullrange=T)+
  #geom_smooth(method="lm",se=F)+
  #geom_smooth(method="lm",se=F,fullrange=T)+
  labs(y="probablity\nP(y=1)")+
  xlim(0,12)+
  NULL
```
]
???
with the continuous outcome, we can model the outcome directly. 
with the binary outcome, we can't because probability is not linear. it is bounded between 0 and 1

---
count:false
# logistic regression visualised

$ln \left( \frac{p}{1-p} \right)$  
__log-odds__ are linear  

```{r echo=FALSE,eval=FALSE}
ggplot(broom::augment(mod1) %>% mutate(fit2 = predict(mod1,type="link"),pob =log(y/(1-y))), 
       aes(x=x,y=fit2))+
  geom_line() + 
  geom_point(aes(y=pob),size=7,alpha=.3)+
  labs(y="log-odds\n ln(p/p-1)")+
  NULL + 
ggplot(broom::augment(mod1) %>% mutate(fit2 = exp(predict(mod1,type="link")),pob =y/(1-y)), 
       aes(x=x,y=fit2))+
  geom_line() + 
  geom_point(aes(y=pob),size=7,alpha=.3)+
  labs(y="odds\n p/p-1")+ylim(0,70)+
  NULL +
ggplot(broom::augment(mod1) %>% mutate(fit2 = exp(predict(mod1,type="link"))/(1+exp(predict(mod1,type="link"))),pob =y), 
       aes(x=x,y=fit2))+
  geom_line() + 
  geom_point(aes(y=pob),size=7,alpha=.3)+
  labs(y="probability\n p")+
  NULL
```

```{r echo=FALSE, out.height = "400px"}
knitr::include_graphics("jk_img_sandbox/logoddp.png")
```


???
so what we do is model the log-odds. the odds of an event is the probabilty of it happening, divided by the probability of it not happening. and these can range from 0 to infinity.
when we take the natural log of these, we get something that ranges from negative to postivie infinity.  
  
now if we try to take our raw outcome variable as probabilities which we can translate into log-odds, we run into a little problem. 
when we observe a binary variable, we observe whether something IS or ISN'T. we don't MEASURE the probability that someone gets a question correct. We just measure that it IS correct or incorrect. 
now if we translate those into log-odds, we get values of negative infinity and infinity for values of 0 and 1 respectively. 
We can try to fit a line to these, but it doesn't really make sense. what would the residuals be? residuals would also all be infinity, and so it becomes impossible to work out anything!  
so when we fit these models, we use maximum likelihood estimation to find the slope of this line that has the greatest probability of giving rise to the data that we have. 
now this is all covered in dapr2, so it's maybe worth going back to some of these if you are interested. 

---
# lmer() and glmer()

.pull-left[

```{r echo=FALSE,fig.asp=.8}
crq <- read_csv("https://uoepsy.github.io/data/crqdetentiondata.csv")
linmod <- lmer(emot_dysreg ~ crq + (1 + crq | schoolid), crq)
crq %>% mutate(
  fit = predict(linmod)
) %>% 
  ggplot(.,aes(x=crq, y=fit))+
  geom_point(aes(y=emot_dysreg))+
  geom_smooth(method="lm",se=F,aes(group=schoolid))+
  labs(x="Childhood Routines Questionnaire (CRQ)",y="Model estimated\nEmotion Dysregulation Score (EDS)")
```

] 
.pull-right[

```{r echo=FALSE,fig.asp=.8}
logmod <- glmer(detention ~ crq + (1 + crq | schoolid), crq, family=binomial)
crq %>% mutate(
  fit = predict(logmod, type="response")
) %>% 
  ggplot(.,aes(x=crq, y=fit))+
  geom_point(aes(y=detention))+
  geom_smooth(method="glm", method.args=list(family=binomial),aes(group=schoolid), se=F)+
  labs(x="Childhood Routines Questionnaire (CRQ)",y="Model estimated\nProbability of receiving detention")
```

]

???
but for now we'll return to the multilevel model.  
we've seen already that for the linear mixed model, we can model groups of observations as varying in the intercept and slopes. 
and not much is different for the logistic multilevel model, we can simply allow those groups to vary in intercept and slope of the log-odds. and then when we translate these back on to the probability scale, we see that the probability curve is different for each group

---
count:false
# lmer() and glmer()

.pull-left[
```{r echo=FALSE,fig.asp=.8}
crq <- read_csv("https://uoepsy.github.io/data/crqdetentiondata.csv")
linmod <- lmer(emot_dysreg ~ crq + (1 + crq | schoolid), crq)
crq %>% mutate(
  fit = predict(linmod)
) %>% 
  ggplot(.,aes(x=crq, y=fit))+
  geom_point(aes(y=emot_dysreg))+
  geom_smooth(method="lm",se=F,aes(group=schoolid))+
  labs(x="Childhood Routines Questionnaire (CRQ)",y="Model estimated\nEmotion Dysregulation Score (EDS)")
```

] 
.pull-right[


```{r echo=FALSE,fig.asp=.8}
logmod <- glmer(detention ~ crq + (1 + crq | schoolid), crq, family=binomial)
crq %>% mutate(
  fit = predict(logmod, type="link")
) %>% 
  ggplot(.,aes(x=crq, y=fit))+
  geom_point(aes(y=log(detention/(1-detention))))+
  geom_smooth(method="lm",aes(group=schoolid), se=F)+
  labs(x="Childhood Routines Questionnaire (CRQ)",y="Model estimated\nLog-Odds of receiving detention")
```

]
???
but really this is the same idea underneath, when we see the fit on the log-odds scale

---
# fitting glmer()

.pull-left[

> Researchers are interested in whether the level of routine a child has in daily life influences their probability of receiving a detention at school. 200 pupils from 20 schools completed a survey containing the Child Routines Questionnaire (CRQ), and a binary variable indicating whether or not they had received detention in the past school year. 

]
.pull-right[
```{r}
crq <- read_csv("https://uoepsy.github.io/data/crqdetentiondata.csv")
crq %>% 
  select(schoolid, crq, detention) %>%
  head()
```
]

```{r}
detentionmod <- glmer(detention ~ crq + (1 + crq | schoolid),
      data = crq, 
      family="binomial",
      control = glmerControl(optimizer = "bobyqa"))
```


???
and when we fit these models just like lm and glm, we have the glmer() function, where we can set the family. 
so we might be interested in how the level of routine a child has influences probabiltiy of receiving a detentiom at school. we can fit this model with glmer(), and you can see the structure is much the same as with lmer. 

family
lmerControl >> glmerControl


---
# fitting glmer()

.pull-left[
```{r}
summary(detentionmod)
```
]
.pull-right[
```{r}
exp(fixef(detentionmod))
```
]

???
one thing to note is that our summary output  now has p-values based on Wald tests.  

The other key thing is that these fixed effects are in terms of changes in log-odds. so just like a single level logistic regression, we can exponentiate them to get an odds ratio 
so this is that for each unit increase on the CRQ, a child has 0.11 times the odds of receiving a detention. 

---
# interpretating coefficients


- `lm(y ~ x + ...)`
  - $\beta_x$ denotes the change in the average $y$ when $x$ is increased by one unit and all other covariates are fixed.

- `lmer(y ~ x + ... + (1 + x + ... | cluster))`
  - $\beta_x$ denotes the change in the average $y$ when $x$ is increased by one unit, averaged across clusters

- `glmer(ybin ~ x + ... + (1 + x + ... | cluster), family=binomial)`
  - $e^{\beta_x}$ denotes the change in the average $y$ when $x$ is increased by one unit, __holding cluster constant.__
 

???
there's one more nuance to the logistic multilevel model, and that is that the effects we get out are cluster-specific. 
because the model is using a non-linear link function (the logit), when we exponentiate the fixed effect, the resulting number is interpreted as the effect "when holding the cluster constant". 

so there is this distinction beteen cluster specific and population average effects, which is quite tricky.  
our  effects are cluster specific in that our odds ratio we just saw was the ratio of odds of receiving detention when our predictor increases by 1, for a child FROM THE SAME SCHOOL.
whereas the population average effect would be the ratio of odds relative to a child picked at random from any school

---
# why are glmer() coefficients cluster-specific?
consider a __linear__ multilevel model: `lmer(respiratory_rate ~ treatment + (1|hospital))`

Imagine two patients from different hospitals. One has a treatment, one does not. 
  - patient $j$ from hospital $i$ is "control"   
  - patient $j'$ from hospital $i'$ is "treatment"  

The difference in estimated outcome between patient $j$ and patient $j'$ is the "the effect of having treatment" plus the distance in random deviations between hospitals $i$ and $i'$  

model for patient $j$ from hospital $i$  
$\hat{y}_{ij} = (\gamma_{00} + \zeta_{0i}) + \beta_1 (Treatment_{ij} = 0)$

model for patient $j'$ from hospital $i'$  
$\hat{y}_{i'j'} = (\gamma_{00} + \zeta_{0i'}) + \beta_1 (Treatment_{i'j'} = 1)$

difference:  
$\hat{y}_{i'j'} - \hat{y}_{ij} = \beta_1 + (\zeta_{0i'} - \zeta_{0i}) = \beta_1$

Because $\zeta \sim N(0,\sigma_\zeta)$, the differences between all different $\zeta_{0i'} - \zeta_{0i}$ average out to be 0. 

???
the zeta differences here will be, on average 0. 
hist(replicate(1000, mean(map_dbl(combn(rnorm(100),2, simplify=F), diff))),breaks=20)


---
# why are glmer() coefficients cluster-specific?

consider a __logistic__ multilevel model: `glmer(needs_op ~ treatment + (1|hospital), family="binomial")`

Imagine two patients from different hospitals. One has a treatment, one does not. 
  - patient $j$ from hospital $i$ is "control"   
  - patient $j'$ from hospital $i'$ is "treatment"  
  
The difference in __probability of outcome__ between patient $j$ and patient $j'$ is the "the effect of having treatment" plus the distance in random deviations between hospitals $i$ and $i'$  

model for patient $j$ from hospital $i$  
$log \left( \frac{p_{ij}}{1 - p_{ij}} \right)  = (\gamma_{00} + \zeta_{0i}) + \beta_1 (Treatment_{ij} = 0)$

model for patient $j'$ from hospital $i'$  
$log \left( \frac{p_{i'j'}}{1 - p_{i'j'}} \right) = (\gamma_{00} + \zeta_{0i'}) + \beta_1 (Treatment_{i'j'} = 1)$

difference (log odds):  
$log \left( \frac{p_{i'j'}}{1 - p_{i'j'}} \right) - log \left( \frac{p_{ij}}{1 - p_{ij}} \right) = \beta_1 + (\zeta_{0i'} - \zeta_{0i})$

---
# why are glmer() coefficients cluster-specific?

consider a __logistic__ multilevel model: `glmer(needs_op ~ treatment + (1|hospital), family="binomial")`

Imagine two patients from different hospitals. One has a treatment, one does not. 
  - patient $j$ from hospital $i$ is "control"   
  - patient $j'$ from hospital $i'$ is "treatment"  
  
The difference in __probability of outcome__ between patient $j$ and patient $j'$ is the "the effect of having treatment" plus the distance in random deviations between hospitals $i$ and $i'$  

model for patient $j$ from hospital $i$  
$log \left( \frac{p_{ij}}{1 - p_{ij}} \right)  = (\gamma_{00} + \zeta_{0i}) + \beta_1 (Treatment_{ij} = 0)$

model for patient $j'$ from hospital $i'$  
$log \left( \frac{p_{i'j'}}{1 - p_{i'j'}} \right) = (\gamma_{00} + \zeta_{0i'}) + \beta_1 (Treatment_{i'j'} = 1)$

difference (odds ratio):  
$\frac{p_{i'j'}/(1 - p_{i'j'})}{p_{ij}/(1 - p_{ij})} = \exp(\beta_1 + (\zeta_{0i'} - \zeta_{0i}))$

---
# why are glmer() coefficients cluster-specific?

consider a __logistic__ multilevel model: `glmer(needs_op ~ treatment + (1|hospital), family="binomial")`

Imagine two patients from different hospitals. One has a treatment, one does not. 
  - patient $j$ from hospital $i$ is "control"   
  - patient $j'$ from hospital $i'$ is "treatment"  
  
The difference in __probability of outcome__ between patient $j$ and patient $j'$ is the "the effect of having treatment" plus the distance in random deviations between hospitals $i$ and $i'$  

model for patient $j$ from hospital $i$  
$log \left( \frac{p_{ij}}{1 - p_{ij}} \right)  = (\gamma_{00} + \zeta_{0i}) + \beta_1 (Treatment_{ij} = 0)$

model for patient $j'$ from hospital $i'$  
$log \left( \frac{p_{i'j'}}{1 - p_{i'j'}} \right) = (\gamma_{00} + \zeta_{0i'}) + \beta_1 (Treatment_{i'j'} = 1)$

difference (odds ratio):  
$\frac{p_{i'j'}/(1 - p_{i'j'})}{p_{ij}/(1 - p_{ij})} = \exp(\beta_1 + (\zeta_{0i'} - \zeta_{0i})) \neq \exp(\beta_1)$

```{r eval=F,echo=F}
#fixed effect is 1.2
gamma00 = 1.2
# 10 groups. random effects are:
zetas = rnorm(10)
# the difference between random chosen observation from group i with x = 0, 
# and randomly chosen observation from group i' with x = 1
# is gamma_00 + (ranef_i' - ranef_i)
# these are all the (ranef_i' - ranef_i)'s
map_dbl(combn(zetas, 2, simplify=F),diff)
# so the expected value, because we assume zetas are N(0,s), is gamma00:
hist(replicate(1e4, mean(gamma00 + map_dbl(combn(rnorm(10),2, simplify=F), diff))), breaks=20)
# hence beta (e.g. gamma + zeta) is the effect of x "averaged across clusters"

##### 
# BUT WAIT!
# glmm says "what about me?"
# logistic model means gamma00 and zetas are all in log-odds. 
# the exponent of gamma_00 + (ranef_i' - ranef_i) is not the exponent of gamma_00
gamma00 = 1.2 # equivalent to odds ratio of 3.3
zetas = rnorm(10) # random deviations (in log odds) around gamma 
hist(replicate(1e4, mean(exp(gamma00 + map_dbl(combn(rnorm(10),2, simplify=F), diff)))), breaks=20)
```

---
# why are glmer() coefficients cluster-specific?

consider a __logistic__ multilevel model: `glmer(needs_op ~ treatment + (1|hospital), family="binomial")`  

Hence, the interpretation of $e^{\beta_1}$ is not the odds ratio for the effect of treatment "averaged over hospitals", but rather for patients _from the same hospital_. 
 
---
# Summary

- Differences between linear and logistic multi-level models are analogous to the differences between single-level linear and logistic regression models.  

- Fixed effects in logistic multilevel models are "conditional upon" holding the cluster constant. 

???
okay, that's a bit of a tangent. the key thing here is the similarity between lm and glm and lmer and glmer.  
Much like when we include interactions in a model, our effects of individual predictors are "conditional upon" the level of the other variable. 


---
class: inverse, center, middle, animated, rotateInDownLeft

# End

