<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>WEEK 1 Linear Models and Clustered Data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Josiah King" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <link href="jk_libs/libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="jk_libs/libs/tile-view/tile-view.js"></script>
    <link href="jk_libs/libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="jk_libs/libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="jk_libs/libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <b>WEEK 1<br>Linear Models and Clustered Data</b>
## Data Analysis for Psychology in R 3
### Josiah King
### Department of Psychology<br/>The University of Edinburgh
### AY 2020-2021

---










---
class: inverse, center, middle

# Part 1&lt;br&gt;Linear Regression Refresh

---

# deterministic vs statistical model

y = mx + c

`\(y = \alpha + \beta x + \epsilon\)`  

.br3.pa2.f3.white.bg-gray[
$$ \textrm{outcome} = (\textrm{model}) + \textrm{error} $$
]

---
# The Linear Model

.br3.pa2.f2[
$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error} \\
\color{red}{y} &amp; = \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x} + \epsilon \\
\text{where } \\
\epsilon &amp; \sim N(0, \sigma) \text{ independently} \\
\end{align}`
$$
]

---
# Model structure

.flex.items-top[
.w-50.pa2[

`\(\color{red}{y} = \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x} + \epsilon\)`  
  
so the _fitted_ linear model itself is:  

`\(\hat{y} = \color{blue}{\hat \beta_0 \cdot{} 1 + \hat \beta_1 \cdot{} x}\)`  

]
.w-50.pa2[
![](dapr3_lec1_files/figure-html/bb-1.png)&lt;!-- --&gt;
]]

---
# An Example



.flex.items-top[
.w-50.pa2[

`\(\color{red}{y_i} = \color{blue}{5 \cdot{} 1 + 2 \cdot{} x_i} + \epsilon_i\)`  
  
{{content}}
]
.w-50.pa2[
![](dapr3_lec1_files/figure-html/errplot-1.png)&lt;!-- --&gt;
]]

--

For the `\(i^{th}\)` observation
  - `\(\color{red}{y_i}\)` is the value we observe for `\(x_i\)`   
  - `\(\hat{y}_i\)` is the value the model _predicts_ for `\(x_i\)`   
  - `\(\color{red}{y_i} = \hat{y}_i + \epsilon_i\)`  

{{content}}

--

__e.g.__ for an observation `\(x_i = 1.2\)`, `\(y_i = 9.9\)`:
$$
`\begin{align}
\color{red}{9.9} &amp; = \color{blue}{5 \cdot{}} 1 + \color{blue}{2 \cdot{}} 1.2 + \epsilon_i \\
&amp; = 7.4 + \epsilon_i \\
&amp; = 7.4 + 2.5 \\
\end{align}`
$$

---
# Extending the linear model
## Categorical Predictors

---
count: false
# Extending the linear model
## Multiple predictors


---
count: false
# Extending the linear model
## Interactions

---
count: false
# Extending the linear model
## Link functions



---
# Linear Models in R


```r
linear_model &lt;- lm(y ~ x1 + x2 + x3*x4, data = df)
```


```r
logistic_model &lt;- glm(y ~ x1 + x2 + x3*x4, data = df, family="binomial")
```



---
# Inference for the linear model

&lt;img src="jk_img_sandbox/sum1.png" width="2560" height="500px" /&gt;

---
# Inference for the linear model

&lt;img src="jk_img_sandbox/sum2.png" width="2560" height="500px" /&gt;

---
# Inference for the linear model

&lt;img src="jk_img_sandbox/sum3.png" width="2560" height="500px" /&gt;

---
# Inference for the linear model

&lt;img src="jk_img_sandbox/sum4.png" width="2560" height="500px" /&gt;

---
# Assumptions

$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error} \\
\color{red}{y} &amp; = \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x} + \epsilon \\
\text{where } \\
\epsilon &amp; \sim N(0, \sigma) \text{ independently} \\
\end{align}`
$$

---
# Assumptions

Our linear model is expressing that 
`$$y = X\beta + \epsilon$$`
`$$y \sim Normal(X\beta, \sigma)$$`

--

Recall, our ability to generalise from our model fitted on sample data to the wider population requires making some _assumptions_

--

- assumptions about the nature of the **model** .tr[
(linear)
]

--

- assumptions about the nature of the **errors** .tr[
(normal)
]

---
count: false
# Checking Assumptions

.pull-left[

residuals should be zero mean and constant variance. 
what does this look like? 

well, we want the mean of the residuals to be zero, and we want a close to normal distribution.
furthermore, we want that spread to be constant across the fitted values. 

]
.pull-right[


```r
library(tidyverse)
df&lt;-tibble(x=rnorm(1000),y=2*x+rnorm(1000))
lm(y~x,df) %&gt;% plot(which=1)
```

![](dapr3_lec1_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

]


---
count: false
# Checking Assumptions
## (the "recipe book" way)

&lt;div class="acronym"&gt;
L
&lt;/div&gt; inearity&lt;br&gt;
&lt;div class="acronym"&gt;
I
&lt;/div&gt; ndependence&lt;br&gt;
&lt;div class="acronym"&gt;
N
&lt;/div&gt; ormality&lt;br&gt;
&lt;div class="acronym"&gt;
E
&lt;/div&gt; qual variance&lt;br&gt;

.footnote["Line without N is a Lie!" (Umberto)]

---

# The Broader Idea


All our work here is in aim of making models of the world.

- Models are models. They are simplifications, and so wrong/imperfect.  
- Our residuals ( `\(y - \hat{y}\)` ) reflect everything that we don't account for in our model
- In an ideal world, our model accounts for _all_ the systematic relationships. What is left over (our residuals) is just randomness. 
    - If our model is mis-specified, or misses out something systematic, then our residuals will reflect this.
- We check by examining how much "like randomness" the residuals appear to be (zero mean, normally distributed, constant variance, i.i.d ("independent and identically distributed")
    - _this tends to get referred to as our "assumptions"_
- We will never know whether our residuals contain only randomness - we can never observe everything! 

---

# What if our model doesn't meet assumptions?

- bootstrap!

what about independence? 




---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 1

---
class: inverse, center, middle

# Part 2&lt;br&gt;Clustered Data

---

# What is clustered data?

- children within schools
- patients within clinics
- observations within individuals

terms: "levels","hierarchical"

- children within classrooms within schools within districts etc...

---
# Why is it relevant?  

- clustering will likely result in measurement on observational units within a given cluster being more similar to those of other clusters.  
  - e.g. our measured outcome for children in a given class will tend to be more similar to one another (because of class specific things such as the teacher) than to children in other classes

- clustering is expressed in terms of the correlation among the measurements within the same cluster

---
# ICC (intra-class correlation coefficient)

- various forms
- variance within / total variance  
- `\(\rho = \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_\epsilon}\)`


---
# Why is clustered data a problem for lm?

`$$\epsilon \sim N(0, \sigma) \textbf{ independently}$$` 

- clustering is something systematic that our model should (arguably) take into account. 
- "independence" assumption.  

---
# HOW is clustered data a problem for lm?

example

We saw:
`$$SE(\hat \beta_1) = \sqrt{\frac{ SS_{Residual}/(n-k-1)}{\sum(x_i - \bar{x})^2}}$$`

suppose that `\(\rho = 1\)`. i.e., all the variation we see is due to the clustering. 

---
# Various values of `\(\rho\)`

![](dapr3_lec1_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

---
count: false
# Various values of `\(\rho\)`

![](dapr3_lec1_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---

# Summary

---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 2

---
class: inverse, center, middle

# Part 3
## Possible solutions



---
# Some toy data

&lt;img src="dapr3_lec1_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

---
# Ignore it


```r
model &lt;- lm(nworms ~ arrival_time, data = df)
summary(model)$coefficients
```

```
##              Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)    8.9120     1.5930   5.595 1.456e-07
## arrival_time   0.6331     0.2194   2.886 4.647e-03
```

---
count: false
# Ignore it

.pull-left[

__Complete pooling__  

Data from all gardens is pooled together to estimate over x 

]
.pull-right[
![](dapr3_lec1_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;
]

---
count: false
# Ignore it 

.pull-left[
### __(Complete pooling)__  

Information from all clusters is pooled together to estimate over x 

But different clusters show different patterns. 
Residuals are not independent.  
]
.pull-right[
![](dapr3_lec1_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;
]

---
# Lesser used solutions  

Don't model the clustering directly, but incorporate the dependency into our error term. 

$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error}^* \\
\end{align}`
$$
* Where errors are correlated with clusters/with the error previously/etc. 

---
count: false
# Lesser used solutions  

.pull-left[
#### __Cluster Robust Standard Errors__


```r
library(plm)
clm &lt;- plm(y~x,data=df, model="pooling", index="id")
summary(clm)$coefficients
```

```
##             Estimate Std. Error t-value  Pr(&gt;|t|)
## (Intercept)   8.9120     1.5930   5.595 1.456e-07
## x             0.6331     0.2194   2.886 4.647e-03
```

```r
sqrt(diag(vcovHC(clm, method='arellano', cluster='group')))
```

```
## (Intercept)           x 
##       2.948       0.440
```
]
.pull-right[
#### __Generalised Estimating Equartions (GEE)__  


```r
library(geepack)
df &lt;- df %&gt;% arrange(id) %&gt;%
  mutate(
    id = as.numeric(as.factor(id))
  )
geemod  = geeglm(y~x, data=df, corstr='independence', id=id)
summary(geemod)$coefficients %&gt;% round(3)
```

```
##             Estimate Std.err  Wald Pr(&gt;|W|)
## (Intercept)    8.912   2.948 9.137    0.003
## x              0.633   0.440 2.070    0.150
```
]

---
# fixed effects


```r
model &lt;- lm(nworms ~ arrival_time + gardenid, data = df)
summary(model)$coefficients
```

```
##                  Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)       20.9224     2.4704  8.4692 1.441e-13
## arrival_time      -2.0432     0.3335 -6.1273 1.514e-08
## gardenidgarden10   4.6657     1.4432  3.2328 1.630e-03
## gardenidgarden11  -4.9860     1.6822 -2.9640 3.744e-03
## gardenidgarden12   0.7877     1.4545  0.5415 5.893e-01
## gardenidgarden2   20.1093     1.7479 11.5049 2.014e-20
## gardenidgarden3   -2.6904     1.8769 -1.4335 1.546e-01
## gardenidgarden4    5.9131     1.6014  3.6925 3.514e-04
## gardenidgarden5   12.3545     1.6141  7.6543 9.096e-12
## gardenidgarden6    7.2528     1.4465  5.0140 2.126e-06
## gardenidgarden7   19.1282     1.6356 11.6952 7.525e-21
## gardenidgarden8    2.1677     1.4248  1.5214 1.311e-01
## gardenidgarden9   12.0886     1.7181  7.0362 1.960e-10
```

---
count: false
# fixed effects

.pull-left[
### __(No Pooling)__

Information from a cluster contributes to estimate *for that cluster*, but information is not pooled to estimate an overall effect. 

]
.pull-right[
![](dapr3_lec1_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]

---
# LMM



```r
library(lme4)
model &lt;- lmer(y~x+(1|id),df)
summary(model)$coefficients
```

```
##             Estimate Std. Error t value
## (Intercept)   25.213     3.0888   8.163
## x             -1.737     0.3177  -5.466
```


---
count: false
# LMM 

__(Partial Pooling)__



---

# Summary


---
class: inverse, center, middle, animated, rotateInDownLeft

# End

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
