<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Linear Models and Clustered Data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Josiah King" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <script src="jk_libs/libs/clipboard/clipboard.min.js"></script>
    <link href="jk_libs/libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="jk_libs/libs/shareon/shareon.min.js"></script>
    <link href="jk_libs/libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="jk_libs/libs/xaringanExtra-shareagain/shareagain.js"></script>
    <link href="jk_libs/libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="jk_libs/libs/tile-view/tile-view.js"></script>
    <link href="jk_libs/libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="jk_libs/libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="jk_libs/libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b>Linear Models and Clustered Data</b>
]
.subtitle[
## Data Analysis for Psychology in R 3
]
.author[
### Josiah King
]
.institute[
### Department of Psychology<br/>The University of Edinburgh
]

---





class: inverse, center, middle

&lt;h2&gt;Part 1: Linear Regression Refresh&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 2: Clustered Data&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 3: Where we're going&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Extra slides (optional): Other Approaches&lt;/h2&gt;

???

Before we get to the main focus of this 5 week block, we're going to start with a refresher of Linear models  

Treat as a sort of high-level overview of DAPR2.

limited time, so we might have to go quickly. but do remember that things like piazza and the lab sessions are there for you to ask any questions, and that inludes on stuff like this 


---

# Models

.pull-left[
__deterministic__  

given the same input, deterministic functions return *exactly* the same output

- `\(y = mx + c\)`  

- area of sphere = `\(4\pi r^2\)`  

- height of fall = `\(1/2 g t^2\)`
    - `\(g = \textrm{gravitational constant, }9.8m/s^2\)`
    - `\(t = \textrm{time (in seconds) of fall}\)`

]

???
getting straight into it, what all of this is about is making models of the world, that we can use in some way.  

models tend to come in two forms, the deterministic, mathematical model.  
think laws of nature and physics, geometry etc.  

--

.pull-right[
__statistical__  

.br2.f4.white.bg-gray[
$$ 
\textrm{outcome} = (\textrm{model}) + \color{black}{\textrm{error}}
$$
]

- handspan = height + randomness  

- cognitive test score = age + premorbid IQ + ... + randomness

]

???
for us though, we're working with statistical models.  
these are models where there is an overall pattern, but there is randomness.  
i.e. individual variation from the pattern


---
# The Linear Model

.br3.pa2.f2[
$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error} \\
\color{red}{y_i} &amp; = \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x_i} + \varepsilon_i \\
\text{where } \\
\varepsilon_i &amp; \sim N(0, \sigma) \text{ independently} \\
\end{align}`
$$
]

???
the linear model is one such type of model, where an outcome variable y
is models a linear combination of some set of predictor variables x, plus some error term.  
this is what we worked with all last year, y = beta0 + beta1 x + e  

---
# The Linear Model

.flex.items-top[
.w-50.pa2[
Our proposed model of the world:

`\(\color{red}{y_i} = \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x_i} + \varepsilon_i\)`  
  
{{content}}
]
.w-50.pa2[
![](01_lmcluster_files/figure-html/bb-1.svg)&lt;!-- --&gt;
]]

???
in it's simplest form with one continuous predictor, it looks something like this - a straight line.  

--

Our model _fitted_ to some data (note the `\(\widehat{\textrm{hats}}\)`):  

`\(\hat{y}_i = \color{blue}{\hat \beta_0 \cdot{} 1 + \hat \beta_1 \cdot{} x_i}\)`  

{{content}}

???
the model is our blue line, with model predicted values (use y hat for those)

--

For the `\(i^{th}\)` observation:
  - `\(\color{red}{y_i}\)` is the value we observe for `\(x_i\)`   
  - `\(\hat{y}_i\)` is the value the model _predicts_ for `\(x_i\)`   
  - `\(\color{red}{y_i} = \hat{y}_i + \hat\varepsilon_i\)`  
  
???
and there is variation around that line, these deviations from observed value to model predicted value are our residuals. 

---
# An Example


.flex.items-top[
.w-50.pa2[

`\(\color{red}{y_i} = \color{blue}{5 \cdot{} 1 + 2 \cdot{} x_i} + \hat\varepsilon_i\)`  
  
__e.g.__   
for the observation `\(x_i = 1.2, \; y_i = 9.9\)`:  

$$
`\begin{align}
\color{red}{9.9} &amp; = \color{blue}{5 \cdot{}} 1 + \color{blue}{2 \cdot{}} 1.2 + \hat\varepsilon_i \\
&amp; = 7.4 + \hat\varepsilon_i \\
&amp; = 7.4 + 2.5 \\
\end{align}`
$$
]
.w-50.pa2[
![](01_lmcluster_files/figure-html/errplot-1.svg)&lt;!-- --&gt;
]]

???
and the individual observations are going to deviate a little from this due to other stray causes and randomness  

so if our estimate for beta0 is 5 and beta1 is 2, our line is defined by those numbers  
- it hits the y axis at 5
- every 1 it increases in x, it increases by 2 in y

---
# Categorical Predictors

.pull-left[  
&lt;br&gt;&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; y &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; x &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 7.99 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 4.73 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3.66 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3.41 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5.75 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5.66 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Category0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ... &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ... &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]
.pull-right[
![](01_lmcluster_files/figure-html/unnamed-chunk-2-1.svg)&lt;!-- --&gt;
]

???
the linear model is really useful, and can be applied to a range of scenarios. 
categorical predictors get entered into our model as sets of variables of 0s and 1s. we can do some clever things to change what the 0s and 1s represent, but the default is:
- zero as some reference category
- changes of 1 representing changes from that reference to some other category


---
# Multiple Predictors

.pull-left[
![](01_lmcluster_files/figure-html/unnamed-chunk-3-1.svg)&lt;!-- --&gt;
]

???
we can have more than one predictor too. rather than fitting a line, our model becomes a 3 dimensional surface fitted to a 3 dimensional cloud of datapoints.  
residuals continue to be deviations from this model to the observations.  

--

.pull-right[
![](01_lmcluster_files/figure-html/unnamed-chunk-4-1.svg)&lt;!-- --&gt;
]

???
add in another categorical predictor, and we have two surfaces.  
add in another continuous predictor, and i can't visualise it anymore because we're in more than 3 dimensions, but the logic persists.  

---
exclude: true
# Multiple Predictors

.pull-left[
&lt;img src="jk_img_sandbox/SSblank1.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]
.pull-right[]

---
# Multiple Predictors

.pull-left[
&lt;img src="jk_img_sandbox/SSblank1cov.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]
.pull-right[



```r
lm(y ~ x1)
```

```
## 
## Call:
## lm(formula = y ~ x1)
## 
## Coefficients:
## (Intercept)           x1  
##      0.0469       0.1436
```

]

???
when we have multiple predictors, what do the coefficients represent?  
one way i like to think of this is with venn diagrams.  
consider the simple model with 1 predictor.  
the circle for y is all of the variance in y, and likewise for x1  

the overlap is the shared variance, or covariance, and the linear model is really just re-expressing that.  

so think of this blue bit as the bit of y that is explained by x1  



---
# Multiple Predictors

.pull-left[
&lt;img src="jk_img_sandbox/SStype3.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]
.pull-right[

```r
lm(y ~ x1 + x2)
```

```
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Coefficients:
## (Intercept)           x1           x2  
##      0.0428       0.1425       0.1273
```


```r
resx1.x2 = resid(lm(x1 ~ x2))
lm(y ~ resx1.x2)
```

```
## 
## Call:
## lm(formula = y ~ resx1.x2)
## 
## Coefficients:
## (Intercept)     resx1.x2  
##      0.0198       0.1425
```
]


???
enter x2, and the regression coefficients we get are more like the red and blue bits here.  

it's the bit of y explained by x1 _after_ controlling for x2  

we're basically saying that we want to look at the bit of x1 that explains y that is _unique_ to x1 

because x2 will explain a bit of x1

---
# Interactions

.pull-left[
![](01_lmcluster_files/figure-html/unnamed-chunk-12-1.svg)&lt;!-- --&gt;
]

???
we can extend this to include interactions, where the effect of x1 on y _depends on_ x2. 

here we have a continuous by categorical interaction, which is best visualised as two lines that aren't parallel

--

.pull-right[
![](01_lmcluster_files/figure-html/unnamed-chunk-13-1.svg)&lt;!-- --&gt;
]

???
if it's continuous by continuous, this is more like a twisted surface.

but the logic is the same, right? imagine we just took the close edge and far edge of the surface - we'd have two non-parallel lines. with the continuous variable it's just that we're also considering the bit in between the lines, because x2 can take any value


---
# Notation

`\(\begin{align} \color{red}{y} \;\;\;\; &amp; = \;\;\;\;\; \color{blue}{\beta_0 \cdot{} 1 + \beta_1 \cdot{} x_1 + ... + \beta_k \cdot x_k} &amp; + &amp; \;\;\;\varepsilon \\ \qquad \\ \color{red}{\begin{bmatrix}y_1 \\ y_2 \\ y_3 \\ y_4 \\ y_5 \\ \vdots \\ y_n \end{bmatrix}} &amp; = \color{blue}{\begin{bmatrix} 1 &amp; x_{11} &amp; x_{21} &amp; \dots &amp; x_{k1} \\ 1 &amp; x_{12} &amp; x_{22} &amp;  &amp; x_{k2} \\ 1 &amp; x_{13} &amp; x_{23} &amp;  &amp; x_{k3} \\ 1 &amp; x_{14} &amp; x_{24} &amp;  &amp; x_{k4} \\ 1 &amp; x_{15} &amp; x_{25} &amp;  &amp; x_{k5} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_{1n} &amp; x_{2n} &amp; \dots &amp; x_{kn} \end{bmatrix} \begin{bmatrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_k \end{bmatrix}} &amp; + &amp; \begin{bmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \varepsilon_3 \\ \varepsilon_4 \\ \varepsilon_5 \\ \vdots \\ \varepsilon_n \end{bmatrix} \\ \qquad \\ \\\color{red}{\boldsymbol y} \;\;\;\;\; &amp; = \qquad \qquad \;\;\; \mathbf{\color{blue}{X \qquad \qquad \qquad \;\;\;\: \boldsymbol \beta}} &amp; + &amp; \;\;\; \boldsymbol \varepsilon \\ \end{align}\)`

???
so the notation we saw a lot of in DAPR2 was this top bit here
y = beta0 + beta1 x +.... + e

again, outcome (red) = model (blue) + error

you might also see it like this, in matrices. 

which are collapsed to look like this. 

- y is a vector of length n
- x is an n by p matrix (p is the number of predictors)
- b is the vector of coefficients. 
- e is the vector of residuals

and regression is just finding those betas that minimise the residuals.  


---
# Link functions

`\(\begin{align} \color{red}{y} = \mathbf{\color{blue}{X \boldsymbol{\beta}} + \boldsymbol{\varepsilon}} &amp; \qquad  &amp; (-\infty, \infty) \\ \qquad \\ \qquad \\ \color{red}{ln \left( \frac{p}{1-p} \right) } = \mathbf{\color{blue}{X \boldsymbol{\beta}} + \boldsymbol{\varepsilon}} &amp; \qquad  &amp; [0,1] \\ \qquad \\ \qquad \\ \color{red}{ln (y) } = \mathbf{\color{blue}{X \boldsymbol{\beta}} + \boldsymbol{\varepsilon}} &amp; \qquad  &amp; (0, \infty) \\ \end{align}\)`  

???
now this can be extended so that instead of modelling y directly, we model some function of y.  

this is useful for studying outcomes that aren't continuous, so things like binary yes/no outcomes. 

fundamentally, the model is the same, but there are extra bits we need to do when interpreting betas. 

---
# Linear Models in R

- Linear regression

```r
linear_model &lt;- lm(continuous_y ~ x1 + x2 + x3*x4, data = df)
```

- Logistic regression

```r
logistic_model &lt;- glm(binary_y ~ x1 + x2 + x3*x4, data = df, family=binomial(link="logit"))
```

- Poisson regression

```r
poisson_model &lt;- glm(count_y ~ x1 + x2 + x3*x4, data = df, family=poisson(link="log"))
```

???
and we saw how to fit these in R using lm() and glm() with the family argument to specify the distribution


---
# Inference for Coefficients

&lt;img src="jk_img_sandbox/sum1.png" width="2560" height="500px" /&gt;

???
when it came to conducting inferences (i.e. drawing conclusions) from the linear models, it was fairly straightforward because it was all contained in the summary




---
# Inference for Coefficients

&lt;img src="jk_img_sandbox/sum2.png" width="2560" height="500px" /&gt;

???
each coefficient has a standard error, so we can reason about what values for the coefficients we _would_ expect if the true value in the population is zero  


---
# Inference for Coefficients

&lt;img src="jk_img_sandbox/sum3.png" width="2560" height="500px" /&gt;

???
this allows us to calculate a statistic which essentially standardises "how far away from zero is our coefficient, in units of these standard errors"


---
# Inference for Coefficients

&lt;img src="jk_img_sandbox/sum4.png" width="2560" height="500px" /&gt;

???
which in turn we can express as a probability of observing the coefficient _if the true value in the population is zero_  

so a quick reminder, the fundamental idea here of statistics here is:

- we take a sample, and calculate an estimate
- samples will vary, so the estimate could be higher/lower than the true value in the population
- we're asking _if the true value in the population is zero_, what's the probability of observing a sample estimate as extreme as this one? that's the p-value


---
# Sums of Squares

Rather than specific coefficients, we can also think of our model as a whole.  
We can talk in terms of the sums of squared residuals  
`\(\sum^{n}_{i=1}(y_i - \hat y_i)^2\)`.  

.pull-left[
&lt;img src="jk_img_sandbox/SS3xmodel1.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]


.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-22-1.svg)&lt;!-- --&gt;

]

???
as well as the coefficients, in DAPR2 we saw that we can think about partitioning up the variance into different parts 

the total sums of squares, the model explained sums of squares, and the residual sums of squares

---
# `\(R^2\)`


.pull-left[
&lt;img src="jk_img_sandbox/SSr2.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]
.pull-right[
`\(R^2 = \frac{SS_{Model}}{SS_{Total}} = 1 - \frac{SS_{Residual}}{SS_{Total}}\)`


```r
mdl &lt;- lm(y ~ x1 + x2)
summary(mdl)$r.squared
```

```
## [1] 0.1935
```
]

???
so this gave us metrics like the Rsquared, so get a picture of the proportion of variance explained by the model as a whole

so that includes this middle bit of the venn diagram


---
# Inference: Joint tests



We can test reduction in residual sums of squares:

.pull-left[

```r
m1 &lt;- lm(y ~ x1, data = df)
```
&lt;img src="jk_img_sandbox/SS3xmodel1.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]
.pull-right[

```r
m2 &lt;- lm(y ~ x1 + x2 + x3, data = df)
```
&lt;img src="jk_img_sandbox/SS3xfullmodel.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;

]

???
but we also can test reductions in sums of squares, which is essentially a model comparison.

so we compare this model on the left, to the one on the right

---
# Inference: Joint tests

i.e. isolating the improvement in model fit due to inclusion of additional parameters

.pull-left[

```r
m1 &lt;- lm(y ~ x1, data = df)
m2 &lt;- lm(y ~ x1 + x2 + x3, data = df)
anova(m1,m2)
```

```
## Analysis of Variance Table
## 
## Model 1: y ~ x1
## Model 2: y ~ x1 + x2 + x3
##   Res.Df  RSS Df Sum of Sq   F Pr(&gt;F)    
## 1     98 1141                            
## 2     96  357  2       785 106 &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]
.pull-right[
&lt;img src="jk_img_sandbox/SS3xincrement.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]

???
and we're isolating this bit here - the improvement in the model due to the inclusion of x2 and x3 combined

---
# Inference: Joint tests

"additional parameters" could be a set of coefficients for levels of a categorical variable.  
This provides a way of assessing "are there differences in group means?".  

.pull-left[

```r
m1 = lm(y ~ x1, data = df)
m2 = lm(y ~ x1 + grp, data = df)
coef(m2)
```

```
## (Intercept)          x1        grpb        grpc        grpd 
##      13.841       1.059      -3.162      -2.943      -3.415
```

```r
anova(m1, m2)
```

```
## Analysis of Variance Table
## 
## Model 1: y ~ x1
## Model 2: y ~ x1 + grp
##   Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    
## 1     98 1141                              
## 2     95  950  3       192 6.39 0.00055 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]
.pull-right[
&lt;img src="jk_img_sandbox/SSblankq.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]

???
one thing this is really useful for is that the additional bit we add to the model might be a load of different groupings.  

so rather than the coefficients which test the specific differences between groups, this joint test can tell us "does the grouping make a difference?"


---
exclude: true
# Inference: Joint tests

This is kind of where traditional analysis of variance sits.  
Think of it as testing the addition of each variable entered in to the model,

.pull-left[

```r
m2 = lm(y ~ x1 + grp, data = df)
anova(m2)
```

```
## Analysis of Variance Table
## 
## Response: y
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## x1         1     91    90.6    9.06 0.00334 ** 
## grp        3    192    63.9    6.39 0.00055 ***
## Residuals 95    950    10.0                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]
.pull-right[
&lt;img src="jk_img_sandbox/SStype1.png" width="400px" height="350px" style="display: block; margin: auto;" /&gt;
]

???
this is where "traditional ANOVA" sits. 
we have p categorical predictors with k levels and we assess the reduction in RSS due to inclusion grouping by those k levels


---
# Assumptions

Our model:  

`\(\color{red}{y} = \color{blue}{\mathbf{X \boldsymbol \beta}} + \varepsilon \qquad \text{where } \boldsymbol \varepsilon \sim N(0, \sigma) \text{ independently}\)`


Our ability to generalise from the model we fit on sample data to the wider population requires making some _assumptions._

???
Now.. all this inference relies on our model meeting certain assumptions 

--

- assumptions about the nature of the **model** .tr[
(linear)
]

--

- assumptions about the nature of the **errors** .tr[
(normal)
]


.footnote[
You can also phrase the linear model as: `\(\color{red}{\boldsymbol  y} \sim Normal(\color{blue}{\mathbf{X \boldsymbol \beta}}, \sigma)\)`
]



---
# Assumptions: The Broad Idea

All our work here is in
aim of making **models of the world**.  

- Models are models. They are simplifications. They are therefore wrong.  

.pull-left[]
.pull-right[
![](jk_img_sandbox/joeymap.jpg)
]


---
count:false
# Assumptions: The Broad Idea

All our work here is in
aim of making **models of the world**.  

- Models are models. They are simplifications. They are therefore wrong.  

- Our residuals ( `\(y - \hat{y}\)` ) reflect everything that we **don't** account for in our model.  


--

- In an ideal world, our model accounts for _all_ the systematic relationships. The leftovers (our residuals) are just random noise.  

--

  - If our model is mis-specified, or we don't measure some systematic relationship, then our residuals will reflect this.

--

- We check by examining how much "like randomness" the residuals appear to be (zero mean, normally distributed, constant variance, i.i.d ("independent and identically distributed")
    - _these ideas tend to get referred to as our "assumptions"_

--

- We will **never** know whether our residuals contain only randomness - we can never observe everything! 


---
# Assumptions

.pull-left[

What does "zero mean and constant variance" look like?  

- mean of the residuals = zero across the predicted values on the linear predictor.  

- spread of residuals is normally distributed and constant across the predicted values on the linear predictor.  


]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-37-1.svg)&lt;!-- --&gt;

]

---
# Assumptions

.pull-left[

What does "zero mean and constant variance" look like?  

- __mean of the residuals = zero across the predicted values on the linear predictor.__    

- spread of residuals is normally distributed and constant across the predicted values on the linear predictor.  


]
.pull-right[


![](01_lmcluster_files/figure-html/unnamed-chunk-38-1.svg)&lt;!-- --&gt;

]

---
# Assumptions

.pull-left[

What does "zero mean and constant variance" look like?  

- mean of the residuals = zero across the predicted values on the linear predictor.  

- __spread of residuals is normally distributed and constant across the predicted values on the linear predictor.__  


]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-39-1.svg)&lt;!-- --&gt;
]

---
# Assumptions

.pull-left[

What does "zero mean and constant variance" look like?  

- mean of the residuals = zero across the predicted values on the linear predictor.  

- spread of residuals is normally distributed and constant across the predicted values on the linear predictor.  



]
.pull-right[
__`plot(model)`__




```r
my_model &lt;- lm(y ~ x, data = df)
plot(my_model, which = 1)
```

![](01_lmcluster_files/figure-html/unnamed-chunk-41-1.svg)&lt;!-- --&gt;

]


---
# Assumptions: Recipe Book
&lt;br&gt;&lt;br&gt;
&lt;center&gt;
&lt;div class="acronym"&gt;
L
&lt;/div&gt; inearity&lt;br&gt;
&lt;div class="acronym"&gt;
I
&lt;/div&gt; ndependence&lt;br&gt;
&lt;div class="acronym"&gt;
N
&lt;/div&gt; ormality&lt;br&gt;
&lt;div class="acronym"&gt;
E
&lt;/div&gt; qual variance&lt;br&gt;
&lt;/center&gt;
.footnote["Line without N is a Lie!" (Umberto)]

---
# What if our model doesn't meet assumptions?

- is our model mis-specified?  
  - is the relationship non-linear? higher order terms? (e.g. `\(y \sim x + x^2\)`)
  - is there an omitted variable or interaction term? 
  
  
--

- transform the outcome variable?
  - makes things look more "normal"
  - but can make things more tricky to interpret:  
    `lm(y ~ x)` and `lm(log(y) ~ x)` are quite different models

--

- bootstrap
  - do many times: resample (w/ replacement) your data, and refit your model.
  - obtain a distribution of parameter estimate of interest. 
  - compute a confidence interval for estimate
  - celebrate

--

__looking ahead:__ these don't help if we have violated our assumption of independence...

---
# Summary

- we can fit a linear regression model which takes the form `\(\color{red}{y} = \color{blue}{\mathbf{X} \boldsymbol{\beta}} + \boldsymbol{\varepsilon}\)`  

- in R, we fit this with `lm(y ~ x1 + .... xk, data = mydata)`.  

- we can extend this to different link functions to model outcome variables which follow different distributions.  

- when drawing inferences from a fitted model to the broader population, we rely on certain assumptions.  

  - one of these is that the errors are independent.


---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 1

---
class: inverse, center, middle

&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 1: Linear Regression Refresh&lt;/h2&gt;
&lt;h2&gt;Part 2: Clustered Data&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 3: Where we're going&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Extra slides (optional): Other Approaches&lt;/h2&gt;

???
okay. we're now going to move on to the main focus of this first block of dapr3.  
we're going to start by getting to grips with what it means for us to have clustered data  


---
# Clustered Data

.pull-left[
- children within schools  

- patients within clinics  

- observations within individuals  
]
.pull-left[
&lt;img src="jk_img_sandbox/h2.png" width="1716" /&gt;
]

???
what is clustered data?  

simply put - it's when our observations have some grouping.  
note we're not talking about something like an "old vs young" or "drug vs placebo", or "condition1 vs condition2" groups. 
those are typically the things we're wanting to study.  

the _clusters_ are the groupings in our data that are kind of another level of random sampling. 

children schools
patients clinics
observations individuals


---
# Clustered Clustered Data?

.pull-left[
- children within classrooms within schools within districts etc...  

- patients within doctors within hospitals... 

- time-periods within trials within individuals
]
.pull-right[
&lt;img src="jk_img_sandbox/h3.png" width="1716" /&gt;
]

.footnote[
Other relevant terms you will tend to see: "grouping structure", "levels", "hierarchies". 
]

???
and we can have clusters of clusters too. 

[SLIDE EXAMPLES]

so you can see that this can get quite complicated. Typically, this gets called the grouping structure, or multilevel data, or the hierarchical structure.  



---
# Importance of Clustering

Clustering will likely result in measurements on observational units within a given cluster being more similar to each other than to those in other clusters.  

- For example, our measure of academic performance for children in a given class will tend to be more similar to one another (because of class specific things such as the teacher) than to children in other classes.

&lt;img src="jk_img_sandbox/lev1.png" width="60%" style="display: block; margin: auto;" /&gt;

???
why do we need to think about clustering?  

observations within a cluster are going to be more similar to one another than they are to those in other clusters

for instance, children in a given class might score more similarly to one another than they do to children in other classes, because of things like how good the teacher is

but this like 'non-independence'! the children are not independent from one another.  
call back to our regression assumptions!  

and this happens a lot right?
we've said children and schools, employees in departments etc. 

probably the most relevant for your dissertations, is repeatedly measuring the same participants. So we get 30 people, but we give each one 20 trials, we've suddenly got 500 observations, but it's all clustered.


---
# ICC (intra-class correlation coefficient)

Clustering is expressed in terms of the correlation among the measurements within the same cluster - known as the __intra-class correlation coefficient (ICC).__


There are various formulations of ICC, but the basic principle = ratio of *variance between groups* to *total variance*.  

&lt;br&gt;
`\(\rho = \frac{\sigma^2_{b}}{\sigma^2_{b} + \sigma^2_e} \\ \qquad \\\textrm{Where:} \\ \sigma^2_{b} = \textrm{variance between clusters} \\ \sigma^2_e = \textrm{variance within clusters (residual variance)} \\\)`

???
at the outset, we might want to quantify how much clustering there is in our outcome variable.
and for that we have the ICC

basic premise is that this is the ratio of between cluster variance to the total variance  

we'll take a look at this in just a second

--

Can also be interpreted as the correlation between two observations from the same group. 

???
it's also interpreted as the expected correlation between two observations from the same group  

---
# ICC (intra-class correlation coefficient)

The larger the ICC, the lower the variability is within the clusters (relative to the variability between clusters). The greater the correlation between two observations from the same group. 

.pull-left[
&lt;img src="01_lmcluster_files/figure-html/unnamed-chunk-45-1.svg" style="display: block; margin: auto;" /&gt;

]

???
so between cluster variance vs total variance.  

[DESCRIBE PLOT]



--

.pull-right[

&lt;img src="01_lmcluster_files/figure-html/unnamed-chunk-46-1.svg" style="display: block; margin: auto;" /&gt;
]

???
and you could imagine if we were assessing the relationship between some outcome and a predictor, and all of the variance in the outcome is due to the clustering then we'd have this bottom one here

---
# Clustered Data &amp; Linear Models

.pull-left[
#### Why is it a problem?

Clustering is something **systematic** that our model should (arguably) take into account.  

- remember, `\(\varepsilon \sim N(0, \sigma) \textbf{ independently}\)` 

]

--

.pull-right[
#### How is it a problem?  

Standard errors tend to be smaller than they should be, meaning that:  

  - confidence intervals will be too narrow 
  
  - `\(t\)`-statistics will be too large  
  
  - `\(p\)`-values will be misleadingly small

]

---
class: inverse, center, middle

&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 1: Linear Regression Refresh&lt;/h2&gt;
&lt;h2&gt;&lt;b style="opacity:0.4;"&gt;Part 2: Clustered Data&lt;/b&gt;&lt;b&gt;A Practical Comment on Data&lt;/b&gt;&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 3: Where we're going&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Extra slides (optional): Other Approaches&lt;/h2&gt;


---
# Wide Data/Long Data

.pull-left[
__Wide Data__  


```
## # A tibble: 5 × 5
##   ID    age   trial_1 trial_2 trial_3
##   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  
## 1 001   28    10      12.5    18     
## 2 002   36    7.5     7       5      
## 3 003   61    12      14.5    11     
## 4 004   45    10.5    17      14     
## 5 ...   ...   ...     ...     ...
```



]
.pull-right[
__Long Data__



```
## # A tibble: 13 × 4
##    ID    age   trial   score
##    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;
##  1 001   36    trial_1 10   
##  2 001   36    trial_2 12.5 
##  3 001   36    trial_3 18   
##  4 002   70    trial_1 7.5  
##  5 002   70    trial_2 7    
##  6 002   70    trial_3 5    
##  7 003   68    trial_1 12   
##  8 003   68    trial_2 14.5 
##  9 003   68    trial_3 11   
## 10 004   31    trial_1 10.5 
## 11 004   31    trial_2 17   
## 12 004   31    trial_3 14   
## 13 ...   ...   ...     ...
```


]


---
# Wide Data/Long Data


![](https://www.fromthebottomoftheheap.net/assets/img/posts/tidyr-longer-wider.gif)&lt;!-- --&gt;
.footnote[
Source: Examples of wide and long representations of the same data. Source: Garrick Aden-Buie’s (\@grrrck) [Tidy Animated Verbs](https://github.com/gadenbuie/tidyexplain)
]

---
# Long Data = Good for Plotting

.pull-left[
__`group` aesthetic__  


```r
ggplot(longd, aes(x=trial,y=score, group=ID, col=ID))+
  geom_point(size=4)+
  geom_path()
```

![](01_lmcluster_files/figure-html/unnamed-chunk-50-1.svg)&lt;!-- --&gt;

]
.pull-right[
__`facet_wrap()`__  

```r
ggplot(longd, aes(x=trial,y=score))+
  geom_point(size=4)+
  geom_path(aes(group=1))+
  facet_wrap(~ID)
```

![](01_lmcluster_files/figure-html/unnamed-chunk-51-1.svg)&lt;!-- --&gt;
]

---
# Long Data = Good for by-Cluster Computations


```r
longd %&gt;% 
  group_by(ID) %&gt;%
  summarise(
    ntrials = n_distinct(trial),
    meanscore = mean(score),
    sdscore = sd(score)
  )
```

```
## # A tibble: 4 × 4
##   ID    ntrials meanscore sdscore
##   &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 001         3      13.5    4.09
## 2 002         3       6.5    1.32
## 3 003         3      12.5    1.80
## 4 004         3      13.8    3.25
```



---
# Summary

- Clustering can take many forms, and exist at many levels  

- Clustering is something systematic that we would want our model to take into account

  - Ignoring it can lead to incorrect statistical inferences

- Clustering is typically assessed using intra-class correlation coefficient (ICC) - the ratio of variance between clusters to the total variance `\(\rho = \frac{\sigma^2_b}{\sigma^2_b + \sigma^2_e}\)`

- Tidying your data and converting it to *long* format (one observational unit per row, and a variable identifying the cluster ID) is a good start. 

---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 2


---
class: inverse, center, middle

&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 1: Linear Regression Refresh&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 2: Clustered Data&lt;/h2&gt;
&lt;h2&gt;Part 3: Where we're going&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Other Approaches&lt;/h2&gt;

---
# Our Data

.pull-left[
&gt; Sample of 200 pupils from 20 schools completed a survey containing the Emotion Dysregulation Scale (EDS) and the Child Routines Questionnaire (CRQ). 


```r
crq_data &lt;- read_csv("https://uoepsy.github.io/data/crqdata.csv")
head(crq_data)
```

```
## # A tibble: 6 × 6
##   emot_dysreg   crq int       schoolid sleep   age
##         &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;
## 1        4.12  1.92 Treatment school1  &lt;8hr     14
## 2        3.22  1.65 Treatment school1  &lt;8hr     11
## 3        4.86  3.56 Treatment school1  &lt;8hr     16
## 4        4.79  1.45 Treatment school1  8hr+     16
## 5        3.58  0.81 Treatment school1  &lt;8hr     12
## 6        4.41  2.71 Treatment school1  &lt;8hr     15
```


```r
library(ICC)
ICCbare(x = schoolid, y = emot_dysreg, data = crq_data)
```

```
## [1] 0.2443
```
]
.pull-right[
&lt;img src="01_lmcluster_files/figure-html/unnamed-chunk-55-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Ignoring Clustering

.pull-left[
__(Complete pooling)__  

+ `lm(y ~ 1 + x, data = df)`  

+ Information from all clusters is pooled together to estimate over x  


```r
model &lt;- lm(emot_dysreg ~ crq, data = crq_data)
```

```
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.4470     0.1259   35.31   &lt;2e-16 ***
## crq          -0.0525     0.0448   -1.17     0.24
```
]
.pull-right[
![](01_lmcluster_files/figure-html/unnamed-chunk-58-1.svg)&lt;!-- --&gt;
]

---
# Ignoring Clustering

.pull-left[
__(Complete pooling)__  

+ `lm(y ~ 1 + x, data = df)`  

+ Information from all clusters is pooled together to estimate over x  


```r
model &lt;- lm(emot_dysreg ~ crq, data = crq_data)
```

```
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.4470     0.1259   35.31   &lt;2e-16 ***
## crq          -0.0525     0.0448   -1.17     0.24
```

But different clusters show different patterns.  
Residuals are __not__ independent.  
]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-61-1.svg)&lt;!-- --&gt;
]

---
count:false
# Ignoring Clustering

.pull-left[
__(Complete pooling)__  

+ `lm(y ~ 1 + x, data = df)`  

+ Information from all clusters is __pooled__ together to estimate over x  


```r
model &lt;- lm(emot_dysreg ~ crq, data = crq_data)
```

```
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.4470     0.1259   35.31   &lt;2e-16 ***
## crq          -0.0525     0.0448   -1.17     0.24
```

But different clusters show different patterns.  
Residuals are __not__ independent.  
]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-64-1.svg)&lt;!-- --&gt;
]


---
# Fixed Effects Models

.pull-left[

__(No pooling)__  

- `lm(y ~ x * cluster, data = df)`  

- Information from a cluster contributes to estimate *for that cluster*, but information is not pooled to estimate an overall effect. 


```r
model &lt;- lm(emot_dysreg ~ 1 + crq * schoolid, 
            data = crq_data)
```
{{content}}
]
.pull-right[
![](01_lmcluster_files/figure-html/unnamed-chunk-66-1.svg)&lt;!-- --&gt;
]

--

+ Lots of estimates (separate for each cluster). 
+ Variance estimates constructed based on information *only* within each cluster. 
+ No overall estimate of effect over x. 

```
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           3.31835    0.45187    7.34  1.8e-11 ***
## crq                   0.38247    0.20087    1.90  0.05904 .  
## schoolidschool10      1.89925    0.88643    2.14  0.03396 *  
## schoolidschool11      2.15526    0.72639    2.97  0.00356 ** 
## schoolidschool12      1.31007    0.63199    2.07  0.04009 *  
## schoolidschool13      0.39744    0.69852    0.57  0.57033    
## schoolidschool14      0.67908    0.70058    0.97  0.33414    
## schoolidschool15      1.09387    0.60494    1.81  0.07281 .  
## schoolidschool16      2.08396    0.74354    2.80  0.00582 ** 
## schoolidschool17      1.23261    0.63109    1.95  0.05289 .  
## schoolidschool18     -0.20698    0.92070   -0.22  0.82247    
## schoolidschool19      1.34223    0.59066    2.27  0.02465 *  
## schoolidschool2       1.31507    0.86143    1.53  0.12922    
## schoolidschool20      1.05688    0.63934    1.65  0.10066    
## schoolidschool3       1.17962    0.65361    1.80  0.07336 .  
## schoolidschool4       0.94437    0.60360    1.56  0.12005    
## schoolidschool5       1.49329    0.67013    2.23  0.02752 *  
## schoolidschool6       2.76414    0.68697    4.02  9.5e-05 ***
## schoolidschool7      -0.00683    0.60138   -0.01  0.99095    
## schoolidschool8       1.15007    0.62754    1.83  0.06907 .  
## schoolidschool9       0.62842    0.81937    0.77  0.44446    
## crq:schoolidschool10 -0.67112    0.34804   -1.93  0.05594 .  
## crq:schoolidschool11 -0.68897    0.29202   -2.36  0.01975 *  
## crq:schoolidschool12 -0.49875    0.25901   -1.93  0.05627 .
```

---
# Random Effects Models (MLM)

.pull-left[
__(Partial Pooling)__

- `lmer(y ~ 1 + x + (1 + x| cluster), data = df)`
- cluster-level variance in intercepts and slopes is modeled as randomly distributed around fixed parameters.
- effects are free to vary by cluster, but information from clusters contributes (according to cluster `\(n\)` and outlyingness of cluster) to an overall fixed parameter. 


```r
library(lme4)
model &lt;- lmer(emot_dysreg ~ 1 + crq + 
                (1 + crq | schoolid),
              data = crq_data)
summary(model)$coefficients
```

```
##             Estimate Std. Error t value
## (Intercept)  4.43772    0.15690   28.28
## crq         -0.05166    0.05063   -1.02
```


]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-69-1.svg)&lt;!-- --&gt;
]

---
# Random Effects Models (MLM)

.pull-left[
__(Partial Pooling)__

- `lmer(y ~ 1 + x + (1 + x| cluster), data = df)`
- cluster-level variance in intercepts and slopes is modeled as randomly distributed around fixed parameters.
- effects are free to vary by cluster, but information from clusters contributes (according to cluster `\(n\)` and outlyingness of cluster) to an overall fixed parameter. 


```r
library(lme4)
model &lt;- lmer(emot_dysreg ~ 1 + crq + 
                (1 + crq | schoolid),
              data = crq_data)
summary(model)$coefficients
```

```
##             Estimate Std. Error t value
## (Intercept)  4.43772    0.15690   28.28
## crq         -0.05166    0.05063   -1.02
```


]
.pull-right[

![](01_lmcluster_files/figure-html/unnamed-chunk-71-1.svg)&lt;!-- --&gt;
]


---
# Summary

With clustered data, there are many possible approaches. Some of the main ones are:  

- Ignore it (**complete pooling**)  

    - and make inappropriate inferences.  

- Completely partition out any variance due to clustering into fixed effects for each cluster (__no pooling__).  

    - and limit our estimates to being cluster specific and low power.  
    
- Model cluster-level variance as randomly distributed around fixed parameters, and partially pool information across clusters.  

    - best of both worlds?  
    

---
class: inverse, center, middle, animated, rotateInDownLeft

# End

---
class: inverse, center, middle

&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 1: Linear Regression Refresh&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 2: Clustered Data&lt;/h2&gt;
&lt;h2 style="text-align: left;opacity:0.3;"&gt;Part 3: Where we're going&lt;/h2&gt;
&lt;h2&gt;Extra slides (optional): Other Approaches&lt;/h2&gt;



---
# Other: Repeated Measures ANOVA

## ANOVA revisited

.pull-left[
- We've been using `anova()` as a test of whether _several_ parameters are simultaneously zero

    - The "omnibus"/"overall F"/"joint" test (can also be viewed as a model comparison)  
    
]

--

.pull-right[
- Traditional "ANOVA" is essentially a linear model with categorical predictor(s) where it looks for overall differences in group means (or differences in differences in group means etc).    

    - Still quite popular in psychology because we often design experiments with discrete conditions. 
    
    - Require post-hoc tests to examine _where_ any differences are.
]

---
exclude: true
# ANOVA revisited

In R, functions typically create anova tables from linear model objects:

```r
lin_mod &lt;- lm(y ~ grp, df)
anova(lin_mod)
car::Anova(lin_mod)
```
or are wrappers which use the `lm()` function internally. So they're doing the same thing.

```r
summary(aov(y ~ grp, df))
```

&lt;img src="01_lmcluster_files/figure-html/unnamed-chunk-75-1.svg" style="display: block; margin: auto;" /&gt;


---
exclude: true
# ANOVA sums of squares

.pull-left[

With multiple predictors, sums of squares can be calculated differently

1. Sequential Sums of Squares = Order matters
2. &lt;p style="opacity:0.4"&gt;Partially Sequential Sums of Squares&lt;/p&gt;
3. &lt;p style="opacity:0.4"&gt;Partial Sums of Squares&lt;/p&gt;

&lt;img src="jk_img_sandbox/SStype1b.png" width="200px" height="150px" style="display: block; margin: auto;" /&gt;

]
.pull-right[
__sequential SS__

```r
anova(lm(y~x1*x2,df))
```

```
## Analysis of Variance Table
## 
## Response: y
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## x1         1     91      91   13.55 0.00038 ***
## x2         1    484     484   72.45 2.3e-13 ***
## x1:x2      1     16      16    2.32 0.13097    
## Residuals 96    642       7                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
anova(lm(y~x2*x1,df))
```

```
## Analysis of Variance Table
## 
## Response: y
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## x2         1    449     449   67.14 1.1e-12 ***
## x1         1    126     126   18.86 3.5e-05 ***
## x2:x1      1     16      16    2.32    0.13    
## Residuals 96    642       7                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
]

---
exclude: true
# ANOVA sums of squares

.pull-left[

with multiple predictors, sums of squares can be calculated differently

1. &lt;p style="opacity:0.4"&gt;Sequential Sums of Squares&lt;/p&gt;
2. &lt;p style="opacity:0.4"&gt;Partially Sequential Sums of Squares&lt;/p&gt;
3. Partial Sums of Squares = Each one calculated as if its the last one in sequential SS (order doesn't matter).

&lt;img src="jk_img_sandbox/SStype3.png" width="200px" height="150px" style="display: block; margin: auto;" /&gt;


]
.pull-right[
__partial SS__

```r
car::Anova(lm(y~x1*x2,df), type="III")
```

```
## Anova Table (Type III tests)
## 
## Response: y
##             Sum Sq Df F value  Pr(&gt;F)    
## (Intercept)  11924  1 1784.14 &lt; 2e-16 ***
## x1             122  1   18.27 4.5e-05 ***
## x2             497  1   74.30 1.4e-13 ***
## x1:x2           16  1    2.32    0.13    
## Residuals      642 96                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
car::Anova(lm(y~x2*x1,df), type="III")
```

```
## Anova Table (Type III tests)
## 
## Response: y
##             Sum Sq Df F value  Pr(&gt;F)    
## (Intercept)  11924  1 1784.14 &lt; 2e-16 ***
## x2             497  1   74.30 1.4e-13 ***
## x1             122  1   18.27 4.5e-05 ***
## x2:x1           16  1    2.32    0.13    
## Residuals      642 96                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]
    
---
# Other: Repeated Measures ANOVA

## ANOVA: Partitioning Variance

&lt;img src="jk_img_sandbox/anova.png" width="1288" /&gt;


.footnote[  
The terminology here can be a nightmare.  
`\(SS_{between}\)` sometimes gets referred to as `\(SS_{model}\)`, `\(SS_{condition}\)`, `\(SS_{regression}\)`, or `\(SS_{treatment}\)`.  
Meanwhile `\(SS_{residual}\)` also gets termed `\(SS_{error}\)`.  
To make it all worse, there are inconsistencies in the acronyms used, `\(SSR\)` vs. `\(RSS\)`! 

]

---
# Other: Repeated Measures ANOVA

## ANOVA: Partitioning Variance

&lt;img src="jk_img_sandbox/rmanova.png" width="1288" /&gt;

---
# Other: Repeated Measures ANOVA in R


.pull-left[
![](01_lmcluster_files/figure-html/unnamed-chunk-82-1.svg)&lt;!-- --&gt;
]
.pull-right[

```r
library(afex)
aov_ez(id = "subject", dv = "y", data = df, within = "t")
```

```
## Anova Table (Type 3 tests)
## 
## Response: y
##   Effect          df  MSE         F  ges p.value
## 1      t 1.00, 39.18 3.20 36.65 *** .074   &lt;.001
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
## 
## Sphericity correction method: GG
```

```r
library(ez)
ezANOVA(data = df, dv = y, wid = subject, 
        within = t)
```

```
## $ANOVA
##   Effect DFn DFd     F         p p&lt;.05     ges
## 2      t   2  78 36.65 5.991e-12     * 0.07383
## 
## $`Mauchly's Test for Sphericity`
##   Effect        W         p p&lt;.05
## 2      t 0.008994 1.335e-39     *
## 
## $`Sphericity Corrections`
##   Effect    GGe    p[GG] p[GG]&lt;.05    HFe     p[HF] p[HF]&lt;.05
## 2      t 0.5023 4.14e-07         * 0.5024 4.123e-07         *
```

]


---
# Other: Mixed ANOVA in R


.pull-left[
![](01_lmcluster_files/figure-html/unnamed-chunk-84-1.svg)&lt;!-- --&gt;
]
.pull-right[

```r
library(afex)
aov_ez(id = "subject", dv = "y", data = df, 
       between = "condition", within = "t")
```

```
## Anova Table (Type 3 tests)
## 
## Response: y
##        Effect          df   MSE         F  ges p.value
## 1   condition       3, 36 10.38 31.46 *** .695   &lt;.001
## 2           t 1.01, 36.35  1.57 74.18 *** .215   &lt;.001
## 3 condition:t 3.03, 36.35  1.57 14.31 *** .137   &lt;.001
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
## 
## Sphericity correction method: GG
```

```r
library(ez)
ezANOVA(data = df, dv = y, wid = subject, 
        within = t, between = condition)
```

```
## $ANOVA
##        Effect DFn DFd     F         p p&lt;.05    ges
## 2   condition   3  36 31.46 3.654e-10     * 0.6945
## 3           t   2  72 74.18 3.241e-18     * 0.2148
## 4 condition:t   6  72 14.31 1.156e-10     * 0.1367
## 
## $`Mauchly's Test for Sphericity`
##        Effect       W         p p&lt;.05
## 3           t 0.01948 1.164e-30     *
## 4 condition:t 0.01948 1.164e-30     *
## 
## $`Sphericity Corrections`
##        Effect    GGe     p[GG] p[GG]&lt;.05    HFe     p[HF] p[HF]&lt;.05
## 3           t 0.5049 2.389e-10         * 0.5053 2.352e-10         *
## 4 condition:t 0.5049 2.428e-06         * 0.5053 2.407e-06         *
```
]

---
# Other: Advantages of MLM over ANOVA

- Rpt Measures and Mixed ANOVA are special cases of the MLM

- MLM can easily be extended to modelling different types of dependent variables. ANOVA cannot. 

- MLM can be extended to model more complex grouping structures (e.g. children in schools in districts, or independent clusters of both participants as well as experimental items)

- MLM allows us to model an effect as varying 

- MLM provides more options for dealing with unbalanced designs and missing data.  

---
# Other: Cluster Robust Standard Errors

.pull-left[
&lt;!-- https://rlbarter.github.io/Practical-Statistics/2017/05/10/generalized-estimating-equations-gee/ --&gt;

Don't include clustering as part of the model directly, but incorporate the dependency into our residuals term. 

$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error}^* \\
\end{align}`
$$
.footnote[`*` Where errors are clustered]

]

.pull-right[
Simply adjusts our standard errors:

```r
library(plm)
clm &lt;- plm(emot_dysreg ~ 1 + crq, data=crq_data, 
           model="pooling", index="schoolid")
```

```
## Coefficients:
##             Estimate Std. Error t-value Pr(&gt;|t|)    
## (Intercept)   4.4470     0.1259   35.31   &lt;2e-16 ***
## crq          -0.0525     0.0448   -1.17     0.24
```

```r
sqrt(diag(vcovHC(clm, 
                 method='arellano', 
                 cluster='group')))
```

```
## (Intercept)         crq 
##     0.14410     0.04601
```
]

---
# Other: Generalised Estimating Equations 

.pull-left[
Don't include clustering as part of the model directly, but incorporate the dependency into our residuals term. 

$$
`\begin{align}
\color{red}{\textrm{outcome}} &amp; = \color{blue}{(\textrm{model})} + \textrm{error}^* \\
\end{align}`
$$

  
GEE is a "population average" model:  

- __population average:__ how the _average_ response changes for a 1-unit increase in `\(x\)`, while accounting for within-group correlation.   
- __subject specific:__ how the response changes for a group when they increase 1-unit in `\(x\)`.  


.footnote[`*` Where errors are clustered, and follow some form of correlational&lt;br&gt;structure within clusters (e.g. based on how many timepoints apart&lt;br&gt;two observations are).]


]

.pull-right[
Specifying a correlational structure for residuals within clusters can influence _what_ we are estimating

```r
library(geepack)
# needs to be arranged by cluster, 
# and for cluster to be numeric
crq_data &lt;- 
  crq_data %&gt;%
  mutate(
    cluster_id = as.numeric(as.factor(schoolid))
  ) %&gt;% arrange(cluster_id)
# 
geemod  = geeglm(emot_dysreg ~ 1 + crq, 
                 data = crq_data, 
                 corstr = 'exchangeable',
                 id = cluster_id)
```

```
##  Coefficients:
##             Estimate Std.err   Wald Pr(&gt;|W|)    
## (Intercept)   4.4304  0.1471 906.97   &lt;2e-16 ***
## crq          -0.0510  0.0473   1.16     0.28
```

]

???
https://quantscience.rbind.io/2020/12/28/unit-specific-vs-population-average-models/


---
class: inverse, center, middle, animated, rotateInDownLeft

# End

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
