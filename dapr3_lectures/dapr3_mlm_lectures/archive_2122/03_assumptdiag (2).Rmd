---
title: "<b>Assumptions & Diagnostics<br>More random effects</b>"
subtitle: "Data Analysis for Psychology in R 3"
author: "Josiah King"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: jk_libs/libs
    css: 
      - xaringan-themer.css
      - jk_libs/tweaks.css
    nature:
      beforeInit: "jk_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
params: 
    show_extra: false
    finalcompile: TRUE
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval=FALSE)
options(htmltools.dir.version = FALSE)
options(digits=4,scipen=2)
options(knitr.table.format="html")
xaringanExtra::use_xaringan_extra(c("tile_view","animate_css","tachyons"))
xaringanExtra::use_tile_view()
xaringanExtra::use_extra_styles(
  mute_unhighlighted_code = FALSE
)
xaringanExtra::use_share_again()
library(knitr)
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(patchwork)
knitr::opts_chunk$set(
  dev = "png",
  warning = FALSE,
  message = FALSE,
  cache = FALSE
)
themedapr3 = function(){
  theme_minimal() + 
    theme(text = element_text(size=20))
}
source("jk_source/jk_presfuncs.R")
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  # base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  code_font_size = "0.7rem",
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  extra_css = list(".scroll-output" = list("height"="90%","overflow-y"="scroll"))
)
```

class: inverse, center, middle

<h2>Part 1: Assumptions</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Case Diagnostics in MLM</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Random Effect Structures</h2>


---
# Assumptions in LM

.pull-left[
#### The general idea

- $\varepsilon_i \sim N(0,\sigma^2)$ iid
- "zero mean and constant variance"

```{r echo=FALSE, fig.asp=.7}
set.seed(20)
tibble(
  fitted_values = 1:1000,
  residuals = rnorm(1000,0,20)
) -> plotdat

bb = seq(0,975,10)
map_dbl(bb, ~filter(plotdat, between(fitted_values, ., .+10)) %>% summarise(s=sd(residuals)) %>% pull(s)) %>% 
cbind(fitted_values = bb + 5, sd = .) %>%
  cbind(., m = map_dbl(bb, ~filter(plotdat, between(fitted_values, ., .+10)) %>% summarise(m = mean(residuals)) %>% pull(m))) %>% as_tibble %>% mutate(
    u = m + sd*2,
    l = m - sd*2
  ) -> prib


ggplot(plotdat, aes(x=fitted_values, y=residuals))+
  geom_point(alpha=.3) + 
  geom_smooth(se=F)+
  geom_smooth(data=prib, inherit.aes = F,
              aes(x=fitted_values,y=u), alpha=.3, se=F, lty="dashed", col="darkorange")+
  geom_smooth(data=prib, inherit.aes = F,
              aes(x=fitted_values,y=l), alpha=.3, se=F, lty="dashed", col="darkorange")+
  themedapr3()+
  theme(axis.text = element_blank())
```

]

--

.pull-right[
#### Recipe book

+ **L**inearity
+ **I**ndependence
+ **N**ormality
+ **E**qual Variances

]


---
# What's different in MLM?

- Not much is different!  

--

- General idea is unchanged: error is random  

<!-- Consequently, we want to check for homoscedasiticity of the error term as well as normality of the error termâ€™s distribution -->

--

- We now have residuals at multiple levels!


---
# Random effects as level 2 residuals

```{r echo=FALSE, fig.align="left", fig.asp=.5}
knitr::include_graphics("jk_img_sandbox/lmmwodot.png")
```


---
count:false
# Random effects as level 2 residuals

```{r echo=FALSE, fig.align="left", fig.asp=.5}
knitr::include_graphics("jk_img_sandbox/lmmwdot.png")
```


---
# Random effects as level 2 residuals

$\begin{align} & \text{for observation }j\text{ in group }i \\ \quad \\ & \text{Level 1:} \\ & \color{red}{y_{ij}} = \color{blue}{\beta_{0i} \cdot 1 + \beta_{1i} \cdot x_{ij}} + \varepsilon_{ij} \\ & \text{Level 2:} \\ & \color{blue}{\beta_{0i}} = \gamma_{00} + \color{orange}{\zeta_{0i}} \\ & \color{blue}{\beta_{1i}} = \gamma_{10} + \color{orange}{\zeta_{1i}} \\ \quad \\ \end{align}$

$\varepsilon, \, \color{orange}{\zeta_0}, \, \text{ and } \, \color{orange}{\zeta_1}$ are all assumed to be normally distributed with mean 0. 


---
count:false
# Random effects as level 2 residuals
<!-- > 200 pupils from 20 schools completed a survey containing the Emotion Dysregulation Scale (EDS) and the Child Routines Questionnaire (CRQ). Eight of the schools were taking part in an initiative to specifically teach emotion regulation as part of the curriculum. Data were also gathered regarding the average hours each child slept per night. -->
```{r echo=FALSE}
library(sjPlot)
library(lme4)
crq <- read_csv("https://uoepsy.github.io/data/crqdata.csv")
crq %>% mutate(
  y = emot_dysreg,
  x1 = crq,
  x2 = int, 
  x3 = age, 
  cluster = gsub("school","cluster",schoolid)
) %>% filter(!schoolid %in% c("school6","school15", "school17")) -> df
full_model<-lmer(y ~ x1 * x2 + x3 + (1 + x1 | cluster), data = df)
model <- full_model
pp <- plot_model(full_model, type = "diag")
```


.pull-left[

$\varepsilon$  
`resid(model)`  
mean zero, constant variance  
<br><br>
```{r echo=FALSE, fig.asp=.5, out.width="400px"}
pp[[1]]
```

]

--

.pull-right[
$\color{orange}{\zeta}$  
`ranef(model)`  
mean zero, constant variance  

```{r echo=FALSE, fig.asp=.5, out.width="400px"}
pp[[2]]
```

]

---
# Assumption Plots: Residuals vs Fitted

```{r fig.asp=.7}
plot(model, type=c("p","smooth"))
```

---
# Assumption Plots: qqplots

```{r fig.asp=.7}
library(lattice)
qqmath(model, id=.05)
```


---
# Assumption Plots: Scale-Location

```{r fig.asp=.7}
plot(model, 
     form = sqrt(abs(resid(.))) ~ fitted(.),
     type = c("p","smooth"))
```


---
count:false
# Assumption Plots: Scale-Location

```{r fig.asp=.7}
plot(model, 
     form = sqrt(abs(resid(.))) ~ fitted(.) | cluster,
     type = c("p","smooth"))
```

---
# Assumption Plots: Ranefs

.pull-left[
```{r fig.asp=.7}
qqmath(ranef(model))
```
]
.pull-right[
```{r eval=FALSE}
rans <- as.data.frame(ranef(model)$cluster)

ggplot(rans, aes(sample = `(Intercept)`)) + 
  stat_qq() + stat_qq_line() +
  labs(title="random intercept")

ggplot(rans, aes(sample = x1)) + 
  stat_qq() + stat_qq_line()
  labs(title="random slope")
```
```{r echo=FALSE, fig.asp=.4}
rans <- as.data.frame(ranef(model)$cluster)
ggplot(rans, aes(sample = `(Intercept)`)) + 
  stat_qq() + stat_qq_line() +
  labs(title="random intercept") + 
ggplot(rans, aes(sample = x1)) + 
  stat_qq() + stat_qq_line()+
  labs(title="random slope")
```

]


---
# for a quick check

if nothing else... 

```{r eval=FALSE}
sjPlot::plot_model(model, type = "diag")
```
```{r echo=FALSE, fig.asp=.8}
(pp[[1]] + pp[[2]]) / (pp[[3]] + pp[[4]])
```


---

class: inverse, center, middle

<h2><b style="opacity:0.4;">Part 1: Assumptions </b><b>Troubleshooting</b></h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Case Diagnostics in MLM</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Random Effect Structures</h2>

---
# Some Data

.pull-left[

> 200 pupils from 20 schools completed a survey containing the Emotion Dysregulation Scale (EDS) and the Child Routines Questionnaire (CRQ). Eleven of the schools were taking part in an initiative to specifically teach emotion regulation as part of the curriculum.  
  
  
>Adjusting for levels of daily routines, do children from schools partaking in the intervention present with lower levels of emotional dysregulation? 

]
.pull-right[
```{r echo=F, fig.asp=.7}
library(ggExtra)
library(patchwork)
crq <- read_csv("https://uoepsy.github.io/data/crqdata.csv")
p <- ggplot(crq[crq$int=="Control",], aes(x=crq, y=emot_dysreg, col=schoolid)) + 
  geom_point()+geom_smooth(method="lm",se=F)+
  guides(col="none")+themedapr3()+
  labs(title="Control")
p1 <- ggplot(crq[crq$int=="Treatment",], aes(x=crq, y=emot_dysreg, col=schoolid)) + 
  geom_point()+geom_smooth(method="lm",se=F)+
  guides(col="none")+themedapr3()+
  labs(title="Treatment")
gridExtra::grid.arrange(
ggMarginal(p, type="boxplot", margins="y"),
ggMarginal(p1, type="boxplot", margins="y"),
nrow=1
)
```
]

---
# When things look wrong

```{r}
mymodel <- lmer(emot_dysreg ~ crq + int + (1 | schoolid), data = crq)
```
```{r echo=FALSE, fig.asp=.7}
pp <- sjPlot::plot_model(mymodel, type = "diag")
pp[[1]] + pp[[4]]
#(pp[[1]] + pp[[2]]) / (pp[[3]] + pp[[4]])
```

---
# When things look wrong
### __Model mis-specification?__

.pull-left[
```{r eval=F}
mymodel <- lmer(emot_dysreg ~ crq + int + (1 | schoolid), data = crq)
```

```{r echo=FALSE, fig.asp=.7}
model<-lmer(emot_dysreg ~ crq + int + (1 | schoolid), data = crq)
pp <- plot_model(model, type = "diag")
pp[[1]]
```
]
.pull-right[
```{r eval=F}
mymodel <- lmer(emot_dysreg ~ crq + age + int + (1 | schoolid), data = crq)
```

```{r echo=FALSE, fig.asp=.7}
model<-mymodel <- lmer(emot_dysreg ~ crq + age + int +   (1 | schoolid), data = crq)
pp <- plot_model(model, type = "diag")
pp[[1]]
```
]


---
# When things look wrong
### __Transformations?__  

- Transforming your outcome variable may help to satisfy model assumptions


--

  - log(y)
  - 1/y
  - sqrt(y)
  - forecast::BoxCox(y)

---
count:false
# When things look wrong
### __Transformations?__  

```{r include=F}
set.seed(1166050148)
d = c()
for(i in 1:10){
  x=rnorm(rdunif(1,6,12), 0, 1)
  g=sample(0:1,1)
  xmat=cbind(1,x,g)
  lp = xmat %*% c(rnorm(1,10,2), rnorm(1,2,2), 1)
  d = rbind(d, cbind(xmat, lp, i))
}
df <- as_tibble(d[,2:5])
names(df) <- c("x1","g","y","cluster")
df$y <- df$y + sn::rsn(nrow(df),0,30,50)
df<-df[-c(37,47, 65, 68, 82 ), ]
```


- Transforming your outcome variable may help to satisfy model assumptions


.pull-left[
```{r eval=F}
lmer(y ~ x1 + g + (1 | cluster), df)
```
```{r echo=FALSE, fig.asp=.5}
model <- lmer(y ~ x1 + g + (1  | cluster), df)
pp <- plot_model(model, type = "diag")
ggplot(df, aes(x=y)) + geom_histogram() +
pp[[1]]
```

]
.pull-right[
```{r eval=F}
lmer(forecast::BoxCox(y,lambda="auto") ~ x1 + g + (1 | cluster), df)
```
```{r echo=FALSE, fig.asp=.5}
model <- lmer(forecast::BoxCox(y,lambda="auto") ~ x1 + g + (1 | cluster), df)
pp <- plot_model(model, type = "diag")
ggplot(df, aes(x=forecast::BoxCox(y,lambda="auto"))) + geom_histogram() +
pp[[1]]
```
]

---
count:false
# When things look wrong
### __Transformations?__  

- Transforming your outcome variable may help to satisfy model assumptions **but it comes at the expense of interpretability.**  

.pull-left[
```{r eval=F}
lmer(y ~ x1 + g + (1 | cluster), df)
```
```{r echo=FALSE}
model <- lmer(y ~ x1 + g + (1 | cluster), df)
fixef(model)
```

]
.pull-right[
```{r eval=F}
lmer(forecast::BoxCox(y,lambda="auto") ~ x1 + g + (1 | cluster), df)
```
```{r echo=FALSE}
model <- lmer(forecast::BoxCox(y,lambda="auto") ~ x1 + g + (1 | cluster), df)
fixef(model)
```
]

---
count:false
class: extra
exclude: `r params$show_extra`
# When things look wrong
### __robustlmm__

.pull-left[
```{r}
mymodel <- lmer(emot_dysreg ~ crq * int + age + (1 | schoolid), data = crq)
summary(mymodel)$coefficients
```
]
.pull-right[
```{r}
library(robustlmm)
mymodelr <- rlmer(emot_dysreg ~ crq * int + age + (1 | schoolid), data = crq)
summary(mymodelr)$coefficients
```
]


---
# When things look wrong

### __Bootstrap?__

basic idea: 

1. do many many times:  
    &ensp;a. take a sample (e.g. sample with replacement from your data, or simulated from your model parameters)  
    &ensp;b. fit the model to the sample  
2. then:  
    &ensp;a. based on all the models fitted in step 1, obtain a distribution of parameter estimate of interest.  
    &ensp;b. based on the bootstrap distribution from 2a, compute a confidence interval for estimate.  
    &ensp;c. celebrate  

---
# Bootstrap: What do we (re)sample?

resample based on the estimated distributions of parameters?  
  - assumes explanatory variables are fixed, model specification and the distributions (e.g. $\zeta \sim N(0,\sigma_{\zeta})$ and $\varepsilon \sim N(0,\sigma_{\varepsilon})$) are correct.  


--

resample residuals
  - $y* = \hat{y} + \hat{\varepsilon}_{\textrm{sampled with replacement}}$
  - assumes explanatory variables are fixed, and model specification is correct. 
  
--

resample cases
  - **minimal** assumptions - that we have correctly specified the hierarchical structure of data
  - **But** do we resample:
      - observations?
      - clusters?
      - both?
      
---
# Bootstrap: Parametric

```{r}
reducedmodel <- lmer(emot_dysreg ~ crq + age + (1 | schoolid), data = crq)
mymodel <- lmer(emot_dysreg ~ crq + age + int + (1 | schoolid), data = crq)
```

- bootstrap LRT
    ```{r eval=F}
    library(pbkrtest)
    PBmodcomp(mymodel, reducedmodel)
    ```

- bootstrap CIs
    ```{r eval=F}
    confint(mymodel, method="boot")
    ```


--

- __lmeresampler__ package bootstrap() function
    ```{r eval=F}
    library(lmeresampler)
    mymodelBS <- bootstrap(mymodel, .f = fixef, type = "parametric", B = 2000)
    confint(mymodelBS, type = "norm")
    ```

.footnote[At time of writing, there is a minor bug with the version of **lmeresampler** that you can download from CRAN, so we recommend installing directly from the package maintainer: `devtools::install_github("aloy/lmeresampler")`]

---
# Bootstrap: Cases

```{r}
mymodel <- lmer(emot_dysreg ~ crq + age + int + (1 | schoolid), data = crq)
```

.pull-left[
```{r eval=params$finalcompile}
# devtools::install_github("aloy/lmeresampler")
library(lmeresampler)
# resample only children, not schools
mymodelBScase <- bootstrap(mymodel, .f = fixef, 
                           type = "case", B = 2000, 
                           resample = c(FALSE, TRUE))
summary(mymodelBScase)
```

]
.pull-right[
```{r eval=params$finalcompile}
confint(mymodelBScase, type = "basic")
```
]

.footnote[<br>For a nice how-to guide on the **lmeresampler** package, see http://aloy.github.io/lmeresampler/articles/lmeresampler-vignette.html.  
For a discussion of different bootstrap methods for multilevel models, see Leeden R.., Meijer E., Busing F.M. (2008) Resampling Multilevel Models. In: Leeuw J.., Meijer E. (eds) Handbook of Multilevel Analysis. Springer, New York, NY. DOI: 10.1007/978-0-387-73186-5_11 ]


---
count:false
# Bootstrap: Cases

```{r}
mymodel <- lmer(emot_dysreg ~ crq + age + int + (1 | schoolid), data = crq)
```

.pull-left[
```{r eval=FALSE}
# devtools::install_github("aloy/lmeresampler")
library(lmeresampler)
# resample only children, not schools
mymodelBScase <- bootstrap(mymodel, .f = fixef, 
                           type = "case", B = 2000, 
                           resample = c(FALSE, TRUE))
summary(mymodelBScase)
```
```{r eval=params$finalcompile,echo=FALSE}
summary(mymodelBScase)
```

]
.pull-right[
```{r eval=params$finalcompile,fig.asp=.6}
plot(mymodelBScase,"intTreatment")
```
]

.footnote[<br>For a nice how-to guide on the **lmeresampler** package, see http://aloy.github.io/lmeresampler/articles/lmeresampler-vignette.html.  
For a discussion of different bootstrap methods for multilevel models, see Leeden R.., Meijer E., Busing F.M. (2008) Resampling Multilevel Models. In: Leeuw J.., Meijer E. (eds) Handbook of Multilevel Analysis. Springer, New York, NY. DOI: 10.1007/978-0-387-73186-5_11 ]


---
# Summary

- Our assumptions for multi-level models are similar to that of a standard linear model in that we are concerned with the our residuals
  - in the multi-level case, we have residuals are multiple levels. 
  
- When assumptions appear violated, there are various courses of action to consider. 
  - primarily, we should think about whether our model makes theoretical sense
  
- Resampling methods (e.g. Bootstrapping) can be used to obtain confidence intervals and bias-corrected estimates of model parameters. 
  - There are various forms of the bootstrap, with varying assumptions. 

---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 1

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Assumptions</h2>
<h2>Part 2: Case Diagnostics in MLM</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Random Effect Structures</h2>


---
# Influence

Just like standard `lm()`, observations can have unduly high influence on our model through a combination of high leverage and outlyingness. 

```{r echo=FALSE, fig.asp=.5, fig.width=12, fig.align="center"}
set.seed(18)
tibble(
  x = rnorm(20),
  y = 2*x + rnorm(20,0,.3)
) -> df
loo = coef(lm(y~x,df))
df[21,]<-cbind(4,8)
ggplot(df,aes(x=x,y=y))+geom_point(alpha=.5)+
  theme_minimal()+
  geom_abline(intercept=loo[1],slope=loo[2], lty="dotted", lwd=1)+
  scale_y_continuous(limits=c(-3,8))+
  scale_x_continuous(limits=c(-2,4))+
  geom_point(x=4,y=8,size=2,col="red")+
  geom_smooth(method="lm",se=F) +
  labs(title="not outlying, high leverage") -> p1

df[21,]<-cbind(0,6)
ggplot(df,aes(x=x,y=y))+geom_point(alpha=.5)+
  theme_minimal()+
  geom_abline(intercept=loo[1],slope=loo[2], lty="dotted", lwd=1)+
  scale_y_continuous(NULL,limits=c(-3,8))+
  scale_x_continuous(limits=c(-2,4))+
  geom_point(x=0,y=6,size=2,col="red")+
  geom_smooth(method="lm",se=F) +
  labs(title="high outlier, low leverage") -> p2

df[21,]<-cbind(4,0)
ggplot(df,aes(x=x,y=y))+geom_point(alpha=.5)+
  theme_minimal()+
  geom_abline(intercept=loo[1],slope=loo[2], lty="dotted", lwd=1)+
  scale_y_continuous(NULL, limits=c(-3,8))+
  scale_x_continuous(limits=c(-2,4))+
  geom_point(x=4,y=0,size=2,col="red")+
  geom_smooth(method="lm",se=F) +
  labs(title="high outlier, high leverage") -> p3

p1 + p2 + p3

```



---
# multiple levels...

- Both observations (level 1 units) __and__ clusters (level 2+ units) can be influential. 


--

- several packages, but current recommendation is **HLMdiag:** http://aloy.github.io/HLMdiag/index.html 


---
# Level 1 influential points

.pull-left[
```{r fig.asp=.5}
mymodel <- lmer(emot_dysreg ~ crq + age + 
                  int + (1 | schoolid), 
                data = crq)
qqmath(mymodel, id=0.05)
```
]


--

.pull-right[
```{r}
library(HLMdiag)
infl1 <- hlm_influence(mymodel, level = 1)
names(infl1)
infl1
```
]



---
count:false
# Level 1 influential points

.pull-left[
```{r fig.asp=.5}
mymodel <- lmer(emot_dysreg ~ crq + age + 
                  int + (1 | schoolid), 
                data = crq)
qqmath(mymodel, id=0.05)
```
]
.pull-right[
```{r fig.asp=.7}
library(HLMdiag)
infl1 <- hlm_influence(mymodel, level = 1)
dotplot_diag(infl1$cooksd, cutoff = "internal")
```
]

---
# Level 2 influential clusters

```{r eval=F}
infl2 <- hlm_influence(mymodel, level = "schoolid")
dotplot_diag(infl2$cooksd, cutoff = "internal", index=infl2$schoolid)
```
```{r echo=FALSE, fig.asp=.7}
infl2 <- hlm_influence(mymodel, level = "schoolid")
dotplot_diag(infl2$cooksd, cutoff = "internal", index=infl2$schoolid) +
  scale_y_continuous(limits=c(0,.45))
```


---
# What to do?

- In this context (children from schools), I would be inclined not to worry too much about the individual children who have high values on cook's distance, __if__ we plan on case-based bootstrap for our inferential tests (and plan on resampling the level 1 units - the children). 


--

- It's worth looking into school 6 a bit further. 

- `mdffits` is a measure of multivariate "difference in fixed effects"
    ```{r}
    infl2 %>% arrange(desc(mdffits))
    ```



---
count:false
# What to do?

- In this context (children from schools), I would be inclined not to worry too much about the individual children who have high values on cook's distance, __if__ we plan on bootstrapping our inferential tests (and plan on resampling the level 1 units - the children). 

- It's worth looking into school 6 a bit further. 

- examine fixed effects upon deletion of schools 6
    ```{r}
    delete6 <- case_delete(mymodel, level = "schoolid", type = "fixef", delete = "school6")
    cbind(delete6$fixef.original, delete6$fixef.delete)
    ```


---
# Sensitivity Analysis?

Would our conclusions change if we excluded these schools?  

```{r eval=params$finalcompile}
mymodelrm6 <- lmer(emot_dysreg ~ crq + age +
                  int + (1 | schoolid), 
                data = crq %>% 
                  filter(!schoolid %in% c("school6")))
mymodelrm6BS <- bootstrap(mymodelrm6, .f = fixef, 
                           type = "case", B = 2000, 
                           resample = c(FALSE, TRUE))
confint(mymodelrm6BS, type = "basic")
```

---
# Summary

- Influence can be exerted by individual observations and higher lever groups of observations  
  - e.g. by children and by schools, or by individual trials and by participants.   
  
- We can get measures of influence at different levels, and consider how estimates and conclusions might change when certain observations (or groups) are excluded

- Bootstrapping is relevant as whether we are resampling at the level of an influential group/observation is going to affect the extent to which our estimates are biased by that observation/group

---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 3

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Assumptions</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Case Diagnostics in MLM</h2>
<h2>Part 3: Random Effect Structures</h2>

---
# What have we seen so far?

- children within schools

- birds within gardens

- measurements within participants

- nurses within hospitals

- and probably some others...

---
# Nested

- the level $j$ observations in a level $i$ group belong __only__ to that level $i$ group. 

```{r out.width="450px", echo=FALSE, fig.align="center"}
knitr::include_graphics("https://media.gettyimages.com/photos/albatross-chick-between-parents-feet-falkland-islands-picture-id642348358?s=2048x2048")
```

---
count:false
# Nested

- the level $j$ observations in a level $i$ group belong __only__ to that level $i$ group.  

- __`(1 | school/class)`__ or __`(1 | school) + (1 | class:school)`__

```{r echo=FALSE, fig.align="center"}
knitr::include_graphics("jk_img_sandbox/structure_id.png")
```

---
count:false
# Nested

- the level $j$ observations in a level $i$ group belong __only__ to that level $i$ group.  

- If labels are unique, __`(1 | school) + (1 | class)`__ is the same as __`(1 | school/class)`__  

```{r echo=FALSE, fig.align="center"}
knitr::include_graphics("jk_img_sandbox/structure_nested.png")
```


---
# Crossed

- "crossed" = not nested!

--

- __`(1 | subject) + (1 | task)`__  

```{r echo=FALSE, fig.align="center", out.height="450px"}
knitr::include_graphics("jk_img_sandbox/structure_crossed.png")
```


---
# Fixed or random

.pull-left[

| Criterion: | Repetition: <br> _If the experiment were repeated:_ | Desired inference: <br> _The conclusions refer to:_ |
|----------------|--------------------------------------------------|----------------------------------------------------|
| Fixed effects  | <center>Same levels would be used</center>     |    <center>The levels used </center>                                   |
| Random effects | <center>Different levels would be used</center>   | <center>A population from which the levels used<br> are just a (random) sample</center> |

]

.pull-right[

- If only small number of clusters, estimating variance components may be unstable.  

- Partialling out cluster-differences as fixed effects *may* be preferable. 

]

---
# Maximal Structures

- "maximal" = the most complex random effect structure that you can fit to the data

--

- requires sufficient variance at all levels (for both intercepts and slopes where relevant). Which is often not the case.  


--

```{r warning=T}
maxmodel <- lmer(emot_dysreg ~ crq + age + int + (1 + crq + age | schoolid), data = crq)
```

--

another example: 16 items each occur in 4 different combinations: condition A vs B $\times$ type 1 vs 2.  
40 participants see all items in all conditions (64 trials each participant).

```{r echo=FALSE}
kelly<-read.csv("https://uoepsy.github.io/data/kelly2010_replication.csv")
kelly %>% filter(condition!="baseline") %>%
  mutate(
    condition = fct_recode(factor(modality), "A"="gesture","B"="speech"),
    type = fct_recode(factor(strength), "1"="strong","2"="weak"),
    outcome = rtime, 
    ppt = subject_nr
  ) -> kelly
```

```{r warning=T,message=T}
mmod <- lmer(outcome ~ condition * type + (1 + condition * type | ppt) + 
               (1 + condition * type | item), data = kelly)
```


---
# Model Convergence

- Don't report results from a model that doesn't converge. You will probably not be able to trust the estimates. 

--

- Try a different optimiser, adjust the max iterations, or the stopping tolerances

```{r echo=FALSE, fig.asp=.3}
knitr::include_graphics("jk_img_sandbox/tolerance.png")
```


---
count:false
# Model Convergence

- Don't report results from a model that doesn't converge. You will probably not be able to trust the estimates. 

- Try a different optimiser, adjust the max iterations, or the stopping tolerances

<br><br>

- Remove random effects with least variance until model converges (see Barr et al., 2013)

- Use a criterion for model selection (e.g. AIC, BIC) to choose a random effect structure that is supported by the data (see Matsuchek et al., 2017)


--

- __No right answer__


---
# correlations between random effects

```{r echo=FALSE}
VarCorr(mmod)
```


---
count:false
# correlations between random effects

.pull-left[
__perfect correlations__

```{r echo=FALSE}
data <- read_csv('https://uoepsy.github.io/data/MathsAchievement.csv')
data$clusterid <- as.factor(data$childid)
data$x1<-data$year
data$y <- data$math
df<-data
```
```{r}
m1 <- lmer(y ~ 1 + x1 + 
             (1 + x1 | clusterid), data = df)
VarCorr(m1)
```
```{r echo=FALSE, fig.asp=.5}
dotplot.ranef.mer(ranef(m1))
```
]

--

.pull-right[
```{r echo=FALSE}
set.seed(33)
tibble(
  g = 1:10,
  i = rnorm(10,1,1),
  x = i+rnorm(10,0,.1)
) %>% mutate(
  pre = list(1:10)
) %>% unnest() %>% mutate(
  y = i+x*pre
) %>%
  ggplot()+
  geom_line(aes(x=pre,y=y,group=g))+
  labs(x="x1",y=".fitted")+
  themedapr3()
```
]

---
count:false
# correlations between random effects

.pull-left[
__perfect correlations__

```{r echo=FALSE}
data <- read_csv('https://uoepsy.github.io/data/MathsAchievement.csv')
data$clusterid <- as.factor(data$childid)
data$x1<-data$year
data$y <- data$math
df<-data
```
```{r}
m1 <- lmer(y ~ 1 + x1 + 
             (1 + x1 | clusterid), data = df)
VarCorr(m1)
```
```{r echo=FALSE, fig.asp=.5}
dotplot.ranef.mer(ranef(m1))
```
]

.pull-right[
__zero correlations__

```{r}
zcpmodel <- lmer(y ~ 1 + x1 + 
                   (1 + x1 || clusterid), data = df)
VarCorr(zcpmodel)
```
```{r echo=FALSE, fig.asp=.5}
dotplot.ranef.mer(ranef(zcpmodel))
```
]

---
# correlations between random effects

When should we remove them?

--
 
__When it makes theoretical sense to do so.__


---
# Summary

- random effect structures can get complicated quite quickly
    - we can have multiple levels of nesting
    - we can have crossed random effects 

- the maximal random effect structure is the most complex structure we can fit to the data. 
    - it often leads to problems with model convergence
    
- building MLMs is a balancing act between accounting for different sources of variance and attempting to fit a model that is too complex for our data.  

---
class: inverse, center, middle, animated, rotateInDownLeft

# End

