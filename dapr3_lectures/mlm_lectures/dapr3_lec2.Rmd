---
title: "<b>WEEK 2<br>Multi-level Models</b>"
subtitle: "Data Analysis for Psychology in R 3"
author: "Josiah King"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: "AY 2020-2021"
output:
  xaringan::moon_reader:
    lib_dir: jk_libs/libs
    css: 
      - xaringan-themer.css
      - jk_libs/tweaks.css
    nature:
      beforeInit: "jk_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(digits=4,scipen=2)
options(knitr.table.format="html")
xaringanExtra::use_xaringan_extra(c("tile_view","animate_css","tachyons"))
xaringanExtra::use_extra_styles(
  mute_unhighlighted_code = FALSE
)
library(knitr)
library(tidyverse)
library(ggplot2)
knitr::opts_chunk$set(
  dev = "png",
  warning = FALSE,
  message = FALSE,
  cache = FALSE
)
themedapr3 = function(){
  theme_minimal() + 
    theme(text = element_text(size=20))
}
#source('R/myfuncs.R')
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  # base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r premable, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(patchwork)
```

---
class: inverse, center, middle

# Part 1<br>LM to LMM

---
# Terminology

names

---
# From LM to LMM


---
# data

---
# lm

---
# random int

fit, plot
compare w FE, return to "partial pooling"

---
# random slopes

fit, plot
partial pooling again.


---



---
# Summary

LM to LMM
notation
Random intercepts
Random slopes

---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 1

---
class: inverse, center, middle

# Part 2<br>Inference

---
# Summary

Inference, df etc.


---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 2

---
class: inverse, center, middle

# Part 3<br>Model Comparison

---
# Summary


---
class: inverse, center, middle, animated, rotateInDownLeft

# End of Part 3

---
class: inverse, center, middle

# Part 4<br>Repeated Measures ANOVA


---
# ANOVA is a special case of linear model

- anova is essentially lm with categorical predictors. examines group mean differences
- does it by partitioning variance.
- can calculate more easily by hand.
- still fairly popular in psychology because we often design experiments with discrete conditions. means we can balance designs and examine condition mean differences

---
# ANOVA in R

```{r}
df <- read.table("~/Desktop/jk_codebits/wip/data/growth.txt", header=T) %>%
  rename(y = gain, x1 = supplement, x2 = diet)
  
lm(y ~ x1, df) %>% anova()
aov(y~x1,df) %>% summary

lm(y ~ x1+x2, df) %>% anova()
aov(y~x1+x2,df) %>% summary
```

order matters (when using type 1 SS as above)

---
# anova() for model comparison


- anova() function to compare models. 
- if we run it on one model, it does so incrementally adding the predictors
```{r eval=F}
m1<-lm(y~x1+x2, df)
m2<-lm(y~x1+x2+x3, df)

anova(m1, m2)
#is the same as the last term from
anova(m2)
```



---
# Why use 1 vs another?

anova asks the question "are there differences between group means?/is there an effect of x?". 
the coefficient tests from the linear model ask "*what* are the differences between group means?/*what* is the effect of x?"

anova requires post-hoc tests comparing specific differences, but has the advantage of conducting fewer tests. 

---
# Repeated measures ANOVA


partitioning variance further



---
# Summary



---
class: inverse, center, middle, animated, rotateInDownLeft

# End

