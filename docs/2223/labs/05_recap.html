<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DAPR3 - Recap of multilevel models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-hand-o-right')) {
    f.classList.add('fa-hand-o-left')
    f.classList.remove('fa-hand-o-right')
} else {
    f.classList.add('fa-hand-o-right')
    f.classList.remove('fa-hand-o-left')
}
}
</script>

<script src="https://kit.fontawesome.com/120b08a6f5.js" crossorigin="anonymous"></script>
<link href="site_libs/panelset-0.2.6/panelset.css" rel="stylesheet">
<script src="site_libs/panelset-0.2.6/panelset.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">DAPR3</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-multi-level-models" role="button" data-bs-toggle="dropdown" aria-expanded="false">Multi Level Models</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-multi-level-models">    
        <li>
    <a class="dropdown-item" href="./01_regressionrefresh.html">
 <span class="dropdown-text">1: Linear Regression | Clustered Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./02_intromlm.html">
 <span class="dropdown-text">2: Multilevel Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./03_assumptranef.html">
 <span class="dropdown-text">3: Assumptions, Diagnostics &amp; Random Effect Structures</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./04_centerglmer.html">
 <span class="dropdown-text">4: Centering in MLM | Logistic</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./05_recap.html">
 <span class="dropdown-text">5: Recap</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-dimension-reduction--sem" role="button" data-bs-toggle="dropdown" aria-expanded="false">Dimension reduction &amp; SEM</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-dimension-reduction--sem">    
        <li>
    <a class="dropdown-item" href="./07_path1.html">
 <span class="dropdown-text">7: Path Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./08_path2.html">
 <span class="dropdown-text">8: Path Mediation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./09_pca.html">
 <span class="dropdown-text">9: Dimension Reduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_efa.html">
 <span class="dropdown-text">10: EFA: Part 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./11_efa2.html">
 <span class="dropdown-text">11: EFA: Part 2</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-extra" role="button" data-bs-toggle="dropdown" aria-expanded="false">Extra</a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-extra">    
        <li>
    <a class="dropdown-item" href="./example_01_repeated_measures.html">
 <span class="dropdown-text">Example: Repeated Measures MLM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./example_02_intervention.html">
 <span class="dropdown-text">Example: Intervention Study</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./example_03_many_trials.html">
 <span class="dropdown-text">Example: Many Trials</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./example_00_anova.html">
 <span class="dropdown-text">Example: ANOVA (rpt measures &amp; mixed)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./example2_01_EFA.html">
 <span class="dropdown-text">Example: Exploratory Factor Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./lvp.html">
 <span class="dropdown-text">Likelihood vs Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./explainer_3leveleq.html">
 <span class="dropdown-text">Writing 3-level MLM equations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./explainer_pcavar.html">
 <span class="dropdown-text">PCA and Unequal Variances</span></a>
  </li>  
    </ul>
  </li>
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#flashcards-lm-to-lmer" id="toc-flashcards-lm-to-lmer" class="nav-link active" data-scroll-target="#flashcards-lm-to-lmer">Flashcards: <code>lm</code> to <code>lmer</code></a></li>
  <li><a href="#mlm-in-a-nutshell" id="toc-mlm-in-a-nutshell" class="nav-link" data-scroll-target="#mlm-in-a-nutshell">MLM in a nutshell</a></li>
  <li><a href="#flashcards-getting-p-valuescis-for-multilevel-models" id="toc-flashcards-getting-p-valuescis-for-multilevel-models" class="nav-link" data-scroll-target="#flashcards-getting-p-valuescis-for-multilevel-models">Flashcards: Getting p-values/CIs for Multilevel Models</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Recap of multilevel models</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="lo">
<p><strong>No specific exercises this week</strong></p>
<p>This week, there aren’t any exercises, but there is a small recap reading of multilevel models, followed by some ‘flashcard’ type boxes to help you test your understanding of some of the key concepts.</p>
<p>Please use the lab sessions to go over exercises from previous weeks, as well as asking any questions about the content below.</p>
</div>
<section id="flashcards-lm-to-lmer" class="level1">
<h1>Flashcards: <code>lm</code> to <code>lmer</code></h1>
<div class="cell" data-layout-align="center">

</div>
<p>In a simple linear regression, there is only considered to be one source of random variability: any variability left unexplained by a set of predictors (which are modelled as fixed estimates) is captured in the model residuals.</p>
<p>Multi-level (or ‘mixed-effects’) approaches involve modelling more than one source of random variability - as well as variance resulting from taking a random sample of observations, we can identify random variability across different groups of observations. For example, if we are studying a patient population in a hospital, we would expect there to be variability across the our sample of patients, but also across the doctors who treat them.</p>
<p>We can account for this variability by allowing the outcome to be lower/higher for each group (a random intercept) and by allowing the estimated effect of a predictor vary across groups (random slopes).</p>
<div class="blue">
<p>Before you expand each of the boxes below, think about how comfortable you feel with each concept.<br>
This content is very cumulative, which means often going back to try to isolate the place which we need to focus efforts in learning.</p>
</div>
<div class="optional-begin">
<span id="opt-start-1" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-1', 'opt-start-1')"> <span class="olab">Simple Linear Regression</span></span>
</div>
<div id="opt-body-1" class="optional-body" style="display: none;">
<div class="frame">
<p><strong>Formula:</strong></p>
<ul>
<li><span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \epsilon_i\)</span></li>
</ul>
<p><strong>R command:</strong></p>
<ul>
<li><code>lm(outcome ~ predictor, data = dataframe)</code></li>
</ul>
<p><em>Note:</em> this is the same as <code>lm(outcome ~ 1 + predictor, data = dataframe)</code>. The <code>1 +</code> is always there unless we specify otherwise (e.g., by using <code>0 +</code>).</p>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-2" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-2', 'opt-start-2')"> <span class="olab">Clustered (multi-level) data</span></span>
</div>
<div id="opt-body-2" class="optional-body" style="display: none;">
<p>When our data is clustered (or ‘grouped’) such that datapoints are no longer independent, but belong to some grouping such as that of multiple observations from the same subject, we have multiple sources of random variability. A simple regression does not capture this.</p>
<p>If we separate out our data to show an individual plot for each grouping (in this data the grouping is by subjects), we can see how the fitted regression line from <code>lm()</code> is assumed to be the same for each group.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-3" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-3', 'opt-start-3')"> <span class="olab">Random intercepts</span></span>
</div>
<div id="opt-body-3" class="optional-body" style="display: none;">
<p>By including a random-intercept term, we are letting our model estimate random variability around an average parameter (represented by the fixed effects) for the clusters.</p>
<div class="frame">
<p><strong>Formula:</strong><br>
Level 1:</p>
<ul>
<li><span class="math inline">\(y_{ij} = \beta_{0i} + \beta_{1i} x_{ij} + \epsilon_{ij}\)</span></li>
</ul>
<p>Level 2:</p>
<ul>
<li><span class="math inline">\(\beta_{0i} = \gamma_{00} + \zeta_{0i}\)</span></li>
</ul>
<p>Where the expected values of <span class="math inline">\(\zeta_{0}\)</span>, and <span class="math inline">\(\epsilon\)</span> are 0, and their variances are <span class="math inline">\(\sigma_{0}^2\)</span> and <span class="math inline">\(\sigma_\epsilon^2\)</span> respectively. We will further assume that these are normally distributed.</p>
<p>We can now see that the intercept estimate <span class="math inline">\(\beta_{0i}\)</span> for a particular group <span class="math inline">\(i\)</span> is represented by the combination of a mean estimate for the parameter (<span class="math inline">\(\gamma_{00}\)</span>) and a random effect for that group (<span class="math inline">\(\zeta_{0i}\)</span>).</p>
<p><strong>R command:</strong></p>
<ul>
<li><code>lmer(outcome ~ predictor + (1 | grouping), data = dataframe)</code></li>
</ul>
</div>
<p>Notice how the fitted line of the random intercept model has an adjustment for each subject.<br>
Each subject’s line has been moved up or down accordingly.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-4" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-4', 'opt-start-4')"> <span class="olab">Shrinkage</span></span>
</div>
<div id="opt-body-4" class="optional-body" style="display: none;">
<p>If you think about it, we might have done a similar thing to the random intercept with the tools we already had at our disposal, by using <code>lm(y~x+subject)</code>. This would give us a coefficient for the difference between each subject and the reference level intercept, or we could extend this to <code>lm(y~x*subject)</code> to give us an adjustment to the slope for each subject.</p>
<p>However, the estimate of these models will be slightly different:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Why?</strong> One of the benefits of multi-level models is that our cluster-level estimates are shrunk towards the average depending on a) the level of across-cluster variation and b) the number of datapoints in clusters.</p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-5" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-5', 'opt-start-5')"> <span class="olab">Random slopes</span></span>
</div>
<div id="opt-body-5" class="optional-body" style="display: none;">
<div class="frame">
<p><strong>Formula:</strong><br>
Level 1:</p>
<ul>
<li><span class="math inline">\(y_{ij} = \beta_{0i} + \beta_{1i} x_{ij} + \epsilon_{ij}\)</span></li>
</ul>
<p>Level 2:</p>
<ul>
<li><span class="math inline">\(\beta_{0i} = \gamma_{00} + \zeta_{0i}\)</span><br>
</li>
<li><span class="math inline">\(\beta_{1i} = \gamma_{10} + \zeta_{1i}\)</span></li>
</ul>
<p>Where the expected values of <span class="math inline">\(\zeta_0\)</span>, <span class="math inline">\(\zeta_1\)</span>, and <span class="math inline">\(\epsilon\)</span> are 0, and their variances are <span class="math inline">\(\sigma_{0}^2\)</span>, <span class="math inline">\(\sigma_{1}^2\)</span>, <span class="math inline">\(\sigma_\epsilon^2\)</span> respectively. We will further assume that these are normally distributed.</p>
<p>As with the intercept <span class="math inline">\(\beta_{0i}\)</span>, the slope of the predictor <span class="math inline">\(\beta_{1i}\)</span> is now modelled by a mean <span class="math inline">\(\gamma_{10}\)</span> and a random effect for each group (<span class="math inline">\(\zeta_{1i}\)</span>).</p>
<p><strong>R command:</strong></p>
<ul>
<li><code>lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)</code></li>
</ul>
<p><em>Note:</em> this is the same as <code>lmer(outcome ~ predictor + (predictor | grouping), data = dataframe)</code> . Like in the fixed-effects part, the <code>1 +</code> is assumed in the random-effects part.</p>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-6" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-6', 'opt-start-6')"> <span class="olab">Fixed effects</span></span>
</div>
<div id="opt-body-6" class="optional-body" style="display: none;">
<p>The plot below show the fitted values for each subject from the random slopes model <code>lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)</code></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>The thick green line shows the fixed intercept and slope around which the groups all vary randomly.</p>
<p>The <em>fixed effects</em> are the parameters that define the thick green line, and we can extract them using the <code>fixef()</code> function:</p>
<p>These are the overall intercept and slope.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(random_slopes_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)          x1 
405.7897675  -0.6722654 </code></pre>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-7" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-7', 'opt-start-7')"> <span class="olab">Random effects</span></span>
</div>
<div id="opt-body-7" class="optional-body" style="display: none;">
<p>The plots below show the fitted values for each subject from each model that we have gone through in these expandable boxes (simple linear regression, random intercept, and random intercept &amp; slope):</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>In the random-intercept model (center panel), the differences from each of the subjects’ intercepts to the fixed intercept (thick green line) have mean 0 and standard deviation <span class="math inline">\(\sigma_0\)</span>. The standard deviation (and variance, which is <span class="math inline">\(\sigma_0^2\)</span>) is what we see in the random effects part of our model summary (or using the <code>VarCorr()</code> function).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/varcors.PNG" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
</div>
</div>
<p>In the random-slope model (right panel), the same is true for the differences from each subjects’ slope to the fixed slope. We can extract the deviations for each group from the fixed effect estimates using the <code>ranef()</code> function.</p>
<p>These are the deviations from the overall intercept (<span class="math inline">\(\widehat \gamma_{00} = 405.79\)</span>) and slope (<span class="math inline">\(\widehat \gamma_{10} = -0.672\)</span>) for each subject <span class="math inline">\(i\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(random_slopes_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$subject
        (Intercept)          x1
sub_308   31.327291 -1.43995253
sub_309  -28.832219  0.41839420
sub_310    2.711822  0.05993766
sub_330   59.398971  0.38526670
sub_331   74.958481  0.17391602
sub_332   91.086535 -0.23461836
sub_333   97.852988 -0.19057838
sub_334  -54.185688 -0.55846794
sub_335  -16.902018  0.92071637
sub_337   52.217859 -1.16602280
sub_349  -67.760246 -0.68438960
sub_350   -5.821271 -1.23788002
sub_351   61.198823  0.05499816
sub_352   -7.905596 -0.66495059
sub_369  -47.636645 -0.46810258
sub_370  -33.121093 -1.11001234
sub_371   77.576205 -0.20402571
sub_372  -36.389281 -0.45829505
sub_373 -197.579562  1.79897904
sub_374  -52.195357  4.60508775

with conditional variances for "subject" </code></pre>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-8" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-8', 'opt-start-8')"> <span class="olab">Group-level coefficients</span></span>
</div>
<div id="opt-body-8" class="optional-body" style="display: none;">
<p>We can also see the actual intercept and slope for each subject <span class="math inline">\(i\)</span> directly, using the <code>coef()</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(random_slopes_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$subject
        (Intercept)         x1
sub_308    437.1171 -2.1122179
sub_309    376.9575 -0.2538712
sub_310    408.5016 -0.6123277
sub_330    465.1887 -0.2869987
sub_331    480.7482 -0.4983494
sub_332    496.8763 -0.9068837
sub_333    503.6428 -0.8628438
sub_334    351.6041 -1.2307333
sub_335    388.8877  0.2484510
sub_337    458.0076 -1.8382882
sub_349    338.0295 -1.3566550
sub_350    399.9685 -1.9101454
sub_351    466.9886 -0.6172672
sub_352    397.8842 -1.3372160
sub_369    358.1531 -1.1403680
sub_370    372.6687 -1.7822777
sub_371    483.3660 -0.8762911
sub_372    369.4005 -1.1305604
sub_373    208.2102  1.1267137
sub_374    353.5944  3.9328224

attr(,"class")
[1] "coef.mer"</code></pre>
</div>
</div>
<p>Notice that the above are the fixed effects + random effects estimates, i.e.&nbsp;the overall intercept and slope + deviations for each subject.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(random_intercept_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$subject
        (Intercept)         x1
sub_308    384.0955 -0.9135829
sub_309    406.5426 -0.9135829
sub_310    421.8658 -0.9135829
sub_330    492.0476 -0.9135829
sub_331    498.0868 -0.9135829
sub_332    496.0130 -0.9135829
sub_333    504.6193 -0.9135829
sub_334    338.5855 -0.9135829
sub_335    440.3964 -0.9135829
sub_337    416.7346 -0.9135829
sub_349    319.6674 -0.9135829
sub_350    356.3696 -0.9135829
sub_351    479.2943 -0.9135829
sub_352    379.5162 -0.9135829
sub_369    349.0152 -0.9135829
sub_370    335.0869 -0.9135829
sub_371    484.0427 -0.9135829
sub_372    360.5322 -0.9135829
sub_373    293.6168 -0.9135829
sub_374    511.3440 -0.9135829

attr(,"class")
[1] "coef.mer"</code></pre>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-9" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-9', 'opt-start-9')"> <span class="olab">Visualising Model Fitted values</span></span>
</div>
<div id="opt-body-9" class="optional-body" style="display: none;">
<p>The model fitted (or “model predicted”) values can be obtained using <code>predict()</code> (returning just the values) or <code>broom.mixed::augment()</code> (returning the values attached to the data that is inputted to the model).</p>
<p>To plot, them, we would typically like to plot the fitted values for each group (e.g.&nbsp;subject)</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom.mixed)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(random_slopes_model) <span class="sc">%&gt;%</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(.,<span class="fu">aes</span>(<span class="at">x=</span>x1, <span class="at">y=</span>.fitted, <span class="at">group=</span>subject))<span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-10" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-10', 'opt-start-10')"> <span class="olab">Visualising Fixed Effects</span></span>
</div>
<div id="opt-body-10" class="optional-body" style="display: none;">
<p>If we want to plot the fixed effects from our model, we have to do something else. Packages like <strong>sjPlot</strong> make it incredibly easy (but sometimes <em>too</em> easy), so a nice option is to use the <strong>effects</strong> package to construct a dataframe of the linear prediction accross the values of a predictor, plus standard errors and confidence intervals. We can then pass this to <code>ggplot()</code>, giving us all the control over the aesthetics.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(effects)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>ef <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">effect</span>(<span class="at">term=</span><span class="st">"x1"</span>,<span class="at">mod=</span>random_slopes_model))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ef, <span class="fu">aes</span>(<span class="at">x=</span>x1,<span class="at">y=</span>fit, <span class="at">ymin=</span>lower,<span class="at">ymax=</span>upper))<span class="sc">+</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">alpha=</span>.<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-11" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-11', 'opt-start-11')"> <span class="olab">Plotting random effects</span></span>
</div>
<div id="opt-body-11" class="optional-body" style="display: none;">
<p>The quick and easy way to plot your random effects is to use the <code>dotplot.ranef.mer()</code> function in <code>lme4</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>randoms <span class="ot">&lt;-</span> <span class="fu">ranef</span>(random_slopes_model, <span class="at">condVar=</span><span class="cn">TRUE</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dotplot.ranef.mer</span>(randoms)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$subject</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05_recap_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<!-- 

<div class="optional-begin"><span id='opt-start-12' class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-12', 'opt-start-12')"> <span class="olab">Completely optional - extracting them for plotting in ggplot</span></span></div><div class="optional-body" id = "opt-body-12" style="display: none;">

 -->
<!-- Sometimes, however, we might want to have a bit more control over our plotting, we can extract the estimates and correlations for each subject:   -->
<!-- ```{r} -->
<!-- #we can get the random effects: -->
<!-- #(note that we use $subject because there might be other groupings, and the ranef() function will give us a list, with one element for each grouping variable) -->
<!-- randoms <- -->
<!--   ranef(random_slopes_model)$subject %>% -->
<!--   mutate(subject = row.names(.)) %>%  # the subject IDs are stored in the rownames, so lets add them as a variable -->
<!--   pivot_longer(cols=1:2, names_to="term",values_to="estimate") # finally, let's reshape it for plotting -->
<!-- #and the same for the standard errors (from the arm package): -->
<!-- randoms_se <- -->
<!--   arm::se.ranef(random_slopes_model)$subject %>% -->
<!--   as.data.frame() %>% -->
<!--   mutate(subject = row.names(.)) %>% -->
<!--   pivot_longer(cols=1:2, names_to="term",values_to="se") -->
<!-- # join them together: -->
<!-- ranefs_plotting <- left_join(randoms, randoms_se) -->
<!-- # it's easier for plotting if we -->
<!-- ggplot(ranefs_plotting, aes(y=subject, x=estimate))+ -->
<!--   geom_errorbarh(aes(xmin=estimate-2*se, xmax=estimate+2*se))+ -->
<!--   facet_wrap(~term, scales="free_x") -->
<!-- ``` -->
<!-- 

</div><p class="optional-end"></p>

 -->
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-13" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-13', 'opt-start-13')"> <span class="olab">Nested and Crossed structures</span></span>
</div>
<div id="opt-body-13" class="optional-body" style="display: none;">
<p>The same principle we have seen for one level of clustering can be extended to clustering at different levels (for instance, observations are clustered within subjects, which are in turn clustered within groups).</p>
<p>Consider the example where we have observations for each student in every class within a number of schools:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/structure_id.png" class="img-fluid figure-img" width="1200"></p>
</figure>
</div>
</div>
</div>
<p><strong>Question:</strong> Is “Class 1” in “School 1” the same as “Class 1” in “School 2”?</p>
<p>No.<br>
The classes in one school are distinct from the classes in another <strong>even though they are named the same</strong>.</p>
<p>The classes-within-schools example is a good case of <strong>nested random effects</strong> - one factor level (one group in a grouping varible) appears <em>only within</em> a particular level of another grouping variable.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | school) + (1 | class:school)</code></p>
<p>or, more succinctly:</p>
<p><code>(1 | school/class)</code></p>
<p>Consider another example, where we administer the same set of tasks at multiple time-points for every participant.</p>
<p><strong>Question:</strong> Are tasks nested within participants?</p>
<p>No.<br>
Tasks are seen by multiple participants (and participants see multiple tasks).</p>
<p>We could visualise this as the below:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/structure_crossed.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
</div>
</div>
<p>In the sense that these are not nested, they are <strong>crossed</strong> random effects.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | subject) + (1 | task)</code></p>
<div class="blue">
<p><strong>Nested vs Crossed</strong></p>
<p><em>Nested:</em> Each group belongs uniquely to a higher-level group.</p>
<p><em>Crossed:</em> Not-nested.</p>
</div>
<p>Note that in the schools and classes example, had we changed data such that the classes had unique IDs (e.g., see below), then the structures <code>(1 | school) + (1 | class)</code> and <code>(1 | school/class)</code> would give the same results.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/structure_nested.png" class="img-fluid figure-img" width="1200"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
</section>
<section id="mlm-in-a-nutshell" class="level1">
<h1>MLM in a nutshell</h1>
<div class="statbox">
<p><strong>Model Structure &amp; Notation</strong></p>
<p>MLM allows us to model effects in the linear model as <em>varying</em> between groups. Our coefficients we remember from simple linear models (the <span class="math inline">\(\beta\)</span>’s) are modelled as a distribution that has an overall mean around which our groups vary. We can see this in <a href="#fig-unlmm">Figure&nbsp;1</a>, where both the intercept and the slope of the line are modelled as varying by-groups. <a href="#fig-unlmm">Figure&nbsp;1</a> shows the overall line in blue, with a given group’s line in green.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-unlmm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/un_lmm.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 1: Multilevel Model. Each group (e.g.&nbsp;the group in the green line) deviates from the overall fixed effects (the blue line), and the individual observations (green points) deviate from their groups line</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The formula notation for these models involves separating out our effects <span class="math inline">\(\beta\)</span> into two parts: the overall effect <span class="math inline">\(\gamma\)</span> + the group deviations <span class="math inline">\(\zeta_i\)</span>:</p>
<p><span class="math display">\[
\begin{align}
&amp; \text{for observation }j\text{ in group }i \\
\quad \\
&amp; \text{Level 1:} \\
&amp; \color{red}{y_{ij}}\color{black} = \color{blue}{\beta_{0i} \cdot 1 + \beta_{1i} \cdot x_{ij}}\color{black} + \varepsilon_{ij} \\
&amp; \text{Level 2:} \\
&amp; \color{blue}{\beta_{0i}}\color{black} = \gamma_{00} + \color{orange}{\zeta_{0i}} \\
&amp; \color{blue}{\beta_{1i}}\color{black} = \gamma_{10} + \color{orange}{\zeta_{1i}} \\
\quad \\
&amp; \text{Where:} \\
&amp; \gamma_{00}\text{ is the population intercept, and }\color{orange}{\zeta_{0i}}\color{black}\text{ is the deviation of group }i\text{ from }\gamma_{00} \\
&amp; \gamma_{10}\text{ is the population slope, and }\color{orange}{\zeta_{1i}}\color{black}\text{ is the deviation of group }i\text{ from }\gamma_{10} \\
\end{align}
\]</span></p>
<p>The group-specific deviations <span class="math inline">\(\zeta_{0i}\)</span> from the overall intercept are assumed to be normally distributed with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma_0^2\)</span>. Similarly, the deviations <span class="math inline">\(\zeta_{1i}\)</span> of the slope for group <span class="math inline">\(i\)</span> from the overall slope are assumed to come from a normal distribution with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma_1^2\)</span>. The correlation between random intercepts and slopes is <span class="math inline">\(\rho = \text{Cor}(\zeta_{0i}, \zeta_{1i}) = \frac{\sigma_{01}}{\sigma_0 \sigma_1}\)</span>:</p>
<p><span class="math display">\[
\begin{bmatrix} \zeta_{0i} \\ \zeta_{1i} \end{bmatrix}
\sim N
\left(
    \begin{bmatrix} 0 \\ 0 \end{bmatrix},
    \begin{bmatrix}
        \sigma_0^2 &amp; \rho \sigma_0 \sigma_1 \\
        \rho \sigma_0 \sigma_1 &amp; \sigma_1^2
    \end{bmatrix}
\right)
\]</span></p>
<p>The random errors, independently from the random effects, are assumed to be normally distributed with a mean of zero</p>
<p><span class="math display">\[
\epsilon_{ij} \sim N(0, \sigma_\epsilon^2)
\]</span></p>
</div>
<div class="rtip">
<p><strong>MLM in R</strong></p>
<p>We can fit these models using the R package <strong>lme4</strong>, and the function <code>lmer()</code>. Think of it like building your linear model <code>lm(y ~ 1 + x)</code>, and then allowing effects (i.e.&nbsp;things on the right hand side of the <code>~</code> symbol) to vary by the grouping of your data. We specify these by adding <code>(vary these effects | by these groups)</code> to the model:</p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lmer</span>(y <span class="sc">~</span> x <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> x <span class="sc">|</span> group), <span class="at">data =</span> df)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: y ~ x + (1 + x | group)
   Data: df

REML criterion at convergence: 637.9

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-2.49449 -0.57223 -0.01353  0.62544  2.39122 

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 group    (Intercept) 2.2616   1.5038       
          x           0.7958   0.8921   0.55
 Residual             4.3672   2.0898       
Number of obs: 132, groups:  group, 20

Fixed effects:
            Estimate Std. Error t value
(Intercept)   1.7261     0.9673   1.785
x             1.1506     0.2968   3.877

Correlation of Fixed Effects:
  (Intr)
x -0.552</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">

</div>
<p>The summary of the <code>lmer</code> output returns estimated values for</p>
<p>Fixed effects:</p>
<ul>
<li><span class="math inline">\(\widehat \gamma_{00} = 1.726\)</span></li>
<li><span class="math inline">\(\widehat \gamma_{10} = 1.151\)</span></li>
</ul>
<p>Variability of random effects:</p>
<ul>
<li><span class="math inline">\(\widehat \sigma_{0} = 1.504\)</span></li>
<li><span class="math inline">\(\widehat \sigma_{1} = 0.892\)</span></li>
</ul>
<p>Correlation of random effects:</p>
<ul>
<li><span class="math inline">\(\widehat \rho = 0.546\)</span></li>
</ul>
<p>Residuals:</p>
<ul>
<li><span class="math inline">\(\widehat \sigma_\epsilon = 2.09\)</span></li>
</ul>
</div>
</section>
<section id="flashcards-getting-p-valuescis-for-multilevel-models" class="level1">
<h1>Flashcards: Getting p-values/CIs for Multilevel Models</h1>
<div class="frame">
<p>Inference for multilevel models is tricky, and there are lots of different approaches.<br>
You might find it helpful to think of the majority of these techniques as either:</p>
<p>A. Fitting a full model and a reduced model. These differ only with respect to the relevant effect. Comparing the overall fit of these models by some metric allows us to isolate the improvement due to our effect of interest. B. Fitting the full model and - using some method of approximating the degrees of freedom for the tests of whether a coefficient is zero. - constructing some confidence intervals (e.g.&nbsp;via bootstrapping) in order to gain a range of plausible values for the estimate (typically we then ask whether zero is within the interval)</p>
<p>Neither of these is <em>correct</em> or <em>incorrect</em>, but they each have different advantages. In brief:</p>
<ul>
<li>Satterthwaite <span class="math inline">\(df\)</span> = Very easy to implement, can fit with REML</li>
<li>Kenward-Rogers <span class="math inline">\(df\)</span> = Good when working with small samples, can fit with REML</li>
<li>Likelihood Ratio Tests = better with bigger samples (of groups, and of observations within groups), requires <code>REML = FALSE</code></li>
<li>Parametric Bootstrap = takes time to run, but in general a reliable approach. , requires <code>REML = FALSE</code> if doing comparisons, but not for confidence intervals</li>
<li>Non-Parametric Bootstrap = takes time, needs careful thought about which levels to resample, but means we can relax distributional assumptions (e.g.&nbsp;about normality of residuals).</li>
</ul>
<p>For the examples below, we’re investigating how “hours per week studied” influences a child’s reading age. We have data from 132 children from 20 schools, and we have fitted the model:</p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread)</span></code></pre></div>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-14" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-14', 'opt-start-14')"> <span class="olab">Use a normal approximation (not advisable)</span></span>
</div>
<div id="opt-body-14" class="optional-body" style="display: none;">
<p>Remember that the <span class="math inline">\(t\)</span> distribution starts to look more and more like the <span class="math inline">\(z\)</span> (“normal”) distribution when degrees of freedom increase? We could just assume we have infinite degrees of freedom in our test statistics, and pretend that the <span class="math inline">\(t\)</span>-values we get are actually <span class="math inline">\(z\)</span>-values. This is “anti-conservative” inasmuch as it is not a very cautious approach, and we are likely to have a higher false positive rate (e.g.&nbsp;more chance of saying “there <strong>is</strong> an effect!” when there actually isn’t.)</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">summary</span>(full_model)<span class="sc">$</span>coefficients)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>coefs<span class="sc">$</span>p.z <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fu">abs</span>(coefs[,<span class="dv">3</span>])))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>coefs</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error  t value          p.z
(Intercept) 1.726120  0.9672824 1.784504 0.0743417714
hrs_week    1.150637  0.2968219 3.876525 0.0001059589</code></pre>
</div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-15" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-15', 'opt-start-15')"> <span class="olab">Satterthwaite df approximation</span></span>
</div>
<div id="opt-body-15" class="optional-body" style="display: none;">
<p>There have been a couple of methods proposed to estimate the degrees of freedom in order to provide a better approximation to the null distribution of our tests. The way the Satterthwaite method has been implemented in R will just add a column for p-values to your <code>summary(model)</code> output).</p>
<p>Load the <strong>lmerTest</strong> package, refit the model, and voila!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmerTest)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_model)<span class="sc">$</span>coefficients</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error       df  t value    Pr(&gt;|t|)
(Intercept) 1.726120  0.9672824 16.23589 1.784504 0.093038229
hrs_week    1.150637  0.2968219 17.50762 3.876525 0.001155763</code></pre>
</div>
</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>To account for the extra uncertainty brought by the inclusion of random effects in the model, the degrees of freedom in the coefficients tests have been corrected via Satterthwaite’s method.<br>
…<br>
…<br>
Weekly hours of reading practice was associated increased reading age (<span class="math inline">\(\beta = 1.15,\ SE = 0.30,\ t(17.51^*) = 3.88,\ p = .001\)</span>).</p>
</div>
<p><strong>Note:</strong> if you have the <strong>lmerTest</strong> package loaded, then all the models you fit with <code>lmer()</code> will show p-values! If you want to stop this, then you will have to detach/unload the package, and refit the model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(<span class="st">"package:lmerTest"</span>, <span class="at">unload=</span><span class="cn">TRUE</span>)</span></code></pre></div>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-16" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-16', 'opt-start-16')"> <span class="olab">Kenward Rogers df approximations</span></span>
</div>
<div id="opt-body-16" class="optional-body" style="display: none;">
<p>The Kenward-Rogers approach is slightly more conservative than the Satterthwaite method, and has been implemented for model comparison between a full model and a restricted model (a model without the parameter of interest), using the KR adjustment for the denominator degrees of freedom in the <span class="math inline">\(F\)</span>-test.<br>
For this, models must be fitted with REML, <strong>not</strong> ML. The function <code>KRmodcomp()</code> will take care of this and re-fit them for you.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pbkrtest)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>restricted_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">KRmodcomp</span>(full_model, restricted_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>large : reading_age ~ 1 + hrs_week + (1 + hrs_week | school)
small : reading_age ~ 1 + (1 + hrs_week | school)
        stat    ndf    ddf F.scaling p.value   
Ftest 14.710  1.000 17.741         1 0.00124 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>To account for the extra uncertainty brought by the inclusion of random effects in the model, the denominator degrees of freedom in have been corrected via Kenward-Rogers’ method.<br>
…<br>
…<br>
Inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(F(1,17.74^*) = 14.71,\ p = .001\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-17" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-17', 'opt-start-17')"> <span class="olab">Likelihood Ratio Test (LRT)</span></span>
</div>
<div id="opt-body-17" class="optional-body" style="display: none;">
<p>Conduct a model comparison between your model and a restricted model (a model without the parameter of interest), evaluating the change in log-likelihood.</p>
<div class="sticky">
<p><strong>Likelihood</strong></p>
<p>“likelihood” is a function that associates to a parameter the probability (or probability density) of observing the given sample data.<br>
In simpler terms, the likelihood is the probability of the model given that we have this data.</p>
<p>The intuition behind likelihood:</p>
<ol type="1">
<li>I toss a coin 10 time and observed 8 Heads.<br>
</li>
<li>We can think of a ‘model’ of the process that governs the coin’s behaviour in terms of just one number: a parameter that indicates the probability of the coin landing on heads.<br>
I have two models:</li>
</ol>
<ul>
<li>Model 1: The coin will land on heads 20% of the time. <span class="math inline">\(P(Heads)=0.2\)</span><br>
</li>
<li>Model 2: The coin will land on heads 70% of the time. <span class="math inline">\(P(Heads)=0.7\)</span><br>
</li>
</ul>
<ol start="3" type="1">
<li>Given the data I observe (see 1, above), we can (hopefully) intuit that Model 2 is more likely than Model 1.</li>
</ol>
<p>For a (slightly) more detailed explanation, see <a href="lvp.html">here</a>.</p>
</div>
<p>This method assumes that the ratio of two likelihoods will (as sample size increases) become closer to being <span class="math inline">\(\chi^2\)</span> distributed, and so may be unreliable for small samples.</p>
<p>Models must be fitted with ML, <strong>not</strong> REML. The function <code>anova()</code> will re-fit them for you.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>restricted_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">FALSE</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">FALSE</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(restricted_model, full_model, <span class="at">test =</span> <span class="st">"Chisq"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: childread
Models:
restricted_model: reading_age ~ 1 + (1 + hrs_week | school)
full_model: reading_age ~ 1 + hrs_week + (1 + hrs_week | school)
                 npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
restricted_model    5 660.52 674.93 -325.26   650.52                         
full_model          6 650.66 667.96 -319.33   638.66 11.857  1  0.0005744 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>A likelihood ratio test indicated that the inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(\chi^2(1) = 11.86, p &lt; .001\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-18" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-18', 'opt-start-18')"> <span class="olab">Parametric Bootstrap LRT</span></span>
</div>
<div id="opt-body-18" class="optional-body" style="display: none;">
<p>There are also various “bootstrapping” methods which it is worth looking into. Think back to USMR when we first learned about hypothesis testing. Remember that we did lots of simulating data, so that we can compare what we actually observe with what we would expect if the null hypothesis were true? By doing this, we were essentially <em>creating</em> a null distribution, so that our calculating a p-value can become an issue of summarising data (e.g.&nbsp;calculate the proportion of our simulated null distribution that is more extreme than our observed statistic)</p>
<p>Instead of assuming that the likelihood ratio test statistics are <span class="math inline">\(\chi^2\)</span>-distributed, we can bootstrap this test instead. This approach simulates data from the simpler model, fits both the simple model and the complex model and evaluates the change in log-likelihood. By doing this over and over again, we build a distribution of what changes in log-likelihood we would be likely to see if the more complex model is not any better. In this way it actually constructs a distribution reflecting our null hypothesis, against which we can then compare our actual observed effect</p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pbkrtest)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>restricted_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">FALSE</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">FALSE</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="fu">PBmodcomp</span>(full_model, restricted_model, <span class="at">nsim=</span><span class="dv">1000</span>)</span></code></pre></div>
</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>A parametric bootstrap likelihood ratio test (R = 1000) indicated that the inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(LRT = 11.84, p = .002\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-19" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-19', 'opt-start-19')"> <span class="olab">Parametric Bootstrap Confidence Intervals</span></span>
</div>
<div id="opt-body-19" class="optional-body" style="display: none;">
<p>Much the same as above, but with just one model we simulate data many times and refit the model, so that we get an empirical distribution that we can use to construct confidence intervals for our effects.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(full_model, <span class="at">method=</span><span class="st">"boot"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 2.5 %   97.5 %
.sig01       0.0000000 3.913368
.sig02      -0.5647829 1.000000
.sig03       0.3927015 1.376779
.sigma       1.7921405 2.349858
(Intercept) -0.1214629 3.370657
hrs_week     0.5567827 1.752359</code></pre>
</div>
</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>95% Confidence Intervals were obtained via parametric bootstrapping with 1000 iterations.<br>
…<br>
…<br>
Weekly hours of reading practice was associated increased reading age (<span class="math inline">\(\beta = 1.15,\ 95%\ CI\ [0.63 -- 1.73]\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-20" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-20', 'opt-start-20')"> <span class="olab">Non-Parametric Bootstrap Confidence Intervals</span></span>
</div>
<div id="opt-body-20" class="optional-body" style="display: none;">
<p>It’s worth noting that there are many different types of bootstrapping that we can conduct. Different methods of bootstrapping vary with respect to the assumptions we will have to make when using them for drawing inferences. For instance, the parametric bootstrap discussed above assumes that explanatory variables are fixed and that model specification and the distributions such as <span class="math inline">\(\zeta_i \sim N(0,\sigma_{\zeta})\)</span> and <span class="math inline">\(\varepsilon_i \sim N(0,\sigma_{\varepsilon})\)</span> are correct.<br>
An alternative is to generate a distribution by <strong>resampling with replacement</strong> from our data, fitting our model to the resample, and then repeating this over and over. This doesn’t have to rely on assumptions about the shape of the distributions of <span class="math inline">\(\zeta_i\)</span> and <span class="math inline">\(\varepsilon_i\)</span> - we just need to ensure that we correctly specify the hierarchical dependency of data. It does, however, require the decision of at which levels to resample.</p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lmer</span>(reading_age <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> hrs_week <span class="sc">|</span> school), </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> childread, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmeresampler)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>fullmod_bs <span class="ot">&lt;-</span> </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bootstrap</span>(full_model, <span class="co"># this is the model</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">.f =</span> fixef, <span class="co"># we want the fixef from each bootstrap</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">type =</span> <span class="st">"case"</span>, <span class="co"># case based bootstrap</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">B=</span><span class="dv">2000</span>, <span class="co"># do 2000 bootstraps</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">resample =</span> <span class="fu">c</span>(<span class="cn">TRUE</span>, <span class="cn">TRUE</span>) <span class="co"># resample both schools and individual children</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(fullmod_bs, <span class="at">type =</span> <span class="st">"perc"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
  term        estimate  lower upper type  level
  &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
1 (Intercept)     1.73 -1.44   3.57 perc   0.95
2 hrs_week        1.15  0.681  2.02 perc   0.95</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">

</div>
<div class="int">
<p><strong>Reporting</strong></p>
<p>95% Confidence Intervals were obtained via case-based bootstrapping (resampling both toy types and individual toys) with 2000 iterations.<br>
…<br>
…<br>
Weekly hours of reading practice was associated increased reading age (<span class="math inline">\(\beta\)</span> = 1.1506375, 95% CI [0.6811553 – 2.0204023]).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>