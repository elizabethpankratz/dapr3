[
  {
    "objectID": "01_regressionrefresh.html",
    "href": "01_regressionrefresh.html",
    "title": "Regression Refresh and Clustered Data",
    "section": "",
    "text": "New Packages!\n\nThese are the main packages we’re going to use in this block. It might make sense to install them now if you do not have them already.\n\n\ntidyverse : for organising data\n\nICC : for quickly calculating intraclass correlation coefficient\nlme4 : for fitting generalised linear mixed effects models\nlmeresampler : for bootstrapping!\neffects : for tabulating and graphing effects in linear models\nbroom.mixed : tidying methods for mixed models\nsjPlot : for plotting models\nHLMdiag : for examining case diagnostics at multiple levels\n\n\ninstall.packages(c(\"tidyverse\",\"ICC\",\"lme4\",\"effects\",\"broom.mixed\",\"sjPlot\",\"HLMdiag\"))\n# the lmeresampler package has had some recent updates. better to install the most recent version:\ninstall.packages(\"devtools\")\ndevtools::install_github(\"aloy/lmeresampler\")\n\n\n\n\nLinear Model Refresh\n\nData: Wellbeing in Scotland\nIn DAPR2, one of the examples we used in learning about linear regression was in examining the relationship between time spent outdoors and mental wellbeing. In that example researchers had collected data from 32 residents of Edinburgh & Lothians.\nResearchers want to study this relationship across all of Scotland. They contact all the Local Authority Areas (LAAs) and ask them to collect data for them for them, with participants completing the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being, and being asked to estimate the average number of hours they spend outdoors each week.\nTwenty of the Local Authority Areas provided data. It is available at https://uoepsy.github.io/data/LAAwellbeing.csv, and you can read it into your R environment using the code below:\n\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\")\n\nThe dataset contains information on 132 participants. You can see the variables in the table below\n\n\n\n\n\n\n  \n  \n    \n      variable\n      description\n    \n  \n  \n    laa\nLocal Authority Area\n    ppt\nParticipant\n    outdoor_time\nSelf report estimated number of hours per week spent outdoors\n    wellbeing\nWarwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\n  \n  \n  \n\n\n\n\n\n\nQuestion A1\n\n\nRead in the Local Authority data from https://uoepsy.github.io/data/LAAwellbeing.csv and plot the bivariate relationship between wellbeing and time spent outdoors.\n\n\n\n\n Solution \n\n\n\nscotmw <- read_csv(\"https://uoepsy.github.io/data/LAAwellbeing.csv\") \n\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Refresh\nRecall that in the DAPR2 course last year we learned all about the linear regression model, which took the form:\n\\[\n\\begin{align}\\\\\n& \\text{for observation }i \\\\\n& \\color{red}{Y_i}\\color{black} = \\color{blue}{\\beta_0 \\cdot{} 1 + \\beta_1 \\cdot{} X_{1i} \\ + \\ ... \\ + \\ \\beta_p \\cdot{} X_{pi}}\\color{black} + \\varepsilon_i \\\\\n\\end{align}\n\\]\nAnd if we wanted to write this more simply, we can express \\(X_1\\) to \\(X_p\\) as an \\(n \\times p\\) matrix (samplesize \\(\\times\\) parameters), and \\(\\beta_0\\) to \\(\\beta_p\\) as a vector of coefficients:\n\\[\n\\begin{align}\n& \\color{red}{\\mathbf{y}}\\color{black} = \\color{blue}{\\boldsymbol{X\\beta}}\\color{black} + \\boldsymbol{\\varepsilon} \\\\\n& \\quad \\\\\n& \\text{where} \\\\\n& \\varepsilon \\sim N(0, \\sigma) \\text{ independently} \\\\\n\\end{align}\n\\]\nIn R, we fitted these models using:\n\nlm(y ~ x1 + x2 + .... xp, data = mydata)  \n\n\n\nQuestion A2\n\n\nUsing lm(), fit the simple linear model:\n\\[\n\\text{Wellbeing}_i = \\beta_0 + \\beta_1 \\cdot \\text{Hours per week spent outdoors}_i + \\varepsilon_i\n\\]\nThink about the assumptions we make about this model:\n\\[\n\\text{where} \\quad \\varepsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nHave we satisfied this assumption (specifically, the assumption of independence of errors)?\n\n\n\n\n Solution \n\n\n\nsimplemod <- lm(wellbeing ~ outdoor_time, data = scotmw)\nsummary(simplemod)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time, data = scotmw)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-28.7089  -7.3501   0.0758   6.6307  25.4873 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   39.6086     2.6414  14.995   <2e-16 ***\noutdoor_time   0.1962     0.1449   1.354    0.178    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.51 on 130 degrees of freedom\nMultiple R-squared:  0.0139,    Adjusted R-squared:  0.006313 \nF-statistic: 1.832 on 1 and 130 DF,  p-value: 0.1782\n\n\nOur model from the previous question will assume that the residuals for all participants are independent of one another. But is this a reasonable assumption that we can make? Might we not think that the residents of the highlands might have generally higher levels of wellbeing than those living in Glasgow? Additionally, the association between outdoor time and wellbeing might be different depending on where you live?\nThe natural grouping of the people into their respective geographic area introduces a level of dependence which we would be best to account for.\n\n\n\n\nQuestion A3\n\n\nTry running the code below.\n\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n\nThen try editing the code to include an aesthetic mapping from the LAA to the color in the plot.\nHow do your thoughts about the relationship between outdoor time and wellbeing change?\n\n\n\n\n Solution \n\n\n\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n\n\n\n\n\n\n\n\n\nggplot(data = scotmw, aes(x = outdoor_time, y = wellbeing, col = laa))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE)\n\n\n\n\n\n\n\n\nFrom the second plot, we see a lot of the LAA appear to have a positive relationship (outdoor time is associated with higher wellbeing). There seem to be differences between LAAs in both the general wellbeing level (residents of Na h-Eileanan Siar - the outer hebrides - have high wellbeing), and in how outdoor time is associated with wellbeing (for instance, outdoor time doesn’t seem to help in Glasgow City).\n\n\n\n\n\nComplete pooling, No pooling\n\nComplete Pooling\nWe can consider the simple regression model (lm(wellbeing ~ outdoor_time, data = scotmw)) to “pool” the information from all observations together. In this ‘Complete Pooling’ approach, we simply ignore the natural clustering of the people into their local authority areas, as if we were unaware of it. The problem is that this assumes the same regression line for all local authority areas, which might not be that appropriate. Additionally, we violate the assumption that our residuals are independent, because all of the residuals from certain groups will be more like one another than they are to the others.\n\n\n\n\n\nComplete pooling can lead to bad fit for certain groups\n\n\n\n\n\n\nNo Pooling\nThere are various ways we could attempt to deal with the problem that our data are in groups (or “clusters”). With the tools you have learned in DAPR2, you may be tempted to try including LAA in the model as another predictor, to allow for some local authority areas being generally better than others:\n\nlm(wellbeing ~ outdoor_time + laa, data = scotmw)\n\nOr even to include an interaction to allow for local authority areas to show different patterns of association between outdoor time and wellbeing:\n\nlm(wellbeing ~ outdoor_time * laa, data = scotmw)\n\nThis approach gets termed the “No Pooling” method, because the information from each cluster contributes only to an estimated parameter for that cluster, and there is no pooling of information across clusters. This is a good start, but it means that a) we are estimating a lot of parameters, and b) we are not necessarily estimating the parameter of interest (the overall effect of practice on reading age). Furthermore, we’ll probably end up having high variance in the estimates at each group.\n\n\nQuestion A4\n\n\nFit a linear model which accounts for the grouping of participants into their different local authorities, but holds the association between outdoor time and wellbeing as constant across LAAs:\n\nmod1 <- lm(wellbeing ~ outdoor_time + laa, data = scotmw)\n\nCan you construct a plot of the fitted values from this model, coloured by LAA?\n(Hint: you might want to use the augment() function from the broom package)\n\n\n\n\n Solution \n\n\n\nlibrary(broom)\naugment(mod1) %>%\n  ggplot(.,aes(x=outdoor_time, y=.fitted, col=laa))+\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion A5\n\n\nWhat happens (to the plot, and to your parameter estimates) when you include the interaction between laa and outdoor_time?\n\n\n\n\n Solution \n\n\n\nmod2 <- lm(wellbeing ~ outdoor_time * laa, data = scotmw)\n\nbroom::augment(mod2) %>%\n  ggplot(.,aes(x=outdoor_time, y=.fitted, col=laa))+\n  geom_line()\n\n\n\n\n\n\n\n\nWe can see now that our model is fitting a different relationship between wellbeing and outdoor time for each LAA. This is good - we’re going to get better estimates for different LAAs (e.g. wellbeing of residents of the Highlands increases with more outdoor time, and wellbeing of residents of Glasgow does not).\nWe can see that this model provides a better fit - it results in a significant reduction in the residual sums of squares:\n\nanova(mod1, mod2)\n\nAnalysis of Variance Table\n\nModel 1: wellbeing ~ outdoor_time + laa\nModel 2: wellbeing ~ outdoor_time * laa\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1    111 2726.2                              \n2     92 1973.8 19    752.36 1.8456 0.02866 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBut accounting for this heterogeneity over clusters in the effect of interest comes at the expense of not pooling information across groups to get one estimate for “the association between outdoor time and wellbeing”. Additionally, these models will tend to have low statistical power because they are using fewer observations (only those within each cluster) to estimate parameters which only represent within-cluster effects.\n\n\n\n\n\nSome Data Wrangling\nWith more complex data structures comes more in-depth data wrangling in order to get it ready for fitting and estimating our model. Typically, the data we get will not be neat and tidy, and will come in different formats. Often we simply get whatever our experiment/questionnaire software spits out, and we have to work from there. When you are designing a study, you can do work on the front end to minimise the data-wrangling. Try to design an experiment/questionnaire while keeping in mind what the data comes out looking like.\nBelow we have some data from a fake experiment. We’ve tried to make it a bit more difficult to work with - a bit more similar to what we would actually get when doing real-life research.\n\nData: Raising the stakes\nOur study is investigating how levels of stress are influenced by size and type of potential rewards.\n30 volunteers from an amateur basketball league participated. Each participant completed 20 trials in which they were tasked with throwing a basketball and scoring a goal in order to score points. The number of points up for grabs varied between trials, ranging from 1 to 20 points, with the order randomised for each participant. If a participant successfully threw the ball in the basket, then their score increased accordingly. If they missed, their score decreased accordingly. Participants were informed of the number of points available prior to each throw.\nTo examine the influence of the type of reward/loss on stress-levels, the study consisted of two conditions. In the monetary condition, (n = 15) participants were informed at the start of the study that they would receive their final score in £ at the end of the study. In the reputation condition, (n = 15) participants were informed that the points would be inputted on to a scoreboard and distributed around the local basketball clubs and in the league newsletter.\nThroughout each trial, participants’ heart rate variability (HRV) was measured via a chest strap. HRV is considered to be indirectly related to levels of stress (i.e., higher HRV = less stress).\nThe data is in stored in two separate files.\n\nInformation on the conditions for each trial for each participant is stored in .csv format at https://uoepsy.github.io/data/basketballconditions.csv.\n\n\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nstakes\nNumber of points available to be won/lost based on successful completion of trial\n\n\ncondition\nWhether the final score will be converted to £ or will be placed on a public leader-board\n\n\nsub\nParticipant Identifier\n\n\nthrow\nWhether the participant successfully threw the ball in the basket\n\n\ntrial_no\nTrial number (1 to 20\n\n\n\n\n\n\nInformation on participants’ HRV for each trial is stored in .xlsx format, and can be downloaded from https://uoepsy.github.io/data/basketballhrv.xlsx.\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nsub\nSubject Identifier\n\n\ntrial_1\nHRV average during trial 1\n\n\ntrial_2\nHRV average during trial 2\n\n\ntrial_3\nHRV average during trial 3\n\n\n…\nHRV average during trial …\n\n\n\n\n\n\n\nQuestion B1\n\n\nGet the data into your R session.\nNote: For one of the files, this is a bit different to how we have given you data in previous exercises. You may remember that for a .csv file, you can read directly into R from the link using, read_csv(\"https://uoepsy.......).\nHowever, in reality you are likely to be confronted with data in all sorts of weird formats, such as .xlsx files from MS Excel. Have a look around the internet to try and find any packages/functions/techniques for getting both the datasets in to R.\n\n\n\n\n Solution \n\n\n\nUnfortunately, a few students are getting error messages which we could not solve when trying to read in the .xlsx data. The same data is available at https://uoepsy.github.io/data/bballhrv.csv so that you can read it in in the normal way.\n\n\nbball <- read_csv(\"https://uoepsy.github.io/data/basketballconditions.csv\")\nhead(bball)\n\n# A tibble: 6 × 5\n  stakes condition   sub throw trial_no\n   <dbl> <chr>     <dbl> <dbl> <chr>   \n1     13 money         1     1 trial_1 \n2     17 money         1     1 trial_2 \n3      7 money         1     1 trial_3 \n4      1 money         1     1 trial_4 \n5      2 money         1     1 trial_5 \n6      8 money         1     1 trial_6 \n\n\nFor the .xlsx data:\n\nStep 1: download the data to your computer\n\nStep 2: load the readxl package.\n\nStep 3: use the read_xlsx() function to read in the data, pointing it to the relevant place on your computer.\n\nYou can actually do all these steps from within R.\n\n# Step 1\ndownload.file(url = \"https://uoepsy.github.io/data/basketballhrv.xlsx\", \n              destfile = \"baskeballhrvdata.xlsx\")\n# Step 2\nlibrary(readxl)\n# Step 3\nbballhrv <- read_xlsx(\"baskeballhrvdata.xlsx\")\nhead(bballhrv)\n\n# A tibble: 6 × 21\n    sub trial_1 trial_2 trial_3 trial_4 trial_5 trial_6 trial_7 trial_8 trial_9\n  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    5.47    6.69    2.72    4.95    5.96    4.93    4.62    4.70    5.78\n2     2    4.60    6.46    3.77    4.80    6.33    5.15    5.04    5.70    4.66\n3     3    5.14    5.98    4.30    4.40    4.97    5.16    4.71    4.60    5.94\n4     4    5.85    3.74    3.40    4.97    6.46    3.87    5.14    6.26    3.60\n5     5    7.46    5.83    4.83    6.26    3.52    5.92    4.24    4.39    5.75\n6     6    3.53    2.89    2.07    2.20    3.92    4.45    3.19    5.20    3.81\n# … with 11 more variables: trial_10 <dbl>, trial_11 <dbl>, trial_12 <dbl>,\n#   trial_13 <dbl>, trial_14 <dbl>, trial_15 <dbl>, trial_16 <dbl>,\n#   trial_17 <dbl>, trial_18 <dbl>, trial_19 <dbl>, trial_20 <dbl>\n\n\n\n\n\n\nQuestion B2\n\n\nIs each dataset in wide or long format? We want them both in long format, so try to reshape either/both if necessary.\nHint - in the tidyverse functions, you can specify all columns between column x and column z by using the colon, x:z.\n\n\n\n\n Solution \n\n\nOnly the HRV data is in wide format:\n\nhead(bballhrv)\n\n# A tibble: 6 × 21\n    sub trial_1 trial_2 trial_3 trial_4 trial_5 trial_6 trial_7 trial_8 trial_9\n  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    5.47    6.69    2.72    4.95    5.96    4.93    4.62    4.70    5.78\n2     2    4.60    6.46    3.77    4.80    6.33    5.15    5.04    5.70    4.66\n3     3    5.14    5.98    4.30    4.40    4.97    5.16    4.71    4.60    5.94\n4     4    5.85    3.74    3.40    4.97    6.46    3.87    5.14    6.26    3.60\n5     5    7.46    5.83    4.83    6.26    3.52    5.92    4.24    4.39    5.75\n6     6    3.53    2.89    2.07    2.20    3.92    4.45    3.19    5.20    3.81\n# … with 11 more variables: trial_10 <dbl>, trial_11 <dbl>, trial_12 <dbl>,\n#   trial_13 <dbl>, trial_14 <dbl>, trial_15 <dbl>, trial_16 <dbl>,\n#   trial_17 <dbl>, trial_18 <dbl>, trial_19 <dbl>, trial_20 <dbl>\n\n\n\nbballhrv <-\n  bballhrv %>%\n  pivot_longer(trial_1:trial_20, names_to = \"trial_no\", values_to = \"hrv\")\n\nhead(bballhrv)\n\n# A tibble: 6 × 3\n    sub trial_no   hrv\n  <dbl> <chr>    <dbl>\n1     1 trial_1   5.47\n2     1 trial_2   6.69\n3     1 trial_3   2.72\n4     1 trial_4   4.95\n5     1 trial_5   5.96\n6     1 trial_6   4.93\n\n\n\n\n\n\nPivot!\nOne of the more confusing things to get to grips with is the idea of reshaping a dataframe.\nFor different reasons, you might sometimes want to have data in wide, or in long format.\n\n\n\n\n\nSource: https://fromthebottomoftheheap.net/2019/10/25/pivoting-tidily/\n\n\n\n\nWhen the data is wide, we can make it long using pivot_longer(). When we make data longer, we’re essentially making lots of columns into 2 longer columns. Above, in the animation, the wide variable x, y and z go into a new longer column called name that specifies which (x/y/z) it came from, and the values get put into the val column.\nThe animation takes a shortcut in the code it displays above, but you could also use pivot_longer(c(x,y,z), names_to = \"name\", values_to = \"val\"). To reverse this, and put it back to being wide, we tell R which columns to take the names and values from: pivot_wider(names_from = name, values_from = val).\n\nNow comes a fun bit. You may have noticed that we have two datasets for this study. If we are interested in relationships between the heart rate variability (HRV) of participants during each trial, as well as the experimental manipulations (i.e., the condition of each trial), these are currently in different datasets.\nSolution: we need to join them together!\nProvided that both data-sets contain information on participant number and trial number, which uniquely identify each observation, we can join them together matching on those variables!\n\nQuestion B3\n\n\nJoin the two datasets (both in long format) together.\nNote that the variables we are matching on need to have the information in the same format. For instance, R won’t be able to match \"trial_1\",\"trial_2\",\"trial_3\" with 1, 2, 3 because they are different things. We would need to edit one of them to be in the same format.\nHint: You should end up with 600 rows.\n\n\n\n\n Solution \n\n\n\nbball <- full_join(bball, bballhrv)\nhead(bball)\n\n# A tibble: 6 × 6\n  stakes condition   sub throw trial_no   hrv\n   <dbl> <chr>     <dbl> <dbl> <chr>    <dbl>\n1     13 money         1     1 trial_1   5.47\n2     17 money         1     1 trial_2   6.69\n3      7 money         1     1 trial_3   2.72\n4      1 money         1     1 trial_4   4.95\n5      2 money         1     1 trial_5   5.96\n6      8 money         1     1 trial_6   4.93\n\n\n\n\n\n\nJoining data\nThere are lots of different ways to join data-sets, depending on whether we want to keep rows from one data-set or the other, or keep only those in both data-sets etc.\n\n\n\n\n\nCheck out the help documentation for them all using ?full_join.\n\n\n\n\n\n\n\nExploring Clustering\n\nQuestion B4\n\n\nContinuing with our basketball/hrv study, consider the following questions:\nWhat are the units of observations?\nWhat are the groups/clusters?\nWhat varies within these clusters?\nWhat varies between these clusters?\n\n\n\n\n Solution \n\n\nWhat are the units of observations? trials\nWhat are the groups/clusters? participants What varies within these clusters? size of reward\nWhat varies between these clusters? type of reward\n\n\n\n\nQuestion B5\n\n\nNow that you have tidied and joined all the data together, plot the relationship between size of reward and HRV, ignoring the fact that there are repeated observations for each subject.\nCan you make a separate plot for each of the experimental conditions? (Hint: facet_wrap())\n\n\n\n\n Solution \n\n\n\nggplot(bball, aes(x=stakes,y=hrv))+geom_smooth(method=\"lm\", alpha=.2)+\n  geom_point() +\n  facet_wrap(~condition)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion B6\n\n\n\nHow are stress levels (measured via HRV) influenced by the size of potential reward/loss?\n\nIgnore the clustering, and fit a simple linear regression estimating how heart rate variability is influenced by how high the stakes are (i.e. how big the reward is) for a given throw.\n\n\n\n\n Solution \n\n\n\nsimple_mod <- lm(hrv ~ stakes, data = bball)\nsummary(simple_mod)\n\n\nCall:\nlm(formula = hrv ~ stakes, data = bball)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6396 -0.8275  0.0418  0.8787  4.0314 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.978570   0.114654  43.423   <2e-16 ***\nstakes      -0.022790   0.009571  -2.381   0.0176 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.352 on 598 degrees of freedom\nMultiple R-squared:  0.009392,  Adjusted R-squared:  0.007736 \nF-statistic:  5.67 on 1 and 598 DF,  p-value: 0.01757\n\n\n\n\n\n\nQuestion B7\n\n\nConsider the following research question:\n\nHow do size and type of reward/loss interact to influence levels of stress?\n\nExtend your model to include the interaction between stakes and experimental condition and examine the parameter values.\n\n\n\n\n Solution \n\n\n\nsimple_mod <- lm(hrv ~ condition*stakes, data = bball)\nanova(simple_mod)\n\nAnalysis of Variance Table\n\nResponse: hrv\n                  Df  Sum Sq Mean Sq F value    Pr(>F)    \ncondition          1   36.62  36.621 20.8484 6.042e-06 ***\nstakes             1   10.36  10.362  5.8989   0.01544 *  \ncondition:stakes   1    9.34   9.344  5.3194   0.02143 *  \nResiduals        596 1046.91   1.757                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(simple_mod)\n\n\nCall:\nlm(formula = hrv ~ condition * stakes, data = bball)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.4250 -0.8292  0.0231  0.8821  4.1205 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            4.998385   0.158965  31.443   <2e-16 ***\nconditionmoney        -0.039631   0.224810  -0.176   0.8601    \nstakes                -0.001148   0.013270  -0.087   0.9311    \nconditionmoney:stakes -0.043284   0.018767  -2.306   0.0214 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.325 on 596 degrees of freedom\nMultiple R-squared:  0.05106,   Adjusted R-squared:  0.04628 \nF-statistic: 10.69 on 3 and 596 DF,  p-value: 7.494e-07\n\n\n\nHeart Rate Variability (HRV) was found to be influenced by both the size of the potential reward/loss of a given trial, whether whether participants were playing for money or for a place on the scoreboard, and the interaction between the two. For a 1 point increase in stakes, HRV decreased by -0.04 (\\(SE=0.02,t(596)=-2.31,p=0.02\\))**** in the condition in which participants played for money relative to that in which participants played for kudos, suggesting that the size of the reward has a greater effect on stress levels when playing for money compared to playing for reputation.\n**** Caveat: Our model did not account for by-participant clustering of data, thereby violating the assumption that errors are iid (independent and identically distributed).\n\n\n\n\n\nQuestion B8\n\n\nLet’s start to examine the clustering a bit more.\nPlot the relationship between size of reward and HRV, with a separate line for each subject.\nHint: remember the group = aesthetic in ggplot!\n\n\n\n\n Solution \n\n\n\nggplot(bball, aes(x=stakes, y=hrv, group=sub, col=condition))+\n  geom_smooth(method=\"lm\",se=F, alpha=.2)+\n  geom_point()+NULL\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion B9\n\n\nCalculate the ICC, using the ICCbare() function from the ICC package.\nRemember, you can look up the help for a function by typing a ? followed by the function name in the console.\n\n\n\n\n Solution \n\n\n\nlibrary(ICC)\nICCbare(x = sub, y = hrv, data = bball)\n\n[1] 0.3141482\n\n\n\n\n\n\n Optional - Extra difficult. Calculate ICC manually\n\n\nWe have equal group sizes here (there are 2 \\(\\times\\) 15 participants, each with 20 observations), which makes calculating ICC by hand a lot easier, but it’s still a bit tricky.\nLet’s take a look at the formula for ICC\n\\[\n\\begin{align}\nICC \\; (\\rho) = & \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2_e} \\\\\n\\qquad \\\\\n= & \\frac{\\frac{MS_b - MS_e}{k}}{\\frac{MS_b - MS_e}{k} + MS_e} \\\\\n\\qquad \\\\\n= & \\frac{MS_b - MS_e}{MS_b + (k-1)MS_e} \\\\\n\\qquad \\\\\n\\qquad \\\\\n\\text{Where:} & \\\\\nk = & \\textrm{number of observations in each group} \\\\\nMS_b = & \\textrm{Mean Squares between groups} = \\frac{\\text{Sums Squares between groups}}{df_\\text{groups}}\n= \\frac{\\sum\\limits_{i=1}(\\bar{y}_i - \\bar{y})^2}{\\textrm{n groups}-1}\\\\\nMS_e = & \\textrm{Mean Squares within groups} \\frac{\\text{Sums Squares within groups}}{df_\\text{within groups}}\n= \\frac{\\sum\\limits_{i=1}\\sum\\limits_{j=1}(y_{ij} - \\bar{y_i})^2}{\\textrm{n obs}-\\textrm{n groups}}\\\\\n\\end{align}\n\\]\nSo we’re going to need to calculate the grand mean of \\(y\\), the group means of \\(y\\), and then the various squared differences between group means and grand mean, and between observations and their respective group means.\nThe code below will give us a new column which is the overall mean of y. This bit is fairly straightforward.\n\nbball %>% mutate(\n  grand_mean = mean(hrv)\n)\n\n\nWe have seen a lot of the combination of group_by() %>% summarise(), but we can also combine group_by() with mutate()!\n\nTry the following:\n\nbball %>% mutate(\n    grand_mean = mean(hrv)\n  ) %>% \n  group_by(sub) %>%\n  mutate(\n    group_mean = mean(hrv)\n  )\n\n\nThe grouping gets carried forward.\nUsing group_by() can quite easily land you in trouble if you forget that you have grouped the dataframe.\nLook at the output of class() when we have grouped the data. It still mentions something about the grouping.\n\nbball <- bball %>% mutate(\n    grand_mean = mean(hrv)\n  ) %>% \n  group_by(sub) %>%\n  mutate(\n    group_mean = mean(hrv)\n  )\n\nclass(bball)\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTo remove the grouping, we can use ungroup() (we could also just add this to the end of our code sequence above and re-run it):\n\nbball <- ungroup(bball)\nclass(bball)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nNow we need to create a column which is the squared differences between the observations \\(y_{ij}\\) and the group means \\(\\bar{y_i}\\).\nWe also want a column which is the squared differences between the group means \\(\\bar{y_i}\\) and the overall mean \\(\\bar{y}\\).\n\nbball <- bball %>% \n  mutate(\n    within = (hrv-group_mean)^2,\n    between = (group_mean-grand_mean)^2\n  )\n\nAnd then we want to sum them:\n\nssbetween = sum(bball$between)\nsswithin = sum(bball$within)\n\nFinally, we divide them by the degrees of freedom.\n\n# Mean Squares between\nmsb = ssbetween / (30-1)\n# Mean Squares within \nmse = sswithin / (600-30)\n\nAnd calculate the ICC!!!\n\n# ICC\n(msb-mse) /(msb + (19*mse))\n\n[1] 0.3141482\n\n\n\n\n\n\nUnderstanding ICC a bit better\nThink about what ICC represents - the ratio of the variance between the groups to the total variance.\nYou can think of the “variance between the groups” as the group means varying around the overall mean (the black dots around the black line), and the total variance as that plus the addition of the variance of the individual observations around each group mean (each set of coloured points around their respective larger black dot):\n\nggplot(bball, aes(x=sub, y=hrv))+\n  geom_point(aes(col=sub),alpha=.3)+\n  stat_summary(geom = \"pointrange\")+\n  geom_hline(yintercept = mean(bball$hrv))+\n  guides(col=FALSE)\n\n\n\n\n\n\n\n\nYou can also think of the ICC as the correlation between two randomly drawn observations from the same group. This is a bit of a tricky thing to get your head round if you try to relate it to the type of “correlation” that you are familiar with. Pearson’s correlation (e.g think about a typical scatterplot) operates on pairs of observations (a set of values on the x-axis and their corresponding values on the y-axis), whereas ICC operates on data which is structured in groups.\n\n Optional - ICC as the expected correlation between two observations from same group\n\n\nLet’s suppose we had only 2 observations in each group.\n\n\n  cluster observation   y\n1 group_1           1   4\n2 group_1           2   2\n3 group_2           1   4\n4 group_2           2   2\n5 group_3           1   7\n6 group_3           2   5\n7     ...         ... ...\n\n\nThe ICC for this data is 0.18:\nNow suppose we reshape our data so that we have one row per group, and one column for each observation to look like this:\n\n\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 4     2    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 3     8    \n6 group_6 6     7    \n7 ...     ...   ...  \n\n\nCalculating Pearson’s correlation on those two columns yields 0.2, which isn’t quite right. It’s close, but not quite..\n\nThe crucial thing here is that it is completely arbitrary which observations get called “obs1” and which get called “obs2”.\nThe data aren’t paired, but grouped.\n\nEssentially, there are lots of different combinations of “pairs” here. There are the ones we have shown above:\n\n\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 4     2    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 3     8    \n6 group_6 6     7    \n7 ...     ...   ...  \n\n\nBut we might have equally chosen these:\n\n\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 4     2    \n2 group_2 4     2    \n3 group_3 5     7    \n4 group_4 7     2    \n5 group_5 8     3    \n6 group_6 7     6    \n7 ...     ...   ...  \n\n\nor these:\n\n\n# A tibble: 7 × 3\n  cluster obs1  obs2 \n  <chr>   <chr> <chr>\n1 group_1 2     4    \n2 group_2 4     2    \n3 group_3 7     5    \n4 group_4 2     7    \n5 group_5 3     8    \n6 group_6 7     6    \n7 ...     ...   ...  \n\n\nIf we take the correlation of all these combinations of pairings, then we get our ICC of 0.18!\nICC = the expected correlation of a randomly drawn pair of observations from the same group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion C1\n\n\nLet’s suppose we want to account for the by-participant clustering in our data with the “No pooling” method (i.e., in our multiple regression model, include participant ID as an additional predictor, along with its interaction with explanatory variable of interest).\n\nMake sure that the participant ID variable is a factor!\n\nFit the model\nUse the plot_model() function (with type = \"int\") to plot the interaction terms between stakes and each participant.\n\nNote: When examining parameter values, remember to think about how HRV is considered to relate to stress, and whether the direction of any effect you see makes theoretical sense.\n\n\n\n\n Solution \n\n\n\nbball <- bball %>% mutate(sub = factor(sub))\nnopool_mod <- lm(hrv ~ stakes*sub, data=bball)\nsjPlot::plot_model(nopool_mod, type = \"int\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion C2\n\n\nWe have fitted two models so far:\n\nThe complete pooling model: lm(hrv ~ stakes, data = bball), which ignores the fact that our data has some inherent grouping (multiple datapoints per participant)\nThe no pooling model: lm(hrv ~ stakes*sub, data = bball), which estimates only participant-specific effects.\n\nCompare the two models using anova(). Which model provides the best fit?\n\n\n\n\n Solution \n\n\n\npool_mod <- lm(hrv ~ stakes, data=bball)\nnopool_mod <- lm(hrv ~ stakes*sub, data=bball)\nanova(pool_mod, nopool_mod)\n\nAnalysis of Variance Table\n\nModel 1: hrv ~ stakes\nModel 2: hrv ~ stakes * sub\n  Res.Df     RSS Df Sum of Sq      F    Pr(>F)    \n1    598 1092.87                                  \n2    540  477.39 58    615.48 12.003 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe can see that the no pooling model provides a significantly better fit to the data.\n\n\n\n\nQuestion C3\n\n\nRecall our research question: “How are stress levels (measured via HRV) influenced by the size of potential reward/loss?”\nFrom the model lm(hrv ~ stakes*sub, data=bball), do we estimate a parameter that allows us to complete the following sentence?:\n\n“For every 1 point increase in reward, heart rate variability changed by _ ? _ units.”\n\n\n\n\n\n Solution \n\n\nRemember that when there is an interaction term, coefficients for individual variables included in the interaction term are conditional effects. In the model lm(y ~ x * z), the coefficient for x is the estimated effect of x on y when z=0 (and vice versa). When one of these is categorical, 0 is a reference level.\nSo we don’t really estimate a parameter for the overall effect of stakes on hrv - we simply have the participant-specific estimates.\n\nsummary(nopool_mod)$coefficients\n\n                 Estimate Std. Error     t value     Pr(>|t|)\n(Intercept)   4.300458869 0.43677304  9.84598064 3.793839e-21\nstakes        0.061259772 0.03646111  1.68014014 9.350841e-02\nsub2          0.551948310 0.61769035  0.89356796 3.719512e-01\nsub3          0.820197993 0.61769035  1.32784653 1.847898e-01\nsub4          0.532046420 0.61769035  0.86134811 3.894286e-01\nsub5          4.050033460 0.61769035  6.55673743 1.287653e-10\nsub6         -1.487195643 0.61769035 -2.40767180 1.638893e-02\nsub7         -0.176553063 0.61769035 -0.28582778 7.751196e-01\nsub8          0.487065284 0.61769035  0.78852662 4.307348e-01\nsub9          1.523370708 0.61769035  2.46623685 1.396366e-02\nsub10        -0.227750652 0.61769035 -0.36871331 7.124859e-01\nsub11         1.046044119 0.61769035  1.69347653 9.094150e-02\nsub12        -0.943711183 0.61769035 -1.52780625 1.271462e-01\nsub13         2.373490152 0.61769035  3.84252424 1.362505e-04\nsub14        -0.456905318 0.61769035 -0.73969962 4.598037e-01\nsub15         1.782354021 0.61769035  2.88551377 4.063958e-03\nsub16         1.532933894 0.61769035  2.48171901 1.337812e-02\nsub17         0.500646099 0.61769035  0.81051306 4.180024e-01\nsub18         0.983211079 0.61769035  1.59175398 1.120252e-01\nsub19         1.502042629 0.61769035  2.43170809 1.535192e-02\nsub20         3.241516039 0.61769035  5.24780098 2.215398e-07\nsub21         1.147792016 0.61769035  1.85819968 6.368464e-02\nsub22        -0.612560929 0.61769035 -0.99169580 3.217901e-01\nsub23        -0.205178646 0.61769035 -0.33217071 7.398893e-01\nsub24         1.712626937 0.61769035  2.77263022 5.752586e-03\nsub25         1.384399492 0.61769035  2.24125160 2.541529e-02\nsub26        -2.317817283 0.61769035 -3.75239353 1.941184e-04\nsub27         1.393567204 0.61769035  2.25609352 2.446399e-02\nsub28        -0.425881245 0.61769035 -0.68947369 4.908214e-01\nsub29         0.642571954 0.61769035  1.04028167 2.986746e-01\nsub30        -0.010970790 0.61769035 -0.01776099 9.858361e-01\nstakes:sub2  -0.012862460 0.05156379 -0.24944751 8.031095e-01\nstakes:sub3  -0.035097345 0.05156379 -0.68065869 4.963792e-01\nstakes:sub4  -0.029913376 0.05156379 -0.58012364 5.620732e-01\nstakes:sub5  -0.386778846 0.05156379 -7.50097719 2.621397e-13\nstakes:sub6  -0.018284698 0.05156379 -0.35460343 7.230251e-01\nstakes:sub7  -0.045618976 0.05156379 -0.88470944 3.767071e-01\nstakes:sub8  -0.111747546 0.05156379 -2.16717073 3.065825e-02\nstakes:sub9  -0.225284706 0.05156379 -4.36904826 1.496785e-05\nstakes:sub10 -0.055625358 0.05156379 -1.07876775 2.811729e-01\nstakes:sub11 -0.143857500 0.05156379 -2.78989360 5.458818e-03\nstakes:sub12 -0.166749061 0.05156379 -3.23384000 1.296027e-03\nstakes:sub13 -0.192176570 0.05156379 -3.72696718 2.142290e-04\nstakes:sub14  0.057197973 0.05156379  1.10926618 2.678091e-01\nstakes:sub15 -0.218576167 0.05156379 -4.23894652 2.641414e-05\nstakes:sub16 -0.207404000 0.05156379 -4.02227964 6.585414e-05\nstakes:sub17 -0.087620016 0.05156379 -1.69925461 8.984716e-02\nstakes:sub18 -0.160005481 0.05156379 -3.10305871 2.015560e-03\nstakes:sub19 -0.025923824 0.05156379 -0.50275245 6.153433e-01\nstakes:sub20 -0.202111254 0.05156379 -3.91963501 1.000874e-04\nstakes:sub21 -0.075588319 0.05156379 -1.46591848 1.432525e-01\nstakes:sub22 -0.046772269 0.05156379 -0.90707577 3.647713e-01\nstakes:sub23  0.014323707 0.05156379  0.27778613 7.812829e-01\nstakes:sub24 -0.116921035 0.05156379 -2.26750254 2.375390e-02\nstakes:sub25 -0.056800361 0.05156379 -1.10155511 2.711459e-01\nstakes:sub26  0.220232109 0.05156379  4.27106095 2.298973e-05\nstakes:sub27 -0.093440459 0.05156379 -1.81213311 7.052092e-02\nstakes:sub28  0.019860359 0.05156379  0.38516094 7.002698e-01\nstakes:sub29 -0.120547800 0.05156379 -2.33783803 1.975988e-02\nstakes:sub30  0.002596578 0.05156379  0.05035662 9.598568e-01\n\n\n\n\n\n\nQuestion C4\n\n\nLet’s suppose we want to examine the interaction between size and type of reward (stakes * condition), using the “no pooling” method (i.e., including participant as a fixed effect).\nWe have the variable stakes, that varies within each participant, and another variable condition that varies between participants.\nThis becomes difficult because the sub variable (the participant id variable) uniquely identifies the two conditions. Note that if we fit the following model, some coefficients are not defined. Try it and see:\n\nlm(hrv ~ stakes*sub + stakes*condition, data=bball)\n\nThis sort of perfectly balanced design has traditionally been approached with extensions of ANOVA (“repeated measures ANOVA”, “mixed ANOVA”). These methods can partition out variance due to one level of clustering (e.g. subjects), and can examine factorial designs when one factor is within cluster, and the other is between. You can see an example here if you are interested. However, ANOVA has a lot of constraints - it can’t handle multiple levels of clustering (e.g. children in classes in schools), it will likely require treating variables such as time as a factor, and it’s not great with missing data.\nThe multi-level model (MLM) provides a more flexible framework, and this is what we will begin to look at next week."
  },
  {
    "objectID": "02_intromlm.html",
    "href": "02_intromlm.html",
    "title": "Introducing Multilevel Models",
    "section": "",
    "text": "Information about solutions\nSolutions for these exercises are available immediately below each question.\nWe would like to emphasise that much evidence suggests that testing enhances learning, and we strongly encourage you to make a concerted attempt at answering each question before looking at the solutions. Immediately looking at the solutions and then copying the code into your work will lead to poorer learning.\nWe would also like to note that there are always many different ways to achieve the same thing in R, and the solutions provided are simply one approach."
  },
  {
    "objectID": "02_intromlm.html#introducing-lme4",
    "href": "02_intromlm.html#introducing-lme4",
    "title": "Introducing Multilevel Models",
    "section": "Introducing lme4",
    "text": "Introducing lme4\n\nWe’re going to use the lme4 package, and specifically the functions lmer() and glmer().\n“(g)lmer” here stands for “(generalised) linear mixed effects regression”.\nYou will have seen some use of these functions in the lectures. The broad syntax is:\n\n\nlmer(formula, REML = logical, data = dataframe)\n\n\nWe write the first bit of our formula just the same as our old friend the normal linear model y ~ 1 + x + x2 + ..., where y is the name of our outcome variable, 1 is the intercept (which we don’t have to explicitly state as it will be included anyway) and x, x2 etc are the names of our explanatory variables.\nWith lme4, we now have the addition of __random effect terms)), specified in parenthesis with the | operator (the vertical line | is often found to the left of the z key on QWERTY keyboards).\nWe use the | operator to separate the parameters (intercept, slope etc.) on the LHS, from the grouping variable(s) on the RHS, by which we would like to model these parameters as varying.\nRandom Intercept\nLet us suppose that we wish to model our intercept not as a fixed constant, but as varying randomly according to some grouping around a fixed center. We can such a model by allowing the intercept to vary by our grouping variable (g below):\n\n\nlmer(y ~ 1 + x + (1|g), data = df)\n\n\\[\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{Y_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot X_{ij}} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\end{align}\n\\]\n\nRandom Slope\nBy extension we can also allow the effect y~x to vary between groups, by including the x on the left hand side of | in the random effects part of the call to lmer().\n\n\nlmer(y ~ 1 + x + (1 + x |g), data = df)\n\n\\[\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1i} \\cdot x_{ij}} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{\\beta_{1i}} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "02_intromlm.html#estimation",
    "href": "02_intromlm.html#estimation",
    "title": "Introducing Multilevel Models",
    "section": "Estimation",
    "text": "Estimation\n\nMaximum Likelihood (ML)\nRemember back to DAPR2 when we introduced logistic regression, and we briefly discussed Maximum likelihood in an explanation of how models are fitted.\nThe key idea of maximum likelihood estimation (MLE) is that we (well, the computer) iteratively finds the set of estimates for our model which it considers to best reproduce our observed data. Recall our simple linear regression model of how practice (hrs per week) affects reading age:\n\\[\n\\color{red}{ReadingAge_i} = \\color{blue}{\\beta_0 \\cdot{} 1 + \\beta_1 \\cdot{} Practice_{i}} + \\varepsilon_i\n\\]\nThere are values of \\(\\beta_0\\) and \\(\\beta_1\\) and \\(\\sigma_\\varepsilon\\) which maximise the probability of observing the data that we have. For linear regression, these we obtained these same values a different way, via minimising the sums of squares. And we saw that this is not possible for more complex models (e.g., logistic), which is where we turn to MLE.\n\nTo read about the subtle difference between “likelihood” and “probability”, you can find a short explanation at https://uoepsy.github.io/faq/lvp.html\n\nIf we are estimating just one single parameter (e.g. a mean), then we can imagine the process of maximum likelihood estimation in a one-dimensional world - simply finding the top of the curve:\n\n\n\n\n\nMLE\n\n\n\n\nHowever, our typical models estimate a whole bunch of parameters. The simple regression model above is already having to estimate \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma_\\varepsilon\\), and our multi-level models have far more! With lots of parameters being estimated and all interacting to influence the likelihood, our nice curved line becomes a complex surface (see Left panel of Figure @ref(fig:multisurf)). So what we (our computers) need to do is find the maximum, but avoid local maxima and singularities (see Figure @ref(fig:maxima)).\n\n\n\n\n\nMLE for a more complex model\n\n\n\n\n\n\nRestricted Maximum Likelihood (REML)\nWhen it comes to estimating multilevel models, maximum likelihood will consider the fixed effects as unknown values in its estimation of the variance components (the random effect variances). This leads to biased estimates of the variance components, specifically biasing them toward being too small, especially if \\(n_\\textrm{clusters} - n_\\textrm{level 2 predictors} - 1 < 50\\). Restricted Maximum Likelihood (REML), however, separates the estimation of fixed and random parts of the model, leading to unbiased estimates of the variance components.\n\nlmer() models are by default fitted with REML. This is better for small samples.\n\n\nComparing Models, ML & REML\nWhen we compare models that differ in their fixed effects via comparing model deviance (e.g. the likelihood ratio), REML should not be used as only the variance components are included in the likelihood. Functions like anova() will automatically refit your models with ML for you, but it is worth checking.\nWe cannot compare (either with ML or REML) models that differ in both the fixed and random parts.\n\n\n\nModel Convergence\nFor large datasets and/or complex models (lots of random-effects terms), it is quite common to get a convergence warning. There are lots of different ways to deal with these (to try to rule out hypotheses about what is causing them).\nFor now, if lmer() gives you convergence errors, you could try changing the optimizer. Bobyqa is a good one: add control = lmerControl(optimizer = \"bobyqa\") when you run your model.\n\nlmer(y ~ 1 + x1 + ... + (1 + .... | g), data = df, \n     control = lmerControl(optimizer = \"bobyqa\"))\n\n\n What is a convergence warning??\n\n\nThere are different techniques for maximum likelihood estimation, which we apply by using different ‘optimisers’. Technical problems to do with model convergence and ‘singular fit’ come into play when the optimiser we are using either can’t find a suitable maximum, or gets stuck in a singularity (think of it like a black hole of likelihood, which signifies that there is not enough variation in our data to construct such a complex model).\n\n\n\n\n\nlocal/global maxima and singularities"
  },
  {
    "objectID": "02_intromlm.html#toy-dataset",
    "href": "02_intromlm.html#toy-dataset",
    "title": "Introducing Multilevel Models",
    "section": "Toy Dataset",
    "text": "Toy Dataset\n\n\nRecall our toy example data in which we might use linear regression to determine how practice (in hours per week) influences the reading age of different toy figurines. We have data on various types of toys, from Playmobil to Powerrangers, to Farm Animals.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntoys_read <- read_csv(\"https://uoepsy.github.io/data/toyexample.csv\")\n\n\n\nQuestion A3\n\n\nUsing lmer() from the lme4 package, fit a model of practice (hrs_week) predicting Reading age (R_AGE), with by-toytype random intercepts.\nPass the model to summary() to see the output.\n\n\n\n\n Solution \n\n\n\nlibrary(lme4)\nri_model <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toys_read)\nsummary(ri_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: R_AGE ~ hrs_week + (1 | toy_type)\n   Data: toys_read\n\nREML criterion at convergence: 653.1\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.31139 -0.62361  0.05812  0.63477  1.71073 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n toy_type (Intercept) 23.188   4.815   \n Residual              5.006   2.237   \nNumber of obs: 132, groups:  toy_type, 20\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   1.6274     1.4462   1.125\nhrs_week      1.1547     0.2317   4.983\n\nCorrelation of Fixed Effects:\n         (Intr)\nhrs_week -0.654\n\n\n\n\n\n\nQuestion A4\n\n\nSometimes the easiest way to start understanding your model is to visualise it.\nLoad the package broom.mixed. Along with some handy functions tidy() and glance() which give us the information we see in summary(), there is a handy function called augment() which returns us the data in the model plus the fitted values, residuals, hat values, Cook’s D etc..\n\nri_model <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toys_read)\nlibrary(broom.mixed)\naugment(ri_model)\n\n# A tibble: 132 × 14\n   R_AGE hrs_week toy_type   .fitted  .resid  .hat .cooksd .fixed    .mu .offset\n   <dbl>    <dbl> <fct>        <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>   <dbl>\n 1  9.31     3.84 Furby       10.0   -0.701  0.122 7.75e-3   6.06 10.0         0\n 2 12.2      4.88 Toy Story   12.1    0.105  0.142 2.14e-4   7.26 12.1         0\n 3  8.08     3.48 Stretch A…   6.02   2.06   0.192 1.25e-1   5.64  6.02        0\n 4  9.08     3.68 Peppa Pig    6.05   3.03   0.126 1.52e-1   5.87  6.05        0\n 5  2.07     2.96 Lego Mini…   0.621  1.45   0.146 4.20e-2   5.04  0.621       0\n 6 10.2      3.71 G.I.Joe     11.9   -1.67   0.122 4.41e-2   5.91 11.9         0\n 7  8.05     3.73 Minecraft    7.97   0.0730 0.139 9.96e-5   5.94  7.97        0\n 8 11.6      4.59 Polly Poc…   9.99   1.60   0.172 6.42e-2   6.92  9.99        0\n 9 12.3      4.01 Star Wars   11.2    1.13   0.140 2.40e-2   6.25 11.2         0\n10  5.06     4.37 Sock Pupp…   4.89   0.171  0.163 6.78e-4   6.67  4.89        0\n# … with 122 more rows, and 4 more variables: .sqrtXwt <dbl>, .sqrtrwt <dbl>,\n#   .weights <dbl>, .wtres <dbl>\n\n\nAdd to the code below to plot the model fitted values, and color them according to toy type.\n(you will need to edit ri_model to be whatever name you assigned to your model).\n\naugment(ri_model) %>%\n  ggplot(aes(x = hrs_week, y = ...... \n\n\n\n\n\n Solution \n\n\n\naugment(ri_model) %>%\n  ggplot(aes(x = hrs_week, y = .fitted, col = toy_type)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion A5\n\n\nWe have just fitted the model:\n\\[\n\\begin{align}\n& \\text{For toy } j \\text{ of toy-type } i \\\\\n& \\color{red}{\\textrm{Reading_Age}_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot \\textrm{Practice}_{ij}} + \\varepsilon_{ij} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\end{align}\n\\]\nFor our estimates of \\(\\gamma_{00}\\) (the fixed value around which toy-type intercepts vary) and \\(\\beta_1\\) (the fixed estimate of the relationship between reading age and practice), we can use fixef().\n\nfixef(ri_model)\n\n(Intercept)    hrs_week \n   1.627422    1.154725 \n\n\nCan you add to the plot in the previous question, a thick black line with the intercept and slope given by fixef()?\nHint: geom_abline()\n\n\n\n\n Solution \n\n\n\naugment(ri_model) %>%\n  ggplot(aes(x = hrs_week, y = .fitted, col = toy_type)) + \n  geom_line() + \n  geom_abline(intercept = fixef(ri_model)[1], slope = fixef(ri_model)[2], lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion A6\n\n\nBy now, you should have a plot which looks more or less like the left-hand figure below (we have added on the raw data - the points).\n\n\n\n\n\n\n\nModel fitted values\n\n\n\n\n\n\n\n\n\n\n\nSummary model outputlmer(R_AGE~1 + hrs_week + (1|toy_type),data = toys_read)\n\n\n\n\n\n  We’re going to map the parts of the plot in Figure @ref(fig:modfit) to the summary() output of the model in Figure @ref(fig:lmersummap). Match the coloured sections Red, Orange, Yellow and Blue in Figure @ref(fig:lmersummap) to the descriptions below of @ref(fig:modfit) A through D.\n\nwhere the black line cuts the y axis\nthe standard deviation of the distances from all the individual toy types lines to the black lines\nthe slope of the black lines\nthe standard deviation of the distances from all the individual observations to the line for the toy type to which it belongs.\n\n\n\n\n\n Solution \n\n\n\nYellow = B\n\nRed = D\n\nBlue = A\n\nOrange = C\n\n\n\n\n\nQuestion A7 - Harder\n\n\nCan you now map those same coloured sections in Figure @ref(fig:lmersummap) to the mathematical terms in the model equation:\n\\[\n\\begin{align}\n& \\text{Level 1:} \\\\\n& \\color{red}{ReadingAge_{ij}} = \\color{blue}{\\beta_{0i} \\cdot 1 + \\beta_{1} \\cdot Practice_{ij}} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{\\beta_{0i}} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n\\quad \\\\\n& \\text{where} \\\\\n& \\color{orange}{\\zeta_0} \\sim N(0, \\sigma_{\\color{orange}{\\zeta_{0}}})  \\text{ independently} \\\\\n& \\varepsilon \\sim N(0, \\sigma_{\\varepsilon}) \\text{ independently} \\\\\n\\end{align}\n\\]\n\n\n\n\n Solution \n\n\n\nYellow = \\(\\sigma_{\\color{orange}{\\zeta_{0}}}\\)\n\nRed = \\(\\sigma_{\\varepsilon}\\)\n\nBlue = \\(\\gamma_{00}\\)\n\nOrange = \\(\\beta_{1}\\)\n\n\n\n\n\nQuestion A8\n\n\nFit a model which allows also (along with the intercept) the effect of practice (hrs_week) to vary by-toytype.\nThen, using augment() again, plot the model fitted values. What do you think you will see?\n\n\n\n\n Solution \n\n\n\nrs_model <- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week | toy_type), data = toys_read)\naugment(rs_model) %>%\n  ggplot(aes(x = hrs_week, y = .fitted, col = toy_type)) + \n  geom_line() + \n  geom_point(aes(y=R_AGE), alpha=.4)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion A9\n\n\nPlot the model fitted values but only for the Farm Animals and the Scooby Doo toys, and add the observed reading ages too.\nDo this for both the model with the random intercept only, and the model with both the random intercept and slope.\n\n\n\n\n Solution \n\n\n\naugment(ri_model) %>%\n  filter(str_detect(toy_type, \"Scooby|Farm\")) %>%\n  ggplot(aes(x = hrs_week, y = .fitted, col = toy_type)) + \n  geom_line() + \n  geom_point(aes(y=R_AGE), alpha=.4)\n\n\n\n\n\n\n\naugment(rs_model) %>%\n  filter(str_detect(toy_type, \"Scooby|Farm\")) %>%\n  ggplot(aes(x = hrs_week, y = .fitted, col = toy_type)) + \n  geom_line() + \n  geom_point(aes(y=R_AGE), alpha=.4)"
  },
  {
    "objectID": "02_intromlm.html#basketballhrv",
    "href": "02_intromlm.html#basketballhrv",
    "title": "Introducing Multilevel Models",
    "section": "Basketball/HRV",
    "text": "Basketball/HRV\nWhile the toy example considers the groupings or ‘clusters’ of different types of toy, a more relate-able grouping in psychological research is that of several observations belonging to the same individual. One obvious benefit of this is that we can collect many more observations with fewer participants, and account for the resulting dependency of observations.\n\nRecall the data from the previous week, from an experiment in which heart rate variability (HRV) was measured for amateur basketball players when tasked with scoring a goal with varying levels and type of potential loss/reward.\nThe data was split over two files. The code below will read in both datasets and join them for you:\n\nlibrary(readxl)\ndownload.file(url = \"https://uoepsy.github.io/data/basketballhrv.xlsx\", \n              destfile = \"baskeballhrvdata.xlsx\")\n\nbball <- \n  left_join(\n    read_csv(\"https://uoepsy.github.io/data/basketballconditions.csv\"),\n    read_xlsx(\"baskeballhrvdata.xlsx\") %>%\n      pivot_longer(trial_1:trial_20, names_to = \"trial_no\", values_to = \"hrv\")\n  ) %>%\n  mutate(sub = factor(sub))\n\n!!! Note if read_xlsx() was causing problems for you, this will also work:\n\nbball <- \n  left_join(\n    read_csv(\"https://uoepsy.github.io/data/basketballconditions.csv\"),\n    read_csv(\"https://uoepsy.github.io/data/bballhrv.csv\") %>%\n      pivot_longer(trial_1:trial_20, names_to = \"trial_no\", values_to = \"hrv\")\n  ) %>%\n  mutate(sub = factor(sub))\n\n\n\nQuestion B1\n\n\nRecall that the research question was concerned with how the size and type of potential reward influence stress levels (as measured by heart rate variability):\n\nHow do size and type of reward/loss interact to influence levels of stress?\n\nRemember to think about:\n- what is our outcome variable of interest? - what is the clustering? - does size of reward vary within clusters, or between? - does type of reward vary within clusters, or between?\nCan you fit a linear mixed model to examine the effects of size and type of reward on HRV, and their interaction?\nTip: If you get an error about model convergence, consider changing the optimiser (see above)\n\n\n\n\n Solution \n\n\n\nmod <- lmer(hrv ~ stakes * condition + (1 + stakes | sub), data = bball,\n            control = lmerControl(optimizer=\"bobyqa\"))\nsummary(mod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hrv ~ stakes * condition + (1 + stakes | sub)\n   Data: bball\nControl: lmerControl(optimizer = \"bobyqa\")\n\nREML criterion at convergence: 1783.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6483 -0.6515  0.0088  0.6310  2.8235 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n sub      (Intercept) 1.61412  1.2705        \n          stakes      0.01103  0.1050   -0.81\n Residual             0.88406  0.9402        \nNumber of obs: 600, groups:  sub, 30\n\nFixed effects:\n                       Estimate Std. Error t value\n(Intercept)            4.998385   0.346880  14.410\nstakes                -0.001148   0.028707  -0.040\nconditionmoney        -0.039631   0.490563  -0.081\nstakes:conditionmoney -0.043284   0.040598  -1.066\n\nCorrelation of Fixed Effects:\n            (Intr) stakes cndtnm\nstakes      -0.817              \nconditinmny -0.707  0.577       \nstks:cndtnm  0.577 -0.707 -0.817\n\n\n\n\n\n\nQuestion B2\n\n\nConstruct some parametric bootstrapped confidence intervals for your fixed effects.\nUsing the sjPlot package, produce a plot of the interaction between size and type of reward on HRV. Before you get R to make your plot, can you predict what it is going to look like?\n\n\n\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\n\nfixef(mod)\n\n          (Intercept)                stakes        conditionmoney \n          4.998385433          -0.001148365          -0.039630923 \nstakes:conditionmoney \n         -0.043283505 \n\nconfint(mod, method=\"boot\")\n\n                            2.5 %      97.5 %\n.sig01                 0.86965749  1.60051013\n.sig02                -0.91970970 -0.58029929\n.sig03                 0.07354089  0.13362400\n.sigma                 0.88366852  0.99894451\n(Intercept)            4.32323086  5.64349022\nstakes                -0.05950708  0.05255156\nconditionmoney        -0.89561036  0.91924152\nstakes:conditionmoney -0.11344071  0.03834757\n\n\nThe intercept is about 5, and there is no significant difference between the reward and money conditions, so both lines will start around 5 (the “money” line will be -0.04 lower). The coefficient for stakes is pretty much 0, so we know that the line for the reference group (condition = “kudos” will be fairly flat). The interaction indicates that when we move from the “kudos” to the “money” condition, we adjust the effect of stakes by -0.04, so the line for the “money” condition will be going slightly more downward than that for the “kudos” condition. However, 0 is well within the 95% CI for this interaction term, so we would expect the errorbars around the lines to be overlapping.\n\nlibrary(sjPlot)\nplot_model(mod, type = \"int\")"
  },
  {
    "objectID": "02_intromlm.html#weightmaintain-study",
    "href": "02_intromlm.html#weightmaintain-study",
    "title": "Introducing Multilevel Models",
    "section": "WeightMaintain Study",
    "text": "WeightMaintain Study\nAnother very crucial advantage is that we can use the same methods to study how people change over time.\n\nWeightMaintain Data Codebook\nThe weight maintenance data (WeightMaintain3), a made-up data set based on Lowe et al. (2014, Obesity, 22, 94-100), contains information on overweight participants who completed a 12-week weight loss program, and were then randomly assigned to one of three weight maintenance conditions:\n\nNone (Control)\n\nMR (meal replacements): use MR to replace one meal and snack per day\n\nED (energy density intervention): book and educational materials on purchasing and preparing foods lower in ED (reducing fat content and/or increasing water content of foods)\n\nWeight was assessed at baseline (start of maintenance), 12 months post, 24 months post, and 36 months post.\nIt is available, in .rda format, at https://uoepsy.github.io/data/WeightMaintain3.rda\n\n\nQuestion C1\n\n\nLoad the data, and take a look at what is in there. Hopefully it should match the description above.\nHint: load(url(\"https://uoepsy.github.io/data/WeightMaintain3.rda\"))\n\n\n\n\n Solution \n\n\n\nload(url(\"https://uoepsy.github.io/data/WeightMaintain3.rda\"))\nsummary(WeightMaintain3)\n\n       ID      Condition    Assessment    WeightChange    \n 101    :  4   None:240   Min.   :0.00   Min.   :-8.3781  \n 102    :  4   ED  :240   1st Qu.:0.75   1st Qu.:-0.5024  \n 103    :  4   MR  :240   Median :1.50   Median : 0.7050  \n 104    :  4              Mean   :1.50   Mean   : 1.4438  \n 105    :  4              3rd Qu.:2.25   3rd Qu.: 2.8806  \n 106    :  4              Max.   :3.00   Max.   :14.9449  \n (Other):696                                              \n\nhead(WeightMaintain3)\n\n   ID Condition Assessment WeightChange\n1 101      None          0 -0.116138529\n2 101      None          1  0.333508907\n3 101      None          2  1.678653492\n4 101      None          3  2.756023400\n5 102      None          0 -0.004420188\n6 102      None          1  1.746725487\n\n\n\n\n\n\nQuestion C2\n\n\n\nQ: Overall, did the participants maintain their weight loss or did their weights change?\n\nEach of our participants have measurements at 4 assessments. We need to think about what this means for the random effects that we will include in our model (our random effect structure). Would we like our models to accommodate individuals to vary in their starting weight change, to vary in their weight change over the course of the assessment period, or both?\nTo investigate whether weights changed over the course of the assessments, or whether they stayed the same, we can fit and compare 2 models:\n\nThe “null” or “intercept-only” model.\nA model with weight change predicted by assessment.\n\nAnd we can then compare them in terms of model fit. As discussed in the lecture, there are lots of ways to assess inference in multilevel models.\nOur sample size here (180 participants, each with 4 observations) is reasonably large given the relative simplicity of our model. We might consider running a straightforward Likelihood Ratio Test using anova(restricted_model, full_model) to compare our two models. This will assume that the difference in model deviances ( \\(-2 \\times \\text{LogLikelihood}\\) ) is \\(\\chi^2\\)-distributed.\nIf we wish to use a more robust test, we might use the PBmodcomp() function from the pbkrtest package, in order to bootstrap the likelihood ratio statistic based on simulations based on the parameters of the model.\nTip: For now, don’t worry too much about “singular fits”. We’ll talk more about how we might deal with them next week!\n\n\n\n\n Solution \n\n\nThis is our null model:\n\nm.null <- lmer(WeightChange ~ 1 + (1 | ID), data=WeightMaintain3)\nsummary(m.null)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: WeightChange ~ 1 + (1 | ID)\n   Data: WeightMaintain3\n\nREML criterion at convergence: 3601.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4349 -0.5330 -0.1154  0.4255  3.7017 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 3.765    1.940   \n Residual             6.431    2.536   \nNumber of obs: 720, groups:  ID, 180\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   1.4438     0.1728   8.357\n\n\nWe can see the 3.77 / (3.77 + 6.43), or 0.37 of the total variance is attributable to participant-level variation.\nNow lets suppose we want to compare this null model with a model with an effect of Assessment (to assess whether there is overall change over time). Which model should we compare m.null to?\n\nmodA <- lmer(WeightChange ~ 1 + Assessment + (1 + Assessment | ID), data=WeightMaintain3)\nmodB <- lmer(WeightChange ~ 1 + Assessment + (1 | ID), data=WeightMaintain3)\n\nA comparison between these m.null and modA will not be assessing the influence of only the fixed effect of Assessment. Remember, we shouldn’t compare models with different random effect structures.\nHowever, modB doesn’t include our by-participant random effects of assessment, so comparing this to m.null is potentially going to misattribute random deviations in participants’ change to being an overall effect of assessment.\nIf we want to conduct a model comparison to isolate the effect of overall change over time (a fixed effect of Assessment), we might want to compare these two models:\n\nm.base0 <- lmer(WeightChange ~ 1 + (1 + Assessment | ID), data=WeightMaintain3)\nm.base <- lmer(WeightChange ~ 1 + Assessment + (1 + Assessment | ID), data=WeightMaintain3)\n\nThe first of these models is a bit weird to think about - how can we have by-participant random deviations of Assessment if we don’t have a fixed effect of Assessment? That makes very little sense. What it is actually fitting is a model where there is assumed to be no overall effect of Assessment. So the fixed effect is 0.\n\n# Straightforward LRT\nanova(m.base0, m.base)\n\nData: WeightMaintain3\nModels:\nm.base0: WeightChange ~ 1 + (1 + Assessment | ID)\nm.base: WeightChange ~ 1 + Assessment + (1 + Assessment | ID)\n        npar    AIC    BIC  logLik deviance Chisq Df Pr(>Chisq)    \nm.base0    5 2638.0 2660.9 -1314.0   2628.0                        \nm.base     6 2579.4 2606.8 -1283.7   2567.4 60.66  1  6.782e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# parametric bootstrap LRT\nlibrary(pbkrtest)\nPBmodcomp(m.base, m.base0)\n\n\n\n           stat df      p.value\nLRT    60.65978  1 6.772360e-15\nPBtest 60.65978 NA 1.464129e-03\n\n\n\nParametric Bootstrap Likelihood Ratio test found that the inclusion of Assessment significantly improved model fit over the null model ( \\(\\chi^2(1)\\) = 60.66, p = 0.001), suggesting that participants’ weights changed over course of 36 month assessment period.\n\n\n\n\n\nQuestion C3\n\n\n\nQ: Did the experimental condition groups differ in overall weight change and rate of weight change (non-maintenance)?\n\nHint: It helps to break it down. There are two questions here:\n\ndo groups differ overall?\n\ndo groups differ over time?\n\nWe can begin to see that we’re asking two questions about the Condition variable here: “is there an effect of Condition?” and “Is there an interaction between Assessment and Condition?”.\nTry fitting two more models which incrementally build these levels of complexity, and compare them (perhaps to one another, perhaps to models from the previous question - think about what each comparison is testing!)\n\n\n\n\n Solution \n\n\n\nm.int <- lmer(WeightChange ~ Assessment + Condition + (Assessment | ID), \n              data=WeightMaintain3)\nm.full <- lmer(WeightChange ~ Assessment*Condition + (Assessment | ID), \n               data=WeightMaintain3)\n\nWe’re going to compare each model to the previous one to examine the improvement in fit due to inclusion of each parameter. We could do this quickly with\n\nanova(m.base0, m.base, m.int, m.full)\n\nData: WeightMaintain3\nModels:\nm.base0: WeightChange ~ 1 + (1 + Assessment | ID)\nm.base: WeightChange ~ 1 + Assessment + (1 + Assessment | ID)\nm.int: WeightChange ~ Assessment + Condition + (Assessment | ID)\nm.full: WeightChange ~ Assessment * Condition + (Assessment | ID)\n        npar    AIC    BIC  logLik deviance   Chisq Df Pr(>Chisq)    \nm.base0    5 2638.0 2660.9 -1314.0   2628.0                          \nm.base     6 2579.4 2606.8 -1283.7   2567.4 60.6605  1  6.782e-15 ***\nm.int      8 2573.9 2610.6 -1279.0   2557.9  9.4418  2   0.008907 ** \nm.full    10 2537.5 2583.3 -1258.8   2517.5 40.3814  2  1.703e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nConditions differed overall in weight change \\(\\chi^2(2)=9.4, p = .009\\)\nConditions differed in change over assessment period \\(\\chi^2(2)=40.4, p < .001\\)\n\nHowever, we may instead want to bootstrap this test instead (especially if we have a small sample size):\n\nPBmodcomp(m.int, m.base)\n\n\n\n           stat df     p.value\nLRT    9.441648  2 0.008907834\nPBtest 9.441648 NA 0.013986014\n\n\n\nPBmodcomp(m.full, m.int)\n\n\n\n           stat df      p.value\nLRT    40.37396  2 1.709643e-09\nPBtest 40.37396 NA 9.990010e-04\n\n\n\nConditions differed overall in weight change (bootstrap likelihood ratio = 9.4, \\(p = .014\\) ).\nConditions differed in change over assessment period (bootstrap likelihood ratio = 40.4, \\(p = .001\\) ).\n\n\n\n\n\nQuestion C4\n\n\nWe saw that we can get the coefficients using fixef(model). We can also use tidy(model), and similar to models fitted with lm(), we can pull out the bit of the summary() using:\n\nsummary(model)$coefficients\n\nFrom your model from the previous question which investigates whether conditions differed over in their rate of weight change, can you state how the conditions differed?\n\n\n\n\n Solution \n\n\n\nsummary(m.full)$coefficients\n\n                          Estimate Std. Error    t value\n(Intercept)             0.06038642 0.09835879  0.6139402\nAssessment              1.84917936 0.18544623  9.9715123\nConditionED            -0.14303302 0.13910033 -1.0282723\nConditionMR            -0.14944649 0.13910033 -1.0743792\nAssessment:ConditionED -1.74949968 0.26226057 -6.6708452\nAssessment:ConditionMR -0.83624053 0.26226057 -3.1885865\n\n\n\nCompared to no intervention, weight (re)gain was 1.75 lbs/year slower for the ED intervention and 0.84 lbs/year slower for the MR intervention.\n\n\n\n\n\nQuestion C5\n\n\nMake a graph of the model fit and the observed data.\nHint: There are lots of ways you can do this, try a couple:\n\nUsing the effects package, does this help? as.data.frame(effect(\"Assessment:Condition\", model))\n\nUsing fitted(model)\nUsing augment() from the broom.mixed package.\n\n\n\n\n\n Solution \n\n\n\nUsing the effect() function (and then adding the means and SEs from the original data):\n\n\nef <- as.data.frame(effect(\"Assessment:Condition\", m.full))\n\nggplot(ef, aes(Assessment, fit, color=Condition)) + \n  geom_line() +\n  stat_summary(data=WeightMaintain3, aes(y=WeightChange), \n               fun.data=mean_se, geom=\"pointrange\", size=1) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nUsing the fitted() function to extract and plot fitted values from the model:\n\n\nggplot(WeightMaintain3, aes(Assessment, WeightChange, color=Condition)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\", size=1) + \n  stat_summary(aes(y=fitted(m.full)), fun=mean, geom=\"line\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nOr using augment():\n\n\naugment(m.full) %>%\nggplot(., aes(Assessment, WeightChange, color=Condition)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\", size=1) + \n  stat_summary(aes(y=.fitted), fun=mean, geom=\"line\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion C6\n\n\nExamine the parameter estimates and interpret them (i.e., what does each parameter represent?)\n\nm.full <- lmer(WeightChange ~ Assessment*Condition + (Assessment | ID), \n               data=WeightMaintain)\nsummary(m.full)\n\n\n\n\n\n Solution \n\n\n\nround(coef(summary(m.full)), 3)\n\n                       Estimate Std. Error t value\n(Intercept)               0.060      0.098   0.614\nAssessment                1.849      0.185   9.972\nConditionED              -0.143      0.139  -1.028\nConditionMR              -0.149      0.139  -1.074\nAssessment:ConditionED   -1.749      0.262  -6.671\nAssessment:ConditionMR   -0.836      0.262  -3.189\n\n\n\n(Intercept) ==> weight change at baseline in None group\nAssessment ==> slope of weight change in None group\nConditionED ==> baseline weight change in ED group relative to None group\nConditionMR ==> baseline weight change in MR group relative to None group\nAssessment:ConditionED ==> slope of weight change in ED group relative to None group\nAssessment:ConditionMR ==> slope of weight change in MR groups relative to None group"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "example2_01_EFA.html",
    "href": "example2_01_EFA.html",
    "title": "Analysis Example: Exploratory Factor Analysis",
    "section": "",
    "text": "Intro\nThis is a quick demonstration of one way of dealing with these tasks. It is by no means the only correct way. There is a substantial level of subjectivity in Exploratory Factor Analysis and the method involves repeated evaluation and re-evaluation of the model in light of the extracted factors and their conceptual relationships with the analysed items. In other words, a good EFA requires you to get your hands dirty.\n\nData: Work Pressures Survey\nThe Work Pressures Survey (WPS) data is available at the following link: https://uoepsy.github.io/data/WPS_data.csv.\nThe data contains responses from 946 workers from a variety of companies to the Work Pressures Survey. You can look at the survey taken by the study participants at the following link: https://uoepsy.github.io/data/WPS_data_codebook.pdf\nWe will be performing a factor analysis of the main section of this survey (Job1 to Job50).\n\n\n\nRead in Data\nRead the WPS data into R. Make sure to take a look at the variable names and data structure.\n\n\nCode\nlibrary(tidyverse)\ndf <- read.csv(\"https://uoepsy.github.io/data/WPS_data.csv\")\nhead(df)\n\n\n  job_yrs job_mths worktype cont_hrs act_hrs gender dobm doby status youngdep\n1       1        6        1       45      45      1    7   83      1        1\n2       5        8        1       36      36      2    1   58      2        2\n3       2        8        1       40      40      2    2   82      1        1\n4       4        3        1       35      35      1    4   78      1        1\n5       7        1        1       40      41      1    2   73      2        2\n6       3       11        1       32      32      1    8   75      2        2\n  elderdep qualif exercise cigs alcohol time_rel when_rel job1 job2 job3 job4\n1        1      5        4    1       1        2        1    5    4    5    4\n2        1      5        2    2       0        2        2    5    7    4    3\n3        1      4        6    2       0        1        1    1    4    7    1\n4        2      5        3    1       2        2        1    6    4    5    5\n5        1      4        2    1       3        2        1    1    1    5    5\n6        2      5        6    1       4        5        2    3    4    5    3\n  job5 job6 job7 job8 job9 job10 job11 job12 job13 job14 job15 job16 job17\n1    6    4    7    7    4     7     4     4     1     4     4     6     4\n2    6    2    1    4    5     6     1     5     4     5     7     5     1\n3    1    1    7    7    3     1     7     4     1     7     3     1     1\n4    6    4    5    5    5     6     5     3     4     2     7     2     4\n5    1    2    2    2    5     2     3     3     4     6     2     2     2\n6    4    3    4    3    5     4     3     3     4     1     6     3     5\n  job18 job19 job20 job21 job22 job23 job24 job25 job26 job27 job28 job29 job30\n1     7     7     3     4     3     5     4     4     7     2     3     3     4\n2     7     1     5     1     1     1     4     5     6     4     6     3     3\n3     7     7     7     7     1     2     5     6     7     1     7     5     6\n4     6     7     5     5     2     4     4     5     3     2     5     7     5\n5     3     2     1     1     4     6     2     3     6     6     2     5     1\n6     5     6     3     3     1     3     4     2     5     5     5     6     2\n  job31 job32 job33 job34 job35 job36 job37 job38 job39 job40 job41 job42 job43\n1     5     5     6     4     4     4     4     4     5     4     6     6     6\n2     1     7     4     6     6     1     5     5     7     3     5     4     1\n3     5     3     6     5     3     2     1     5     5     5     3     5     7\n4     3     2     5     7     5     3     3     2     7     3     5     4     3\n5     4     2     4     4     4     2     2     2     2     4     1     5     4\n6     5     1     3     5     1     5     3     1     5     3     1     3     5\n  job44 job45 job46 job47 job48 job49 job50\n1     6     6     3     3     3     6     3\n2     4     6     1     4     7     5     5\n3     6     7     2     5     7     5     1\n4     5     7     3     5     7     6     3\n5     2     6     6     1     6     2     1\n6     3     3     6     3     4     2     7\n\n\nVariable names - Option 1:\n\n\nCode\nnames(df)\n\n\n [1] \"job_yrs\"  \"job_mths\" \"worktype\" \"cont_hrs\" \"act_hrs\"  \"gender\"  \n [7] \"dobm\"     \"doby\"     \"status\"   \"youngdep\" \"elderdep\" \"qualif\"  \n[13] \"exercise\" \"cigs\"     \"alcohol\"  \"time_rel\" \"when_rel\" \"job1\"    \n[19] \"job2\"     \"job3\"     \"job4\"     \"job5\"     \"job6\"     \"job7\"    \n[25] \"job8\"     \"job9\"     \"job10\"    \"job11\"    \"job12\"    \"job13\"   \n[31] \"job14\"    \"job15\"    \"job16\"    \"job17\"    \"job18\"    \"job19\"   \n[37] \"job20\"    \"job21\"    \"job22\"    \"job23\"    \"job24\"    \"job25\"   \n[43] \"job26\"    \"job27\"    \"job28\"    \"job29\"    \"job30\"    \"job31\"   \n[49] \"job32\"    \"job33\"    \"job34\"    \"job35\"    \"job36\"    \"job37\"   \n[55] \"job38\"    \"job39\"    \"job40\"    \"job41\"    \"job42\"    \"job43\"   \n[61] \"job44\"    \"job45\"    \"job46\"    \"job47\"    \"job48\"    \"job49\"   \n[67] \"job50\"   \n\n\nVariable names - Option 2:\n\n\nCode\ncolnames(df)\n\n\nData structure - Option 1:\n\n\nCode\nstr(df)\n\n\n'data.frame':   946 obs. of  67 variables:\n $ job_yrs : int  1 5 2 4 7 3 4 4 1 0 ...\n $ job_mths: num  6 8 8 3 1 11 2 0 1 11 ...\n $ worktype: int  1 1 1 1 1 1 1 1 1 1 ...\n $ cont_hrs: num  45 36 40 35 40 32 30 54 37 37 ...\n $ act_hrs : num  45 36 40 35 41 32 30 54 37 37 ...\n $ gender  : int  1 2 2 1 1 1 2 1 2 2 ...\n $ dobm    : int  7 1 2 4 2 8 3 5 12 11 ...\n $ doby    : int  83 58 82 78 73 75 72 85 70 70 ...\n $ status  : int  1 2 1 1 2 2 2 2 2 2 ...\n $ youngdep: int  1 2 1 1 2 2 2 2 2 2 ...\n $ elderdep: int  1 1 1 2 1 2 1 1 1 1 ...\n $ qualif  : int  5 5 4 5 4 5 4 5 2 2 ...\n $ exercise: int  4 2 6 3 2 6 4 3 1 3 ...\n $ cigs    : int  1 2 2 1 1 1 2 2 1 1 ...\n $ alcohol : num  1 0 0 2 3 4 0 0 1 4 ...\n $ time_rel: int  2 2 1 2 2 5 1 3 1 2 ...\n $ when_rel: int  1 2 1 1 1 2 1 2 2 2 ...\n $ job1    : int  5 5 1 6 1 3 5 4 6 6 ...\n $ job2    : int  4 7 4 4 1 4 4 1 2 6 ...\n $ job3    : int  5 4 7 5 5 5 6 7 4 7 ...\n $ job4    : int  4 3 1 5 5 3 7 7 5 6 ...\n $ job5    : int  6 6 1 6 1 4 5 7 4 7 ...\n $ job6    : int  4 2 1 4 2 3 5 1 2 7 ...\n $ job7    : int  7 1 7 5 2 4 4 5 4 6 ...\n $ job8    : int  7 4 7 5 2 3 5 5 6 7 ...\n $ job9    : int  4 5 3 5 5 5 6 7 2 7 ...\n $ job10   : int  7 6 1 6 2 4 5 7 4 7 ...\n $ job11   : int  4 1 7 5 3 3 6 1 5 7 ...\n $ job12   : int  4 5 4 3 3 3 3 1 4 7 ...\n $ job13   : int  1 4 1 4 4 4 4 1 5 7 ...\n $ job14   : int  4 5 7 2 6 1 2 1 1 7 ...\n $ job15   : int  4 7 3 7 2 6 6 7 5 5 ...\n $ job16   : int  6 5 1 2 2 3 3 7 4 5 ...\n $ job17   : int  4 1 1 4 2 5 3 7 3 7 ...\n $ job18   : int  7 7 7 6 3 5 5 3 6 2 ...\n $ job19   : int  7 1 7 7 2 6 7 3 6 2 ...\n $ job20   : int  3 5 7 5 1 3 7 6 3 3 ...\n $ job21   : int  4 1 7 5 1 3 3 1 5 6 ...\n $ job22   : int  3 1 1 2 4 1 2 1 2 6 ...\n $ job23   : int  5 1 2 4 6 3 6 1 5 7 ...\n $ job24   : int  4 4 5 4 2 4 4 4 5 6 ...\n $ job25   : int  4 5 6 5 3 2 3 7 5 4 ...\n $ job26   : int  7 6 7 3 6 5 6 7 6 4 ...\n $ job27   : int  2 4 1 2 6 5 1 1 3 7 ...\n $ job28   : int  3 6 7 5 2 5 6 1 4 7 ...\n $ job29   : int  3 3 5 7 5 6 5 1 3 7 ...\n $ job30   : int  4 3 6 5 1 2 3 6 6 4 ...\n $ job31   : int  5 1 5 3 4 5 4 1 5 5 ...\n $ job32   : int  5 7 3 2 2 1 3 2 6 5 ...\n $ job33   : int  6 4 6 5 4 3 7 4 6 4 ...\n $ job34   : int  4 6 5 7 4 5 6 1 5 5 ...\n $ job35   : int  4 6 3 5 4 1 3 1 5 6 ...\n $ job36   : int  4 1 2 3 2 5 2 1 5 6 ...\n $ job37   : int  4 5 1 3 2 3 3 7 3 6 ...\n $ job38   : int  4 5 5 2 2 1 3 1 3 7 ...\n $ job39   : int  5 7 5 7 2 5 6 7 6 5 ...\n $ job40   : int  4 3 5 3 4 3 3 7 3 6 ...\n $ job41   : int  6 5 3 5 1 1 3 1 5 7 ...\n $ job42   : int  6 4 5 4 5 3 4 1 4 5 ...\n $ job43   : int  6 1 7 3 4 5 1 2 3 7 ...\n $ job44   : int  6 4 6 5 2 3 7 1 5 7 ...\n $ job45   : int  6 6 7 7 6 3 6 7 6 7 ...\n $ job46   : int  3 1 2 3 6 6 3 7 3 5 ...\n $ job47   : int  3 4 5 5 1 3 3 3 3 6 ...\n $ job48   : int  3 7 7 7 6 4 6 7 5 6 ...\n $ job49   : int  6 5 5 6 2 2 5 2 6 7 ...\n $ job50   : int  3 5 1 3 1 7 4 1 5 6 ...\n\n\nData structure - Option 2:\n\n\nCode\nglimpse(df)\n\n\nRows: 946\nColumns: 67\n$ job_yrs  <int> 1, 5, 2, 4, 7, 3, 4, 4, 1, 0, 2, 2, 11, 4, 1, 2, 1, 0, 1, 0, …\n$ job_mths <dbl> 6, 8, 8, 3, 1, 11, 2, 0, 1, 11, 0, 5, 1, 2, 10, 10, 4, 3, 0, …\n$ worktype <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1…\n$ cont_hrs <dbl> 45.0, 36.0, 40.0, 35.0, 40.0, 32.0, 30.0, 54.0, 37.0, 37.0, 3…\n$ act_hrs  <dbl> 45.0, 36.0, 40.0, 35.0, 41.0, 32.0, 30.0, 54.0, 37.0, 37.0, 3…\n$ gender   <int> 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1…\n$ dobm     <int> 7, 1, 2, 4, 2, 8, 3, 5, 12, 11, 1, 12, 11, 3, 6, 6, 3, 5, 3, …\n$ doby     <int> 83, 58, 82, 78, 73, 75, 72, 85, 70, 70, 77, 77, 74, 68, 88, 8…\n$ status   <int> 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ youngdep <int> 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2…\n$ elderdep <int> 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ qualif   <int> 5, 5, 4, 5, 4, 5, 4, 5, 2, 2, 2, 3, 2, 5, 2, 1, 1, 2, 3, 5, 2…\n$ exercise <int> 4, 2, 6, 3, 2, 6, 4, 3, 1, 3, 3, 2, 4, 1, 4, 3, 3, 4, 5, 2, 4…\n$ cigs     <int> 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 4…\n$ alcohol  <dbl> 1, 0, 0, 2, 3, 4, 0, 0, 1, 4, 0, 10, 40, 30, 10, 0, 15, 0, 15…\n$ time_rel <int> 2, 2, 1, 2, 2, 5, 1, 3, 1, 2, 3, 2, 2, 1, 2, 4, 2, 3, 1, 2, 3…\n$ when_rel <int> 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 4, 2, 1, 2, 1, 1…\n$ job1     <int> 5, 5, 1, 6, 1, 3, 5, 4, 6, 6, 5, 5, 4, 6, 4, 5, 5, 5, 4, 5, 5…\n$ job2     <int> 4, 7, 4, 4, 1, 4, 4, 1, 2, 6, 3, 2, 3, 2, 1, 2, 4, 6, 4, 5, 3…\n$ job3     <int> 5, 4, 7, 5, 5, 5, 6, 7, 4, 7, 1, 4, 3, 2, 4, 3, 1, 6, 3, 5, 6…\n$ job4     <int> 4, 3, 1, 5, 5, 3, 7, 7, 5, 6, 7, 7, 3, 6, 6, 6, 6, 6, 4, 3, 2…\n$ job5     <int> 6, 6, 1, 6, 1, 4, 5, 7, 4, 7, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 5…\n$ job6     <int> 4, 2, 1, 4, 2, 3, 5, 1, 2, 7, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1…\n$ job7     <int> 7, 1, 7, 5, 2, 4, 4, 5, 4, 6, 5, 6, 5, 7, 4, 4, 7, 5, 6, 7, 7…\n$ job8     <int> 7, 4, 7, 5, 2, 3, 5, 5, 6, 7, 7, 6, 4, 6, 5, 4, 6, 6, 5, 3, 6…\n$ job9     <int> 4, 5, 3, 5, 5, 5, 6, 7, 2, 7, 3, 4, 6, 2, 1, 2, 1, 5, 2, 6, 3…\n$ job10    <int> 7, 6, 1, 6, 2, 4, 5, 7, 4, 7, 6, 6, 6, 6, 6, 4, 4, 5, 5, 6, 4…\n$ job11    <int> 4, 1, 7, 5, 3, 3, 6, 1, 5, 7, 3, 5, 5, 6, 6, 4, 5, 5, 6, 4, 6…\n$ job12    <int> 4, 5, 4, 3, 3, 3, 3, 1, 4, 7, 4, 2, 1, 4, 2, 2, 2, 2, 2, 2, 2…\n$ job13    <int> 1, 4, 1, 4, 4, 4, 4, 1, 5, 7, 3, 4, 2, 7, 1, 4, 2, 4, 4, 6, 4…\n$ job14    <int> 4, 5, 7, 2, 6, 1, 2, 1, 1, 7, 7, 6, 4, 6, 4, 4, 7, 4, 6, 6, 4…\n$ job15    <int> 4, 7, 3, 7, 2, 6, 6, 7, 5, 5, 4, 4, 7, 6, 3, 5, 5, 4, 4, 3, 5…\n$ job16    <int> 6, 5, 1, 2, 2, 3, 3, 7, 4, 5, 6, 6, 6, 6, 5, 4, 4, 6, 5, 6, 3…\n$ job17    <int> 4, 1, 1, 4, 2, 5, 3, 7, 3, 7, 2, 2, 3, 2, 1, 2, 2, 2, 1, 2, 3…\n$ job18    <int> 7, 7, 7, 6, 3, 5, 5, 3, 6, 2, 3, 5, 5, 6, 5, 5, 6, 6, 4, 5, 3…\n$ job19    <int> 7, 1, 7, 7, 2, 6, 7, 3, 6, 2, 1, 2, 2, 6, 1, 5, 5, 6, 2, 2, 2…\n$ job20    <int> 3, 5, 7, 5, 1, 3, 7, 6, 3, 3, 4, 3, 3, 4, 3, 6, 1, 5, 3, 6, 5…\n$ job21    <int> 4, 1, 7, 5, 1, 3, 3, 1, 5, 6, 3, 5, 5, 6, 4, 4, 3, 5, 4, 2, 5…\n$ job22    <int> 3, 1, 1, 2, 4, 1, 2, 1, 2, 6, 2, 5, 2, 2, 1, 6, 1, 5, 3, 5, 3…\n$ job23    <int> 5, 1, 2, 4, 6, 3, 6, 1, 5, 7, 2, 5, 6, 4, 4, 2, 4, 5, 5, 6, 6…\n$ job24    <int> 4, 4, 5, 4, 2, 4, 4, 4, 5, 6, 4, 6, 4, 2, 3, 6, 5, 6, 5, 4, 2…\n$ job25    <int> 4, 5, 6, 5, 3, 2, 3, 7, 5, 4, 5, 5, 5, 3, 4, 6, 4, 6, 4, 6, 3…\n$ job26    <int> 7, 6, 7, 3, 6, 5, 6, 7, 6, 4, 1, 5, 6, 6, 4, 6, 4, 4, 5, 4, 4…\n$ job27    <int> 2, 4, 1, 2, 6, 5, 1, 1, 3, 7, 6, 3, 1, 1, 1, 2, 2, 4, 6, 6, 2…\n$ job28    <int> 3, 6, 7, 5, 2, 5, 6, 1, 4, 7, 3, 3, 5, 1, 3, 4, 1, 3, 2, 6, 5…\n$ job29    <int> 3, 3, 5, 7, 5, 6, 5, 1, 3, 7, 4, 4, 3, 2, 2, 4, 3, 3, 5, 5, 3…\n$ job30    <int> 4, 3, 6, 5, 1, 2, 3, 6, 6, 4, 7, 6, 4, 4, 3, 4, 4, 6, 4, 2, 3…\n$ job31    <int> 5, 1, 5, 3, 4, 5, 4, 1, 5, 5, 5, 3, 4, 6, 5, 6, 6, 6, 5, 4, 2…\n$ job32    <int> 5, 7, 3, 2, 2, 1, 3, 2, 6, 5, 5, 5, 4, 7, 5, 5, 5, 6, 5, 5, 5…\n$ job33    <int> 6, 4, 6, 5, 4, 3, 7, 4, 6, 4, 6, 3, 4, 2, 3, 6, 6, 6, 4, 2, 2…\n$ job34    <int> 4, 6, 5, 7, 4, 5, 6, 1, 5, 5, 2, 2, 2, 2, 3, 5, 5, 5, 1, 2, 4…\n$ job35    <int> 4, 6, 3, 5, 4, 1, 3, 1, 5, 6, 5, 5, 4, 6, 5, 4, 5, 5, 7, 5, 6…\n$ job36    <int> 4, 1, 2, 3, 2, 5, 2, 1, 5, 6, 5, 3, 4, 6, 5, 6, 6, 5, 7, 5, 5…\n$ job37    <int> 4, 5, 1, 3, 2, 3, 3, 7, 3, 6, 7, 4, 6, 7, 4, 5, 6, 5, 6, 5, 5…\n$ job38    <int> 4, 5, 5, 2, 2, 1, 3, 1, 3, 7, 7, 5, 6, 7, 3, 6, 6, 5, 6, 5, 5…\n$ job39    <int> 5, 7, 5, 7, 2, 5, 6, 7, 6, 5, 4, 5, 6, 7, 3, 5, 5, 5, 2, 1, 4…\n$ job40    <int> 4, 3, 5, 3, 4, 3, 3, 7, 3, 6, 3, 5, 6, 7, 4, 4, 6, 6, 4, 6, 1…\n$ job41    <int> 6, 5, 3, 5, 1, 1, 3, 1, 5, 7, 3, 5, 5, 6, 4, 5, 7, 6, 5, 6, 5…\n$ job42    <int> 6, 4, 5, 4, 5, 3, 4, 1, 4, 5, 4, 6, 5, 7, 4, 5, 5, 6, 4, 3, 5…\n$ job43    <int> 6, 1, 7, 3, 4, 5, 1, 2, 3, 7, 2, 6, 4, 6, 5, 4, 7, 6, 2, 6, 4…\n$ job44    <int> 6, 4, 6, 5, 2, 3, 7, 1, 5, 7, 7, 6, 4, 5, 6, 5, 6, 6, 6, 5, 3…\n$ job45    <int> 6, 6, 7, 7, 6, 3, 6, 7, 6, 7, 5, 4, 6, 6, 5, 6, 4, 6, 4, 2, 6…\n$ job46    <int> 3, 1, 2, 3, 6, 6, 3, 7, 3, 5, 5, 2, 2, 2, 1, 2, 2, 5, 1, 1, 2…\n$ job47    <int> 3, 4, 5, 5, 1, 3, 3, 3, 3, 6, 5, 5, 4, 4, 3, 6, 5, 5, 4, 4, 3…\n$ job48    <int> 3, 7, 7, 7, 6, 4, 6, 7, 5, 6, 5, 3, 6, 3, 4, 5, 4, 5, 3, 1, 6…\n$ job49    <int> 6, 5, 5, 6, 2, 2, 5, 2, 6, 7, 5, 3, 6, 6, 7, 6, 7, 6, 6, 6, 7…\n$ job50    <int> 3, 5, 1, 3, 1, 7, 4, 1, 5, 6, 5, 4, 4, 5, 1, 2, 5, 3, 4, 5, 7…\n\n\n\n\nSanity Checks\nProduce a table of summary statistics for the variables in the data.\n\n\nCode\ndf %>%\n    summarise(across(everything(), \n                     list(M = mean, SD = sd, MIN = min, MAX = max))) %>%\n    pivot_longer(everything())\n\n\n# A tibble: 268 × 2\n   name          value\n   <chr>         <dbl>\n 1 job_yrs_M     4.03 \n 2 job_yrs_SD    5.86 \n 3 job_yrs_MIN  -1    \n 4 job_yrs_MAX  37    \n 5 job_mths_M   NA    \n 6 job_mths_SD  NA    \n 7 job_mths_MIN NA    \n 8 job_mths_MAX NA    \n 9 worktype_M    1.24 \n10 worktype_SD   0.427\n# … with 258 more rows\n\n\nWe can see that there are a few missing values in some variables.\nIf you were to analyse this data for a research project hopefully leading to a paper, you would probably want to perform sanity check on the variables, such as check if everyone is an adult (assuming this was a requirement for partaking of the study).\nCheck whether all participants in the study are adults.\n\n\nCode\nunique(df$doby)\n\n\n [1]   83   58   82   78   73   75   72   85   70   77   74   68   88   81   90\n[16]   59   89   87   80   86   84   67   79   55   71   56   57   62   61   91\n[31]   52   63   69   60   53   76   50   49   64   NA   54    0   66   35   65\n[46]   47   48   45   51   46 1979 1982 1980 1975 1969 1981 1973 1946   -1   43\n[61]   44   42 1971 1976 1983 1965 1985 1955 1950 1974 1984\n\n\nThe data look like a bit of a mess.. Some participants have the full year of birth, some only the last 2 digits. Let’s only extract the last 2 digits from all rows then.\nLet’s use the str_sub() function to take only the last 2 characters.\n\n\nCode\ndf <- df %>%\n    mutate(doby = str_sub(doby, -2, -1))\n\n\nIt seems like it’s now a character rather than a number:\n\n\nCode\nclass(df$doby)\n\n\n[1] \"character\"\n\n\nLet’s make it a number again:\n\n\nCode\ndf$doby <- as.numeric(df$doby)\n\n\nVisualise the distribution of birth year. Do we notice anything strange?\n\n\nCode\nggplot(df, aes(x = doby)) + \n    geom_histogram(color = 'white')\n\n\n\n\n\n\n\n\n\nOr a dotplot if you prefer:\n\n\nCode\nggplot(df, aes(x = doby)) + \n    geom_dotplot(dotsize = 0.6, binwidth = 1, fill = 'dodgerblue', color = NA)\n\n\n\n\n\n\n\n\n\nA year of birth equal to −1 doesn’t make any sense and, since we only want to keep adults, we will remove the rows in the data set having a year of birth equal to -1.\nIn the meantime, we will also remove those participants who don’t have a value for doby.\n\n\nCode\ndf <- df %>%\n    filter(!is.na(doby) | doby > 0)\n\nhist(df$doby)\n\n\n\n\n\n\n\n\n\nThat looks much better!\nNormally, you’d want to check other variables too. For now, because we are focusing on EFA, we’ll just assume that the other variables are okay.\n\n\nSubset\nRemember that the only variables we are interested in for our EFA are the job1 to job50 variables. We need to subset the data set to only include those variables.\n\n\nCode\ndf <- df %>%\n    select(job1:job50)\n\n\nCreate a table of descriptive summary statistics for each variable.\n\n\nCode\nlibrary(psych)\ndescribe(df)\n\n\n      vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\njob1     1 943 4.20 2.43      4    4.18 1.48  -1  55    56  9.62   201.28 0.08\njob2     2 943 3.76 2.00      4    3.71 2.97  -1   7     8  0.07    -1.29 0.06\njob3     3 943 4.33 2.05      5    4.41 2.97  -1   7     8 -0.24    -1.24 0.07\njob4     4 943 4.05 2.04      4    4.06 2.97  -1   7     8 -0.08    -1.29 0.07\njob5     5 943 4.77 2.11      5    4.89 1.48   0  36    36  3.05    49.63 0.07\njob6     6 943 3.38 2.00      3    3.25 2.97   1   7     6  0.34    -1.20 0.07\njob7     7 943 3.79 2.13      4    3.74 2.97  -1   7     8  0.04    -1.38 0.07\njob8     8 943 4.47 1.72      5    4.55 1.48  -1   7     8 -0.47    -0.66 0.06\njob9     9 943 4.06 1.99      4    4.08 2.97  -1   7     8 -0.06    -1.18 0.06\njob10   10 943 4.52 1.80      5    4.63 1.48   0   7     7 -0.44    -0.81 0.06\njob11   11 943 4.68 1.78      5    4.81 1.48   1   7     6 -0.60    -0.69 0.06\njob12   12 943 3.67 2.03      4    3.59 2.97   0   7     7  0.21    -1.25 0.07\njob13   13 943 3.76 1.94      4    3.71 2.97  -1   7     8  0.10    -1.15 0.06\njob14   14 943 4.77 2.45      5    4.88 1.48   1  52    51  7.34   144.84 0.08\njob15   15 943 3.91 1.91      4    3.89 2.97  -1  14    15  0.08    -0.34 0.06\njob16   16 943 4.11 1.77      4    4.17 1.48  -1   7     8 -0.23    -0.97 0.06\njob17   17 943 3.73 1.97      3    3.66 2.97   1   7     6  0.18    -1.27 0.06\njob18   18 943 4.20 1.79      5    4.26 1.48  -1   7     8 -0.29    -0.97 0.06\njob19   19 943 2.83 1.89      2    2.61 1.48  -1   7     8  0.73    -0.67 0.06\njob20   20 943 4.02 1.98      4    4.03 2.97  -1   7     8 -0.07    -1.15 0.06\njob21   21 943 4.35 1.66      5    4.42 1.48  -1   7     8 -0.40    -0.50 0.05\njob22   22 943 3.60 1.90      3    3.54 1.48  -1   7     8  0.24    -1.11 0.06\njob23   23 943 4.06 1.88      4    4.08 2.97  -1   7     8 -0.10    -1.15 0.06\njob24   24 943 3.83 1.69      4    3.86 1.48  -1   7     8 -0.11    -0.76 0.06\njob25   25 943 3.97 1.77      4    3.99 1.48  -1   7     8 -0.15    -0.65 0.06\njob26   26 943 4.13 1.81      4    4.17 2.97   0   7     7 -0.20    -1.07 0.06\njob27   27 943 3.84 2.22      4    3.80 2.97   1   7     6  0.11    -1.45 0.07\njob28   28 943 3.79 2.02      4    3.74 2.97   1   7     6  0.16    -1.26 0.07\njob29   29 943 4.55 1.76      5    4.63 1.48  -1   7     8 -0.38    -0.80 0.06\njob30   30 943 3.99 1.92      4    3.98 2.97   1   7     6 -0.10    -1.16 0.06\njob31   31 943 4.20 2.00      4    4.25 2.97  -1   7     8 -0.22    -1.21 0.07\njob32   32 943 5.14 1.47      5    5.29 1.48   0   7     7 -0.78     0.24 0.05\njob33   33 943 3.59 1.80      4    3.55 2.97  -1   7     8  0.13    -0.99 0.06\njob34   34 943 3.56 1.86      4    3.50 2.97   0   7     7  0.14    -1.13 0.06\njob35   35 943 4.89 1.51      5    5.02 1.48  -1   7     8 -0.84     0.51 0.05\njob36   36 943 4.52 1.81      5    4.63 1.48  -1   7     8 -0.46    -0.79 0.06\njob37   37 943 4.32 1.96      5    4.40 1.48   1   7     6 -0.33    -1.13 0.06\njob38   38 943 4.44 1.87      5    4.54 1.48  -1   7     8 -0.45    -0.93 0.06\njob39   39 943 3.83 1.85      4    3.83 1.48  -1   7     8 -0.07    -1.08 0.06\njob40   40 943 4.29 1.86      4    4.36 2.97  -1   7     8 -0.30    -0.96 0.06\njob41   41 943 4.73 1.55      5    4.84 1.48   1   7     6 -0.60    -0.17 0.05\njob42   42 943 4.20 1.59      5    4.27 1.48   1   8     7 -0.36    -0.72 0.05\njob43   43 943 3.52 1.96      3    3.43 2.97  -1   7     8  0.21    -1.16 0.06\njob44   44 943 3.75 1.88      4    3.71 2.97  -1   7     8  0.07    -1.06 0.06\njob45   45 943 4.50 1.77      5    4.60 1.48  -1   7     8 -0.50    -0.60 0.06\njob46   46 943 3.46 2.05      3    3.36 2.97  -1   7     8  0.23    -1.29 0.07\njob47   47 943 3.71 1.61      4    3.74 1.48  -1   7     8 -0.08    -0.81 0.05\njob48   48 943 4.38 1.94      5    4.48 1.48  -1   7     8 -0.36    -1.09 0.06\njob49   49 943 5.68 1.33      6    5.88 1.48  -1   7     8 -1.34     1.93 0.04\njob50   50 943 4.18 1.97      5    4.23 1.48  -1   7     8 -0.27    -1.17 0.06\n\n\nSome of the variables appear to have values of 0, −1, as well as values larger than 7, even though all the questionnaire items are on a 7-point Likert scale.\nGet rid of infeasible values:\n\n\nCode\ndf[df < 1 | df > 7] <- NA\n\n\n\n\nDescriptives & Visualising\nLet’s now look at the score distributions per item and the correlations between pairs of items.\nSometimes easier to use subsets of ten variables each time. For example, look at the pairwise plots of the first 10 variables, then the next 10, and so on.\n\n\nCode\npairs.panels(df[, 1:10])\n\n\n\n\n\n\n\n\n\nCode\npairs.panels(df[, 11:20])\n\n\n\n\n\n\n\n\n\nCode\npairs.panels(df[, 21:30])\n\n\n\n\n\n\n\n\n\nCode\npairs.panels(df[, 31:40])\n\n\n\n\n\n\n\n\n\nCode\npairs.panels(df[, 41:50])\n\n\n\n\n\n\n\n\n\nAs you can see, while some of the items have pretty much bell-shaped distributions, some others are massively skewed (looking at you job49) or close to uniform (job9). At this stage, you’d want to have a closer look at the wording of these troublesome items and see if you can spot any methodological issues that might account for these distributions. If the items look fine, you might want to consider alternative correlation coefficients (e.g., polychoric correlations) that might be more suitable to items with weird distributions. For now, let’s stick to Pearson’s correlation (r). Since we have NAs in the data, let’s just use complete observations.\nCompute the correlation matrix of the variables.\nInstead of looking at the \\(50 \\times 50\\) matrix of correlations, look at the distribution of correlation coefficients from the lower triangular part of the matrix.\nOption 1:\n\n\nCode\nR <- cor(df, use = \"complete.obs\")\n\n\nOption 2:\n\n\nCode\nR <- cor(na.omit(df))\n\n\n\n\nCode\nhist(R[lower.tri(R)])\n\n\n\n\n\n\n\n\n\nIf you want to be a little fancier, you can categorise the coefficients into negligible, weak, moderate, and strong correlations and plot a bar plot like this:\n\n\nCode\nRc <- cut(abs(R), \n          breaks = c(0, .2, .5, .7, 1), \n          labels = c(\"negligible\", \"weak\", \"moderate\", \"strong\"))\n\nbarplot(table(Rc[lower.tri(Rc)]))\n\n\n\n\n\n\n\n\n\nAs we can see, most of the correlations are negligible and many are weak. There are some moderate and strong relationships in the data. This suggests that there might be multiple independent factors.\n\n\nSuitability for FA\nCheck if the correlations are sufficient for EFA with Bartlett’s test of sphericity and if the sample was adequate with KMO.\n\n\nCode\ncortest.bartlett(R, \n                 n = sum(complete.cases(df))) # we have 917 complete cases\n\n\n$chisq\n[1] 18702.7\n\n$p.value\n[1] 0\n\n$df\n[1] 1225\n\n\n\n\nCode\nKMO(R)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = R)\nOverall MSA =  0.89\nMSA for each item = \n job1  job2  job3  job4  job5  job6  job7  job8  job9 job10 job11 job12 job13 \n 0.95  0.77  0.76  0.88  0.88  0.81  0.91  0.93  0.77  0.84  0.74  0.93  0.80 \njob14 job15 job16 job17 job18 job19 job20 job21 job22 job23 job24 job25 job26 \n 0.76  0.93  0.90  0.76  0.92  0.87  0.87  0.89  0.92  0.79  0.93  0.95  0.93 \njob27 job28 job29 job30 job31 job32 job33 job34 job35 job36 job37 job38 job39 \n 0.92  0.85  0.78  0.95  0.80  0.79  0.90  0.88  0.82  0.76  0.76  0.83  0.91 \njob40 job41 job42 job43 job44 job45 job46 job47 job48 job49 job50 \n 0.93  0.84  0.96  0.91  0.91  0.95  0.81  0.94  0.94  0.85  0.90 \n\n\nA significant Bartlett’s test of sphericity means that our correlation matrix is not proportional to an identity matrix (a matrix with only 1s on the diagonal and 0s everywhere else). This is exactly what we want, so we’re happy!\nLikewise, the sampling adequacy is pretty good. All items have a measure of sampling adequacy (MSA) in the \\(>.7\\) “middling” region and the overall KMO is bordering on the \\(>.9\\) “marvellous” level (I kid you not).\nGiven these results, we can merrily factor-analyse!\n\n\nNumber of Factors\nIn order to decide how many factors to use, look at the suggestions given by parallel analysis and MAP.\n\n\nCode\nfa.parallel(df, fa = 'fa')\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  11  and the number of components =  NA \n\n\n\n\nCode\nVSS(df)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.68  with  2  factors\nVSS complexity 2 achieves a maximimum of 0.78  with  5  factors\n\nThe Velicer MAP achieves a minimum of 0.01  with  7  factors \nBIC achieves a minimum of  -2604.78  with  8  factors\nSample Size adjusted BIC achieves a minimum of  104.3  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2    map  dof chisq     prob sqresid  fit RMSEA   BIC SABIC complex\n1 0.63 0.00 0.0149 1175 11124  0.0e+00      59 0.63 0.095  3076  6808     1.0\n2 0.68 0.71 0.0136 1126  9339  0.0e+00      47 0.71 0.088  1627  5203     1.1\n3 0.59 0.75 0.0119 1078  7703  0.0e+00      37 0.77 0.081   320  3743     1.4\n4 0.51 0.76 0.0103 1031  6309  0.0e+00      30 0.81 0.074  -753  2522     1.6\n5 0.51 0.78 0.0085  985  4953  0.0e+00      25 0.85 0.065 -1793  1335     1.7\n6 0.50 0.75 0.0086  940  4248  0.0e+00      22 0.86 0.061 -2191   795     1.9\n7 0.46 0.72 0.0084  896  3660  0.0e+00      20 0.87 0.057 -2477   369     2.0\n8 0.46 0.70 0.0086  853  3237 1.3e-273      19 0.88 0.054 -2605   104     2.0\n  eChisq  SRMR eCRMS  eBIC\n1  23561 0.101 0.103 15513\n2  16220 0.084 0.087  8508\n3  10627 0.068 0.072  3243\n4   7270 0.056 0.061   208\n5   4414 0.044 0.049 -2332\n6   3488 0.039 0.044 -2950\n7   2746 0.034 0.040 -3391\n8   2167 0.031 0.037 -3675\n\n\nSince parallel analysis (suggesting 11 factor) tends to overextract and MAP (suggesting 6-8 factors) can sometimes underextract, it is reasonable to look at solutions with 7-10 factors. However, looking at the scree plot, it might be reasonable to cast a glance on a 5- or 6-factor solution.\n\n\nPerform EFA\nFit a factor analysis model to the data using 10 factors. Since there is no good reason to expect the factors to be uncorrelated (orthogonal), let’s use the oblimin rotation.\n\n\nCode\nm_10f <- fa(df, nfactors = 10, rotate = \"oblimin\", fm = \"ml\")\n\n\nPrint loadings sorted according to loadings\n\n\nCode\nfa.sort(m_10f)\n\n\nFactor Analysis using method =  ml\nCall: fa(r = df, nfactors = 10, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n        ML1   ML3   ML2   ML4   ML5   ML6   ML7   ML9   ML8  ML10   h2   u2 com\njob42  0.72 -0.10  0.02 -0.02  0.10 -0.06 -0.15 -0.02  0.15  0.03 0.59 0.41 1.3\njob25  0.68 -0.09  0.11  0.01  0.00 -0.17  0.00 -0.15  0.03  0.07 0.53 0.47 1.4\njob45  0.66  0.08 -0.09 -0.08  0.09 -0.21  0.13  0.03 -0.11 -0.01 0.54 0.46 1.5\njob18  0.65 -0.13  0.13 -0.06  0.11 -0.02 -0.20  0.11  0.33 -0.06 0.64 0.36 2.1\njob15  0.65  0.11 -0.08 -0.13  0.15 -0.37  0.19 -0.03 -0.09 -0.05 0.67 0.33 2.2\njob47  0.63  0.02  0.01 -0.13  0.07  0.00 -0.12 -0.16  0.12 -0.02 0.48 0.52 1.4\njob39  0.61  0.17 -0.13 -0.12  0.17 -0.27  0.17 -0.10 -0.09  0.05 0.58 0.42 2.3\njob24  0.60 -0.07  0.32 -0.10  0.04  0.15 -0.09  0.01 -0.12  0.01 0.53 0.47 2.0\njob1   0.60 -0.11  0.16 -0.10  0.04 -0.11 -0.05 -0.06  0.15  0.22 0.50 0.50 1.8\njob26  0.59  0.11 -0.18 -0.22  0.11 -0.04 -0.03 -0.12  0.10 -0.05 0.49 0.51 1.9\njob8   0.59 -0.12  0.05  0.08  0.09  0.04 -0.16  0.14  0.25 -0.06 0.49 0.51 1.9\njob38  0.58  0.22 -0.48  0.05 -0.19  0.18 -0.15 -0.11 -0.08  0.15 0.75 0.25 3.3\njob48  0.55  0.05 -0.01  0.00 -0.02 -0.11  0.10 -0.13 -0.03  0.03 0.35 0.65 1.3\njob33  0.55 -0.04  0.41 -0.16  0.12  0.19 -0.07  0.15 -0.26 -0.04 0.65 0.35 3.3\njob44  0.55  0.03  0.42 -0.05  0.05  0.24 -0.06  0.14 -0.26 -0.04 0.63 0.37 3.1\njob30  0.51 -0.09  0.15 -0.07  0.09 -0.07 -0.13  0.05  0.04  0.21 0.38 0.62 2.0\njob12 -0.50  0.29  0.12  0.04  0.13  0.26 -0.10  0.01  0.13  0.05 0.47 0.53 2.9\njob40  0.50  0.01 -0.27  0.03 -0.06  0.00 -0.07 -0.07  0.02 -0.06 0.34 0.66 1.7\njob16  0.47 -0.06  0.17  0.03 -0.31  0.09  0.25 -0.11  0.19 -0.01 0.47 0.53 3.4\njob5   0.47 -0.06  0.30  0.04 -0.35  0.21  0.34 -0.04  0.09  0.00 0.61 0.39 4.2\njob43  0.46 -0.03  0.23 -0.03 -0.06  0.04 -0.21 -0.07  0.19  0.12 0.37 0.63 2.7\njob22 -0.46  0.07  0.13 -0.03 -0.10  0.27 -0.10  0.01  0.07  0.16 0.35 0.65 2.4\njob10  0.45 -0.02  0.23  0.13 -0.42  0.26  0.35 -0.01  0.18  0.00 0.67 0.33 4.7\njob27 -0.44 -0.04 -0.08  0.00  0.14  0.26 -0.05 -0.02  0.19  0.08 0.33 0.67 2.5\njob34  0.37  0.22 -0.07 -0.18  0.29 -0.20  0.24  0.04 -0.03 -0.05 0.41 0.59 4.9\njob19  0.36 -0.01  0.29 -0.32  0.18  0.04 -0.13  0.04  0.17 -0.08 0.40 0.60 4.4\njob7   0.33  0.00  0.16 -0.06  0.17  0.07 -0.12 -0.03  0.09  0.08 0.20 0.80 2.9\njob21  0.33  0.22 -0.14  0.12  0.20 -0.02  0.17  0.18  0.06  0.02 0.30 0.70 4.9\njob50 -0.33  0.18  0.01  0.11  0.02 -0.06  0.03  0.00 -0.01  0.09 0.16 0.84 2.2\njob20 -0.28  0.14 -0.26  0.12  0.08 -0.01  0.11  0.00  0.21 -0.13 0.26 0.74 4.9\njob3   0.05  0.59  0.26  0.09 -0.32 -0.22 -0.15 -0.01  0.06 -0.03 0.61 0.39 2.6\njob28 -0.06  0.58  0.18  0.03 -0.08 -0.16 -0.06  0.08  0.03 -0.13 0.44 0.56 1.6\njob13 -0.12  0.53  0.25  0.17 -0.27 -0.18 -0.16  0.04 -0.01  0.09 0.53 0.47 3.0\njob9   0.11  0.53  0.26  0.13 -0.32 -0.25 -0.06  0.05  0.00 -0.04 0.55 0.45 3.1\njob2  -0.07  0.49  0.05  0.03 -0.19 -0.10 -0.16  0.12  0.09 -0.23 0.40 0.60 2.5\njob46 -0.10  0.49  0.17 -0.15  0.29  0.18  0.14 -0.17  0.04  0.01 0.47 0.53 3.2\njob6  -0.22  0.46  0.29 -0.06  0.34  0.25  0.05 -0.09  0.04 -0.01 0.53 0.47 4.1\njob17 -0.22  0.44  0.27 -0.14  0.42  0.22  0.14 -0.22  0.09  0.01 0.63 0.37 4.9\njob29 -0.06  0.34  0.18 -0.02  0.25  0.05  0.04  0.04 -0.01  0.21 0.26 0.74 3.4\njob37  0.48  0.28 -0.62 -0.11 -0.08  0.31 -0.04  0.01 -0.06 -0.08 0.82 0.18 3.1\njob4   0.45  0.01  0.48  0.02 -0.13  0.16 -0.02  0.11 -0.29  0.03 0.57 0.43 3.2\njob36  0.26 -0.09  0.11  0.71  0.14  0.04 -0.08 -0.29 -0.07 -0.17 0.74 0.26 2.0\njob35  0.23  0.11 -0.10  0.55  0.24  0.00  0.08  0.21  0.02  0.18 0.51 0.49 2.7\njob32  0.21  0.10 -0.13  0.49  0.12  0.00  0.09  0.23  0.04  0.24 0.45 0.55 3.0\njob41  0.26  0.10 -0.20  0.48  0.24  0.01  0.09  0.17  0.02  0.09 0.45 0.55 3.2\njob31  0.28 -0.19  0.19  0.42  0.10  0.03 -0.14 -0.25 -0.08 -0.13 0.44 0.56 4.4\njob49  0.30 -0.02 -0.15  0.40  0.05  0.02  0.03  0.22  0.04 -0.04 0.33 0.67 2.9\njob14 -0.02  0.23 -0.03  0.39  0.14  0.00  0.01 -0.07 -0.08  0.18 0.27 0.73 2.6\njob11  0.21  0.05 -0.08  0.17  0.22  0.12  0.14  0.33  0.11 -0.29 0.37 0.63 5.5\njob23  0.21 -0.01  0.07  0.05  0.21  0.08  0.01  0.24  0.12 -0.15 0.19 0.81 4.8\n\n                       ML1  ML3  ML2  ML4  ML5  ML6  ML7  ML9  ML8 ML10\nSS loadings           9.48 2.90 2.56 2.28 1.86 1.32 0.96 0.86 0.85 0.66\nProportion Var        0.19 0.06 0.05 0.05 0.04 0.03 0.02 0.02 0.02 0.01\nCumulative Var        0.19 0.25 0.30 0.34 0.38 0.41 0.43 0.44 0.46 0.47\nProportion Explained  0.40 0.12 0.11 0.10 0.08 0.06 0.04 0.04 0.04 0.03\nCumulative Proportion 0.40 0.52 0.63 0.73 0.80 0.86 0.90 0.94 0.97 1.00\n\nMean item complexity =  2.9\nTest of the hypothesis that 10 factors are sufficient.\n\nThe degrees of freedom for the null model are  1225  and the objective function was  20.66 with Chi Square of  19096.72\nThe degrees of freedom for the model are 770  and the objective function was  2.45 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic number of observations is  940 with the empirical chi square  1420.85  with prob <  3e-41 \nThe total number of observations was  943  with Likelihood Chi Square =  2249.02  with prob <  1.2e-144 \n\nTucker Lewis Index of factoring reliability =  0.867\nRMSEA index =  0.045  and the 90 % confidence intervals are  0.043 0.047\nBIC =  -3024.76\nFit based upon off diagonal values = 0.99\nMeasures of factor score adequacy             \n                                                   ML1  ML3  ML2  ML4  ML5  ML6\nCorrelation of (regression) scores with factors   0.98 0.93 0.94 0.92 0.90 0.88\nMultiple R square of scores with factors          0.96 0.86 0.88 0.84 0.81 0.77\nMinimum correlation of possible factor scores     0.91 0.73 0.76 0.68 0.61 0.54\n                                                   ML7  ML9  ML8 ML10\nCorrelation of (regression) scores with factors   0.83 0.80 0.81 0.74\nMultiple R square of scores with factors          0.68 0.64 0.66 0.55\nMinimum correlation of possible factor scores     0.37 0.28 0.31 0.11\n\n\nOK, 10 factors looks like way too many as the last 2 have very few substantive loadings (>.33). Let’s look at a smaller solution, e.g. 9 or 8 factors and see if it’s still the case…\n\n\nCode\nm_9f <- fa(df, nfactors = 9, rotate = \"oblimin\", fm = \"ml\")\nm_8f <- fa(df, nfactors = 8, rotate = \"oblimin\", fm = \"ml\")\n\n\nIt was the case and even the 9-factor solution has only 1 substantive loading on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off: We can see that a few items don’t have any loadings larger than our .33 cut-off:\n\n\nCode\n# get loadings\nx <- m_9f$loadings\nwhich(rowSums(x < .33) == 9)\n\n\njob11 job12 job20 job22 job23 job27 job31 job50 \n   11    12    20    22    23    27    31    50 \n\n\nIt was the case and even the 8-factor solution has only 2 substantive loadings on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off:\n\n\nCode\n# get loadings\nx <- m_8f$loadings\nwhich(rowSums(x < .33) == 8)\n\n\n job7 job11 job14 job20 job22 job23 job27 job31 job50 \n    7    11    14    20    22    23    27    31    50 \n\n\nHere is when we would go back to the item wordings and try to see why these items might not really correlate with any other items. For instance, job11 (“I regularly discuss problems at work with my colleagues.”) might be ambiguous: does it mean that there are often problems or that if there are problems, I discuss them regularly?\nFor argument’s sake, let’s say, all of these identified items are deemed problematic so we should remove them:\n\n\nCode\ncols_to_remove <- names(which(rowSums(x < .33) == 8))\ndf2 <- df[ , !names(df) %in% cols_to_remove]\n\n\nCheck parallel analysis and MAP again.\n\n\nCode\nfa.parallel(df2, fa = 'fa')\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  9  and the number of components =  NA \n\n\n\n\nCode\nVSS(df2)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.7  with  2  factors\nVSS complexity 2 achieves a maximimum of 0.81  with  5  factors\n\nThe Velicer MAP achieves a minimum of 0.01  with  8  factors \nBIC achieves a minimum of  -1789.88  with  8  factors\nSample Size adjusted BIC achieves a minimum of  -138.4  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq     prob sqresid  fit RMSEA   BIC SABIC complex\n1 0.64 0.00 0.018 779  9036  0.0e+00      46 0.64 0.106  3701  6175     1.0\n2 0.70 0.73 0.016 739  7329  0.0e+00      34 0.73 0.097  2267  4614     1.1\n3 0.58 0.77 0.014 700  5910  0.0e+00      27 0.79 0.089  1116  3339     1.4\n4 0.52 0.78 0.013 662  4724  0.0e+00      21 0.83 0.081   190  2292     1.7\n5 0.55 0.81 0.010 625  3568  0.0e+00      17 0.87 0.071  -713  1272     1.6\n6 0.55 0.80 0.011 589  2958 5.5e-311      15 0.88 0.065 -1076   795     1.7\n7 0.50 0.74 0.010 554  2316 2.0e-213      14 0.89 0.058 -1478   281     1.7\n8 0.46 0.73 0.010 520  1772 4.4e-136      12 0.90 0.051 -1790  -138     1.8\n  eChisq  SRMR eCRMS  eBIC\n1  18464 0.109 0.112 13129\n2  11631 0.087 0.091  6569\n3   7521 0.070 0.075  2726\n4   4842 0.056 0.062   308\n5   2772 0.042 0.048 -1509\n6   2045 0.036 0.043 -1989\n7   1429 0.030 0.037 -2365\n8   1013 0.026 0.032 -2548\n\n\nFit an 8-factor model to the new dataset.\n\n\nCode\nm_8f <- fa(df2, nfactors = 8, rotate = \"oblimin\", fm = \"ml\")\nfa.sort(m_8f)\n\n\nFactor Analysis using method =  ml\nCall: fa(r = df2, nfactors = 8, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n        ML1   ML2   ML3   ML4   ML5   ML6   ML7   ML8   h2    u2 com\njob37  0.82 -0.51  0.05  0.01 -0.10  0.02 -0.02 -0.01 0.94 0.056 1.7\njob38  0.74 -0.20  0.01  0.15  0.05 -0.01 -0.06  0.03 0.61 0.388 1.3\njob26  0.61  0.10  0.02 -0.22  0.07 -0.14  0.02  0.14 0.48 0.520 1.6\njob42  0.60  0.40 -0.13 -0.09  0.11 -0.01 -0.13  0.19 0.60 0.397 2.4\njob45  0.60  0.26  0.00 -0.11  0.21 -0.11  0.09 -0.15 0.52 0.477 2.1\njob39  0.58  0.21  0.06 -0.21  0.30 -0.18  0.18 -0.15 0.60 0.398 2.9\njob15  0.57  0.29  0.02 -0.19  0.32 -0.26  0.16 -0.18 0.68 0.322 3.5\njob47  0.55  0.30 -0.01 -0.14  0.01 -0.08 -0.05  0.19 0.46 0.539 2.0\njob40  0.54  0.01 -0.12  0.06  0.09 -0.06 -0.03  0.05 0.32 0.677 1.2\njob25  0.51  0.46 -0.08 -0.01  0.11 -0.10  0.03  0.05 0.51 0.492 2.2\njob18  0.51  0.43 -0.10 -0.09  0.02  0.02 -0.19  0.32 0.60 0.397 3.2\njob48  0.47  0.27  0.01  0.00  0.12 -0.08  0.13  0.00 0.33 0.667 2.0\njob8   0.47  0.34 -0.11  0.01  0.06  0.12 -0.17  0.24 0.45 0.545 3.0\njob12 -0.41 -0.25  0.34 -0.06 -0.10  0.19 -0.07  0.14 0.41 0.586 3.7\njob16  0.37  0.34 -0.01  0.27 -0.17 -0.06  0.30  0.13 0.47 0.528 4.6\njob34  0.36  0.12  0.15 -0.31  0.27 -0.10  0.20 -0.13 0.40 0.602 4.7\njob21  0.34  0.03  0.12 -0.04  0.29  0.15  0.11 -0.03 0.25 0.746 3.0\njob4   0.27  0.52  0.19  0.12 -0.28  0.13 -0.12 -0.29 0.58 0.420 3.7\njob24  0.43  0.51  0.04 -0.09 -0.20  0.09 -0.11 -0.06 0.52 0.479 2.6\njob44  0.39  0.51  0.19 -0.06 -0.27  0.22 -0.18 -0.26 0.68 0.325 4.4\njob33  0.38  0.51  0.12 -0.18 -0.26  0.15 -0.16 -0.21 0.61 0.393 3.9\njob1   0.44  0.46 -0.08 -0.08  0.05 -0.08 -0.01  0.15 0.45 0.547 2.4\njob5   0.34  0.42  0.04  0.32 -0.30  0.03  0.34  0.02 0.61 0.390 4.8\njob30  0.37  0.40 -0.06 -0.10  0.05  0.00 -0.13  0.05 0.33 0.669 2.5\njob43  0.33  0.39  0.04  0.03 -0.08 -0.04 -0.14  0.22 0.34 0.661 3.1\njob19  0.25  0.37  0.09 -0.31 -0.16 -0.09 -0.11  0.15 0.37 0.629 4.2\njob3   0.02  0.10  0.62  0.33  0.12 -0.27 -0.13  0.06 0.61 0.388 2.2\njob28 -0.03 -0.02  0.59  0.10  0.15 -0.16 -0.08  0.00 0.42 0.583 1.4\njob6  -0.20 -0.04  0.57 -0.32 -0.06  0.27  0.08  0.12 0.57 0.432 2.6\njob13 -0.14  0.04  0.56  0.32  0.16 -0.15 -0.15 -0.02 0.51 0.486 2.3\njob9   0.06  0.15  0.56  0.35  0.15 -0.23 -0.07 -0.03 0.53 0.466 2.5\njob46 -0.04 -0.08  0.54 -0.32 -0.04  0.12  0.20  0.08 0.47 0.531 2.2\njob17 -0.21 -0.03  0.54 -0.42 -0.05  0.21  0.22  0.15 0.63 0.374 3.2\njob2   0.00 -0.12  0.47  0.19  0.08 -0.18 -0.18  0.04 0.34 0.659 2.3\njob29 -0.06  0.03  0.37 -0.19  0.08  0.16  0.02  0.01 0.21 0.789 2.1\njob10  0.35  0.34  0.06  0.44 -0.28  0.10  0.35  0.11 0.66 0.341 5.0\njob41  0.28 -0.01 -0.02  0.13  0.43  0.42  0.01 -0.02 0.46 0.542 2.9\njob35  0.20  0.06  0.04  0.19  0.47  0.50  0.00 -0.02 0.55 0.453 2.7\njob32  0.20  0.03  0.00  0.24  0.40  0.42  0.01 -0.01 0.43 0.567 3.1\njob36  0.12  0.22 -0.05  0.22  0.22  0.35 -0.03  0.03 0.28 0.716 3.7\njob49  0.27  0.06 -0.09  0.23  0.26  0.28 -0.04  0.00 0.29 0.712 4.3\n\n                       ML1  ML2  ML3  ML4  ML5  ML6  ML7  ML8\nSS loadings           6.73 3.65 2.97 1.86 1.75 1.53 0.88 0.75\nProportion Var        0.16 0.09 0.07 0.05 0.04 0.04 0.02 0.02\nCumulative Var        0.16 0.25 0.33 0.37 0.41 0.45 0.47 0.49\nProportion Explained  0.33 0.18 0.15 0.09 0.09 0.08 0.04 0.04\nCumulative Proportion 0.33 0.52 0.66 0.76 0.84 0.92 0.96 1.00\n\nMean item complexity =  2.9\nTest of the hypothesis that 8 factors are sufficient.\n\nThe degrees of freedom for the null model are  820  and the objective function was  17.47 with Chi Square of  16202.67\nThe degrees of freedom for the model are 520  and the objective function was  1.89 \n\nThe root mean square of the residuals (RMSR) is  0.03 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic number of observations is  940 with the empirical chi square  1052.5  with prob <  2.3e-38 \nThe total number of observations was  943  with Likelihood Chi Square =  1745.24  with prob <  4.8e-132 \n\nTucker Lewis Index of factoring reliability =  0.874\nRMSEA index =  0.05  and the 90 % confidence intervals are  0.047 0.053\nBIC =  -1816.28\nFit based upon off diagonal values = 0.99\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3  ML4  ML5  ML6\nCorrelation of (regression) scores with factors   0.98 0.96 0.93 0.90 0.89 0.87\nMultiple R square of scores with factors          0.96 0.92 0.86 0.80 0.80 0.76\nMinimum correlation of possible factor scores     0.92 0.85 0.72 0.61 0.59 0.51\n                                                   ML7  ML8\nCorrelation of (regression) scores with factors   0.82 0.79\nMultiple R square of scores with factors          0.67 0.63\nMinimum correlation of possible factor scores     0.34 0.26\n\n\nWe still only get 2 substantive loadings on the last factor, while we want at least 3. This also happens with the 7- and 6-factor solutions. But once we hit the 5-factor solution, we find a better structure:\n\n\nCode\nm_5f <- fa(df2, nfactors = 5, rotate = \"oblimin\", fm = \"ml\")\nfa.sort(m_5f)\n\n\nFactor Analysis using method =  ml\nCall: fa(r = df2, nfactors = 5, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n        ML1   ML2   ML3   ML4   ML5   h2   u2 com\njob42  0.73 -0.08 -0.01  0.04  0.00 0.54 0.46 1.0\njob25  0.69 -0.02 -0.03 -0.05 -0.05 0.48 0.52 1.0\njob15  0.66  0.03  0.14  0.19 -0.24 0.55 0.45 1.6\njob45  0.66  0.01  0.13  0.13 -0.13 0.48 0.52 1.2\njob18  0.66 -0.04 -0.11  0.00  0.05 0.45 0.55 1.1\njob47  0.64  0.02 -0.05  0.11 -0.12 0.44 0.56 1.1\njob1   0.63 -0.01 -0.12 -0.01 -0.02 0.41 0.59 1.1\njob24  0.62  0.11 -0.32 -0.05  0.14 0.52 0.48 1.7\njob39  0.62  0.05  0.18  0.26 -0.22 0.53 0.47 1.9\njob26  0.59  0.00  0.06  0.25 -0.24 0.47 0.53 1.7\njob8   0.58 -0.07  0.00 -0.04  0.13 0.36 0.64 1.1\njob33  0.57  0.17 -0.38  0.01  0.20 0.54 0.46 2.3\njob44  0.56  0.24 -0.32 -0.07  0.26 0.55 0.45 2.6\njob48  0.55  0.03  0.08  0.03 -0.09 0.32 0.68 1.1\njob30  0.53  0.00 -0.11  0.00  0.06 0.30 0.70 1.1\njob38  0.51 -0.07  0.33  0.01 -0.15 0.39 0.61 2.0\njob12 -0.50  0.30 -0.03  0.12  0.15 0.38 0.62 2.0\njob40  0.48 -0.14  0.20  0.01 -0.14 0.31 0.69 1.8\njob43  0.47  0.10 -0.16 -0.13  0.01 0.28 0.72 1.5\njob16  0.47  0.03 -0.09 -0.24 -0.02 0.28 0.72 1.6\njob5   0.46  0.08 -0.18 -0.30  0.08 0.34 0.66 2.2\njob4   0.46  0.25 -0.31 -0.26  0.22 0.49 0.51 3.7\njob10  0.42  0.09 -0.08 -0.34  0.12 0.32 0.68 2.3\njob37  0.39 -0.09  0.30  0.18 -0.20 0.33 0.67 3.1\njob19  0.39  0.14 -0.36  0.14 -0.05 0.32 0.68 2.6\njob34  0.38  0.13  0.13  0.37 -0.15 0.34 0.66 2.8\njob21  0.32  0.09  0.31  0.20  0.09 0.26 0.74 3.0\njob3   0.05  0.65  0.19 -0.32 -0.21 0.60 0.40 1.9\njob28 -0.06  0.59  0.18 -0.06 -0.15 0.41 0.59 1.4\njob9   0.10  0.59  0.21 -0.33 -0.16 0.53 0.47 2.1\njob13 -0.11  0.58  0.21 -0.30 -0.08 0.49 0.51 1.9\njob6  -0.22  0.55 -0.12  0.37  0.22 0.55 0.45 2.6\njob17 -0.21  0.50 -0.15  0.48  0.14 0.57 0.43 2.7\njob46 -0.10  0.50 -0.05  0.41  0.04 0.43 0.57 2.0\njob2  -0.08  0.45  0.21 -0.15 -0.20 0.31 0.69 2.2\njob29 -0.05  0.37  0.00  0.24  0.15 0.22 0.78 2.1\njob35  0.22  0.03  0.50  0.04  0.49 0.54 0.46 2.4\njob41  0.26 -0.04  0.49  0.09  0.38 0.46 0.54 2.5\njob32  0.20 -0.01  0.48 -0.03  0.41 0.44 0.56 2.4\njob49  0.28 -0.10  0.34 -0.10  0.27 0.29 0.71 3.3\njob36  0.23 -0.02  0.21 -0.14  0.40 0.28 0.72 2.5\n\n                       ML1  ML2  ML3  ML4  ML5\nSS loadings           8.56 2.99 2.24 1.75 1.57\nProportion Var        0.21 0.07 0.05 0.04 0.04\nCumulative Var        0.21 0.28 0.34 0.38 0.42\nProportion Explained  0.50 0.17 0.13 0.10 0.09\nCumulative Proportion 0.50 0.67 0.81 0.91 1.00\n\nMean item complexity =  2\nTest of the hypothesis that 5 factors are sufficient.\n\nThe degrees of freedom for the null model are  820  and the objective function was  17.47 with Chi Square of  16202.67\nThe degrees of freedom for the model are 625  and the objective function was  3.84 \n\nThe root mean square of the residuals (RMSR) is  0.04 \nThe df corrected root mean square of the residuals is  0.05 \n\nThe harmonic number of observations is  940 with the empirical chi square  2822.5  with prob <  1.7e-275 \nThe total number of observations was  943  with Likelihood Chi Square =  3545.78  with prob <  0 \n\nTucker Lewis Index of factoring reliability =  0.75\nRMSEA index =  0.07  and the 90 % confidence intervals are  0.068 0.073\nBIC =  -734.88\nFit based upon off diagonal values = 0.97\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3  ML4  ML5\nCorrelation of (regression) scores with factors   0.97 0.93 0.90 0.88 0.86\nMultiple R square of scores with factors          0.94 0.86 0.80 0.77 0.74\nMinimum correlation of possible factor scores     0.88 0.71 0.61 0.53 0.49\n\n\nAlso notice that the 8-factor solution accounted for 49% of the variance and the 5-factor one explains 41%. That is not a huge drop considering that, by choosing the 5-factor over the 8-factor solution, we reduce the dimensionality of the data (number of variables we have to deal with) by further 3 dimensions!\nLooking at the loadings, we can see that only 4 items have substantial cross-loadings (on exactly 2 factors), which is not terrible.\nGlance at the factor correlations of this final model, we see that only factor 1 and 4 are weakly-to-moderately correlated, which is not too bad! It allows us to claim that the factors (except for one) are largely independent of each other. This model accounts for about 39% of the common variance.\nAt this stage, we would go to the individual items, look at which factors load on which items, and try to figure out what is the common theme linking these items. For instance, let’s look at the factor ML5. I would start by looking at the items with the highest loadings, i.e., items 44, 4, 33, and 24. They all have three things in common: they address fairness, openness, and promotions/pay rises. Since we have multiple themes going on here, let’s look at the items with loadings in the .4-.6 range. A stronger theme of fair acknowledgement of performance emerges. Not all of the lower-loading items chime with this theme terribly well, but those that do not tend to have cross-loadings with other factor. I would therefore be reasonable confident that the factor taps into something that could be called “Fair recognition” (apparently this is referred to in the OrgPsych jargon as “Procedural justice”)."
  },
  {
    "objectID": "example_00_anova.html",
    "href": "example_00_anova.html",
    "title": "Analysis Example: Rpt & Mixed ANOVA",
    "section": "",
    "text": "Data\nThe data is from a simulated experiment in which heart rate variability (HRV) was measured for amateur basketball players when tasked with scoring a goal with varying levels and type of potential loss/reward.\nThe data was split over two files. The code below will read in both datasets and join them for you:\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\ndownload.file(url = \"https://uoepsy.github.io/data/basketballhrv.xlsx\", \n              destfile = \"baskeballhrvdata.xlsx\")\n\nbball <- \n  left_join(\n    read_csv(\"https://uoepsy.github.io/data/basketballconditions.csv\"),\n    read_xlsx(\"baskeballhrvdata.xlsx\") %>%\n      pivot_longer(trial_1:trial_20, names_to = \"trial_no\", values_to = \"hrv\")\n  ) %>%\n  mutate(sub = factor(sub))\n\n\n\n\nOne-Way Repeated Measures ANOVA\nFor a repeated measures ANOVA, our independent variables are within groups.\nFollowing from the example study above, we might consider using it to answer the question below.\n\nQuestion: What is the effect of the size of reward on stress levels (as measured by HRV)?\n\nThe easiest way to conduct a repeated measures ANOVA in R is to use the ez package.\nIt comes with some handy functions to visualise the experimental design.\nWe can see from below that every participant completed a trial for each value of reward-size (1-20 points):\n\n\nCode\nlibrary(ez)\nezDesign(data = bball, x = sub, y = stakes)\n\n\n\n\n\n\n\n\n\nThe ezANOVA() function takes a few arguments.\nThe ones you will need for this are:\n\ndata the name of the dataframe\ndv the column name for the dependent variable\nwid the column name for the participant id variable\nwithin the column name(s) for the predictor variable(s) that vary within participants\nbetween the column name(s) for any predictor variable(s) that vary between participants\n\nFit a repeated measures ANOVA to examine the effect of the size of reward on HRV.\n\n\nCode\nezANOVA(data=bball, dv=hrv, wid = sub, within = stakes)\n\n\n$ANOVA\n  Effect DFn DFd        F         p p<.05        ges\n1 stakes   1  29 1.254585 0.2718695       0.04146761\n\n\n\n\nMixed ANOVA\nMixed ANOVA can be used to investigate effects of independent variables that are at two different levels, i.e. some are within clusters and some are between.\n\nQuestion: Does the influence of the size of reward/loss on stress levels differ depending upon whether it is money vs reputation at stake?\n\nLook at the two lines below. Can you work out what the plots will look like before you run them?\n\n\nCode\nezDesign(data = bball, x = condition, y = sub)\nezDesign(data = bball, x = condition, y = stakes)\n\n\nParticipants 1-15 are in one condition, and 16-30 are in another.\nThis should look like a two big blocks on the diagonal.\n\n\nCode\nezDesign(data = bball, x = condition, y = sub)\n\n\n\n\n\n\n\n\n\nIn each condition, the full set of stakes (1-20 points) were observed in the same number of trials. This should be a full grid:\n\n\nCode\nezDesign(data = bball, x = condition, y = stakes)\n\n\n\n\n\n\n\n\n\nFit a mixed ANOVA to examine the interaction between size and type of reward on HRV.\n\n\nCode\nezANOVA(data=bball, dv=hrv, wid = sub, within = stakes, between = condition)\n\n\n$ANOVA\n            Effect DFn DFd        F          p p<.05        ges\n1        condition   1  28 3.021712 0.09314393       0.06041768\n2           stakes   1  28 1.260498 0.27109204       0.01786900\n3 condition:stakes   1  28 1.136668 0.29546463       0.01614191\n\n\nThe ez package also contains some easy plotting functions for factorial experiments, such as ezPlot(). It takes similar arguments to the ezANOVA() function.\n\nlook up the help documentation for ezPlot().\nlet’s use ezPlot() to make a nice plot (Note: we may need to make sure that the stakes variable is a factor).\n\n\n\nCode\nbball <- bball %>% mutate(stakes = factor(stakes))\nezPlot(data=bball, dv=hrv, wid = sub, within = stakes, between = condition, x = stakes, split = condition)"
  },
  {
    "objectID": "example_01_repeated_measures.html",
    "href": "example_01_repeated_measures.html",
    "title": "Analysis Example: Repeated-measures",
    "section": "",
    "text": "Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:\n\nFirst the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated.\nSecond, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\nThen, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in lme4. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals.\nFinally, we visualize and interpret our analysis.\n\nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email ug.ppls.stats@ed.ac.uk."
  },
  {
    "objectID": "example_01_repeated_measures.html#equations",
    "href": "example_01_repeated_measures.html#equations",
    "title": "Analysis Example: Repeated-measures",
    "section": "Equations",
    "text": "Equations\nWe’re going to fit this model, and examine the change in dv associated with moving from time-point 1 to each subsequent time-point.\nRecall that because iv is categorical with 3 levels, we’re going to be estimating 2 (\\(3-1\\)) coefficients.\n\\[\n\\begin{aligned}\n  \\operatorname{dv}_{i[j]} &= \\beta_{0i} + \\beta_1(\\operatorname{iv}_{\\operatorname{T2}_j}) + \\beta_2(\\operatorname{iv}_{\\operatorname{T3}_j}) + \\varepsilon_{i[j]} \\\\\n    \\beta_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n    & \\text{for }\\operatorname{pid}\\text{ i = 1,} \\dots \\text{,I}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "example_01_repeated_measures.html#fitting-the-models",
    "href": "example_01_repeated_measures.html#fitting-the-models",
    "title": "Analysis Example: Repeated-measures",
    "section": "Fitting the models",
    "text": "Fitting the models\n\n\nCode\nlibrary(lme4)\n\n\nHere we run an empty model so that we have something to compare our model which includes our iv. Other than to give us a reference model, we do not have a huge amount of interest in this.\n\n\nCode\nm0 <- lmer(dv ~ 1 + (1 | pid), data = simRPT)\n\n\nNext, we specify our model. Here we include a fixed effect of our predictor (group membership, iv), and a random effect of participant (iv) to take account of the fact we have three measurements per person.\n\n\nCode\nm1 <- lmer(dv ~ 1 + iv + (1 | pid), data = simRPT)\nsummary(m1)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: dv ~ 1 + iv + (1 | pid)\n   Data: simRPT\n\nREML criterion at convergence: 1144.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.52990 -0.57636 -0.02015  0.56073  2.50816 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n pid      (Intercept) 74.66    8.641   \n Residual             84.60    9.198   \nNumber of obs: 150, groups:  pid, 50\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   38.842      1.785   21.76\nivT2          11.976      1.840    6.51\nivT3          28.964      1.840   15.74\n\nCorrelation of Fixed Effects:\n     (Intr) ivT2  \nivT2 -0.515       \nivT3 -0.515  0.500\n\n\nAnd we can compare our models.\n\n\nCode\nlibrary(pbkrtest)\nPBmodcomp(m1, m0)\n\n\nBootstrap test; time: 17.05 sec; samples: 1000; extremes: 0;\nlarge : dv ~ 1 + iv + (1 | pid)\ndv ~ 1 + (1 | pid)\n         stat df   p.value    \nLRT    126.84  2 < 2.2e-16 ***\nPBtest 126.84     0.000999 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nanova(m0,m1)\n\n\nData: simRPT\nModels:\nm0: dv ~ 1 + (1 | pid)\nm1: dv ~ 1 + iv + (1 | pid)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm0    3 1285.9 1294.9 -639.94   1279.9                         \nm1    5 1163.0 1178.1 -576.52   1153.0 126.83  2  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOK, so we can see that we appear to have a significant effect of our repeated factor here. Our parametric bootstrap LRT is in agreement here.\n\nComparison to aov()\nUsing anova() to compare multilevel models will not give you a typical ANOVA output.\nFor piece of mind, it can be useful to compare how we might do this in aov()\n\n\nCode\nm2 <- aov(dv ~ iv + Error(pid), data = simRPT)\n\n\nHere the term Error(pid) is specifying the within person error, or residual. This is what we are doing with our random effect (1 | pid) in lmer()\nAnd we can compare the model sums of squares from both approaches to see the equivalence:\n\n\nCode\nsummary(m2)\n\n\n\nError: pid\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 49  15121   308.6               \n\nError: Within\n          Df Sum Sq Mean Sq F value Pr(>F)    \niv         2  21183   10591   125.2 <2e-16 ***\nResiduals 98   8291      85                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nanova(m1)\n\n\nAnalysis of Variance Table\n   npar Sum Sq Mean Sq F value\niv    2  21183   10591  125.19"
  },
  {
    "objectID": "example_01_repeated_measures.html#check-model",
    "href": "example_01_repeated_measures.html#check-model",
    "title": "Analysis Example: Repeated-measures",
    "section": "Check model",
    "text": "Check model\nThe residuals look reasonably normally distributed, and there seems to be fairly constant variance across the linear predictor. We might be a little concerned about the potential tails of the plot below, at which residuals don’t appear to have a mean of zero\n\n\nCode\nplot(m1, type = c(\"p\",\"smooth\"))\n\n\n\n\n\n\n\n\n\nCode\nlibrary(lattice)\nqqmath(m1)\n\n\n\n\n\n\n\n\n\nRandom effects are (roughly) normally distributed:\n\n\nCode\nrans <- as.data.frame(ranef(m1)$pid)\nggplot(rans, aes(sample = `(Intercept)`)) + \n  stat_qq() + stat_qq_line() +\n  labs(title=\"random intercept\")"
  },
  {
    "objectID": "example_02_intervention.html",
    "href": "example_02_intervention.html",
    "title": "Analysis Example: Intervention",
    "section": "",
    "text": "Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:\n\nFirst the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated.\nSecond, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\nThen, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in lme4. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals.\nFinally, we visualize and interpret our analysis.\n\nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email ug.ppls.stats@ed.ac.uk."
  },
  {
    "objectID": "example_02_intervention.html#equations",
    "href": "example_02_intervention.html#equations",
    "title": "Analysis Example: Intervention",
    "section": "Equations",
    "text": "Equations\n\\[\n\\begin{aligned}\n  \\operatorname{stress}_{i[j]}  &= \\beta_{0i} + \\beta_{1i}(\\operatorname{timeDuring}_j) + \\beta_{2i}(\\operatorname{timePost}_j) + \\varepsilon_{i[j]} \\\\\n  \\beta_{0i} &= \\gamma_{00} + \\gamma_{01}(\\operatorname{groupTreatment}_i) + \\zeta_{0i} \\\\\n  \\beta_{1i} &= \\gamma_{10} + \\gamma_{11}(\\operatorname{groupTreatment}_i) \\\\\n  \\beta_{2i} &= \\gamma_{20} + \\gamma_{21}(\\operatorname{groupTreatment}_i) \\\\\n  & \\text{for ppt i = 1,} \\dots \\text{, I}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "example_02_intervention.html#fitting-the-models",
    "href": "example_02_intervention.html#fitting-the-models",
    "title": "Analysis Example: Intervention",
    "section": "Fitting the models",
    "text": "Fitting the models\n\n\nCode\nlibrary(lme4)\n\n\nBase model:\n\n\nCode\nm0 <- lmer(stress ~ 1 +\n             (1 | ppt), data = simMIX)\nsummary(m0)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: stress ~ 1 + (1 | ppt)\n   Data: simMIX\n\nREML criterion at convergence: 1286.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.02099 -0.49670  0.01511  0.49445  1.96548 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ppt      (Intercept) 179.7    13.40   \n Residual             209.7    14.48   \nNumber of obs: 150, groups:  ppt, 50\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   42.220      2.234    18.9\n\n\nMain effects:\n\n\nCode\nm1 <- lmer(stress ~ 1 + time + group +\n             (1 | ppt), data = simMIX)\nsummary(m1)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: stress ~ 1 + time + group + (1 | ppt)\n   Data: simMIX\n\nREML criterion at convergence: 1185.9\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.69666 -0.62649  0.01574  0.59245  1.92387 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ppt      (Intercept) 166.57   12.91   \n Residual              98.01    9.90   \nNumber of obs: 150, groups:  ppt, 50\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)      61.100      3.046  20.061\ntimeDuring      -13.760      1.980  -6.950\ntimePost        -20.980      1.980 -10.596\ngroupTreatment  -14.600      3.992  -3.657\n\nCorrelation of Fixed Effects:\n            (Intr) tmDrng timPst\ntimeDuring  -0.325              \ntimePost    -0.325  0.500       \ngroupTrtmnt -0.655  0.000  0.000\n\n\nInteraction:\n\n\nCode\nm2 <- lmer(stress ~ 1 + time + group + time*group +\n             (1 | ppt), data = simMIX)\nsummary(m2)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: stress ~ 1 + time + group + time * group + (1 | ppt)\n   Data: simMIX\n\nREML criterion at convergence: 1096.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.83946 -0.53326 -0.05639  0.53766  2.31546 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ppt      (Intercept) 184.82   13.595  \n Residual              43.26    6.577  \nNumber of obs: 150, groups:  ppt, 50\n\nFixed effects:\n                          Estimate Std. Error t value\n(Intercept)                 52.840      3.020  17.494\ntimeDuring                  -3.200      1.860  -1.720\ntimePost                    -6.760      1.860  -3.634\ngroupTreatment               1.920      4.272   0.449\ntimeDuring:groupTreatment  -21.120      2.631  -8.028\ntimePost:groupTreatment    -28.440      2.631 -10.810\n\nCorrelation of Fixed Effects:\n            (Intr) tmDrng timPst grpTrt tmDr:T\ntimeDuring  -0.308                            \ntimePost    -0.308  0.500                     \ngroupTrtmnt -0.707  0.218  0.218              \ntmDrng:grpT  0.218 -0.707 -0.354 -0.308       \ntmPst:grpTr  0.218 -0.354 -0.707 -0.308  0.500\n\n\n\nComparison with aov()\nAs we did with the simple repeated measures, we can also compare the sums of squares breakdown for the LMM (m2) by calling anova() on the lmer() model.\nFirst with aov():\n\n\nCode\nm3 <- aov(stress ~ time + group + time*group +\n            Error(ppt), data = simMIX)\nsummary(m3)\n\n\n\nError: ppt\n          Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup      1   7993    7993   13.37 0.000633 ***\nResiduals 48  28691     598                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n           Df Sum Sq Mean Sq F value Pr(>F)    \ntime        2  11360    5680  131.31 <2e-16 ***\ntime:group  2   5452    2726   63.01 <2e-16 ***\nResiduals  96   4153      43                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd then summarise:\n\n\nCode\nanova(m2)\n\n\nAnalysis of Variance Table\n           npar  Sum Sq Mean Sq F value\ntime          2 11360.4  5680.2 131.305\ngroup         1   578.5   578.5  13.373\ntime:group    2  5452.0  2726.0  63.014\n\n\n\nFor ease, lets compare all models with a parametric bootstrap likelihood ratio test:\n\n\nCode\nlibrary(pbkrtest)\nPBmodcomp(m1, m0)\nPBmodcomp(m2, m1)\n\n\n\n\nBootstrap test; time: 16.21 sec; samples: 1000; extremes: 0;\nlarge : stress ~ 1 + time + group + (1 | ppt)\nstress ~ 1 + (1 | ppt)\n         stat df   p.value    \nLRT    90.348  3 < 2.2e-16 ***\nPBtest 90.348     0.000999 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBootstrap test; time: 17.67 sec; samples: 1000; extremes: 0;\nlarge : stress ~ 1 + time + group + time * group + (1 | ppt)\nstress ~ 1 + time + group + (1 | ppt)\n         stat df   p.value    \nLRT    83.853  2 < 2.2e-16 ***\nPBtest 83.853     0.000999 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd extract some bootstrap 95% CIs\n\n\nCode\nconfint(m2,method=\"boot\")\n\n\n                               2.5 %      97.5 %\n.sig01                     11.063915  16.8989137\n.sigma                      5.570576   7.3318954\n(Intercept)                46.958215  58.9035049\ntimeDuring                 -6.598935  -0.1161317\ntimePost                  -10.473009  -3.1302747\ngroupTreatment             -7.001190  10.0517531\ntimeDuring:groupTreatment -26.395306 -16.1101659\ntimePost:groupTreatment   -33.665532 -23.2588741"
  },
  {
    "objectID": "example_02_intervention.html#check-model",
    "href": "example_02_intervention.html#check-model",
    "title": "Analysis Example: Intervention",
    "section": "Check Model",
    "text": "Check Model\nThe residuals look reasonably normally distributed, and there seems to be fairly constant variance across the linear predictor. We might be a little concerned about the potential tails of the plot below, at which residuals don’t appear to have a mean of zero\n\n\nCode\nplot(m2, type = c(\"p\",\"smooth\"))\n\n\n\n\n\n\n\n\n\nCode\nplot(m2, sqrt(abs(resid(.)))~fitted(.))\n\n\n\n\n\n\n\n\n\nCode\nlibrary(lattice)\nqqmath(m2)\n\n\n\n\n\n\n\n\n\nRandom effects are (roughly) normally distributed:\n\n\nCode\nrans <- as.data.frame(ranef(m2)$ppt)\nggplot(rans, aes(sample = `(Intercept)`)) + \n  stat_qq() + stat_qq_line() +\n  labs(title=\"random intercept\")"
  },
  {
    "objectID": "example_03_many_trials.html",
    "href": "example_03_many_trials.html",
    "title": "Analysis Example 3: Many trials",
    "section": "",
    "text": "Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:\n\nFirst the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated.\nSecond, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\nThen, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in lme4. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals.\nFinally, we visualize and interpret our analysis.\n\nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email ug.ppls.stats@ed.ac.uk."
  },
  {
    "objectID": "example_03_many_trials.html#equations",
    "href": "example_03_many_trials.html#equations",
    "title": "Analysis Example 3: Many trials",
    "section": "Equations",
    "text": "Equations\n\nWhy item as a fixed effect and not by-item random intercepts (e.g.(1 | item))? It is debatable how you decide to treat item here. It could be argued that the different item types (dress/top/bottom, etc) represent a sample from some broader population of garment types, and as such should be modeled as random effects (especially given that we are not interested in specific parameter estimates for differences between item types).\nHowever, we only have 3 different types of item, and it is important to remember that having (1|item) will involve estimating variance components based on these. Variance estimates will be less stable with such a small number of groups. There’s no hard rule to follow here about “how many groups is enough” (some people suggest 5 or 6 at least), but personally I would be inclined to use item as a fixed effect.\nWe should also consider the possibility that certain items should be less desirable to purchase when in a smaller/bigger size. It may be that size differences are more salient, or more influential on our outcome variable, for certain types of item over others. This would involve adding the interaction between size and item type\n\n$$\n\\[\\begin{aligned}\n  \\operatorname{price}_{i[j]}  =& \\beta_{0i} +\n  \\beta_{1i}(\\operatorname{item-size}_j) +\n  \\beta_{1}(\\operatorname{item-type}_j) + \\\\\n  & \\beta_{2}(\\operatorname{item-size}_j \\times \\operatorname{item-type}_j) + \\\\\n  & \\beta_{3i}(\\operatorname{matches-actual-size}_j) + \\\\\n  & \\beta_{4}(\\operatorname{matches-ideal-size}_j) + \\varepsilon_{i[j]}\\\\\n  \\qquad \\\\\n  \n  \\beta_{0i} &= \\gamma_{00} + \\gamma_{01}(\\operatorname{thin-idealisation-score}_i) + \\zeta_{0i} \\\\\n  \\beta_{1i} &= \\gamma_{10} + \\zeta_{1i}\\\\\n  \\beta_{3i} &= \\gamma_{30} + \\gamma_{31}(\\operatorname{thin-idealisation-score}_i)\\\\\n  & \\text{for participant i = 1, } \\dots \\text{, I} \\\\\n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "example_03_many_trials.html#fitting-the-models",
    "href": "example_03_many_trials.html#fitting-the-models",
    "title": "Analysis Example 3: Many trials",
    "section": "Fitting the models",
    "text": "Fitting the models\nWe’re going to want to do lots of model comparisons, and for those we need all our models to be fitted on the same data. We’re going to use these variables:\n\n\nCode\ndf_analysis <-\n  df_analysis %>%\n  filter(\n    !is.na(size),\n    !is.na(item),\n    !is.na(c.match),\n    !is.na(i.match),\n    !is.na(tii_scorez),\n    !is.na(id),\n    !is.na(price)\n  )\n\n\nFirst, the effect of size. We’re going to treat size as a numeric variable here, in part because it makes our models less complex. It also allows us to model by-participant random effects of size (you can think of this as modeling participants as varying in the amount to which size influences the amount that they are prepared to pay).\n\n\nCode\nm0 <- lmer(price ~ 1 + item + \n             (1+size|id),\n           data = df_analysis)\nm1 <- lmer(price ~ 1 + item + size +\n             (1 + size|id),\n           data = df_analysis)\nsummary(m1)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item + size + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14045.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.5003 -0.5885 -0.0396  0.5259  5.1435 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.130   7.882         \n          size         2.371   1.540    -0.07\n Residual             33.570   5.794         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  24.3845     0.7517  32.439\nitemdress     2.6468     0.3081   8.590\nitemtop      -5.3352     0.3073 -17.360\nsize         -0.4893     0.1887  -2.593\n\nCorrelation of Fixed Effects:\n          (Intr) itmdrs itemtp\nitemdress -0.204              \nitemtop   -0.205  0.500       \nsize      -0.051  0.000  0.001\n\n\n\n\nCode\nanova(m0, m1)\n\n\nData: df_analysis\nModels:\nm0: price ~ 1 + item + (1 + size | id)\nm1: price ~ 1 + item + size + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)  \nm0    7 14065 14104 -7025.3    14051                       \nm1    8 14060 14105 -7022.0    14044 6.6082  1    0.01015 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe interaction between size and item:\n\n\nCode\nm2 <- lmer(price ~ 1 +  item * size +\n             (1+size|id),\n           data = df_analysis)\nsummary(m2)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14026.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.5043 -0.5804 -0.0377  0.5095  5.1433 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.135   7.883         \n          size         2.392   1.547    -0.07\n Residual             33.240   5.765         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.3870     0.7514  32.454\nitemdress        2.6449     0.3066   8.626\nitemtop         -5.3370     0.3058 -17.451\nsize            -1.1062     0.2587  -4.277\nitemdress:size   0.4740     0.3071   1.543\nitemtop:size     1.3689     0.3058   4.477\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   itmdr:\nitemdress   -0.203                            \nitemtop     -0.204  0.500                     \nsize        -0.038  0.002  0.002              \nitemdrss:sz  0.001 -0.003 -0.002 -0.591       \nitemtop:siz  0.001 -0.002 -0.002 -0.594  0.500\n\n\n\n\nCode\nanova(m1,m2)\n\n\nData: df_analysis\nModels:\nm1: price ~ 1 + item + size + (1 + size | id)\nm2: price ~ 1 + item * size + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm1    8 14060 14105 -7022.0    14044                         \nm2   10 14043 14100 -7011.7    14023 20.613  2  3.341e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat about the effect of item size matching your current size:\n\n\nCode\nm3 <- lmer(price ~ 1 +  item * size + c.match +\n             (1+size|id),\n           data = df_analysis)\nsummary(m3)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14023.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4754 -0.5995 -0.0312  0.5075  5.1647 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.145   7.883         \n          size         2.317   1.522    -0.08\n Residual             33.233   5.765         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.2782     0.7537  32.214\nitemdress        2.6431     0.3066   8.621\nitemtop         -5.3374     0.3058 -17.454\nsize            -1.0747     0.2580  -4.166\nc.match1         0.6620     0.3494   1.895\nitemdress:size   0.4736     0.3071   1.542\nitemtop:size     1.3689     0.3058   4.477\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 itmdr:\nitemdress   -0.202                                   \nitemtop     -0.203  0.500                            \nsize        -0.048  0.002  0.002                     \nc.match1    -0.076 -0.003 -0.001  0.064              \nitemdrss:sz  0.001 -0.003 -0.002 -0.592  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.595  0.000  0.500\n\n\nCompare models for current size match:\n\n\nCode\nanova(m2,m3)\n\n\nData: df_analysis\nModels:\nm2: price ~ 1 + item * size + (1 + size | id)\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)  \nm2   10 14043 14100 -7011.7    14023                       \nm3   11 14042 14104 -7009.9    14020 3.5856  1    0.05828 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOr your ideal size:\n\n\nCode\nm4 <- lmer(price ~ 1 + item * size + c.match + i.match +\n             (1+size|id),\n           data = df_analysis)\nsummary(m4)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14021.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4705 -0.5911 -0.0355  0.5049  5.1828 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.171   7.885         \n          size         2.281   1.510    -0.08\n Residual             33.244   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     24.2167     0.7556  32.050\nitemdress        2.6439     0.3066   8.622\nitemtop         -5.3369     0.3058 -17.450\nsize            -1.0264     0.2606  -3.938\nc.match1         0.5972     0.3539   1.688\ni.match1         0.4308     0.3650   1.180\nitemdress:size   0.4736     0.3071   1.542\nitemtop:size     1.3685     0.3058   4.475\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 itmdr:\nitemdress   -0.202                                          \nitemtop     -0.203  0.500                                   \nsize        -0.058  0.002  0.002                            \nc.match1    -0.064 -0.003 -0.001  0.038                     \ni.match1    -0.069  0.002  0.001  0.156 -0.160              \nitemdrss:sz  0.001 -0.003 -0.002 -0.586 -0.001  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.500\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00383895 (tol = 0.002, component 1)\n\n\nCompare models for ideal size match:\n\n\nCode\nanova(m3,m4)\n\n\nData: df_analysis\nModels:\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\n   npar   AIC   BIC  logLik deviance Chisq Df Pr(>Chisq)\nm3   11 14042 14104 -7009.9    14020                    \nm4   12 14042 14110 -7009.2    14018 1.399  1     0.2369\n\n\nFixed effects for thin ideals:\n\n\nCode\nm5 <- lmer(price ~ 1 + item * size + c.match + i.match + tii_scorez + \n             (1+size|id),\n           data = df_analysis)\nsummary(m5)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 +  \n    size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14020.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4719 -0.5907 -0.0357  0.5059  5.1829 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.695   7.918         \n          size         2.279   1.510    -0.08\n Residual             33.245   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)    24.21667    0.75848  31.928\nitemdress       2.64389    0.30664   8.622\nitemtop        -5.33684    0.30584 -17.450\nsize           -1.02641    0.26060  -3.939\nc.match1        0.59704    0.35388   1.687\ni.match1        0.43085    0.36497   1.181\ntii_scorez     -0.07229    0.73246  -0.099\nitemdress:size  0.47367    0.30714   1.542\nitemtop:size    1.36846    0.30582   4.475\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 t_scrz itmdr:\nitemdress   -0.201                                                 \nitemtop     -0.202  0.500                                          \nsize        -0.058  0.002  0.002                                   \nc.match1    -0.064 -0.003 -0.001  0.038                            \ni.match1    -0.068  0.002  0.001  0.156 -0.160                     \ntii_scorez   0.000  0.000 -0.001  0.001  0.003 -0.001              \nitemdrss:sz  0.001 -0.003 -0.002 -0.587 -0.001  0.000  0.000       \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.000  0.500\n\n\nCompare models for thin ideal:\n\n\nCode\nanova(m4,m5)\n\n\nData: df_analysis\nModels:\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\nm5: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 + size | id)\n   npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)\nm4   12 14042 14110 -7009.2    14018                     \nm5   13 14044 14118 -7009.2    14018 0.0099  1     0.9208\n\n\nDo they interact?\n\n\nCode\nm6 <- lmer(price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match*tii_scorez + \n             (1+size|id),\n           data = df_analysis)\nsummary(m6)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match *  \n    tii_scorez + (1 + size | id)\n   Data: df_analysis\n\nREML criterion at convergence: 14019.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.4672 -0.5966 -0.0323  0.5021  5.1910 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n id       (Intercept) 62.679   7.917         \n          size         2.281   1.510    -0.08\n Residual             33.243   5.766         \nNumber of obs: 2130, groups:  id, 120\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         24.20683    0.75845  31.916\nitemdress            2.64336    0.30663   8.621\nitemtop             -5.33608    0.30584 -17.448\nsize                -1.02537    0.26062  -3.934\nc.match1             0.56650    0.35506   1.595\ni.match1             0.51739    0.37448   1.382\ntii_scorez          -0.01563    0.73458  -0.021\nitemdress:size       0.47423    0.30713   1.544\nitemtop:size         1.36867    0.30581   4.476\nc.match1:tii_scorez -0.37423    0.36191  -1.034\n\nCorrelation of Fixed Effects:\n            (Intr) itmdrs itemtp size   c.mtc1 i.mtc1 t_scrz itmdr: itmtp:\nitemdress   -0.201                                                        \nitemtop     -0.202  0.500                                                 \nsize        -0.056  0.002  0.002                                          \nc.match1    -0.063 -0.003 -0.001  0.037                                   \ni.match1    -0.070  0.002  0.002  0.153 -0.173                            \ntii_scorez  -0.001  0.000  0.000  0.001 -0.003  0.016                     \nitemdrss:sz  0.001 -0.003 -0.002 -0.586 -0.001  0.001  0.000              \nitemtop:siz  0.001 -0.002 -0.002 -0.589  0.000 -0.001  0.000  0.500       \nc.mtch1:t_s  0.013  0.002 -0.002 -0.004  0.082 -0.224 -0.076 -0.002 -0.001\n\n\nAnd let’s just compare all at once, just for fun:\n\n\nCode\nanova(m0,m1,m2,m3,m4,m5,m6)\n\n\nData: df_analysis\nModels:\nm0: price ~ 1 + item + (1 + size | id)\nm1: price ~ 1 + item + size + (1 + size | id)\nm2: price ~ 1 + item * size + (1 + size | id)\nm3: price ~ 1 + item * size + c.match + (1 + size | id)\nm4: price ~ 1 + item * size + c.match + i.match + (1 + size | id)\nm5: price ~ 1 + item * size + c.match + i.match + tii_scorez + (1 + size | id)\nm6: price ~ 1 + item * size + c.match + i.match + tii_scorez + c.match * tii_scorez + (1 + size | id)\n   npar   AIC   BIC  logLik deviance   Chisq Df Pr(>Chisq)    \nm0    7 14065 14104 -7025.3    14051                          \nm1    8 14060 14105 -7022.0    14044  6.6082  1    0.01015 *  \nm2   10 14043 14100 -7011.7    14023 20.6131  2  3.341e-05 ***\nm3   11 14042 14104 -7009.9    14020  3.5856  1    0.05828 .  \nm4   12 14042 14110 -7009.2    14018  1.3990  1    0.23690    \nm5   13 14044 14118 -7009.2    14018  0.0099  1    0.92076    \nm6   14 14045 14125 -7008.7    14017  1.0720  1    0.30048    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "example_03_many_trials.html#check-models",
    "href": "example_03_many_trials.html#check-models",
    "title": "Analysis Example 3: Many trials",
    "section": "Check model(s)",
    "text": "Check model(s)\n\n\nCode\nlibrary(lattice)\nlibrary(gridExtra)\ngrid.arrange(\n  plot(m1, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m2, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m3, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m4, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m5, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  plot(m6, sqrt(abs(resid(.)))~fitted(.), type = c(\"p\",\"smooth\")),\n  ncol=3\n)\n\n\n\n\n\n\n\n\n\nCode\ngrid.arrange(\n  qqmath(m1),\n  qqmath(m2),\n  qqmath(m3),\n  qqmath(m4),\n  qqmath(m5),\n  qqmath(m6),\n  ncol=3\n)\n\n\n\n\n\n\n\n\n\nI might be a little concerned about our assumptions here. The QQplots look a little off in the tails, however, the histograms of residuals make it look okay:\n\n\n\n\n\n\n\n\n\nFor peace of mind, we could re-do the model comparisons with parametric bootstrapped model comparison for more reliable conclusions. This will assume that the model specified distribution of residuals (\\(\\varepsilon \\sim N(0, \\sigma_\\varepsilon)\\)) holds in the population\n\n\n\n\n\nCode\nlibrary(pbkrtest)\nPBmodcomp(m1, m0)\n\n\n\n\n           stat df    p.value\nLRT    6.605558  1 0.01016610\nPBtest 6.605558 NA 0.01098901\n\n\n\n\nCode\nPBmodcomp(m2, m1)\n\n\n\n\n           stat df      p.value\nLRT    20.61468  2 3.338708e-05\nPBtest 20.61468 NA 9.990010e-04\n\n\n\n\nCode\nPBmodcomp(m3, m2)\n\n\n\n\n           stat df    p.value\nLRT    3.585967  1 0.05826951\nPBtest 3.585967 NA 0.07092907\n\n\n\n\nCode\nPBmodcomp(m4, m3)\n\n\n\n\n           stat df   p.value\nLRT    1.399085  1 0.2368768\nPBtest 1.399085 NA 0.2317682\n\n\n\n\nCode\nPBmodcomp(m5, m4)\n\n\n\n\n             stat df   p.value\nLRT    0.00153228  1 0.9687753\nPBtest 0.00153228 NA 0.9670330\n\n\n\n\nCode\nPBmodcomp(m6, m5)\n\n\n\n\n           stat df   p.value\nLRT    1.072739  1 0.3003275\nPBtest 1.072739 NA 0.2857143"
  },
  {
    "objectID": "example_04_cross_sectional_multilevel.html",
    "href": "example_04_cross_sectional_multilevel.html",
    "title": "Analysis Example: Cross-sectional multi-level",
    "section": "",
    "text": "Each of these pages provides an analysis run through for a different type of design. Each document is structured in the same way:\n\nFirst the data and research context is introduced. For the purpose of these tutorials, we will only use examples where the data can be shared - either because it is from an open access publication, or because it is unpublished or simulated.\nSecond, we go through any tidying of the data that is required, before creating some brief descriptives and visualizations of the raw data.\nThen, we conduct an analysis. Where possible, we translate the research questions into formal equations prior to fitting the models in lme4. Model comparisons are conducted, along with checks of distributional assumptions on our model residuals.\nFinally, we visualize and interpret our analysis.\n\nPlease note that there will be only minimal explanation of the steps undertaken here, as these pages are intended as example analyses rather than additional labs readings. Please also be aware that there are many decisions to be made throughout conducting analyses, and it may be the case that you disagree with some of the choices we make here. As always with these things, it is how we justify our choices that is important. We warmly welcome any feedback and suggestions to improve these examples: please email ug.ppls.stats@ed.ac.uk."
  },
  {
    "objectID": "example_04_cross_sectional_multilevel.html#equations",
    "href": "example_04_cross_sectional_multilevel.html#equations",
    "title": "Analysis Example: Cross-sectional multi-level",
    "section": "Equations",
    "text": "Equations\nOur model will take the structure specified below. However, we may also want to discuss whether public/private moderates the within effect of motivation, or the between effect of motivation, in which case we would need to separate out the group mean motivation and the group-mean centered motivation.\n\\[\n\\begin{align}\n\\operatorname{Perform}_{ij} &= \\beta_{0i} + \\beta_{1i}(\\operatorname{Motivation}_j) + \\varepsilon_{ij}\\\\\n\\beta_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\beta_{1i} &= \\gamma_{10} + \\gamma_{11}(\\operatorname{isPrivate}_i) + \\zeta_{0i} \\\\\n& \\text{for OrgID i = 1,} \\dots \\text{,I}\n\\end{align}\n\\]"
  },
  {
    "objectID": "example_04_cross_sectional_multilevel.html#fitting-the-models",
    "href": "example_04_cross_sectional_multilevel.html#fitting-the-models",
    "title": "Analysis Example: Cross-sectional multi-level",
    "section": "Fitting the models",
    "text": "Fitting the models\nAs we have in many of our examples, let’s run an empty model, and look at the ICC for the grouping variable organisation.\n\n\nCode\nlibrary(lme4)\n# Empty model\nm0 <- lmer(Perform ~ 1 + \n             (1 | OrgID),\n           data = perform)\nsummary(m0)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Perform ~ 1 + (1 | OrgID)\n   Data: perform\n\nREML criterion at convergence: 3560\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.69138 -0.71156 -0.03565  0.73487  2.68864 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n OrgID    (Intercept) 25.05    5.005   \n Residual             80.34    8.964   \nNumber of obs: 487, groups:  OrgID, 23\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   50.613      1.134   44.64\n\n\n\n\nCode\n# ICC\nvarM0 <- as.data.frame(VarCorr(m0))\nvarM0\n\n\n       grp        var1 var2     vcov    sdcor\n1    OrgID (Intercept) <NA> 25.05319 5.005316\n2 Residual        <NA> <NA> 80.34482 8.963527\n\n\n\n\nCode\nround((varM0[1,4]/sum(varM0[,4]))*100,2)\n\n\n[1] 23.77\n\n\nSo, around 24% of the variance in our data is at the grouping level, meaning around 76% is at the person level. So clearly we have scope here for explanatory variables of both types.\nTo begin, we add motivation as a fixed effect:\n\n\nCode\n# Fixed effect for motivation\nm1 <- lmer(Perform ~ 1 + Mot +\n             (1 | OrgID),\n           data = perform)\nsummary(m1)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Perform ~ 1 + Mot + (1 | OrgID)\n   Data: perform\n\nREML criterion at convergence: 3493\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6341 -0.6969 -0.0137  0.6438  3.2444 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n OrgID    (Intercept) 20.30    4.506   \n Residual             70.25    8.381   \nNumber of obs: 487, groups:  OrgID, 23\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   46.035      1.159  39.731\nMot            2.453      0.288   8.517\n\nCorrelation of Fixed Effects:\n    (Intr)\nMot -0.464\n\n\nFrom this, we can calculate the reduction in the residual variance, or the PRV:\n\n\nCode\n# PRV - how much residual variance does motivation account for\nm1_sum <- summary(m1)\nvarM1 <- as.data.frame(m1_sum$varcor)\nvarM1\n\n\n       grp        var1 var2     vcov    sdcor\n1    OrgID (Intercept) <NA> 20.30283 4.505866\n2 Residual        <NA> <NA> 70.24540 8.381253\n\n\n\n\nCode\nround(((varM0[2,4]-varM1[2,4])/varM0[2,4])*100,2)\n\n\n[1] 12.57\n\n\nNot bad, so there is a 12.5% reduction in level 1 residual variance from the inclusion of motivation. The coefficient is positive, which is what we would hope to see, motivated employees have better performance.\nWe will do all of our model comparisons in one go at the end of our model building, so let’s continue. Next, is a random slope (as evidenced by our plots above) for motivation.\n\n\nCode\n# Random slope\nm2 <- lmer(Perform ~ 1 + Mot +\n             (1 + Mot | OrgID),\n           data = perform)\nsummary(m2)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Perform ~ 1 + Mot + (1 + Mot | OrgID)\n   Data: perform\n\nREML criterion at convergence: 3393.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.27286 -0.69631 -0.00381  0.66058  2.82123 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n OrgID    (Intercept) 62.10    7.881         \n          Mot         18.06    4.250    -0.84\n Residual             50.88    7.133         \nNumber of obs: 487, groups:  OrgID, 23\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  46.0257     1.7571  26.195\nMot           2.0031     0.9351   2.142\n\nCorrelation of Fixed Effects:\n    (Intr)\nMot -0.834\n\n\nAnd now we can look to compare the set of models before adding the predictors:\n\n\nCode\nanova(m0, m1, m2)\n\n\nData: perform\nModels:\nm0: Perform ~ 1 + (1 | OrgID)\nm1: Perform ~ 1 + Mot + (1 | OrgID)\nm2: Perform ~ 1 + Mot + (1 + Mot | OrgID)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nm0    3 3568.1 3580.7 -1781.0   3562.1                         \nm1    4 3502.2 3518.9 -1747.1   3494.2 67.894  1  < 2.2e-16 ***\nm2    6 3409.1 3434.2 -1698.5   3397.1 97.087  2  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn each case, adding the additional parameters has improved our model, so we will keep them all.\nOur big interest here is in whether organisations being public or private changes the relationship of motivation to performance. For this, we will want to include the cross level interaction between Mot and PubPri.\n\n\nCode\nm3 <- lmer(Perform ~ 1 + Mot + PubPri + Mot*PubPri +\n             (1 + Mot | OrgID),\n           data = perform)\nsummary(m3)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Perform ~ 1 + Mot + PubPri + Mot * PubPri + (1 + Mot | OrgID)\n   Data: perform\n\nREML criterion at convergence: 3384.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.29012 -0.69613 -0.02848  0.65620  2.76816 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n OrgID    (Intercept) 63.44    7.965         \n          Mot         18.62    4.315    -0.86\n Residual             50.91    7.135         \nNumber of obs: 487, groups:  OrgID, 23\n\nFixed effects:\n                 Estimate Std. Error t value\n(Intercept)       45.2718     2.1765  20.800\nMot                1.7909     1.1737   1.526\nPubPripublic       2.4448     3.7569   0.651\nMot:PubPripublic   0.5623     1.9904   0.283\n\nCorrelation of Fixed Effects:\n            (Intr) Mot    PbPrpb\nMot         -0.853              \nPubPripublc -0.579  0.494       \nMt:PbPrpblc  0.503 -0.590 -0.848\n\n\nThe t-values here are pretty small. This doesn’t look like the added effects have contributed much to our model.\n\n\nCode\n# model comparison\nanova(m2,m3)\n\n\nData: perform\nModels:\nm2: Perform ~ 1 + Mot + (1 + Mot | OrgID)\nm3: Perform ~ 1 + Mot + PubPri + Mot * PubPri + (1 + Mot | OrgID)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)\nm2    6 3409.1 3434.2 -1698.5   3397.1                     \nm3    8 3410.1 3443.6 -1697.1   3394.1 2.9908  2     0.2242\n\n\nAnd indeed our model comparison suggests not. But wait a minute, we forgot about something….\n…we need to center our predictors.\nLet’s create variables which are the group mean motivation, and the group-mean centered motivation.\n\n\nCode\nperform <- \n  perform %>%\n  group_by(OrgID) %>%\n  mutate(\n    Mot_m = mean(Mot, na.rm=T),\n    Mot_c = Mot - mean(Mot, na.rm=T)\n  ) %>% ungroup\n\n\nAnd re-run the models:\n\n\nCode\nm4 <- lmer(Perform ~ 1 + Mot_m + Mot_c +\n             (1 + Mot_c | OrgID),\n           data = perform)\nm5 <- lmer(Perform ~ 1 + Mot_m + Mot_c + PubPri + Mot_c*PubPri +\n             (1 + Mot_c | OrgID),\n           data = perform)\nanova(m4,m5)\n\n\nData: perform\nModels:\nm4: Perform ~ 1 + Mot_m + Mot_c + (1 + Mot_c | OrgID)\nm5: Perform ~ 1 + Mot_m + Mot_c + PubPri + Mot_c * PubPri + (1 + Mot_c | OrgID)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)\nm4    7 3413.8 3443.2 -1699.9   3399.8                     \nm5    9 3414.6 3452.3 -1698.3   3396.6 3.1947  2     0.2024\n\n\nCode\nsummary(m5)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Perform ~ 1 + Mot_m + Mot_c + PubPri + Mot_c * PubPri + (1 +  \n    Mot_c | OrgID)\n   Data: perform\n\nREML criterion at convergence: 3383.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.38702 -0.70580 -0.02145  0.64741  2.79873 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n OrgID    (Intercept) 19.96    4.467         \n          Mot_c       18.62    4.315    -0.09\n Residual             51.01    7.142         \nNumber of obs: 487, groups:  OrgID, 23\n\nFixed effects:\n                   Estimate Std. Error t value\n(Intercept)         45.2647     3.2271  14.027\nMot_m                2.1373     1.8199   1.174\nMot_c                1.7695     1.1752   1.506\nPubPripublic         4.1109     2.4320   1.690\nMot_c:PubPripublic   0.6012     1.9967   0.301\n\nCorrelation of Fixed Effects:\n            (Intr) Mot_m  Mot_c  PbPrpb\nMot_m       -0.925                     \nMot_c       -0.028 -0.001              \nPubPripublc  0.269 -0.497  0.039       \nMt_c:PbPrpb  0.020 -0.003 -0.589 -0.064\n\n\nWhat do you notice about the results? Spend a little bit of time comparing the effects (fixed and random) and see the changes that result from centering a variable. Remember that our interpretation of the conditional main effects is the effect of a predictor on the outcome when the interacting variable = 0. Zero for Mot_c is average motivation, and zero for PubPri is public sector. So for every unit increase in motivation within a public centre organisation, performance increases by 1.77 units."
  },
  {
    "objectID": "explainer_3leveleq.html",
    "href": "explainer_3leveleq.html",
    "title": "3-level multilevel model equations",
    "section": "",
    "text": "It varies in textbooks whether the specification of levels is \\(i\\)>\\(j\\)>\\(k\\) or \\(i\\)<\\(j\\)<\\(k\\).\nIn complex multilevel equations, it becomes a little easier sometimes (for me) to use the latter.\nEither way, we need to be clear about what each index refers to.\n\\[\n\\begin{align}\nk &= \\textrm{Schools}\\\\\nj &= \\textrm{Children}\\\\\ni &= \\textrm{observations}\n\\end{align}\n\\]\nThe outcome, aggressive behaviour score, occurs at the observation level \\(ABS_{ijk}\\).\nLevel of routine occurs at the observation level \\(CRQ_{ijk}\\).\nFamily income occurs at the child level \\(Income_{jk}\\).\nSchool funding occurs at the school level \\(Funding_k\\).\n\nIf we just ignore all of the clustering:\n\\[\nABS = \\beta_0 + \\beta_1(CRQ) + \\beta_2(Income) + \\beta_3(Funding) + \\varepsilon\n\\]\n\n\n\nIf we put random intercepts for schools and children:\n\\[\n\\begin{align}\n\\textrm{Level 1:} & \\\\\n& ABS_{ijk} = \\beta_{0jk} + \\beta_1(CRQ_{ijk}) + \\beta_2(Income_{jk}) + \\beta_3(Funding_k) + \\varepsilon_{ijk}\\\\\n\\textrm{Level 2:} & \\\\\n&\\beta_{0jk} = \\gamma_{00k} +\\zeta_{0jk} \\\\\n\\textrm{Level 3:} & \\\\\n&\\gamma_{00k} = \\pi_{000} + u_{00k}\n\\end{align}\n\\]\n\n\n\nWe can also move the relevant effects to the corresponding level at which they exist. While we’re at it, we can change the symbol to match the other effects at each level:\n\\[\n\\begin{align}\n\\textrm{Level 1:} & \\\\\n& ABS_{ijk} = \\beta_{0jk} + \\beta_{1}(CRQ_{ijk}) + \\varepsilon_{ijk}\\\\\n\\textrm{Level 2:} & \\\\\n&\\beta_{0jk} = \\gamma_{00k} + \\gamma_{010}(Income_{jk}) +\\zeta_{0jk} \\\\\n\\textrm{Level 3:} & \\\\\n&\\gamma_{00k}= \\pi_{000} + \\pi_{001}(Funding_k) + u_{00k}\n\\end{align}\n\\]\n\n\n\nAdding in a random slope of routine for each child:\n\\[\n\\begin{align}\n\\textrm{Level 1:} & \\\\\n& ABS_{ijk} = \\beta_{0jk} + \\beta_{1jk}(CRQ_{ijk}) + \\varepsilon_{ijk}\\\\\n\\textrm{Level 2:} & \\\\\n&\\beta_{0jk} = \\gamma_{00k} + \\gamma_{010}(Income_{jk}) +\\zeta_{0jk} \\\\\n&\\beta_{1jk} = \\gamma_{100} +\\zeta_{1jk} \\\\\n\\textrm{Level 3:} & \\\\\n&\\gamma_{00k}= \\pi_{000} + \\pi_{001}(Funding_k) + u_{00k}\n\\end{align}\n\\]\nAdding in a random slope of routine for each school:\n\\[\n\\begin{align}\n\\textrm{Level 1:} & \\\\\n& ABS_{ijk} = \\beta_{0jk} + \\beta_{1jk}(CRQ_{ijk}) + \\varepsilon_{ijk}\\\\\n\\textrm{Level 2:} & \\\\\n&\\beta_{0jk} = \\gamma_{00k} + \\gamma_{010}(Income_{jk}) +\\zeta_{0jk} \\\\\n&\\beta_{1jk} = \\gamma_{10k} +\\zeta_{1jk} \\\\\n\\textrm{Level 3:} & \\\\\n&\\gamma_{00k}= \\pi_{000} + \\pi_{001}(Funding_k) + u_{00k}\\\\\n&\\gamma_{10k} = \\pi_{100} + u_{10k}\n\\end{align}\n\\]\nAdding in a random slope of income for each school:\n\\[\n\\begin{align}\n\\textrm{Level 1:} & \\\\\n& ABS_{ijk} = \\beta_{0jk} + \\beta_{1jk}(CRQ_{ijk}) + \\varepsilon_{ijk}\\\\\n\\textrm{Level 2:} & \\\\\n&\\beta_{0jk} = \\gamma_{00k} + \\gamma_{01k}(Income_{jk}) +\\zeta_{0jk} \\\\\n&\\beta_{1jk} = \\gamma_{10k} +\\zeta_{1jk} \\\\\n\\textrm{Level 3:} & \\\\\n&\\gamma_{00k}= \\pi_{000} + \\pi_{001}(Funding_k) + u_{00k}\\\\\n&\\gamma_{10k} = \\pi_{100} + u_{10k} \\\\\n& \\gamma_{01k} = \\pi_{010} + u_{01k}\n\\end{align}\n\\]\n\n\n\ncollapsing it all back down in to a “mixed” equation:\n\\[\n\\begin{align}\nABS_{ijk}= &(\\pi_{000} + u_{00k} + \\zeta_{0jk}) + & \\\\\n& (\\pi_{100} + u_{10k} + \\zeta_{1jk})(CRQ_{ijk}) + &\\\\\n&(\\pi_{010} + u_{01k})(Income_{jk}) + &\\\\\n&\\pi_{001}(Funding_k) + &\\\\\n& \\varepsilon_{ijk}& \\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "explainer_pcavar.html",
    "href": "explainer_pcavar.html",
    "title": "PCA and unequal variances",
    "section": "",
    "text": "We’re including this code if you want to create some data and play around with it yourself, but do not worry about understanding it! In brief, what it does is 1) create a covariance matrix 2) generate data based on the covariance matrix and 3) rename the columns to “item1”, “item2”.. etc.\n\n\nCode\nlibrary(tidyverse)\nset.seed(993)\nnitem <- 5  \nA <- matrix(runif(nitem^2)*2-1, ncol=nitem) \nscor <- t(A) %*% A\ndf <- MASS::mvrnorm(n=200,mu=rep(0,5),Sigma = scor) %>% as_tibble()\nnames(df)<-paste0(\"item\",1:5)\n\n\nThe data we created has 5 items, all on similar scales:\n\n\nCode\nlibrary(psych)\nlibrary(knitr)\nkable(describe(df)[,c(3:4)])\n\n\n\n\n\n\nmean\nsd\n\n\n\n\nitem1\n-0.096\n1.48\n\n\nitem2\n0.027\n1.98\n\n\nitem3\n-0.080\n1.22\n\n\nitem4\n-0.047\n1.66\n\n\nitem5\n0.140\n1.65"
  },
  {
    "objectID": "explainer_pcavar.html#pca-on-the-covariance-matrix",
    "href": "explainer_pcavar.html#pca-on-the-covariance-matrix",
    "title": "PCA and unequal variances",
    "section": "PCA on the covariance matrix",
    "text": "PCA on the covariance matrix\nIf we use the covariance matrix, we get slightly different results, because the loadings are proportional to the scale of the variance for each item.\n\n\nCode\nprincipal(cov(df), nfactors = 1, covar = TRUE)$loadings\n\n\n\nLoadings:\n      PC1   \nitem1  0.995\nitem2  1.689\nitem3  0.403\nitem4  1.644\nitem5 -0.613\n\n                PC1\nSS loadings    7.08\nProportion Var 1.42\n\n\n\n\n\n\n \n  \n      \n    variance of item \n    loadings cor PCA \n    loadings cov PCA \n  \n \n\n  \n    item1 \n    2.20 \n    0.662 \n    0.995 \n  \n  \n    item2 \n    3.92 \n    0.658 \n    1.689 \n  \n  \n    item3 \n    1.48 \n    0.576 \n    0.403 \n  \n  \n    item4 \n    2.75 \n    0.957 \n    1.644 \n  \n  \n    item5 \n    2.72 \n    -0.630 \n    -0.613 \n  \n\n\n\n\n\nThis means that if the items are measured on very different scales, using the covariance matrix will lead to the components being dominated by the items with the largest variance.\nLet’s make another dataset in which item2 is just measured on a completely different scale\n\n\nCode\ndfb <- df %>% mutate(item2 = item2*20)\nkable(describe(dfb)[,c(3:4)])\n\n\n\n\n \n  \n      \n    mean \n    sd \n  \n \n\n  \n    item1 \n    -0.096 \n    1.48 \n  \n  \n    item2 \n    0.545 \n    39.58 \n  \n  \n    item3 \n    -0.080 \n    1.22 \n  \n  \n    item4 \n    -0.047 \n    1.66 \n  \n  \n    item5 \n    0.140 \n    1.65 \n  \n\n\n\n\n\n\n\n\n\n \n  \n      \n    variance of item \n    loadings cor PCA \n    loadings cov PCA \n  \n \n\n  \n    item1 \n    2.20 \n    0.662 \n    0.546 \n  \n  \n    item2 \n    1566.53 \n    0.658 \n    39.579 \n  \n  \n    item3 \n    1.48 \n    0.576 \n    0.020 \n  \n  \n    item4 \n    2.75 \n    0.957 \n    1.337 \n  \n  \n    item5 \n    2.72 \n    -0.630 \n    0.069"
  },
  {
    "objectID": "explainer_pcavar.html#use-of-covar..",
    "href": "explainer_pcavar.html#use-of-covar..",
    "title": "PCA and unequal variances",
    "section": "Use of covar=..",
    "text": "Use of covar=..\nThe covar=TRUE/FALSE argument of principal() only makes a difference if you give the function a covariance matrix.\nIf you give the principal() function the raw data, then it will automatically conduct the PCA on the correlation matrix regardless of whether you put covar=TRUE or covar=FALSE\n\n\n\n\n \n  \n    principal(dfb, nfactors = 1, covar = FALSE) \n    dfb, nfactors = 1, covar = TRUE) \n    principal(cor(dfb), nfactors = 1) \n    principal(cov(dfb), nfactors = 1, covar = FALSE) \n    principal(cov(dfb), nfactors = 1, covar = TRUE) \n  \n \n\n  \n    0.662 \n    0.662 \n    0.662 \n    0.662 \n    0.546 \n  \n  \n    0.658 \n    0.658 \n    0.658 \n    0.658 \n    39.579 \n  \n  \n    0.576 \n    0.576 \n    0.576 \n    0.576 \n    0.020 \n  \n  \n    0.957 \n    0.957 \n    0.957 \n    0.957 \n    1.337 \n  \n  \n    -0.630 \n    -0.630 \n    -0.630 \n    -0.630 \n    0.069"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to DAPR3",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 3 (DAPR3) lab workbook. Using the menu above, you can find lab materials for each week. These include sets of exercises along with walkthrough readings in which we introduce some of the more important R code. It is strongly recommended that students have taken Data Analysis for Psychology in R 1 and 2 (DAPR1 & DAPR2)."
  },
  {
    "objectID": "index.html#solutions",
    "href": "index.html#solutions",
    "title": "Welcome to DAPR3",
    "section": "Solutions",
    "text": "Solutions\nSolutions will be made available immediately below each exercise, in the week after they are set, so make sure to re-visit the labs to check your answers."
  },
  {
    "objectID": "index.html#asking-questions",
    "href": "index.html#asking-questions",
    "title": "Welcome to DAPR3",
    "section": "Asking Questions",
    "text": "Asking Questions\nWe encourage you to use the various support options, details of which can be found on the Course Learn Page."
  },
  {
    "objectID": "index.html#tips-on-googling-statistics-and-r",
    "href": "index.html#tips-on-googling-statistics-and-r",
    "title": "Welcome to DAPR3",
    "section": "Tips on googling statistics and R",
    "text": "Tips on googling statistics and R\nSearching online for help with statistics and R can be both a help and a hindrance. If you have an error message in R, copy the error message into google. The results returned can sometimes just cause more confusion, but sometimes something might jump out at you and help you solve the problem. The same applies with searching the internet for help with statistics - search for “what is a p-value”, and you’ll find many many different articles and forum discussions etc. Some of them you will find too technical, but don’t be scared - the vast majority of people work in statistics will find these too technical too. Some of them you might feel are too simple/not helpful. As a general guide, keep clicking around the search responses, and you may end up finding that someone, somewhere, has provided an explanation at the right level. If you find something during your search which you don’t quite understand, feel free to link it in a post on the discussion forum!"
  },
  {
    "objectID": "index.html#feedback-on-labs",
    "href": "index.html#feedback-on-labs",
    "title": "Welcome to DAPR3",
    "section": "Feedback on labs",
    "text": "Feedback on labs\nIf you wish to make suggestions for improvements to these workbooks, please email ppls.psych.stats@ed.ac.uk making sure to include the course name in the subject."
  }
]