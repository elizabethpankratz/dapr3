<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Multilevel Model Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Josiah King" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <script src="jk_libs/libs/clipboard/clipboard.min.js"></script>
    <link href="jk_libs/libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="jk_libs/libs/shareon/shareon.min.js"></script>
    <link href="jk_libs/libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="jk_libs/libs/xaringanExtra-shareagain/shareagain.js"></script>
    <link href="jk_libs/libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="jk_libs/libs/tile-view/tile-view.js"></script>
    <link href="jk_libs/libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="jk_libs/libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="jk_libs/libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b>Multilevel Model Inference</b>
]
.subtitle[
## Data Analysis for Psychology in R 3
]
.author[
### Josiah King
]
.institute[
### Department of Psychology<br/>The University of Edinburgh
]

---





class: inverse, center, middle

&lt;h1 style="text-align: left;"&gt;This Lecture:&lt;/h1&gt;
&lt;h3 style="text-align: left;"&gt;1. Inferential methods with `lmer`&lt;/h3&gt;

---
# &lt;p&gt;&lt;/p&gt;

you might have noticed...


```r
library(lme4)
d3 &lt;- read_csv("https://uoepsy.github.io/data/dapr3_mindfuldecline.csv")

cogtime_model &lt;- lmer(ACE ~ 1 + visit + (1 + visit | ppt), data = d3)

summary(cogtime_model)
```


.pull-left[


```
## Linear mixed model fit by REML ['lmerMod']
## Formula: ACE ~ 1 + visit + (1 + visit | ppt)
##    Data: d3
## 
## REML criterion at convergence: 365.2
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.3120 -0.6818 -0.0526  0.7016  2.4022 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  ppt      (Intercept) 0.157    0.396         
##           visit       0.104    0.322    -0.59
##  Residual             0.244    0.494         
## Number of obs: 177, groups:  ppt, 20
## 
## Fixed effects:
##             Estimate Std. Error t value
*## (Intercept)  85.5843     0.1201  712.67
*## visit        -0.3588     0.0733   -4.89
## 
## Correlation of Fixed Effects:
##       (Intr)
## visit -0.534
```
]
.pull-right[
![](jk_img_sandbox/wotnop.png)
{{content}}

]

--

&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;center&gt;&lt;b&gt;Extensive debate about how best to test parameters from MLMs.&lt;/b&gt;&lt;/center&gt;  

---
# p-values in `lm()`

In simple LM, we test the reduction in residual SS (sums of squares), which follows an `\(F\)` distribution with a known `\(df\)`.  

`\(F\)` tests for each predictor will have `\(k\)` numerator degrees of freedom (how many parameters) and `\(n-k-1\)` denominator degrees of freedom.  

The `\(t\)`-statistics for coefficients will follow `\(t\)`-distributions with the same `\(n-k-1\)` degrees of freedom.

&lt;br&gt; 

$$
`\begin{align}
F \qquad &amp; = \qquad \frac{MS_{model}}{MS_{residual}} \qquad &amp;= \qquad \frac{SS_{model}/df_{model}}{SS_{residual}/df_{residual}} \\
\quad \\
&amp; &amp; df_{model} = k \\
&amp; &amp; df_{residual} = n-k-1 \\
\end{align}`
$$
---
count: false
exclude: true
# p-values in `lm()`

In simple LM, we test the reduction in residual SS (sums of squares), which follows an `\(F\)` distribution with a known `\(df\)`.  

`\(F\)` tests for each predictor will have `\(k\)` numerator degrees of freedom (how many parameters) and `\(n-k-1\)` denominator degrees of freedom.  

The `\(t\)`-statistics for coefficients will follow `\(t\)`-distributions with the same `\(n-k-1\)` degrees of freedom.

&lt;br&gt; 

$$
`\begin{align}
F \qquad &amp; = \qquad  \frac{\text{variance explained by model}/\text{nr model parameters}}{\text{variance left over}/\text{nr residuals that are free to vary}} &amp; \\
\quad \\
&amp; = \frac{\text{avg variance explained per model parameter}}{\text{avg variance explained per residual}} &amp;
\end{align}`
$$



---
# p-values in `lmer()`?  

- In certain *very specific* conditions, we can work out what the degrees of freedom are. 

- Parameter estimates from these models are not based on minimising sums of squared residuals  

  - They are the ML/REML estimates

  - This is good - it means they can handle unbalanced designs and complex random effect structures

- But: 
  - unclear how to calculate denominator `\(df\)`
  - unclear whether the test statistics even follow an `\(F\)` distribution
  
---
# Options for inference

&lt;ol&gt;
&lt;li&gt;approximating ddf&lt;/li&gt;
  &lt;ul&gt;
  &lt;li&gt;satterthwaite&lt;/li&gt;
  &lt;li&gt;kenward-rogers&lt;/li&gt;
  &lt;li&gt;m-l-1&lt;/li&gt;
  &lt;li&gt;...&lt;/li&gt;
  &lt;/ul&gt;
&lt;li&gt;likelihood based methods&lt;/li&gt;
  &lt;ul&gt;
  &lt;li&gt;profile likelihood confidence interval&lt;/li&gt;
  &lt;li&gt;likelihood ratio tests&lt;/li&gt;
  &lt;/ul&gt;
&lt;li&gt;bootstrap&lt;/li&gt;
  &lt;ul&gt;
  &lt;li&gt;parametric&lt;/li&gt;
    &lt;ul&gt;
    &lt;li&gt;confidence interval&lt;/li&gt;
    &lt;li&gt;likelihood ratio test&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li&gt;case-based&lt;/li&gt;
    &lt;ul&gt;
    &lt;li&gt;confidence interval&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/ul&gt;
&lt;/ol&gt;
  
&lt;p&gt;(there are others...)&lt;/p&gt;  

---
# Options for inference

&lt;ol&gt;
&lt;li&gt;approximating ddf&lt;/li&gt;
  &lt;ul&gt;
  &lt;li style="opacity:.4"&gt;satterthwaite&lt;/li&gt;
  &lt;li&gt;kenward-rogers&lt;/li&gt;
  &lt;li style="opacity:.4"&gt;m-l-1&lt;/li&gt;
  &lt;li style="opacity:.4"&gt;...&lt;/li&gt;
  &lt;/ul&gt;
&lt;li&gt;likelihood based methods&lt;/li&gt;
  &lt;ul&gt;
  &lt;li&gt;profile likelihood confidence interval&lt;/li&gt;
  &lt;li&gt;likelihood ratio tests&lt;/li&gt;
  &lt;/ul&gt;
&lt;li style="opacity:.4"&gt;bootstrap&lt;/li&gt;
  &lt;ul&gt;
  &lt;li style="opacity:.4"&gt;parametric&lt;/li&gt;
    &lt;ul&gt;
    &lt;li style="opacity:.4"&gt;confidence interval: &lt;code&gt;confint(model, method = "boot")&lt;/code&gt;&lt;/li&gt;
    &lt;li style="opacity:.4"&gt;likelihood ratio test: &lt;code&gt;pbkrtest::PBmodcomp(full_model, reduced_model)&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;li style="opacity:.4"&gt;case-based&lt;/li&gt;
    &lt;ul&gt;
    &lt;li style="opacity:.4"&gt;confidence interval&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/ul&gt;
&lt;/ol&gt;
  
&lt;p style="opacity:.4"&gt;(there are others...)&lt;/p&gt;  
---
# Kenward-Rogers 

- Adjusts standard errors to avoid small sample bias
- Approximates denominator degrees of freedom
- Models must be fitted with REML (which is good for small samples!)  

__fixed effects__  


```r
library(parameters)
model_parameters(cogtime_model, ci_method = "kr") # %&gt;% print_html()
```

```
## # Fixed Effects
## 
## Parameter   | Coefficient |   SE |         95% CI |      t |    df |      p
## ---------------------------------------------------------------------------
## (Intercept) |       85.58 | 0.12 | [85.33, 85.84] | 710.54 | 18.51 | &lt; .001
## visit       |       -0.36 | 0.07 | [-0.51, -0.21] |  -4.89 | 18.99 | &lt; .001
## 
## # Random Effects
## 
## Parameter                  | Coefficient |   SE |        95% CI
## ---------------------------------------------------------------
## SD (Intercept: ppt)        |        0.40 | 0.12 | [ 0.22, 0.71]
## SD (visit: ppt)            |        0.32 | 0.05 | [ 0.23, 0.45]
## Cor (Intercept~visit: ppt) |       -0.59 | 0.36 | [-0.94, 0.38]
## SD (Residual)              |        0.49 | 0.03 | [ 0.44, 0.56]
```


---
# Kenward-Rogers 


- Adjusts standard errors to avoid small sample bias
- Approximates denominator degrees of freedom
- Models must be fitted with REML (which is good for small samples!)  

__Model Comparison__  


```r
restricted_model &lt;- lmer(ACE ~ 1 + (1 + visit | ppt), data = d3, REML = TRUE)
full_model &lt;- lmer(ACE ~ 1 + visit + (1 + visit | ppt), data = d3, REML = TRUE)  

library(pbkrtest)
KRmodcomp(full_model, restricted_model)
```

```
## large : ACE ~ 1 + visit + (1 + visit | ppt)
## small : ACE ~ 1 + (1 + visit | ppt)
##       stat  ndf  ddf F.scaling p.value    
## Ftest 23.9  1.0 19.0         1  0.0001 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```



---
# Likelihood ratio tests

.pull-left[

- Compares the log-likelihood of two competing models.
- ratio of two likelihoods is **asymptotically** `\(\chi^2\)`-square distributed.
    - *this means for small samples (at any level) it may be unreliable*
    - how small is too small?  
        ¯\\\_(ツ)\_/¯ 42? 

]
.pull-right[
__LRTs and ML/REML__  

&lt;ul&gt;
&lt;li&gt;if models differ in fixed effects only, then fit with ML&lt;/li&gt; 
&lt;li style="opacity:.6"&gt;if models differ in random effects only, then fit with REML (or ML if big N)&lt;/li&gt;
&lt;li style="opacity:.6"&gt;if models differ in both, then fit with ML&lt;/li&gt;
&lt;/ul&gt;
`anova()` will automatically re-fit models with ML.  

]
  
&lt;br&gt;

```r
restricted_model &lt;- lmer(ACE ~ 1 + (1 + visit | ppt), data = d3, REML = FALSE)
full_model &lt;- lmer(ACE ~ 1 + visit + (1 + visit | ppt), data = d3, REML = FALSE)  

anova(restricted_model, full_model)
```

```
## Data: d3
## Models:
## restricted_model: ACE ~ 1 + (1 + visit | ppt)
## full_model: ACE ~ 1 + visit + (1 + visit | ppt)
##                  npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq)    
## restricted_model    5 385 401   -188      375                        
## full_model          6 371 390   -180      359  16.3  1   0.000055 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
# Likelihood-based CIs

- Evaluates the curvature of the likelihood surface at the estimate.  

  - sharp curvature = more certainty in estimate  
  
  - gradual curvature = less certainty in estimate  
  
- models need to be fitted with ML, not REML  



```r
confint(cogtime_model, method="profile")
```

```
##               2.5 %   97.5 %
## .sig01       0.1537  0.64010
## .sig02      -0.9368 -0.04886
## .sig03       0.2339  0.44750
## .sigma       0.4413  0.55875
## (Intercept) 85.3421 85.82385
## visit       -0.5057 -0.21155
```


---
# Summary

- Lots of debate around how best to conduct statistical inferences based on multi-level models. 

--

- Lots of options.  

--

|                  | df approximations                                                  | likelihood-based                                                    | 
| ---------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------- | 
| tests or CIs for model parameters | `library(parameters)`&lt;br&gt;`model_parameters(model, ci_method="kr")` | `confint(model, type="profile")`                                    | 
| model comparison&lt;br&gt;&lt;small&gt;(different fixed effects, same random effects)&lt;/small&gt; | `library(pbkrtest)`&lt;br&gt;`KRmodcomp(model1,model0)`                  | `anova(model0,model)`                                               |
|                  | fit models with `REML=TRUE`.&lt;br&gt;good option for small samples      | fit models with `REML=FALSE`.&lt;br&gt;needs large N at both levels (40+) | 


- check your sample size! but if in doubt, go for KR.  


---
class: inverse, center, middle, animated, rotateInDownLeft

# End

---
class: inverse, center, middle

&lt;h1 style="text-align: left;"&gt;This Lecture:&lt;/h1&gt;
&lt;h3 style="text-align: left;opacity:.4"&gt;1. Inferential methods with `lmer`&lt;/h3&gt;
&lt;h3 style="text-align: left; "&gt;Bonus content&lt;/h3&gt;

---
# Bootstrap

&lt;ul&gt;
&lt;li&gt;Parametric Bootstrap&lt;br&gt;assumes that explanatory variables are fixed and that model specification and the distributions such as `\(\zeta_i \sim N(0,\sigma_{\zeta})\)` and `\(\varepsilon_i \sim N(0,\sigma_{\varepsilon})\)` are correct.&lt;/li&gt;&lt;br&gt;
&lt;li style="opacity: .6"&gt;Case-based Bootstrap&lt;br&gt;minimal assumptions - we just need to ensure that we correctly specify the hierarchical dependency of data.&lt;br&gt;requires decision of at which levels to resample.&lt;br&gt;(discussed more next week)&lt;/li&gt;
&lt;/ul&gt;


---
# Parametric Bootstrap

The basic premise is that we:  

1. fit model(s) to data

2. Do many times:

  - simulate data based on the parameters of the fitted model(s)
  - compute some statistic/estimates from the simulated data

3. Construct a distribution of possible values  

---
# Parametric Bootstrap

.pull-left[
## Confidence Intervals

```r
full_model &lt;- lmer(ACE ~ 1 + visit + 
              (1 + visit | ppt), data = d3)  
confint(full_model, method = "boot")
```
```
              2.5 %  97.5 %
.sig01       0.1130  0.6133
.sig02      -1.0000  0.1028
.sig03       0.2084  0.4225
.sigma       0.4253  0.5542
(Intercept) 85.3443 85.8334
visit       -0.5029 -0.2137
```
]
.pull-right[
## LRT
(a bootstrapped version of the likelihood ratio test):  

```r
restricted_model &lt;- lmer(ACE ~ 1 + 
                    (1 + visit | ppt), data = d3)
full_model &lt;- lmer(ACE ~ 1 + visit + 
              (1 + visit | ppt), data = d3)  

library(pbkrtest)
PBmodcomp(full_model, restricted_model)
```
```
Bootstrap test; time: 71.91 sec; samples: 1000; extremes: 0;
large : ACE ~ 1 + visit + (1 + visit | ppt)
ACE ~ 1 + (1 + visit | ppt)
       stat df  p.value    
LRT    16.3  1 0.000055 ***
PBtest 16.3       0.001 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```
]

---
# Adding more options


|                  | df approximations                                                                                                                                                                                                              | likelihood-based                                                                                 | parametric bootstrap                                                                                 |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------- |
| model parameters | `library(parameters)`&lt;br&gt;`model_parameters(model, ci_method="kr")`                                                                                                                                                             | `confint(model, type="profile")`                                                                 | `confint(model, type="boot")`                                                                        |
| model comparison | `library(pbkrtest)`&lt;br&gt;`KRmodcomp(model1,model0)`                                                                                                                                                                              | `anova(model0,model)`                                                                            | `library(pbkrtest)`&lt;br&gt;`PBmodcomp(model1,model0)`                                                    |
|                  | for KR, fit models with `REML=TRUE` (a good option for small samples).&lt;br&gt;Other options available (e.g. Satterthwaite, m-l-1, ...)&lt;br&gt;easy to implement, but debate as to whether statistics actually follow an F distribution | if models differ in fixed effects, we cannot use `\(-2\Delta LL\)` when models are fitted with REML. | Time consuming, but probably most reliable option (although can be problematic with unstable models) |

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
