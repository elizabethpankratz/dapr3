[
  {
    "objectID": "00prereq.html",
    "href": "00prereq.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Install/Update R & RStudio\nMake sure you have installed both R and RStudio on your computer. You may have done this previously for DAPR2, in which case it is probably worth doing some updates.\nPlease make sure to read and follow the instructions below slowly and carefully!!\n\nFor instructions on how to install R and RStudio, click here\nFor instructions on how to update R and RStudio, click here\n\n\n\nUpdate Packages\nIt’s worth keeping packages up to date, so it might be worth updating all your packages.\nRunning this code will update all your packages. Just put it into the console (bottom left bit of RStudio):\n\noptions(pkgType = \"binary\")\nupdate.packages(ask = FALSE)\n\n\n\nNew packages!\nNow it is probably worth installing a few of the packages that we will be using in DAPR3. There are a few that we will need. For each one, check whether you have it already installed, because there’s not much point wasting time re-installing something you already have!\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models"
  },
  {
    "objectID": "01ex.html",
    "href": "01ex.html",
    "title": "W1 Exercises: Regression Refresher",
    "section": "",
    "text": "Workplace Pride\n\nData: lmm_jsup.csv\nA questionnaire was sent to all UK civil service departments, and the lmm_jsup.csv dataset contains all responses that were received. Some of these departments work as hybrid or ‘virtual’ departments, with a mix of remote and office-based employees. Others are fully office-based.\nThe questionnaire included items asking about how much the respondent believe in the department and how it engages with the community, what it produces, how it operates and how treats its people. A composite measure of ‘workplace-pride’ was constructed for each employee. Employees in the civil service are categorised into 3 different roles: A, B and C. The roles tend to increase in responsibility, with role C being more managerial, and role A having less responsibility. We also have data on the length of time each employee has been in the department (sometimes new employees come straight in at role C, but many of them start in role A and work up over time).\nWe’re interested in whether the different roles are associated with differences in workplace-pride.\nDataset: https://uoepsy.github.io/data/lmm_jsup.csv.\n\n\n\n\n\n\n  \n    \n      variable\n      description\n    \n  \n  \n    department_name\nName of government department\n    dept\nDepartment Acronym\n    virtual\nWhether the department functions as hybrid department with various employees working remotely (1), or as a fully in-person office (0)\n    role\nEmployee role (A, B or C)\n    seniority\nEmployees seniority point. These map to roles, such that role A is 0-4, role B is 5-9, role C is 10-14. Higher numbers indicate more seniority\n    employment_length\nLength of employment in the department (years)\n    wp\nComposite Measure of 'Workplace Pride'\n  \n  \n  \n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and provide some descriptive statistics.\n\n\n\n\n\n\nHints\n\n\n\n\n\nDon’t remember how to do descriptives? Think back to previous courses - it’s time for some means, standard deviations, mins and maxes. For categorical variables we can do counts or proportions.\nWe’ve seen various functions such as summary(), and also describe() from the psych package.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHere’s the dataset:\n\nlibrary(tidyverse) # for data wrangling\nlibrary(psych) \n\njsup &lt;- read_csv(\"https://uoepsy.github.io/data/lmm_jsup.csv\")\n\nLet’s take just the numeric variables and get some descriptives:\n\njsup |&gt; \n  select(employment_length, wp) |&gt; \n  describe()\n\n                  vars   n mean   sd median trimmed  mad  min  max range  skew\nemployment_length    1 295 12.6 4.28   13.0    12.6 4.45 0.00 30.0  30.0  0.08\nwp                   2 295 25.5 5.27   25.4    25.5 5.93 6.34 38.5  32.1 -0.05\n                  kurtosis   se\nemployment_length     0.38 0.25\nwp                   -0.14 0.31\n\n\nAnd make frequency tables for the categorical ones:\n\ntable(jsup$role)\n\n\n  A   B   C \n109  95  91 \n\n\nI’m going to use dept rather than department_name as the output will be easier to see:\n\ntable(jsup$dept)\n\n\n   ACE    CMA    CPS    FSA    GLD   HMRC    NCA   NS&I  OFGEM OFQUAL OFSTED \n    17     21     13     25     17     16     20     20     15      5     17 \n OFWAT    ORR    SFO   UKSA   UKSC \n    16     17     18     45     13 \n\ntable(jsup$virtual)\n\n\n  0   1 \n175 120 \n\n\n\n\n\n\nQuestion 2\n\n\nAre there differences in ‘workplace-pride’ between people in different roles?\n\n\n\n\n\n\nHints\n\n\n\n\n\ndoes y [continuous variable] differ by x [three groups]? lm(y ~ x)?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod1 &lt;- lm(wp ~ role, data = jsup)\n\nRather than doing summary(model) - I’m just going to use the broom package to pull out some of the stats in nice tidy dataframes.\nThe glance() function will give us things like the \\(R^2\\) values and \\(F\\)-statistic (basically all the stuff that is at the bottom of the summary()):\n\nlibrary(broom)\nglance(mod1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.216         0.211  4.68      40.3 3.44e-16     2  -872. 1753. 1768.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nThe tidy() function will give us the coefficients, standard errors, t-statistics and p-values. It’s the same information, just neater!\n\ntidy(mod1)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    28.1      0.448     62.6  3.66e-171\n2 roleB          -2.24     0.657     -3.41 7.33e-  4\n3 roleC          -5.95     0.665     -8.95 4.38e- 17\n\n\nAlternatively, we can get some quick confidence intervals for our coefficients:\n\nconfint(mod1)\n\n            2.5 % 97.5 %\n(Intercept) 27.17 28.933\nroleB       -3.54 -0.949\nroleC       -7.26 -4.638\n\n\nIt looks like roles do differ in their workplace pride. Specifically, compared to people in role A, people who are in roles B and C on average report less pride in the workplace.\n\n\n\n\n\nQuestion 3\n\n\nIs it something about the roles that make people report differences in workplace-pride, or is it possibly just that people who are newer to the company tend to feel more pride than those who have been there for a while (they’re all jaded), and the people in role A tend to be much newer to the company (making it look like the role A results in taking more pride). In other words, if we were to compare people in role A vs role B vs role C but hold constant their employment_length, we might see something different?\nFit another model to find out.\nTo help with interpreting the model, make a plot that shows all of the relevant variables that are in the model in one way or another.\n\n\n\n\n\n\nHints\n\n\n\n\n\nSo we want to adjust for how long people have been part of the company..\nRemember - if we want to estimate the effect of x on y while adjusting for z, we can do lm(y ~ z + x).\nFor the plot - put something on the x, something on the y, and colour it by the other variable.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\ntidy(mod2)\n\n# A tibble: 4 × 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         36.1      0.709     50.9   6.90e-147\n2 employment_length   -0.834    0.0637   -13.1   4.32e- 31\n3 roleB                0.510    0.563      0.906 3.65e-  1\n4 roleC               -0.704    0.663     -1.06  2.89e-  1\n\n\nNote that, after adjusting for employment length, there are no significant differences in wp between roles B or C compared to A.\nIf we plot the data to show all these variables together, we can kind of see why! Given the pattern of wp against employment_length, the wp for different roles are pretty much where we would expect them to be if role doesn’t make any difference (i.e., if role doesn’t shift your wp up or down).\n\nggplot(jsup, aes(x=employment_length,y=wp,col=role))+\n  geom_point(size=3,alpha=.3)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nDo roles differ in their workplace-pride, when adjusting for time in the company?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis may feel like a repeat of the previous question, but note that this is not a question about specific group differences. It is about whether, overall, the role groups differ. So it’s wanting to test the joint effect of the two additional parameters we’ve just added to our model. (hint hint model comparison!)\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod2a &lt;- lm(wp ~ employment_length, data = jsup)\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\nanova(mod2a, mod2)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length\nModel 2: wp ~ employment_length + role\n  Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)\n1    293 4091                         \n2    291 4029  2      61.9 2.23   0.11\n\n\nThis is no surprise given the previous question, we just now have a single test to report if we wanted to - after accounting for employment length, role does not explain a significant amount of variance in workplace pride.\n\n\n\n\nQuestion 5\n\n\nLet’s take a step back and remember what data we actually have. We’ve got 295 people in our dataset, from 16 departments.\nDepartments may well differ in the general amount of workplace-pride people report. People love to say that they work in the “National Crime Agency”, but other departments might not elicit such pride (*cough* HM Revenue & Customs *cough*). We need to be careful not to mistake department differences as something else (like differences due to the job role).\nMake a couple of plots to look at:\n\nhow many of each role we have from each department\nhow departments differ in their employees’ pride in their workplace\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(jsup, aes(x = role)) + \n  geom_bar()+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nIn this case, it looks like most of the departments have similar numbers of each role, apart from the UKSA (“UK Statistics Authority”), where we’ve got loads more of role A, and very few role C..\nNote also that in the plot below, the UKSA is, on average, full of employees who take a lot of pride in their work. Is this due to the high proportion of people in role A? or is the effect of role we’re seeing more due to differences in departments?\n\nggplot(jsup, aes(x = dept, y = wp)) +\n  geom_boxplot() +\n  scale_x_discrete(labels = label_wrap_gen(35)) + \n  coord_flip()\n\n\n\n\n\n\n\n\nEven if we had perfectly equal numbers of roles in each department, we’re also adjusting for other things such as employment_length, and the extent to which this differs by department can have trickle-on effects on our coefficient of interest (the role coefficients).\n\n\n\n\nQuestion 6\n\n\nAdjusting for both length of employment and department, are there differences in ‘workplace-pride’ between the different roles?\nCan you make a plot of all four of the variables involved in our model?\n\n\n\n\n\n\nHints\n\n\n\n\n\nMaking the plot might take some thinking. We’ve now added dept into the mix, so a nice way might be to use facet_wrap() to make the same plot as the one we did previously, but for each department.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod3 &lt;- lm(wp ~ employment_length + dept + role, data = jsup)\ntidy(mod3)\n\n# A tibble: 19 × 5\n   term              estimate std.error statistic   p.value\n   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)        36.4       0.631    57.6    7.17e-156\n 2 employment_length  -0.882     0.0344  -25.7    4.71e- 75\n 3 deptCMA            -3.80      0.649    -5.85   1.39e-  8\n 4 deptCPS            -0.217     0.730    -0.298  7.66e-  1\n 5 deptFSA             4.74      0.625     7.60   4.71e- 13\n 6 deptGLD             0.0582    0.682     0.0853 9.32e-  1\n 7 deptHMRC           -3.79      0.692    -5.47   1.02e-  7\n 8 deptNCA            -3.85      0.655    -5.88   1.18e-  8\n 9 deptNS&I           -0.574     0.654    -0.878  3.81e-  1\n10 deptOFGEM          -0.648     0.705    -0.919  3.59e-  1\n11 deptOFQUAL         -4.94      1.01     -4.89   1.71e-  6\n12 deptOFSTED         -5.88      0.683    -8.61   5.52e- 16\n13 deptOFWAT          -1.21      0.692    -1.75   8.17e-  2\n14 deptORR            -2.85      0.681    -4.18   3.98e-  5\n15 deptSFO            -1.36      0.672    -2.02   4.47e-  2\n16 deptUKSA            4.28      0.576     7.43   1.32e- 12\n17 deptUKSC           -2.31      0.732    -3.16   1.77e-  3\n18 roleB               1.42      0.303     4.68   4.47e-  6\n19 roleC               1.31      0.366     3.59   3.92e-  4\n\n\nIn a way, adding predictors to our model is kind of like splitting up our plots by that predictor to see the patterns. This becomes more and more difficult (/impossible) as we get more variables, but right now we can split the data into all the constituent parts.\n\nggplot(jsup, aes(x = employment_length, y = wp, col = role)) +\n  geom_point(size=3,alpha=.4)+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nThe association between wp and employment_length is clear in all these little sub-plots - there’s a downward trend. The department differences can be seen too: UKSA is generally a bit higher, HMRC and UKSC a bit lower, and so on. By default, the model captures these coefficients as ‘differences from the reference group’, so all these coefficients are in relation to the “ACE” department.\nSeeing the role differences is a bit harder in this plot, but think about what you would expect to see if there were no differences in roles (i.e. imagine if they were all in role A). Take for instance the FSA department, where this is easiest to see - for the people who are in role C, for people of their employment length we would expect their wp to be lower if they were in role A. Likewise for those in role B. Across all these departments, the people in role B and C (green and blue dots respectively) are a bit higher than we would expect. This is what the model coefficients tell us!\n\n\n\n\nQuestion 7\n\n\nNow we’re starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on..\nLet’s try to describe our sample in a bit more detail.\n\nhow many participants do we have, and from how many departments?\nhow many participants are there, on average, from each department? what is the minimum and maximum?\nwhat is the average employment length for our participants?\nhow many departments are ‘virtual departments’ vs office-based?\n\nwhat is the overall average reported workplace-pride?\nhow much variation in workplace-pride is due to differences between departments?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe first lot of these questions can be answered using things like count(), summary(), table(), mean(), min() etc. See 1: Clustered Data #determining-sample-sizes\nFor the last one, we can use the ICC! See 1: Clustered Data #icc\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHow many respondents do we have, and from how many departments?\n\nnrow(jsup)\n\n[1] 295\n\nlength(table(jsup$dept))\n\n[1] 16\n\n\nHow many respondents are there, on average, from each dept? What is the minimum and maximum number of people in any one department?\n\njsup |&gt;\n  count(dept) |&gt; \n  summarise(min=min(n),\n            max=max(n),\n            median=median(n)\n  )\n\n# A tibble: 1 × 3\n    min   max median\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n1     5    45     17\n\n\nWhat is the average employment length of respondents?\n\nmean(jsup$employment_length)\n\n[1] 12.6\n\n\nHow many departments are virtual vs office based? This requires a bit more than just table(jsup$virtual), because we are describing a variable at the department level.\n\njsup |&gt; \n  group_by(virtual) |&gt;\n  summarise(\n    ndept = n_distinct(dept)\n  )\n\n# A tibble: 2 × 2\n  virtual ndept\n    &lt;dbl&gt; &lt;int&gt;\n1       0    11\n2       1     5\n\n\nWhat is the overall average ‘workplace-pride’? What is the standard deviation?\n\nmean(jsup$wp)\n\n[1] 25.5\n\nsd(jsup$wp)\n\n[1] 5.27\n\n\nFinally, how much variation in workplace-pride is attributable to department-level differences?\n\nICC::ICCbare(x = dept, y = wp, data = jsup)\n\n[1] 0.439\n\n\n\n\n\n\nQuestion 8\n\n\nWhat if we would like to know whether, when adjusting for differences due to employment length and roles, workplace-pride differs between people working in virtual-departments compared to office-based ones?\nCan you add this to the model? What happens?\n\n\n\n\n\nSolution\n\n\n\nLet’s add the virtual predictor to our model. Note that we don’t actually get a coefficient here - it is giving us an NA!\n\nmod4 &lt;- lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n\nsummary(mod4)\n\n\nCall:\nlm(formula = wp ~ employment_length + dept + role + virtual, \n    data = jsup)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.690 -1.404 -0.027  1.178  5.054 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        36.3522     0.6310   57.61  &lt; 2e-16 ***\nemployment_length  -0.8817     0.0344  -25.66  &lt; 2e-16 ***\ndeptCMA            -3.7969     0.6490   -5.85  1.4e-08 ***\ndeptCPS            -0.2173     0.7304   -0.30  0.76627    \ndeptFSA             4.7448     0.6245    7.60  4.7e-13 ***\ndeptGLD             0.0582     0.6822    0.09  0.93212    \ndeptHMRC           -3.7859     0.6924   -5.47  1.0e-07 ***\ndeptNCA            -3.8503     0.6549   -5.88  1.2e-08 ***\ndeptNS&I           -0.5737     0.6537   -0.88  0.38095    \ndeptOFGEM          -0.6479     0.7050   -0.92  0.35885    \ndeptOFQUAL         -4.9413     1.0104   -4.89  1.7e-06 ***\ndeptOFSTED         -5.8846     0.6831   -8.61  5.5e-16 ***\ndeptOFWAT          -1.2087     0.6917   -1.75  0.08169 .  \ndeptORR            -2.8452     0.6813   -4.18  4.0e-05 ***\ndeptSFO            -1.3550     0.6719   -2.02  0.04469 *  \ndeptUKSA            4.2820     0.5759    7.43  1.3e-12 ***\ndeptUKSC           -2.3131     0.7325   -3.16  0.00177 ** \nroleB               1.4179     0.3029    4.68  4.5e-06 ***\nroleC               1.3148     0.3663    3.59  0.00039 ***\nvirtual                 NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.98 on 276 degrees of freedom\nMultiple R-squared:  0.867, Adjusted R-squared:  0.859 \nF-statistic:  100 on 18 and 276 DF,  p-value: &lt;2e-16\n\n\nSo what is happening? If we think about it, if we separate out “differences due to departments” then there is nothing left to compare between departments that are virtual vs office based. Adding the between-department predictor of virtual doesn’t explain anything more - the residual sums of squares doesn’t decrease at all:\n\nanova(\n  lm(wp ~ employment_length + dept + role, data = jsup),\n  lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length + dept + role\nModel 2: wp ~ employment_length + dept + role + virtual\n  Res.Df  RSS Df Sum of Sq F Pr(&gt;F)\n1    276 1084                      \n2    276 1084  0         0         \n\n\nAnother way of thinking about this: knowing the average workplace-pride for the department that someone is in tells me what to expect about that person’s workplace pride. But once I know their department’s average workplace-pride, knowing whether it is ‘virtual’ or ‘office-based’ doesn’t tell me anything new, for the very fact that the virtual/office-based distinction comes from comparing different departments.\nBut we’re not really interested in these departments specifically! What would be nice would be if we can look at the relevant effects of interest (things like role and virtual), but then just think of the department differences as just some sort of random variation. So we want to think of departments in a similar way to how we think of our individual employees - they vary randomly around what we expect - only they’re at a different level of observation."
  },
  {
    "objectID": "02ex.html",
    "href": "02ex.html",
    "title": "W2 Exercises: Introducing MLM",
    "section": "",
    "text": "These first set of exercises are not “how to do analyses with multilevel models” - they are designed to get you thinking, and help with an understanding of how these models work.\n\n\nQuestion 1\n\n\nRecall the data from last week’s exercises. Instead of looking at the roles A, B and C, we’ll look in more fine grained detail at the seniority. This is mainly so that we have a continuous variable to work with as it makes this illustration easier.\nThe chunk of code below shows a function for plotting that you might not be familiar with - stat_summary(). This takes the data in the plot and “summarises” the Y-axis variable into the mean at every unique value on the x-axis. So below, rather than having points for every observation, we have the mean of wp at every value of seniority:\n\nlibrary(tidyverse)\njsup &lt;- read_csv(\"https://uoepsy.github.io/data/lmm_jsup.csv\")\n\nggplot(jsup, aes(x = seniority, y = wp, col = role)) +\n  stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nBelow is some code that fits a model of the workplace-pride predicted by seniority level. Line 2 then gets the ‘fitted’ values from the model and adds them as a new column to the dataset, called pred_lm. The fitted values are what the model predicts for every individual observation.\nLines 4-7 then plot the data, split up by each department, and adds lines showing the model fitted values.\nRun the code and check that you get a plot. What do you notice about the lines?\n\nlm_mod &lt;- lm(wp ~ seniority, data = jsup)\njsup$pred_lm &lt;- predict(lm_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n\n\n\n\n\n\nSolution\n\n\n\nWe should get something like this:\n\nlm_mod &lt;- lm(wp ~ seniority, data = jsup)\njsup$pred_lm &lt;- predict(lm_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n\n\n\n\n\n\n\n\nNote that the lines are exactly the same for each department. This makes total sense, because the model (which is where we’ve got the lines from) completely ignores the department variable!\n\n\n\n\nQuestion 2\n\n\nBelow are 3 more code chunks that all 1) fit a model, then 2) add the fitted values of that model to the plot.\nThe first model is a ‘no-pooling’ approach, similar to what we did in last week’s exercises - adding in dept as a predictor.\nThe second and third are multilevel models. The second fits random intercepts by-department, and the third fits random intercepts and slopes of seniority.\nCopy each chunk and run through the code. Pay attention to how the lines differ.\n\n\nCode\nfe_mod &lt;- lm(wp ~ dept + seniority, data = jsup)\njsup$pred_fe &lt;- predict(fe_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n\n\n\n\nCode\nlibrary(lme4)\nri_mod &lt;- lmer(wp ~ seniority + (1|dept), data = jsup)\njsup$pred_ri &lt;- predict(ri_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n\n\n\n\nCode\nrs_mod &lt;- lmer(wp ~ seniority + (1 + seniority|dept), data = jsup)\njsup$pred_rs &lt;- predict(rs_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n\n\n\n\n\n\n\nSolution\n\n\n\nThe first model has an adjustment for each department (we can see this in the coefficients if we want). What this means is that the line for each department is shifted up or down. We can see that the lines are now shifted up for departments like UKSA and FSA, and down for UKSC and OFSTED:\n\nfe_mod &lt;- lm(wp ~ dept + seniority, data = jsup)\njsup$pred_fe &lt;- predict(fe_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n\n\n\n\n\n\n\n\nThis next one looks very similar to the previous one, but it is conceptually doing something a bit different. Rather than separating out every individual department, we are modelling a distribution of deviations for each department from some average.\n\nlibrary(lme4)\nri_mod &lt;- lmer(wp ~ seniority + (1|dept), data = jsup)\njsup$pred_ri &lt;- predict(ri_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n\n\n\n\n\n\n\n\nFinally, we can add in the random slopes of seniority. In this model, we are not only allowing departments to vary in their average workplace-pride, but we are also allowing them to vary in the association between seniority and workplace pride. Some departments (OFQUAL, OFSTED, ORR) have a negative association, some have a flatter association (e.g, FSA, UKSA etc).\n\nrs_mod &lt;- lmer(wp ~ seniority + (1 + seniority|dept), data = jsup)\njsup$pred_rs &lt;- predict(rs_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFrom the previous questions you should have a model called ri_mod.\nBelow is a plot of the fitted values from that model. Rather than having a separate facet for each department as we did above, I have put them all on one plot. The thick black line is the average intercept and slope of the departments lines.\nIdentify the parts of the plot that correspond to A1-4 in the summary output of the model below\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nChoose from these options:\n\nwhere the black line cuts the y axis (at x=0)\n\nthe slope of the black line\n\nthe standard deviation of the distances from all the individual datapoints (employees) to the line for the department in which it works.\n\nthe standard deviation of the distances from all the individual department lines to the black line\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA1 = the standard deviation of the distances from all the individual department lines to the black line\n\nA2 = the standard deviation of the distances from all the individual datapoints (employees) to the line for the department in which it works.\nA3 = where the black line cuts the y axis\n\nA4 = the slope of the black line\n\n\n\n\n\nOptional Extra\n\n\nBelow is the model equation for the ri_mod model.\nIdentify the part of the equation that represents each of A1-4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\n\\text{For Employee }j\\text{ from Dept }i & \\\\\n\\text{Level 1 (Employee):}& \\\\\n\\text{wp}_{ij} &= b_{0i} + b_1 \\cdot \\text{seniority}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Dept):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nChoose from:\n\n\\(\\sigma_{\\varepsilon}\\)\n\n\\(b_{1}\\)\n\n\\(\\sigma_{0}\\)\n\n\\(\\gamma_{00}\\)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nA1 = \\(\\sigma_{0}\\)\n\nA2 = \\(\\sigma_{\\varepsilon}\\)\n\nA3 = \\(\\gamma_{00}\\)\n\nA4 = \\(b_{1}\\)"
  },
  {
    "objectID": "02ex.html#footnotes",
    "href": "02ex.html#footnotes",
    "title": "W2 Exercises: Introducing MLM",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is like taking predict() from the model, and then then grouping by age, and calculating the mean of those predictions. However, we can do this more easily using augment() and then some fancy stat_summary() in ggplot↩︎\nprovided that the confidence intervals and p-values are constructed using the same methods↩︎"
  },
  {
    "objectID": "03ex.html",
    "href": "03ex.html",
    "title": "W3 Exercises: Nested and Crossed Structures",
    "section": "",
    "text": "Data: gadeduc.csv\nThis is synthetic data from a randomised controlled trial, in which 30 therapists randomly assigned patients (each therapist saw between 2 and 28 patients) to a control or treatment group, and monitored their scores over time on a measure of generalised anxiety disorder (GAD7 - a 7 item questionnaire with 5 point likert scales).\nThe control group of patients received standard sessions offered by the therapists. For the treatment group, 10 mins of each sessions was replaced with a specific psychoeducational component, and patients were given relevant tasks to complete between each session. All patients had monthly therapy sessions. Generalised Anxiety Disorder was assessed at baseline and then every visit over 4 months of sessions (5 assessments in total).\nThe data are available at https://uoepsy.github.io/data/lmm_gadeduc.csv\nYou can find a data dictionary below:\n\n\n\n\nTable 1: Data Dictionary: lmm_gadeduc.csv\n\n\nvariable\ndescription\n\n\n\n\npatient\nA patient code in which the labels take the form &lt;Therapist initials&gt;_&lt;group&gt;_&lt;patient number&gt;.\n\n\nvisit_0\nScore on the GAD7 at baseline\n\n\nvisit_1\nGAD7 at 1 month assessment\n\n\nvisit_2\nGAD7 at 2 month assessment\n\n\nvisit_3\nGAD7 at 3 month assessment\n\n\nvisit_4\nGAD7 at 4 month assessment\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nUh-oh… these data aren’t in the same shape as the other datasets we’ve been giving you..\nCan you get it into a format that is ready for modelling?\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nIt’s wide, and we want it long.\n\nOnce it’s long. “visit_0”, “visit_1”,.. needs to become the numbers 0, 1, …\nOne variable (patient) contains lots of information that we want to separate out. There’s a handy function in the tidyverse called separate(), check out the help docs!\n\n\n\n\n\n\n\n\n\n1 - reshaping\n\n\n\nHere’s the data. We have one row per patient, but we have multiple observations for each patient across the columns..\n\ngeduc = read_csv(\"https://uoepsy.github.io/data/lmm_gadeduc.csv\")\nhead(geduc)\n\n# A tibble: 6 × 6\n  patient      visit_0 visit_1 visit_2 visit_3 visit_4\n  &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 VC_Control_1      24      24      26      29      28\n2 VC_Control_2      24      26      28      29      30\n3 VC_Control_3      25      29      27      29      30\n4 VC_Control_4      24      25      25      26      26\n5 VC_Control_5      28      28      27      29      28\n6 VC_Control_6      26      28      25      27      28\n\n\nWe can make it long by taking the all the columns from visit_0 to visit_4 and shoving their values into one variable, and keeping the name of the column they come from as another variable:\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\")\n\n# A tibble: 2,410 × 3\n   patient      visit     GAD\n   &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt;\n 1 VC_Control_1 visit_0    24\n 2 VC_Control_1 visit_1    24\n 3 VC_Control_1 visit_2    26\n 4 VC_Control_1 visit_3    29\n 5 VC_Control_1 visit_4    28\n 6 VC_Control_2 visit_0    24\n 7 VC_Control_2 visit_1    26\n 8 VC_Control_2 visit_2    28\n 9 VC_Control_2 visit_3    29\n10 VC_Control_2 visit_4    30\n# ℹ 2,400 more rows\n\n\n\n\n\n\n\n2 - time is numeric\n\n\n\nNow we know how to get our data long, we need to sort out our time variable (visit) and make it into numbers.\nWe can replace all occurrences of the string \"visit_\" with nothingness \"\", and then convert them to numeric.\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) \n\n# A tibble: 2,410 × 3\n   patient      visit   GAD\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 VC_Control_1     0    24\n 2 VC_Control_1     1    24\n 3 VC_Control_1     2    26\n 4 VC_Control_1     3    29\n 5 VC_Control_1     4    28\n 6 VC_Control_2     0    24\n 7 VC_Control_2     1    26\n 8 VC_Control_2     2    28\n 9 VC_Control_2     3    29\n10 VC_Control_2     4    30\n# ℹ 2,400 more rows\n\n\n\n\n\n\n\n3 - splitting up the patient variable\n\n\n\nFinally, we need to sort out the patient variable. It contains 3 bits of information that we will want to have separated out. It has the therapist (their initials), then the group (treatment or control), and then the patient number. These are all separated by an underscore “_“.\nThe separate() function takes a column and separates it into several things (as many things as we give it), splitting them by some user defined separator such as an underscore:\n\ngeduc_long &lt;- geduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |&gt;\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n\nAnd we’re ready to go!\n\ngeduc_long\n\n# A tibble: 2,410 × 5\n   therapist group   patient visit   GAD\n   &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 VC        Control 1           0    24\n 2 VC        Control 1           1    24\n 3 VC        Control 1           2    26\n 4 VC        Control 1           3    29\n 5 VC        Control 1           4    28\n 6 VC        Control 2           0    24\n 7 VC        Control 2           1    26\n 8 VC        Control 2           2    28\n 9 VC        Control 2           3    29\n10 VC        Control 2           4    30\n# ℹ 2,400 more rows\n\n\n\n\n\n\nQuestion 2\n\n\nVisualise the data. Does it look like the treatment had an effect?\nDoes it look like it worked for every therapist?\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nremember, stat_summary() is very useful for aggregating data inside a plot.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHere’s the overall picture. The average score on the GAD7 at each visit gets more and more different between the two groups. The treatment looks effective..\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nLet’s split this up by therapist, so we can see the averages across each therapist’s set of patients.\nThere’s clear variability between therapists in how well the treatment worked. For instance, the therapists EU and OD don’t seem to have much difference between their groups of patients.\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\") +\n  facet_wrap(~therapist)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFit a model to test if the psychoeducational treatment is associated with greater improvement in anxiety over time.\n\n\n\n\n\n1 - fixed effects\n\n\n\nWe want to know if how anxiety (GAD) changes over time (visit) is different between treatment and control (group).\nHopefully this should hopefully come as no surprise1 - it’s an interaction!\n\nlmer(GAD ~ visit * group + ...\n       ...\n     data = geduc_long)\n\n\n\n\n\n\n2 - grouping structure\n\n\n\nWe have multiple observations for each of the 482 patients, and those patients are nested within 30 therapists.\nNote that in our data, the patient variable does not uniquely specify the individual patients. i.e. patient “1” from therapist “AO” is a different person from patient “1” from therapist “BJ”. To correctly group the observations into different patients (and not ‘patient numbers’), we need to have therapist:patient.\nSo we capture therapist-level differences in ( ... | therapist) and the patients-within-therapist-level differences in ( ... | therapist:patient):\n\nlmer(GAD ~ visit * group + ...\n       ( ... | therapist) + \n       ( ... | therapist:patient),\n     data = geduc_long)\n\n\n\n\n\n\n3 - random effects\n\n\n\nNote that each patient can change differently in their anxiety levels over time - i.e. the slope of visit could vary by participant.\nLikewise, some therapists could have patients who change differently from patients from another therapist, so visit|therapist can be included.\nEach patient is in one of the two groups - they’re either treatment or control. So we can’t say that “differences in anxiety due to treatment varies between patients”, because for any one patient the “difference in anxiety due to treatment” is not defined in our study design.\nHowever, therapists see multiple different patients, some of which are in the treatment group, and some of which are in the control group. So the treatment effect could be different for different therapists!\n\nmod1 &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|therapist:patient),\n             geduc_long)\n\n\n\n\n\nQuestion 4\n\n\nFor each of the models below, what is wrong with the random effect structure?\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\n\n\n\n\n\nSolution\n\n\n\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\nThe patient variable doesn’t capture the different patients within therapists, so this actually fits crossed random effects and treats all data where patient==1 as from the same group (even if this includes several different patients’ worth of data from different therapists!)\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\nUsing the / here means we have the same random slopes fitted for therapists and for patients-within-therapists. but the effect of group can’t vary by patient, so this doesn’t work. hence why we need to split them up into (...|therapist)+(...|therapist:patient).\n\n\n\n\nQuestion 5\n\n\nLet’s suppose that I don’t want the psychoeducation treatment, I just want the standard therapy sessions that the ‘Control’ group received. Which therapist should I go to?\n\n\n\n\n\n\nHints\n\n\n\n\n\ndotplot.ranef.mer() might help here!\nYou can read about ranef in Chapter 2 #making-model-predictions.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nIt would be best to go to one of the therapists SZ, YS, or IT…\nWhy? These therapists all have the most negative slope of visit:\n\ndotplot.ranef.mer(ranef(mod1))$therapist\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecreate this plot.\nThe faint lines represent the model estimated lines for each patient. The points and ranges represent our fixed effect estimates and their uncertainty.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nyou can get the patient-specific lines using augment() from the broom.mixed package, and the fixed effects estimates using the effects package.\nremember that the “patient” column doesn’t group observations into unique patients.\nremember you can pull multiple datasets into ggplot:\n\n\nggplot(data = dataset1, aes(x=x,y=y)) + \n  geom_point() + # points from dataset1\n  geom_line(data = dataset2) # lines from dataset2\n\n\nsee more in Chapter 2 #visualising-models\n\n\n\n\n\n\n\n\n\n1 - the relevant parts\n\n\n\nThe effects package will give us the fixed effect estimates:\n\nlibrary(effects)\nlibrary(broom.mixed)\neffplot &lt;- effect(\"visit*group\",mod1) |&gt;\n  as.data.frame()\n\nWe want to get the fitted values for each patient. We can get fitted values using augment(). But the patient variable doesn’t capture the unique patients, it just captures their numbers (which aren’t unique to each therapist).\nSo we can create a new column called upatient which pastes together the therapists initials and the patient numbers\n\naugment(mod1) |&gt; \n  mutate(\n    upatient = paste0(therapist,patient),\n    .after = patient # place the column next to the patient col\n  )\n\n# A tibble: 2,410 × 17\n     GAD visit group   therapist patient upatient .fitted .resid  .hat .cooksd\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1    24     0 Control VC        1       VC1         24.2 -0.198 0.454 0.0210 \n 2    24     1 Control VC        1       VC1         25.3 -1.28  0.239 0.239  \n 3    26     2 Control VC        1       VC1         26.4 -0.360 0.186 0.0128 \n 4    29     3 Control VC        1       VC1         27.4  1.56  0.294 0.508  \n 5    28     4 Control VC        1       VC1         28.5 -0.522 0.563 0.284  \n 6    24     0 Control VC        2       VC2         24.8 -0.843 0.454 0.383  \n 7    26     1 Control VC        2       VC2         26.2 -0.171 0.239 0.00426\n 8    28     2 Control VC        2       VC2         27.5  0.502 0.186 0.0250 \n 9    29     3 Control VC        2       VC2         28.8  0.174 0.294 0.00633\n10    30     4 Control VC        2       VC2         30.2 -0.153 0.563 0.0246 \n# ℹ 2,400 more rows\n# ℹ 7 more variables: .fixed &lt;dbl&gt;, .mu &lt;dbl&gt;, .offset &lt;dbl&gt;, .sqrtXwt &lt;dbl&gt;,\n#   .sqrtrwt &lt;dbl&gt;, .weights &lt;dbl&gt;, .wtres &lt;dbl&gt;\n\n\n\n\n\n\n\n2 - constructing the plot\n\n\n\n\nlibrary(effects)\nlibrary(broom.mixed)\neffplot &lt;- effect(\"visit*group\",mod1) |&gt;\n  as.data.frame()\n\naugment(mod1) |&gt; \n  mutate(\n    upatient = paste0(therapist,patient),\n    .after = patient # place the column next to the patient col\n  ) |&gt;\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")"
  },
  {
    "objectID": "03ex.html#footnotes",
    "href": "03ex.html#footnotes",
    "title": "W3 Exercises: Nested and Crossed Structures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nif it does, head back to where we learned about interactions in the single level regressions lm(). It’s just the same here.↩︎"
  },
  {
    "objectID": "04ex.html",
    "href": "04ex.html",
    "title": "W4 Exercises: Centering",
    "section": "",
    "text": "Hangry\n\nData: hangry1.csv\nThe study is interested in evaluating whether levels of hunger are associated with levels of irritability (i.e., “the hangry hypothesis”). 81 participants were recruited into the study. Once a week for 5 consecutive weeks, participants were asked to complete two questionnaires, one assessing their level of hunger, and one assessing their level of irritability. The time and day at which participants were assessed was at a randomly chosen hour between 7am and 7pm each week.\nThe data are available at: https://uoepsy.github.io/data/hangry1.csv.\n\n\n\n\n\n\n  \n    \n      variable\n      description\n    \n  \n  \n    q_irritability\nScore on irritability questionnaire (0:100)\n    q_hunger\nScore on hunger questionnaire (0:100)\n    ppt\nParticipant\n  \n  \n  \n\n\n\n\n\n\nQuestion 1\n\n\nRemember that what we’re interested in is “whether levels of hunger are associated with levels of irritability (i.e.,”the hangry hypothesis”)“.\nRead in the data and fit the model below. How well does it address the research question?\n\nmod1 &lt;- lmer(q_irritability ~ q_hunger + \n                (1 + q_hunger | ppt), \n                data = hangry)\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nAlways plot your data! It’s tempting to just go straight to interpreting coefficients of this model, but in order to understand what a model says we must have a theory about how the data are generated.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nhangry &lt;- read_csv(\"https://uoepsy.github.io/data/hangry1.csv\")\n\nmod1 &lt;- lmer(q_irritability ~ q_hunger + \n                (1 + q_hunger | ppt), \n                data = hangry)\n\nThe model above will give us that same old formulaic expression of “for people on average, a 1 unit increase in q_hunger is associated with a 0.17 increase in q_irritability”.\nThe problem is that in trying to estimate what do as q_hunger increases, we’re ignoring the fact that people tend to have different average levels of q_hunger:\n\nggplot(hangry, aes(x = q_hunger, y = q_irritability, group = ppt)) +\n  geom_point() +\n  geom_line(alpha=.4) + \n  facet_wrap(~ppt)\n\n\n\n\n\n\n\n\nSo the interpretation of the fixed effect of our model above as “what happens to a persons’ irritability when they are 1 more hungry?”, we’re not accurately estimating this because our model doesn’t account for the fact that the numbers in q_hunger mean very different things for different people - for person 1 a hunger score of 60 might be “I’m really hungry”, but for person 2 (who is usually in the 80s or 90s) it could mean “I’m not very hungry at all”.\n\n\n\n\nQuestion 2\n\n\n\n\n\n\n\n\nwithin effects, between effects, and smushed effects\n\n\n\n\n\nResearch Question: “whether levels of hunger are associated with levels of irritability (i.e.,”the hangry hypothesis”)“.\nThink about the relationship between irritability and hunger. How should we interpret this research aim?\nIs it:\n\n“Are people more irritable if they are, on average, more hungry than other people?”\n\n“Are people more irritable if they are, for them, more hungry than they usually are?”\n\nSome combination of both a. and b.\n\nThis is just one demonstration of how the statistical methods we use can constitute an integral part of our development of a research project, and part of the reason that data analysis for scientific cannot be so easily outsourced after designing the study and collecting the data.\nAs our data currently is currently stored, the relationship between irritability and the raw scores on the hunger questionnaire q_hunger represents some ‘total effect’ of hunger on irritability. This is a bit like interpretation c. above - it’s a composite of both the ‘within’ ( b. ) and ‘between’ ( a. ) effects. The problem with this is that this isn’t necessarily all that meaningful. It may tell us that ‘being higher on the hunger questionnaire is associated with being more irritable’, but how can we apply this information? It is not specifically about the comparison between hungry people and less hungry people, and nor is it a good estimation of how person \\(i\\) changes when they are more hungry than usual. It is both these things smushed together.\nTo disaggregate the ‘within’ and ‘between’ effects of hunger on irritability, we can group-mean center. For ‘between’, we are interested in how irritability is related to the average hunger levels of a participant, and for ‘within’, we are asking how irritability is related to a participants’ relative levels of hunger (i.e., how far above/below their average hunger level they are.).\n\n\n\nAdd to the data these two columns:\n\na column which contains the average hungriness score for each participant.\na column which contains the deviation from each person’s hunger score to that person’s average hunger score.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou’ll find group_by() |&gt; mutate() very useful here, as seen in Chapter 10 #group-mean-centering.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nhangry &lt;- \n    hangry |&gt; group_by(ppt) |&gt;\n        mutate(\n            avg_hunger = mean(q_hunger),\n            hunger_gc = q_hunger - avg_hunger\n        )\nhead(hangry)\n\n# A tibble: 6 × 5\n# Groups:   ppt [2]\n  q_irritability q_hunger ppt   avg_hunger hunger_gc\n           &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1             42       52 N2p1        39.2     12.8 \n2             24       47 N2p1        39.2      7.8 \n3             17        8 N2p1        39.2    -31.2 \n4             26       47 N2p1        39.2      7.8 \n5             27       42 N2p1        39.2      2.80\n6             17       48 N2p2        39.6      8.4 \n\n\n\n\n\n\nQuestion 3\n\n\nFor each of the new variables you just added, plot the irritability scores against those variables.\n\nDoes it look like hungry people are more irritable than less hungry people?\n\nDoes it look like when people are more hungry than normal, they are more irritable?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou might find stat_summary() useful here for plotting the between effect (see Chapter 10 #group-mean-centering)\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWe might find it easier to look at a plot where each participant is represented as their mean plus an indication of their range of irritability scores:\n\nggplot(hangry,aes(x=avg_hunger,y=q_irritability))+\n    stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nIt’s hard to see any clear relationship between a persons’ average hunger and their irritability scores here.\nIt is also a bit difficult to get at the relationship between participant-centered hunger and irritability, because there are a lot of different lines (one for each participant). To make it easier to get an idea of what’s happening, we’ll make the plot fit a simple lm() (a straight line) for each participants’ data.\n\nggplot(hangry,aes(x=hunger_gc,y=q_irritability, group=ppt)) +\n  geom_point(alpha = .2) + \n  geom_smooth(method=lm, se=FALSE, lwd=.2)\n\n\n\n\n\n\n\n\nIt looks like most of these lines are going upwards, but there’s a fair bit of variation in them.\nSo we can actually make a guess at what we’re going to see when we model. We’ll probably have a positive fixed effect of hunger_gc (i.e. A below will be positive), and there by-participant variation in these slopes will be quite large relative to the fixed effect (i.e B below will be quite large in comparison to A)\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n ppt      (Intercept)      ...      ... \n          hunger_gc        ...      *B*\n Residual                  ...      ...    \n\n...\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)      ...        ...     ...\nhunger_gc        *A*        ...     ...\n...              ...        ...     ...\n\n\n\n\nQuestion 4\n\n\nWe have taken the raw hunger scores and separated them into two parts (raw hunger scores = participants’ average hunger score + observation level deviations from those averages), that represent two different aspects of the relationship between hunger and irritability.\nAdjust your model specification to include these two separate variables as predictors, instead of the raw hunger scores.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nWe can only put one of these variables in the random effects (1 + hunger | participant). Think about the fact that each participant has only one value for their average hungriness.\n\nIf the model fails to converge, and it’s a fairly simple model (i.e one or two random slopes), then often you can switch optimizer (see Chapter 2 #convergence-warnings-singular-fits). For instance, try adding control = lmerControl(optimizer = \"bobyqa\") to the model.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWith the defaults, this model doesn’t converge\n\nhangrywb &lt;- lmer(q_irritability ~ avg_hunger + hunger_gc + \n                (1 + hunger_gc | ppt), \n                data = hangry)\n\nChanging the optimizer helps:\n\nhangrywb &lt;- lmer(q_irritability ~ avg_hunger + hunger_gc + \n                (1 + hunger_gc | ppt), \n                data = hangry,\n                control = lmerControl(optimizer = \"bobyqa\"))\n\n\n\n\n\n\n\noptional - why change the optimizer?\n\n\n\n\n\nNote that the max|grad| convergence error of the initial model was very close to the tolerance (see Chapter 8 #non-convergence for an explanation of what this tolerance is).\nThe fact that it is close indicates that we may be quite close to a solution, so it’s worth investigating if this is simply an optimizer problem.\nOne other thing to do would be to consider all available optimizers, see which ones converge, and compare estimates across them. If the estimates are the same (or pretty close), and some of these converge, then it gives us more trust in our model. We can do this with the code below. We can see that 5 optimizers don’t give error messages, and that they all give pretty much the same estimated fixed effects. We can go further and compare random effects variances too, but we won’t do that here.\n\n# fit with all optimizers\nallopts = allFit(hangrywb)\n\nbobyqa : [OK]\nNelder_Mead : [OK]\nnlminbwrap : [OK]\noptimx.L-BFGS-B : [OK]\nnloptwrap.NLOPT_LN_NELDERMEAD : [OK]\nnloptwrap.NLOPT_LN_BOBYQA : [OK]\n\n# error messages from each optimizer \n# (NULL here means no message, which is good)\nsummary(allopts)$msgs\n\n$bobyqa\nNULL\n\n$Nelder_Mead\nNULL\n\n$nlminbwrap\nNULL\n\n$`optimx.L-BFGS-B`\nNULL\n\n$nloptwrap.NLOPT_LN_NELDERMEAD\nNULL\n\n$nloptwrap.NLOPT_LN_BOBYQA\n[1] \"Model failed to converge with max|grad| = 0.0027028 (tol = 0.002, component 1)\"\n\n# fixed effect estimates for all optimizers\nsummary(allopts)$fixef\n\n                              (Intercept) avg_hunger hunger_gc\nbobyqa                               17.6   -0.00644     0.187\nNelder_Mead                          17.6   -0.00644     0.187\nnlminbwrap                           17.6   -0.00644     0.187\noptimx.L-BFGS-B                      17.6   -0.00644     0.187\nnloptwrap.NLOPT_LN_NELDERMEAD        17.6   -0.00647     0.187\nnloptwrap.NLOPT_LN_BOBYQA            17.6   -0.00648     0.187\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nWrite down an interpretation of each of the fixed effects\n\n\n\n\n\nSolution\n\n\n\nHere they are\n\nfixef(hangrywb)\n\n(Intercept)  avg_hunger   hunger_gc \n   17.62005    -0.00644     0.18663 \n\n\n\n\n\n\n\n\n  \n    \n      term\n      est\n      interpretation\n    \n  \n  \n    (Intercept)\n17.620\nestimated irritability score for someone with an average hunger of 0, and not deviating from that average (i.e. hunger_gc = 0)\n    avg_hunger\n-0.006\nestimated difference in irritability between two people who differ in average hunger level by 1 (e.g., a person with average hunger of 11 vs someone with average hunger level of 10), when they are at their average (hunger_gc = 0)\n    hunger_gc\n0.187\nestimated change in irritability score for every 1 more hungry a person is than they normally are\n  \n  \n  \n\n\n\n\n\n\n\n\nQuestion 6\n\n\nHave a go at also writing an explanation for yourself of the random effects part of the output.\nThere’s no formulaic way to interpret these, but have a go at describing in words what they represent, and how that adds to the picture your model describes.\nDon’t worry about making it read like a report - just write yourself an explanation!\n\n\n\n\n\nSolution\n\n\n\n\nVarCorr(hangrywb)\n\n Groups   Name        Std.Dev. Corr \n ppt      (Intercept) 6.992         \n          hunger_gc   0.366    -0.08\n Residual             4.772         \n\n\n\n\n\n\n\n\n  \n    \n      term\n      est\n      interpretation\n    \n  \n  \n    sd__(Intercept)\n6.992\nParticipant level variability in irritability when they are at their average hunger level - i.e. when everybody is at their own average level of hunger, they vary in their irritability scores with a standard deviation of 7.\n    sd__hunger_gc\n0.366\nParticipants vary quite a bit in how deviations from hunger are associated with irritability. They vary around the fixed effect of 0.19 with a standard deviation of 0.37. To think about what this means, imagine a normal distribution that is centered on 0.19 and has a standard deviation of 0.36. A fairly large portion of that distribution would fall below zero (i.e. have a negative slope). And we would also expect some slopes that are e.g., .5, .6 etc\n    cor__(Intercept).hunger_gc\n-0.080\nthis estimate is basically zero, but represents the relationship between participants relative standing at the intercept and their relative standing on the slopes. So participants who are more irritable than others when at their average hunger, tend to have slightly lower slopes\n    sd__Observation\n4.772\nthe residual variance doesn't really have much of an interpretation - it really just represents all the leftover stuff that the model doesn't explain. If we imagine all of the individual participant lines, this represents how spread out the individual observations are around those lines\n  \n  \n  \n\n\n\n\n\n\n\n\n\nHangry 2\n\nQuestion 7\n\n\nA second dataset on the same variables is available at: https://uoepsy.github.io/data/hangry2.csv.\nThese data are from people who were following a five-two diet, while the original dataset were from people who were not folling any diet.\nCombine the datasets together so we can fit a model to see if the hangry effect differs between people on diets vs those who aren’t.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nSomething like bind_rows() might help here. If you’ve not seen it before, remember that you can look up the help documentation in the bottom-right panel of RStudio\nBe sure to keep an indicator of which group the data are in!!\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHere are our two datasets:\n\nhangry1 &lt;- read_csv(\"https://uoepsy.github.io/data/hangry1.csv\")\nhangry2 &lt;- read_csv(\"https://uoepsy.github.io/data/hangry2.csv\")\n\nWe could simply bind them together using bind_rows()\n\nhangryfull &lt;- \n  bind_rows(\n    hangry1, \n    hangry2\n  )\n\nbut then we wouldn’t know who was from which group! So we’ll need to add a variable to each one first:\n\nhangryfull &lt;- \n  bind_rows(\n    hangry1 |&gt; mutate(diet = \"N\"), \n    hangry2 |&gt; mutate(diet = \"Y\")\n  )\nhead(hangryfull)\n\n# A tibble: 6 × 4\n  q_irritability q_hunger ppt   diet \n           &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1             42       52 N2p1  N    \n2             24       47 N2p1  N    \n3             17        8 N2p1  N    \n4             26       47 N2p1  N    \n5             27       42 N2p1  N    \n6             17       48 N2p2  N    \n\n\n\n\n\n\nQuestion 8\n\n\nDoes the relationship between hunger and irritability depend on whether or not people are following the five-two diet?\n\n\n\n\n\n\nHints\n\n\n\n\n\nWhich relationship between hunger and irritability are we talking about? The between effect or the within effect? It could be both!\nWe’re going to need to create those two variables again for this combined dataset.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nhangryfull &lt;- \n    hangryfull |&gt; group_by(ppt) |&gt;\n        mutate(\n            avg_hunger = mean(q_hunger),\n            hunger_gc = q_hunger - avg_hunger\n        )\n\nhangrywbdiet &lt;- lmer(q_irritability ~ (avg_hunger + hunger_gc) * diet + \n                (1 + hunger_gc | ppt), \n                data = hangryfull,\n                control=lmerControl(optimizer=\"bobyqa\"))\n\nsummary(hangrywbdiet)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: q_irritability ~ (avg_hunger + hunger_gc) * diet + (1 + hunger_gc |  \n    ppt)\n   Data: hangryfull\nControl: lmerControl(optimizer = \"bobyqa\")\n\nREML criterion at convergence: 2735\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4138 -0.5906 -0.0454  0.5426  2.3954 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n ppt      (Intercept) 48.083   6.934         \n          hunger_gc    0.145   0.381    -0.01\n Residual             23.305   4.828         \nNumber of obs: 405, groups:  ppt, 81\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)       17.13095    5.14648    3.33\navg_hunger         0.00386    0.10533    0.04\nhunger_gc          0.18577    0.07560    2.46\ndietY            -10.85470    6.53568   -1.66\navg_hunger:dietY   0.46590    0.13354    3.49\nhunger_gc:dietY    0.38141    0.10139    3.76\n\nCorrelation of Fixed Effects:\n            (Intr) avg_hn hngr_g dietY  avg_:Y\navg_hunger  -0.971                            \nhunger_gc   -0.002  0.000                     \ndietY       -0.787  0.765  0.002              \navg_hngr:dY  0.766 -0.789  0.000 -0.968       \nhngr_gc:dtY  0.002  0.000 -0.746 -0.002  0.000\n\n\n\n\n\n\nQuestion 9\n\n\nConstruct two plots showing the two model estimated interactions. This model is a bit of a confusing one, so plotting may help a bit with understanding what those interactions represent.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\neffects(terms, mod) |&gt; as.data.frame() |&gt; ggplot(.....)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe xlevels bit here just gives us the little dataframe to plot with more levels at it, so that it gives us smoother lines. Try it with and without to see what I mean!\n\nlibrary(effects)\neffect(\"avg_hunger*diet\", hangrywbdiet, xlevels=20) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x=avg_hunger, y=fit,col=diet))+\n  geom_line()+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=diet),alpha=.4)+\n  labs(x=\"participants' average hunger level\")\n\n\n\n\n\n\n\n\nWe saw in our original model that for the reference level of diet, the “N” group, there was no association between how hungry a person is on average and their irritability. This is the red line we see in the plot above. In our full model this is the avg_hunger coefficient.\nWe also saw the interaction avg_hunger:dietY indicates that irritability is estimated to increase by 0.47 more for those in the diet than it does for those not on the diet. So the blue line is should be going up more steeply than the red line (which is flat). And it is!\n\neffect(\"hunger_gc*diet\", hangrywbdiet, xlevels=20) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x=hunger_gc, y=fit,col=diet))+\n  geom_line()+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=diet),alpha=.4)+\n  labs(x=\"increase from participants' average hunger level\")\n\n\n\n\n\n\n\n\nFrom the coefficient of hunger_gc we get the estimated amount by which irritability increases for every 1 more hungry that a person becomes (when they’re in the diet “N” group). This is the slope of the red line - the hunger_gc coefficient from our full model.\nThe interaction hunger_gc:fivetwo1 gave us the adjustment to get from the red line to the blue line. It is positive which matches with the fact that the blue line is steeper in this plot.\n\n\n\n\nQuestion 10\n\n\nProvide tests of the fixed effects and write-up the results.\n\n\n\n\n\nSolution\n\n\n\n\nhangrywbdiet.p &lt;- lmerTest::lmer(q_irritability ~ (avg_hunger + hunger_gc) * diet + \n                (1 + hunger_gc | ppt), \n                data = hangryfull,\n                control=lmerControl(optimizer=\"bobyqa\"))\n\nsummary(hangrywbdiet.p)$coefficients\n\n                  Estimate Std. Error   df t value Pr(&gt;|t|)\n(Intercept)       17.13095     5.1465 77.0  3.3287 0.001341\navg_hunger         0.00386     0.1053 77.0  0.0367 0.970834\nhunger_gc          0.18577     0.0756 65.4  2.4573 0.016659\ndietY            -10.85470     6.5357 77.0 -1.6608 0.100813\navg_hunger:dietY   0.46590     0.1335 77.0  3.4888 0.000806\nhunger_gc:dietY    0.38141     0.1014 68.5  3.7617 0.000352\n\n\nTo investigate the association between irritability and hunger, and whether this relationship is different depending on whether or not participants are on a restricted diet such as the five-two, a multilevel linear model was fitted.\nTo disaggregate between the differences in irritability due to people being in general more/less hungry, and those due to people being more/less hungry than usual for them, irritability was regressed onto both participants’ average hunger scores their relative hunger levels. Both of these were allowed to interact with whether or not participants were on the five-two diet. Random intercepts and slopes of relative-hunger level were included for participants. The model was fitting with restricted maximum likelihood estimation with the lme4 package (Bates et al., 2015), using the bobyqa optimiser from the lme4. \\(P\\)-values were obtained using the Satterthwaite approximation for degrees of freedom.\nResults indicate that for people on no diet, being more hungry than normal was associated with greater irritability (\\(b = 0.19,\\ SE = 0.08,\\ t(2.46) = 65.41,\\ p=0.017\\)), and that this was increased for those following the five-two diet (\\(b = 0.38,\\ SE = 0.1,\\ t(3.76) = 68.49,\\ p&lt;0.001\\)). Although for those not on a specific diet there was no evidence for an association between irritability and being generally a more hungry person (\\(p=0.971\\)), there a significant interaction was found between average hunger and being on the five-two diet (\\(b = 0.47,\\ SE = 0.13,\\ t(3.49) = 77,\\ p&lt;0.001\\)), suggesting that when dieting, hungrier people tend to be more irritable than less hungry people.\nResults suggest that the ‘hangry hypothesis’ may occur within people (when a person is more hungry than they usually are, they tend to be more irritable), but not necessarily between hungry/less hungry people. Dieting was found to increase the association of both between-person hunger and within-person hunger with irritability."
  },
  {
    "objectID": "05ex.html",
    "href": "05ex.html",
    "title": "W5 Exercises: Bringing it all together",
    "section": "",
    "text": "Take your pick!\n\nQuestion 1\n\n\nYou can find all the datasets that we have seen (and more!) as an additional doc in the readings page.\nFor each one, there is a quick explanation of the study design which also details the research aims of the project.\nPick one of the datasets and, in your groups:\n\nexplore the data, and do any required cleaning (most of them are clean already)\nconduct an analysis to address the research aims\nwrite a short description of the sample data (see Chapter 11 #the-sample-data)\nwrite a short explanation of your methods (see Chapter 11 #the-methods)\nwrite a short summary of your results, along with suitable visualisations and tables (see Chapter 11 #the-results)\nPost some of your writing on Piazza and we can collectively discuss it!\n\n\nEach of the datasets contains some tags that give an indication of the type of study. Anything with either “#binomial-outcome” or “#non-linear” you can ignore as we have not covered this in DAPR3.\n\n\n\n\n\n\n\n\n\n\n\nFlashcards: lm to lmer\nIn a simple linear regression, there is only considered to be one source of random variability: any variability left unexplained by a set of predictors (which are modelled as fixed estimates) is captured in the model residuals.\nMulti-level (or ‘mixed-effects’) approaches involve modelling more than one source of random variability - as well as variance resulting from taking a random sample of observations, we can identify random variability across different groups of observations. For example, if we are studying a patient population in a hospital, we would expect there to be variability across the our sample of patients, but also across the doctors who treat them.\nWe can account for this variability by allowing the outcome to be lower/higher for each group (a random intercept) and by allowing the estimated effect of a predictor vary across groups (random slopes).\n\nBefore you expand each of the boxes below, think about how comfortable you feel with each concept.\nThis content is very cumulative, which means often going back to try to isolate the place which we need to focus efforts in learning.\n\n\n\n\n\n\n\nSimple Linear Regression\n\n\n\n\n\n\nFormula:\n\n\\(y_i = b_0 + b_1 x_i + \\epsilon_i\\)\n\nR command:\n\nlm(outcome ~ predictor, data = dataframe)\n\nNote: this is the same as lm(outcome ~ 1 + predictor, data = dataframe). The 1 + is always there unless we specify otherwise (e.g., by using 0 +).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustered (multi-level) data\n\n\n\n\n\nWhen our data is clustered (or ‘grouped’) such that datapoints are no longer independent, but belong to some grouping such as that of multiple observations from the same subject, we have multiple sources of random variability. A simple regression does not capture this.\nIf we separate out our data to show an individual plot for each grouping (in this data the grouping is by subjects), we can see how the fitted regression line from lm() is assumed to be the same for each group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom intercepts\n\n\n\n\n\nBy including a random-intercept term, we are letting our model estimate random variability around an average parameter (represented by the fixed effects) for the clusters.\n\nFormula:\nLevel 1:\n\n\\(y_{ij} = b_{0i} + b_{1} x_{ij} + \\epsilon_{ij}\\)\n\nLevel 2:\n\n\\(b_{0i} = \\gamma_{00} + \\zeta_{0i}\\)\n\nWhere the expected values of \\(\\zeta_{0}\\), and \\(\\epsilon\\) are 0, and their variances are \\(\\sigma_{0}^2\\) and \\(\\sigma_\\epsilon^2\\) respectively. We will further assume that these are normally distributed.\nWe can now see that the intercept estimate \\(b_{0i}\\) for a particular group \\(i\\) is represented by the combination of a mean estimate for the parameter (\\(\\gamma_{00}\\)) and a random effect for that group (\\(\\zeta_{0i}\\)).\nR command:\n\nlmer(outcome ~ predictor + (1 | grouping), data = dataframe)\n\n\nNotice how the fitted line of the random intercept model has an adjustment for each subject.\nEach subject’s line has been moved up or down accordingly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPooling & Shrinkage\n\n\n\n\n\nIf you think about it, we might have done a similar thing to the random intercept with the tools we already had at our disposal, by using lm(y~x+subject). This would give us a coefficient for the difference between each subject and the reference level intercept, or we could extend this to lm(y~x*subject) to give us an adjustment to the slope for each subject.\nHowever, the estimate of these models will be slightly different:\n\n\n\n\n\n\n\n\n\nWhy? One of the benefits of multilevel models is that our cluster-level estimates are shrunk towards the average depending on a) the amount of across-cluster variation and b) the number of datapoints in clusters.\nIn another way, we can think of the multilevel model as “borrowing strength” from what we know about e.g., clusters 1-19 to inform what we think about cluster 20. This also gets termed “partial pooling” because we are partially combining all the information across clusters to get an average, but still allowing those clusters to vary.\n\n\n\n\n\n\n\n\nmodel\npooling\nexplanation\n\n\n\n\nlm(y~x)\ncomplete\nall information across clusters is combined (pooled) together and a line is fitted\n\n\nlm(y~group + x)\nno\ninformation is split up into clusters, and cluster differences are estimated. observations from cluster \\(i\\) contribute only to estimates about cluster \\(i\\)\n\n\nlmer(y~x+(1|group))\npartial\ninformation is combined (pooled) but cluster-level variation is modelled. cluster level estimates are shrunk towards the average depending upon how distinct the clustering is, and how much data a cluster has\n\n\n\n\n\n\n\n\n\n\n\n\nRandom slopes\n\n\n\n\n\n\nFormula:\nLevel 1:\n\n\\(y_{ij} = b_{0i} + b_{1i} x_{ij} + \\epsilon_{ij}\\)\n\nLevel 2:\n\n\\(b_{0i} = \\gamma_{00} + \\zeta_{0i}\\)\n\n\\(b_{1i} = \\gamma_{10} + \\zeta_{1i}\\)\n\nWhere the expected values of \\(\\zeta_0\\), \\(\\zeta_1\\), and \\(\\epsilon\\) are 0, and their variances are \\(\\sigma_{0}^2\\), \\(\\sigma_{1}^2\\), \\(\\sigma_\\epsilon^2\\) respectively. We will further assume that these are normally distributed.\nAs with the intercept \\(b_{0i}\\), the slope of the predictor \\(b_{1i}\\) is now modelled by a mean \\(\\gamma_{10}\\) and a random effect for each group (\\(\\zeta_{1i}\\)).\nR command:\n\nlmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)\n\nNote: this is the same as lmer(outcome ~ predictor + (predictor | grouping), data = dataframe) . Like in the fixed-effects part, the 1 + is assumed in the random-effects part.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel parameters: Fixed effects\n\n\n\n\n\nThe plot below show the fitted values for each subject from the random slopes model lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)\n\n\n\n\n\n\n\n\n\nThe thick green line shows the fixed intercept and slope around which the groups all vary randomly.\nThe fixed effects are the parameters that define the thick green line, and we can extract them using the fixef() function:\n\nfixef(random_slopes_model)\n\n(Intercept)          x1 \n    405.790      -0.672 \n\n\nThe fixed effects are the estimated intercept and slopes for the average group, around which groups vary.\n\n\n\n\n\n\n\n\n\nModel parameters: Variance components\n\n\n\n\n\nAs well as estimating the fixed effects, multilevel models are also defined by the “variance components”. These are the variances and covariances of the random effects. Looking at these we can ask: how much do groups vary in around the fixed intercept? and around the fixed slope? Do groups with higher intercepts also have higher slopes (this is the correlation).\nWe can think of these as the width of the distributions of group deviations from each fixed effect\n\n\n\n\n\n\n\n\n\nWe can extract these using the VarCorr() function, and we can also see them in the “random effects” part of the summary() output from a model.\n\nVarCorr(random_slopes_model)\n\n Groups   Name        Std.Dev. Corr \n subject  (Intercept) 72.72         \n          x1           1.36    -0.35\n Residual             25.74         \n\n\n\nRemember, variance is just standard deviation squared!\n\n\n\n\n\n\n\n\n\n\nGroup-specific random effects\n\n\n\n\n\nThe plots below show the fitted values for each subject from each model that we have gone through in these expandable boxes (simple linear regression, random intercept, and random intercept & slope):\n\n\n\n\n\n\n\n\n\nIn the random-intercept model (center panel), the differences from each of the subjects’ intercepts to the fixed intercept (thick green line) have mean 0 and standard deviation \\(\\sigma_0\\). The standard deviation (and variance, which is \\(\\sigma_0^2\\)) is what we see in the random effects part of our model summary (or using the VarCorr() function).\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 5207     72.2    \n Residual             1512     38.9    \nNumber of obs: 185, groups:  subject, 20\n\n\n\n\n\n\n\n\n\nIn the random-slope model (right panel), the same is true for the differences from each subjects’ slope to the fixed slope. As our fixed effects are:\n\nfixef(random_slopes_model)\n\n(Intercept)          x1 \n    405.790      -0.672 \n\n\nWe can extract the deviations for each group from the fixed effect estimates using the ranef() function. These are the deviations from the overall intercept (\\(\\widehat \\gamma_{00} = 405.79\\)) and slope (\\(\\widehat \\gamma_{10} = -0.672\\)) for each subject \\(i\\).\nSo the first entry, sub_308, has an intercept 31.33 above the fixed intercept of 405.79, and has a slope that is -1.44 below the fixed slope of -0.672.\n\nranef(random_slopes_model)\n\n$subject\n        (Intercept)      x1\nsub_308       31.33 -1.4400\nsub_309      -28.83  0.4184\nsub_310        2.71  0.0599\nsub_330       59.40  0.3853\nsub_331       74.96  0.1739\nsub_332       91.09 -0.2346\nsub_333       97.85 -0.1906\nsub_334      -54.19 -0.5585\nsub_335      -16.90  0.9207\nsub_337       52.22 -1.1660\nsub_349      -67.76 -0.6844\nsub_350       -5.82 -1.2379\nsub_351       61.20  0.0550\nsub_352       -7.91 -0.6650\nsub_369      -47.64 -0.4681\nsub_370      -33.12 -1.1100\nsub_371       77.58 -0.2040\nsub_372      -36.39 -0.4583\nsub_373     -197.58  1.7990\nsub_374      -52.20  4.6051\n\nwith conditional variances for \"subject\" \n\n\n\n\n\n\n\n\n\n\n\nGroup-specific coefficients\n\n\n\n\n\nWe can see the estimated intercept and slope for each subject \\(i\\) specifically, using the coef() function.\n\ncoef(random_slopes_model)\n\n$subject\n        (Intercept)     x1\nsub_308         437 -2.112\nsub_309         377 -0.254\nsub_310         409 -0.612\nsub_330         465 -0.287\nsub_331         481 -0.498\nsub_332         497 -0.907\nsub_333         504 -0.863\nsub_334         352 -1.231\nsub_335         389  0.248\nsub_337         458 -1.838\nsub_349         338 -1.357\nsub_350         400 -1.910\nsub_351         467 -0.617\nsub_352         398 -1.337\nsub_369         358 -1.140\nsub_370         373 -1.782\nsub_371         483 -0.876\nsub_372         369 -1.131\nsub_373         208  1.127\nsub_374         354  3.933\n\nattr(,\"class\")\n[1] \"coef.mer\"\n\n\nNotice that the above are the fixed effects + random effects estimates, i.e. the overall intercept and slope + deviations for each subject.\n\ncbind(\n  int = fixef(random_slopes_model)[1] + \n    ranef(random_slopes_model)$subject[,1],\n  slope = fixef(random_slopes_model)[2] + \n    ranef(random_slopes_model)$subject[,2]\n)\n\n      int  slope\n [1,] 437 -2.112\n [2,] 377 -0.254\n [3,] 409 -0.612\n [4,] 465 -0.287\n [5,] 481 -0.498\n [6,] 497 -0.907\n [7,] 504 -0.863\n [8,] 352 -1.231\n [9,] 389  0.248\n[10,] 458 -1.838\n[11,] 338 -1.357\n[12,] 400 -1.910\n[13,] 467 -0.617\n[14,] 398 -1.337\n[15,] 358 -1.140\n[16,] 373 -1.782\n[17,] 483 -0.876\n[18,] 369 -1.131\n[19,] 208  1.127\n[20,] 354  3.933\n\n\n\n\n\n\n\n\n\n\n\nPlotting random effects\n\n\n\n\n\nThe quick and easy way to plot your random effects is to use the dotplot.ranef.mer() function in lme4.\n\nrandoms &lt;- ranef(random_slopes_model, condVar=TRUE)\ndotplot.ranef.mer(randoms)\n\n$subject\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssumptions, Influence\n\n\n\n\n\nIn the simple linear model \\(\\color{red}{y} = \\color{blue}{b_0 + b_1(x)} \\color{black}{+ \\varepsilon}\\), we distinguished between the systematic model part \\(b_0 + b_1(x)\\), around which observations randomly vary (the \\(\\varepsilon\\) part) - i.e. \\(\\color{red}{\\text{outcome}} = \\color{blue}{\\text{model}}\\) \\(+ \\text{error}\\).\nIn the multi-level model, our random effects are another source of random variation: \\(\\color{red}{\\text{outcome}}\\) = \\(\\color{blue}{\\text{model}}\\) \\(+ \\text{group-error} + \\text{individual-error}\\). As such, random effects are another form of residual, and our assumptions of zero mean constant variance apply at both levels of residuals (see Figure 1).\n\n\n\n\n\nFigure 1: The black dashed lines show our model assumptions.\n\n\n\n\n\nWe can assess these normality of both resid(model) and ranef(model) by constructing plots using functions such as hist(), qqnorm() and qqline().\n\nWe can also use plot(model, type=c(\"p\",\"smooth\")) to give us our residuals vs fitted plot (smooth line should be horizontal at approx zero, showing zero mean).\n\nplot(model, form = sqrt(abs(resid(.))) ~ fitted(.), type = c(\"p\",\"smooth\")) will give us our scale-location plot (smooth line should be horizontal, showing constant variance).\n\nWe can also use the check_model() function from the performance package to get lots of info at once:\n\nlibrary(performance)\ncheck_model(random_slopes_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference\n\n\n\n\n\nTo get p-values for our coefficients, there are lots of different ways (see Optional Chapter 3 if you’re interested).\nFor DAPR3, we are recommending using the “Satterthwaite” method, which can be done by re-fitting the model the lmerTest package:\n\nrandom_slopes_model2 &lt;- lmerTest::lmer( outcome ~ 1 + x1 + (1+x1|subject), data=dat)\nsummary(random_slopes_model2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: outcome ~ 1 + x1 + (1 + x1 | subject)\n   Data: dat\n\nREML criterion at convergence: 1862\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.069 -0.417 -0.014  0.431  5.226 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n subject  (Intercept) 5287.68  72.72         \n          x1             1.86   1.36    -0.35\n Residual              662.33  25.74         \nNumber of obs: 185, groups:  subject, 20\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  405.790     16.666  18.045   24.35    3e-15 ***\nx1            -0.672      0.313  16.757   -2.15    0.047 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n   (Intr)\nx1 -0.370\n\n\nWe can also conduct model comparisons by doing a likelihood ratio test. This can be useful to test multiple coefficients at once. The clearest way to think about this is to start with the full model and remove the bits you want to test.\nTypically, as we are interested in testing the fixed part, our ‘restricted model’ might have random slopes of predictors that are not in the fixed effects, which looks weird but is okay because we’re just using that model as a comparison point:\n\nmodel2 &lt;- lmer( outcome ~ 1 + x1 + x2+ (1+x1|subject), data=dat)\nmodel2.0 &lt;- lmer( outcome ~ 1 + (1+x1|subject), data=dat)\n\nanova(model2.0, model2)\n\n\n\n\n\n\n\n\n\n\nVisualising Model Fitted values\n\n\n\n\n\nThe model fitted (or “model predicted”) values can be obtained using predict() (returning just the values) or broom.mixed::augment() (returning the values attached to the data that is inputted to the model).\nTo plot, them, we would typically like to plot the fitted values for each group (e.g. subject)\n\nlibrary(broom.mixed)\naugment(random_slopes_model) |&gt;\n  ggplot(aes(x=x1, y=.fitted, group=subject))+\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Fixed Effects\n\n\n\n\n\nIf we want to plot the fixed effects from our model, we have to do something else. A good option is to use the effects package to construct a dataframe of the linear prediction across the values of a predictor, plus confidence intervals. We can then pass this to ggplot(), giving us all the control over the aesthetics.\n\n# when you want more control\nlibrary(effects)\nef &lt;- as.data.frame(effect(term=\"x1\",mod=random_slopes_model))\nggplot(ef, aes(x=x1,y=fit, ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\n\n\n\n\n\n\n\nWe might then want to combine this with out plot of fitted values to make a plot that shows both the estimates for the average group (this is the fixed effects part) and the amount to which groups vary around that average (this we can see with the fitted values plot)\n\n# when you want more control\nlibrary(effects)\nef &lt;- as.data.frame(effect(term=\"x1\",mod=random_slopes_model))\n\naugment(random_slopes_model) |&gt;\n  ggplot(aes(x=x1))+\n  geom_line(aes(y=.fitted,group=subject), alpha=.1) + \n  geom_line(data = ef, aes(y=fit))+\n  geom_ribbon(data = ef, aes(y=fit,ymin=lower,ymax=upper), \n              col=\"red\", fill=\"red\",alpha=.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNested and Crossed structures\n\n\n\n\n\nThe same principle we have seen for one level of clustering can be extended to clustering at different levels (for instance, observations are clustered within subjects, which are in turn clustered within groups).\nConsider the example where we have observations for each student in every class within a number of schools:\n\n\n\n\n\n\n\n\n\nQuestion: Is “Class 1” in “School 1” the same as “Class 1” in “School 2”?\nNo.\nThe classes in one school are distinct from the classes in another even though they are named the same.\nThe classes-within-schools example is a good case of nested random effects - one factor level (one group in a grouping varible) appears only within a particular level of another grouping variable.\nIn R, we can specify this using:\n(1 | school) + (1 | class:school)\nor\n(1 | school) + (1 | school:class)\nConsider another example, where we administer the same set of tasks at multiple time-points for every participant.\nQuestion: Are tasks nested within participants?\nNo.\nTasks are seen by multiple participants (and participants see multiple tasks).\nWe could visualise this as the below:\n\n\n\n\n\n\n\n\n\nIn the sense that these are not nested, they are crossed random effects.\nIn R, we can specify this using:\n(1 | subject) + (1 | task)\n\nNested vs Crossed\nNested: Each group belongs uniquely to a higher-level group.\nCrossed: Not-nested.\n\nNote that in the schools and classes example, had we changed data such that the classes had unique IDs (e.g., see below), then the structures (1 | school) + (1 | class) and (1 | school) + (1 | school:class) would give the same results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMLM in a nutshell\n\n\n\n\n\nMLM allows us to model effects in the linear model as varying between groups. Our coefficients we remember from simple linear models (the \\(b\\)’s) are modelled as a distribution that has an overall mean around which our groups vary. We can see this in Figure 2, where both the intercept and the slope of the line are modelled as varying by-groups. Figure 2 shows the overall line in blue, with a given group’s line in green.\n\n\n\n\n\nFigure 2: Multilevel Model. Each group (e.g. the group in the green line) deviates from the overall fixed effects (the blue line), and the individual observations (green points) deviate from their groups line\n\n\n\n\nThe formula notation for these models involves separating out our effects \\(b\\) into two parts: the overall effect \\(\\gamma\\) + the group deviations \\(\\zeta_i\\):\n\\[\n\\begin{align}\n& \\text{for observation }j\\text{ in group }i \\\\\n\\quad \\\\\n& \\text{Level 1:} \\\\\n& \\color{red}{y_{ij}}\\color{black} = \\color{blue}{b_{0i} \\cdot 1 + b_{1i} \\cdot x_{ij}}\\color{black} + \\varepsilon_{ij} \\\\\n& \\text{Level 2:} \\\\\n& \\color{blue}{b_{0i}}\\color{black} = \\gamma_{00} + \\color{orange}{\\zeta_{0i}} \\\\\n& \\color{blue}{b_{1i}}\\color{black} = \\gamma_{10} + \\color{orange}{\\zeta_{1i}} \\\\\n\\quad \\\\\n& \\text{Where:} \\\\\n& \\gamma_{00}\\text{ is the population intercept, and }\\color{orange}{\\zeta_{0i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{00} \\\\\n& \\gamma_{10}\\text{ is the population slope, and }\\color{orange}{\\zeta_{1i}}\\color{black}\\text{ is the deviation of group }i\\text{ from }\\gamma_{10} \\\\\n\\end{align}\n\\]\nThe group-specific deviations \\(\\zeta_{0i}\\) from the overall intercept are assumed to be normally distributed with mean \\(0\\) and variance \\(\\sigma_0^2\\). Similarly, the deviations \\(\\zeta_{1i}\\) of the slope for group \\(i\\) from the overall slope are assumed to come from a normal distribution with mean \\(0\\) and variance \\(\\sigma_1^2\\). The correlation between random intercepts and slopes is $= ({0i}, {1i}):\n\\[\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix}\n\\sim N\n\\left(\n    \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\n    \\begin{bmatrix}\n        \\sigma_0^2 & \\rho_{01}1 \\\\\n        \\rho_{01} & \\sigma_1^2\n    \\end{bmatrix}\n\\right)\n\\]\nThe random errors, independently from the random effects, are assumed to be normally distributed with a mean of zero\n\\[\n\\epsilon_{ij} \\sim N(0, \\sigma_\\epsilon^2)\n\\]\nWe fit these models using the R package lme4, and the function lmer(). Think of it like building your linear model lm(y ~ 1 + x), and then allowing effects (i.e. things on the right hand side of the ~ symbol) to vary by the grouping of your data. We specify these by adding (vary these effects | by these groups) to the model:\n\nlibrary(lme4)\nm1 &lt;- lmer(y ~ x + (1 + x | group), data = df)\nsummary(m1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 + x | group)\n   Data: df\n\nREML criterion at convergence: 638\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4945 -0.5722 -0.0135  0.6254  2.3912 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n group    (Intercept) 2.262    1.504        \n          x           0.796    0.892    0.55\n Residual             4.367    2.090        \nNumber of obs: 132, groups:  group, 20\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)    1.726      0.967    1.78\nx              1.151      0.297    3.88\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.552\n\n\nThe summary of the lmer output returns estimated values for\nFixed effects:\n\n\\(\\widehat \\gamma_{00} = 1.726\\)\n\\(\\widehat \\gamma_{10} = 1.151\\)\n\nVariability of random effects:\n\n\\(\\widehat \\sigma_{0} = 1.504\\)\n\\(\\widehat \\sigma_{1} = 0.892\\)\n\nCorrelation of random effects:\n\n\\(\\widehat \\rho = 0.546\\)\n\nResiduals:\n\n\\(\\widehat \\sigma_\\epsilon = 2.09\\)"
  },
  {
    "objectID": "07ex.html",
    "href": "07ex.html",
    "title": "W7 Exercises: Questionnaire Data & Scale Scores",
    "section": "",
    "text": "Dataset: boxbreathe.csv\nResearchers are interested in different methods for reducing stress. They recruit 522 participants. All participants first filled out a 6-question measure of stress that is aimed to capture feelings of immediate stress and panic. All questions were scored on a 5-point likert scale from “Strongly Disagree” (1) to “Strongly Agree” (5). To obtain an overall measure of stress, participants’ scores on the 6 questions are added together.\nAfter completing the initial stress measure, participants then completed one of three 5 minute tasks. One third of participants sat in silence for 5 minutes, one third played a picture-matching game on their phone for 5 minutes, and the remaining third completed 5 minutes of “box breathing” (inhale for 6, hold for 4, exhale for 6, hold for 4). After the 5 minutes, all participants filled out the same 6-item measure of stress.\nResearchers would like to know whether the different tasks are associated with differences in reduction in stress.\nDataset: https://uoepsy.github.io/data/boxbreathe.csv\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nt1_q1\n(Time1) I feel a bit on edge right now.\n\n\nt1_q2\n(Time1) I find it hard to focus because of how I'm feeling.\n\n\nt1_q3\n(Time1) I feel like things are getting a little out of control.\n\n\nt1_q4\n(Time1) I feel calm and steady in this moment.\n\n\nt1_q5\n(Time1) I feel capable of managing the situation right now.\n\n\nt1_q6\n(Time1) I feel somewhat restless or unsettled at the moment.\n\n\ntask\nTask completed (nothing / game / boxbreathing)\n\n\nt2_q1\n(Time2) I feel a bit on edge right now.\n\n\nt2_q2\n(Time2) I find it hard to focus because of how I'm feeling.\n\n\nt2_q3\n(Time2) I feel like things are getting a little out of control.\n\n\nt2_q4\n(Time2) I feel calm and steady in this moment.\n\n\nt2_q5\n(Time2) I feel capable of managing the situation right now.\n\n\nt2_q6\n(Time2) I feel somewhat restless or unsettled at the moment.\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and have a look at it.\n\nWhat does each row represent?\n\nWhat measurement(s) show us a person’s stress?\n\n\n\n\n\nHere’s the data:\n\n# read_csv()\nhead(bbdat)\n\n                       t1_q1                      t1_q2\n1                   Disagree Neither Disagree nor Agree\n2 Neither Disagree nor Agree                      Agree\n3 Neither Disagree nor Agree                      Agree\n4 Neither Disagree nor Agree                   Disagree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6             Strongly Agree Neither Disagree nor Agree\n                       t1_q3                      t1_q4\n1                   Disagree Neither Disagree nor Agree\n2                      Agree                   Disagree\n3                      Agree Neither Disagree nor Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree                   Disagree\n6 Neither Disagree nor Agree                   Disagree\n                       t1_q5                      t1_q6    task\n1 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n2          Strongly Disagree             Strongly Agree nothing\n3                   Disagree                      Agree nothing\n4 Neither Disagree nor Agree                   Disagree nothing\n5 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n6 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n                       t2_q1                      t2_q2\n1          Strongly Disagree Neither Disagree nor Agree\n2                      Agree                      Agree\n3                      Agree                      Agree\n4                      Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6             Strongly Agree Neither Disagree nor Agree\n                       t2_q3                      t2_q4\n1                   Disagree Neither Disagree nor Agree\n2                      Agree                   Disagree\n3                      Agree Neither Disagree nor Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6 Neither Disagree nor Agree Neither Disagree nor Agree\n                       t2_q5                      t2_q6\n1 Neither Disagree nor Agree Neither Disagree nor Agree\n2          Strongly Disagree             Strongly Agree\n3 Neither Disagree nor Agree                      Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree                      Agree\n6 Neither Disagree nor Agree Neither Disagree nor Agree\n\n\nEach row is a participant, and we have their stress measured at two time points. We can see that for each person there are 6 columns all measuring the construct of “stress” at each time point.\nAnd for each of those columns, there’s a whole load of words in there!\n\n\n\n\nQuestion 2\n\n\nFirst things first, our questionnaire software has given us the responses all in the descriptors used for each point of the likert scale, which is a bit annoying.\nConvert them all to numbers, which we can then work with.\n\n\n\nWhat we have\nWhat we want\n\n\n\n\nStrongly Agree\n5\n\n\nAgree\n4\n\n\nAgree\n4\n\n\nStrongly Disagree\n1\n\n\nNeither Disagree nor Agree\n3\n\n\nAgree\n4\n\n\nDisagree\n2\n\n\n…\n…\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nSee R7#variable-recoding.\n\n\n\n\n\n\n\nWe want to turn all of the variables from t1_q1 to t1_q6 and from t2_q1 to t2_q6, into numbers.\nTo do it with one variable:\n\nbbdat |&gt; mutate(\n  t1_q1 = case_match(t1_q1,\n                     \"Strongly Disagree\" ~ 1,\n                     \"Disagree\" ~ 2,\n                     \"Neither Disagree nor Agree\" ~ 3,\n                     \"Agree\" ~ 4,\n                     \"Strongly Agree\" ~ 5\n  )\n)\n\nAnd we can do it to all at once with across().\nNote we have to specify two sets of columns because there’s a column in the middle (the task column) that we don’t want to do anything to.\n\nbbdat &lt;- bbdat |&gt; mutate(\n  across(c(t1_q1:t1_q6, t2_q1:t2_q6),\n         ~case_match(.,\n                     \"Strongly Disagree\" ~ 1,\n                     \"Disagree\" ~ 2,\n                     \"Neither Disagree nor Agree\" ~ 3,\n                     \"Agree\" ~ 4,\n                     \"Strongly Agree\" ~ 5\n         ))\n  )\n\nhead(bbdat)\n\n  t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6    task t2_q1 t2_q2 t2_q3 t2_q4 t2_q5\n1     2     3     2     3     3     3 nothing     1     3     2     3     3\n2     3     4     4     2     1     5 nothing     4     4     4     2     1\n3     3     4     4     3     2     4 nothing     4     4     4     3     3\n4     3     2     3     3     3     2 nothing     4     3     3     3     3\n5     3     3     3     2     3     3 nothing     3     3     3     3     3\n6     5     3     3     2     3     3 nothing     5     3     3     3     3\n  t2_q6\n1     3\n2     5\n3     4\n4     3\n5     4\n6     3\n\n\n\n\n\n\nQuestion 3\n\n\nJust looking at the data at time 1, create a correlation matrix of the various items that measure stress.\nWhat do you notice? Does it make sense given the wording of the questions?\n\n\n\n\n\ncor(bbdat[,1:6])\n\n       t1_q1  t1_q2  t1_q3  t1_q4  t1_q5  t1_q6\nt1_q1  1.000  0.216  0.427 -0.341 -0.369  0.459\nt1_q2  0.216  1.000  0.757 -0.709 -0.699  0.723\nt1_q3  0.427  0.757  1.000 -0.564 -0.735  0.718\nt1_q4 -0.341 -0.709 -0.564  1.000  0.715 -0.568\nt1_q5 -0.369 -0.699 -0.735  0.715  1.000 -0.807\nt1_q6  0.459  0.723  0.718 -0.568 -0.807  1.000\n\n\nCorrelations are all positive except for those with Q4 and Q5. Q4 and Q5 are positively related, but they are negatively related to the other questions.\nThis makes sense given the way the questions are worded - if people are feeling stressed, they will be more likely to disagree to Q4 and Q5, but agree with the others:\n\nqitems\n\n[1] \"I feel a bit on edge right now.\"                        \n[2] \"I find it hard to focus because of how I'm feeling.\"    \n[3] \"I feel like things are getting a little out of control.\"\n[4] \"I feel calm and steady in this moment.\"                 \n[5] \"I feel capable of managing the situation right now.\"    \n[6] \"I feel somewhat restless or unsettled at the moment.\"   \n\n\n\n\n\n\nQuestion 4\n\n\nReverse score questions 4 and 5.\nWe’ll need to do this for both the data at time 1 and at time 2.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nSee R7#reverse-coding\nBe careful!! if you have some code that reverse scores a question, and you run it twice, you will essentially reverse-reverse score the question, and it goes back to the original ordering!\n\n\n\n\n\n\n\n\nThere’s only 4, so let’s do this individually for each question:\n\nbbdat &lt;- bbdat |&gt; \n  mutate(\n    t1_q4 = 6 - t1_q4,\n    t1_q5 = 6 - t1_q5,\n    t2_q4 = 6 - t2_q4,\n    t2_q5 = 6 - t2_q5\n)\nhead(bbdat)\n\n  t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6    task t2_q1 t2_q2 t2_q3 t2_q4 t2_q5\n1     2     3     2     3     3     3 nothing     1     3     2     3     3\n2     3     4     4     4     5     5 nothing     4     4     4     4     5\n3     3     4     4     3     4     4 nothing     4     4     4     3     3\n4     3     2     3     3     3     2 nothing     4     3     3     3     3\n5     3     3     3     4     3     3 nothing     3     3     3     3     3\n6     5     3     3     4     3     3 nothing     5     3     3     3     3\n  t2_q6\n1     3\n2     5\n3     4\n4     3\n5     4\n6     3\n\n\n\n\n\n\nQuestion 5\n\n\nTake a look at the correlation of the time 1 stress measures again.\nWhat has changed?\n\n\n\n\nThe negative correlations are now positive!\n\ncor(bbdat[,1:6])\n\n      t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6\nt1_q1 1.000 0.216 0.427 0.341 0.369 0.459\nt1_q2 0.216 1.000 0.757 0.709 0.699 0.723\nt1_q3 0.427 0.757 1.000 0.564 0.735 0.718\nt1_q4 0.341 0.709 0.564 1.000 0.715 0.568\nt1_q5 0.369 0.699 0.735 0.715 1.000 0.807\nt1_q6 0.459 0.723 0.718 0.568 0.807 1.000\n\n\n\n\n\n\nQuestion 6\n\n\nWe’re finally getting somewhere! Let’s create a score for “stress” at time 1, and a score for “stress” at time 2.\nThe description of the questionnaire says that we should take the sum of the scores on each question, to get an overall measure of stress.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe function rowSums() should help us here! See an example in R7#row-scoring\n\n\n\n\n\n\n\n\nbbdat$t1_stress &lt;- rowSums(bbdat[,1:6])\nbbdat$t2_stress &lt;- rowSums(bbdat[,8:13])\n\n\n\n\n\nQuestion 7\n\n\nMake a new column that represents the change in stress for each person between the two timepoints.\n\n\n\n\n\nbbdat$stress_change &lt;- bbdat$t2_stress - bbdat$t1_stress\n\n\n\n\n\nQuestion 8\n\n\nProvide some descriptive statistics for the stress scores at time 1 and at time 2, and of the ‘change in stress’ measure.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe describe() function from the psych package is often pretty useful for this kind of thing\n\n\n\n\n\n\n\n\nlibrary(psych)\nbbdat |&gt; \n  select(t1_stress, t2_stress, stress_change) |&gt;\n  describe()\n\n              vars   n  mean   sd median trimmed  mad min max range  skew\nt1_stress        1 522 17.84 4.61     18   17.88 4.45   7  30    23 -0.06\nt2_stress        2 522 17.77 4.55     18   17.78 4.45   6  30    24 -0.03\nstress_change    3 522 -0.07 1.02      0   -0.04 1.48  -3   3     6 -0.11\n              kurtosis   se\nt1_stress        -0.32 0.20\nt2_stress        -0.40 0.20\nstress_change    -0.08 0.04\n\n\n\n\n\n\nQuestion 9\n\n\nPlot the stress-change for each group of participants.\nFit a linear model to investigate whether the different techniques (the timer game and the box-breathing) are associated with differences in stress change.\n\n\n\n\nIt makes more sense to think of “nothing” as the reference level, so let’s make that happen:\n\nbbdat &lt;- bbdat |&gt;\n  mutate(\n    task = factor(task, levels=c(\"nothing\",\"game\",\"boxbreathing\"))\n  )\n\nmod1 &lt;- lm(stress_change ~ task, data = bbdat) \n\nsummary(mod1)\n\n\nCall:\nlm(formula = stress_change ~ task, data = bbdat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6954 -0.6954  0.0632  0.8333  2.8333 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.167      0.076    2.19    0.029 *  \ntaskgame           -0.230      0.107   -2.14    0.033 *  \ntaskboxbreathing   -0.471      0.107   -4.39  1.4e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 519 degrees of freedom\nMultiple R-squared:  0.0357,    Adjusted R-squared:  0.032 \nF-statistic: 9.62 on 2 and 519 DF,  p-value: 7.9e-05\n\n\nWe can make a nice plot of the data, alongside our model estimates. We can actually use the effects() package here too, just like we did for lmer().\n\n# plot the data\nggplot(bbdat, aes(x = task, y = stress_change)) + \n  # jittered points\n  geom_jitter(width=.15, height=0, alpha=.2, size = 3) +\n  # plot the model estimated means and CIs:\n  geom_pointrange(\n    data = effects::effect(\"task\", mod1) |&gt; as.data.frame(),\n    aes(y=fit,ymin=lower,ymax=upper),\n    position = position_nudge(x=.25)\n  )",
    "crumbs": [
      "Week 7",
      "W7 Exercises: Questionnaire Data & Scale Scores"
    ]
  },
  {
    "objectID": "07exACAI.html",
    "href": "07exACAI.html",
    "title": "W7 Exercises: Questionnaire Data & Scale Scores",
    "section": "",
    "text": "Dataset: boxbreathe.csv\nResearchers are interested in different methods for reducing stress. They recruit 522 participants. All participants first filled out a 6-question measure of stress that is aimed to capture feelings of immediate stress and panic. All questions were scored on a 5-point likert scale from “Strongly Disagree” (1) to “Strongly Agree” (5). Participants then completed one of three 5 minute tasks. One third of participants sat in silence for 5 minutes, one third played a picture-matching game on their phone for 5 minutes, and the remaining third completed 5 minutes of “box breathing” (inhale for 6, hold for 4, exhale for 6, hold for 4). After the 5 minutes, all participants filled out the same 6-item measure of stress.\nResearchers would like to know whether the different tasks are associated with differences in reduction in stress.\nDataset: https://uoepsy.github.io/data/boxbreathe.csv\n\n\n\n\n\n\n  \n    \n      variable\n      description\n    \n  \n  \n    t1_q1\n(Time1) I feel a bit on edge right now.\n    t1_q2\n(Time1) I find it hard to focus because of how I'm feeling.\n    t1_q3\n(Time1) I feel like things are getting a little out of control.\n    t1_q4\n(Time1) I feel calm and steady in this moment.\n    t1_q5\n(Time1) I feel capable of managing the situation right now.\n    t1_q6\n(Time1) I feel somewhat restless or unsettled at the moment.\n    task\nTask completed (nothing / game / boxbreathing)\n    t2_q1\n(Time2) I feel a bit on edge right now.\n    t2_q2\n(Time2) I find it hard to focus because of how I'm feeling.\n    t2_q3\n(Time2) I feel like things are getting a little out of control.\n    t2_q4\n(Time2) I feel calm and steady in this moment.\n    t2_q5\n(Time2) I feel capable of managing the situation right now.\n    t2_q6\n(Time2) I feel somewhat restless or unsettled at the moment.\n  \n  \n  \n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and have a look at it.\n\nWhat does each row represent?\n\nWhat measurement(s) show us a person’s stress?\n\n\n\n\n\n\nSolution\n\n\n\nHere’s the data:\n\n# read_csv()\nhead(bbdat)\n\n                       t1_q1                      t1_q2\n1                   Disagree Neither Disagree nor Agree\n2 Neither Disagree nor Agree                      Agree\n3 Neither Disagree nor Agree                      Agree\n4 Neither Disagree nor Agree                   Disagree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6             Strongly Agree Neither Disagree nor Agree\n                       t1_q3                      t1_q4\n1                   Disagree Neither Disagree nor Agree\n2                      Agree                   Disagree\n3                      Agree Neither Disagree nor Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree                   Disagree\n6 Neither Disagree nor Agree                   Disagree\n                       t1_q5                      t1_q6    task\n1 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n2          Strongly Disagree             Strongly Agree nothing\n3                   Disagree                      Agree nothing\n4 Neither Disagree nor Agree                   Disagree nothing\n5 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n6 Neither Disagree nor Agree Neither Disagree nor Agree nothing\n                       t2_q1                      t2_q2\n1          Strongly Disagree Neither Disagree nor Agree\n2                      Agree                      Agree\n3                      Agree                      Agree\n4                      Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6             Strongly Agree Neither Disagree nor Agree\n                       t2_q3                      t2_q4\n1                   Disagree Neither Disagree nor Agree\n2                      Agree                   Disagree\n3                      Agree Neither Disagree nor Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree Neither Disagree nor Agree\n6 Neither Disagree nor Agree Neither Disagree nor Agree\n                       t2_q5                      t2_q6\n1 Neither Disagree nor Agree Neither Disagree nor Agree\n2          Strongly Disagree             Strongly Agree\n3 Neither Disagree nor Agree                      Agree\n4 Neither Disagree nor Agree Neither Disagree nor Agree\n5 Neither Disagree nor Agree                      Agree\n6 Neither Disagree nor Agree Neither Disagree nor Agree\n\n\nEach row is a participant, and we have their stress measured at two time points. We can see that for each person there are 6 columns all measuring the construct of “stress” at each time point.\nAnd for each of those columns, there’s a whole load of words in there!\n\n\n\n\nQuestion 2\n\n\nFirst things first, our questionnaire software has given us the responses all in the descriptors used for each point of the likert scale, which is a bit annoying.\nConvert them all to numbers, which we can then work with.\n\n\n\nWhat we have\nWhat we want\n\n\n\n\nStrongly Agree\n5\n\n\nAgree\n4\n\n\nAgree\n4\n\n\nStrongly Disagree\n1\n\n\nNeither Disagree nor Agree\n3\n\n\nAgree\n4\n\n\nDisagree\n2\n\n\n…\n…\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nSee R7#variable-recoding.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWe want to turn all of the variables from t1_q1 to t1_q6 and from t2_q1 to t2_q6, into numbers.\nTo do it with one variable:\n\nbbdat |&gt; mutate(\n  t1_q1 = case_match(t1_q1,\n                     \"Strongly Disagree\" ~ 1,\n                     \"Disagree\" ~ 2,\n                     \"Neither Disagree nor Agree\" ~ 3,\n                     \"Agree\" ~ 4,\n                     \"Strongly Agree\" ~ 5\n  )\n)\n\nAnd we can do it to all at once with across().\nNote we have to specify two sets of columns because there’s a column in the middle (the task column) that we don’t want to do anything to.\n\nbbdat &lt;- bbdat |&gt; mutate(\n  across(c(t1_q1:t1_q6, t2_q1:t2_q6),\n         ~case_match(.,\n                     \"Strongly Disagree\" ~ 1,\n                     \"Disagree\" ~ 2,\n                     \"Neither Disagree nor Agree\" ~ 3,\n                     \"Agree\" ~ 4,\n                     \"Strongly Agree\" ~ 5\n         ))\n  )\n\nhead(bbdat)\n\n  t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6    task t2_q1 t2_q2 t2_q3 t2_q4 t2_q5\n1     2     3     2     3     3     3 nothing     1     3     2     3     3\n2     3     4     4     2     1     5 nothing     4     4     4     2     1\n3     3     4     4     3     2     4 nothing     4     4     4     3     3\n4     3     2     3     3     3     2 nothing     4     3     3     3     3\n5     3     3     3     2     3     3 nothing     3     3     3     3     3\n6     5     3     3     2     3     3 nothing     5     3     3     3     3\n  t2_q6\n1     3\n2     5\n3     4\n4     3\n5     4\n6     3\n\n\n\n\n\n\nQuestion 3\n\n\nJust looking at the data at time 1, create a correlation matrix of the various items that measure stress.\nWhat do you notice? Does it make sense given the wording of the questions?\n\n\n\n\n\nSolution\n\n\n\n\ncor(bbdat[,1:6])\n\n       t1_q1  t1_q2  t1_q3  t1_q4  t1_q5  t1_q6\nt1_q1  1.000  0.216  0.427 -0.341 -0.369  0.459\nt1_q2  0.216  1.000  0.757 -0.709 -0.699  0.723\nt1_q3  0.427  0.757  1.000 -0.564 -0.735  0.718\nt1_q4 -0.341 -0.709 -0.564  1.000  0.715 -0.568\nt1_q5 -0.369 -0.699 -0.735  0.715  1.000 -0.807\nt1_q6  0.459  0.723  0.718 -0.568 -0.807  1.000\n\n\nCorrelations are all positive except for those with Q4 and Q5. Q4 and Q5 are positively related, but they are negatively related to the other questions.\nThis makes sense given the way the questions are worded - if people are feeling stressed, they will be more likely to disagree to Q4 and Q5, but agree with the others:\n\nqitems\n\n[1] \"I feel a bit on edge right now.\"                        \n[2] \"I find it hard to focus because of how I'm feeling.\"    \n[3] \"I feel like things are getting a little out of control.\"\n[4] \"I feel calm and steady in this moment.\"                 \n[5] \"I feel capable of managing the situation right now.\"    \n[6] \"I feel somewhat restless or unsettled at the moment.\"   \n\n\n\n\n\n\nQuestion 4\n\n\nReverse score questions 4 and 5.\nWe’ll need to do this for both the data at time 1 and at time 2.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nSee R7#reverse-coding\nBe careful!! if you have some code that reverse scores a question, and you run it twice, you will essentially reverse-reverse score the question, and it goes back to the original ordering!\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThere’s only 4, so let’s do this individually for each question:\n\nbbdat &lt;- bbdat |&gt; \n  mutate(\n    t1_q4 = 6 - t1_q4,\n    t1_q5 = 6 - t1_q5,\n    t2_q4 = 6 - t2_q4,\n    t2_q5 = 6 - t2_q5\n)\nhead(bbdat)\n\n  t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6    task t2_q1 t2_q2 t2_q3 t2_q4 t2_q5\n1     2     3     2     3     3     3 nothing     1     3     2     3     3\n2     3     4     4     4     5     5 nothing     4     4     4     4     5\n3     3     4     4     3     4     4 nothing     4     4     4     3     3\n4     3     2     3     3     3     2 nothing     4     3     3     3     3\n5     3     3     3     4     3     3 nothing     3     3     3     3     3\n6     5     3     3     4     3     3 nothing     5     3     3     3     3\n  t2_q6\n1     3\n2     5\n3     4\n4     3\n5     4\n6     3\n\n\n\n\n\n\nQuestion 5\n\n\nTake a look at the correlation of the time 1 stress measures again.\nWhat has changed?\n\n\n\n\n\nSolution\n\n\n\nThe negative correlations are now positive!\n\ncor(bbdat[,1:6])\n\n      t1_q1 t1_q2 t1_q3 t1_q4 t1_q5 t1_q6\nt1_q1 1.000 0.216 0.427 0.341 0.369 0.459\nt1_q2 0.216 1.000 0.757 0.709 0.699 0.723\nt1_q3 0.427 0.757 1.000 0.564 0.735 0.718\nt1_q4 0.341 0.709 0.564 1.000 0.715 0.568\nt1_q5 0.369 0.699 0.735 0.715 1.000 0.807\nt1_q6 0.459 0.723 0.718 0.568 0.807 1.000\n\n\n\n\n\n\nQuestion 6\n\n\nWe’re finally getting somewhere! Let’s create a score for “stress” at time 1, and a score for “stress” at time 2.\nThe description of the questionnaire says that we should take the sum of the scores on each question, to get an overall measure of stress.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe function rowSums() should help us here! See an example in R7#row-scoring\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nbbdat$t1_stress &lt;- rowSums(bbdat[,1:6])\nbbdat$t2_stress &lt;- rowSums(bbdat[,8:13])\n\n\n\n\n\nQuestion 7\n\n\nMake a new column that represents the change in stress for each person between the two timepoints.\n\n\n\n\n\nSolution\n\n\n\n\nbbdat$stress_change &lt;- bbdat$t2_stress - bbdat$t1_stress\n\n\n\n\n\nQuestion 8\n\n\nProvide some descriptive statistics for the stress scores at time 1 and at time 2, and of the ‘change in stress’ measure.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe describe() function from the psych package is often pretty useful for this kind of thing\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(psych)\nbbdat |&gt; \n  select(t1_stress, t2_stress, stress_change) |&gt;\n  describe()\n\n              vars   n  mean   sd median trimmed  mad min max range  skew\nt1_stress        1 522 17.84 4.61     18   17.88 4.45   7  30    23 -0.06\nt2_stress        2 522 17.77 4.55     18   17.78 4.45   6  30    24 -0.03\nstress_change    3 522 -0.07 1.02      0   -0.04 1.48  -3   3     6 -0.11\n              kurtosis   se\nt1_stress        -0.32 0.20\nt2_stress        -0.40 0.20\nstress_change    -0.08 0.04\n\n\n\n\n\n\nQuestion 9\n\n\nPlot the stress-change for each group of participants.\nFit a linear model to investigate whether the different techniques (the timer game and the box-breathing) are associated with differences in stress change.\n\n\n\n\n\nSolution\n\n\n\nIt makes more sense to think of “nothing” as the reference level, so let’s make that happen:\n\nbbdat &lt;- bbdat |&gt;\n  mutate(\n    task = factor(task, levels=c(\"nothing\",\"game\",\"boxbreathing\"))\n  )\n\nmod1 &lt;- lm(stress_change ~ task, data = bbdat) \n\nsummary(mod1)\n\n\nCall:\nlm(formula = stress_change ~ task, data = bbdat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6954 -0.6954  0.0632  0.8333  2.8333 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.167      0.076    2.19    0.029 *  \ntaskgame           -0.230      0.107   -2.14    0.033 *  \ntaskboxbreathing   -0.471      0.107   -4.39  1.4e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 519 degrees of freedom\nMultiple R-squared:  0.0357,    Adjusted R-squared:  0.032 \nF-statistic: 9.62 on 2 and 519 DF,  p-value: 7.9e-05\n\n\nWe can make a nice plot of the data, alongside our model estimates. We can actually use the effects() package here too, just like we did for lmer().\n\n# plot the data\nggplot(bbdat, aes(x = task, y = stress_change)) + \n  # jittered points\n  geom_jitter(width=.15, height=0, alpha=.2, size = 3) +\n  # plot the model estimated means and CIs:\n  geom_pointrange(\n    data = effects::effect(\"task\", mod1) |&gt; as.data.frame(),\n    aes(y=fit,ymin=lower,ymax=upper),\n    position = position_nudge(x=.25)\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the DAPR3 Lab Workbook",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 3 (DAPR3) lab workbook. Exercises for each week can be found in the menu to the left."
  },
  {
    "objectID": "r07_qdata.html",
    "href": "r07_qdata.html",
    "title": "R7: Questionnaire Data Wrangling",
    "section": "",
    "text": "Questionnaire data often comes to us in ‘wide’ format, which is often how we want it for many of the analytical methods we use with questionnaire data. However, working with data in the wide format comes with some specific challenges that generally arise because we have lots and lots of variables.\nBelow we will walk through some of the common ways we want to wrangle and clean questionnaire data."
  },
  {
    "objectID": "r07_qdata.html#footnotes",
    "href": "r07_qdata.html#footnotes",
    "title": "R7: Questionnaire Data Wrangling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically this is pronounced “LICK-URT” and not “LIE-KURT”. It’s named after Dr Rensis Likert, and that’s how he pronounced his name!↩︎"
  }
]