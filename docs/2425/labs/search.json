[
  {
    "objectID": "00prereq.html",
    "href": "00prereq.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Install/Update R & RStudio\nMake sure you have installed both R and RStudio on your computer. You may have done this previously for DAPR2, in which case it is probably worth doing some updates.\nPlease make sure to read and follow the instructions below slowly and carefully!!\n- For instructions on how to install R and RStudio, click here - For instructions on how to update R and RStudio, click here\n\n\nUpdate Packages\nIt’s worth keeping packages up to date, so it might be worth updating all your packages.\nRunning this code will update all your packages. Just put it into the console (bottom left bit of RStudio):\n\noptions(pkgType = \"binary\")\nupdate.packages(ask = FALSE)\n\n\n\nNew packages!\nNow it is probably worth installing a few of the packages that we will be using in DAPR3. There are a few that we will need. For each one, check whether you have it already installed, because there’s not much point wasting time re-installing something you already have!\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models"
  },
  {
    "objectID": "01ex.html",
    "href": "01ex.html",
    "title": "Week 1 Exercises: Regression Refresher",
    "section": "",
    "text": "Workplace Pride\n\nData: jsup.csv\n\nemployees from various departments (some are virtual departments, some are office based).\nemployees are either role A, B, or C. (A tends to have less responsibility, C is more managerial)\nalso have their length of employment. sometimes new employees come straight in at role C, but a lot of them come in at A and work up.\nMeasured their ‘pride in the workplace’\n\n\n\n\n\n\n\n  \n    \n      variable\n      description\n    \n  \n  \n    role\n\n    employment_length\n\n    dept\n\n    virtual\n\n    wp\n\n  \n  \n  \n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and provide some descriptive statistics.\n\n\n\n\n\n\nHints\n\n\n\n\n\nDon’t remember how to do descriptives? Think back to previous courses - it’s time for some means, standard deviations, mins and maxes. For categorical variables we can do counts or proportions.\nWe’ve seen various functions such as summary(), and also describe() from the psych package.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(tidyverse) # for data wrangling\nlibrary(psych) \n\njsup |&gt; \n  select(employment_length, wp) |&gt; \n  describe()\n\n                  vars   n  mean   sd median trimmed  mad    min  max range\nemployment_length    1 300  0.88 1.24   0.92    0.87 1.29  -2.97 5.83  8.79\nwp                   2 300 -0.88 3.27  -0.91   -0.89 3.64 -13.01 7.22 20.23\n                   skew kurtosis   se\nemployment_length  0.09     0.34 0.07\nwp                -0.08    -0.05 0.19\n\ntable(jsup$role)\n\n\n  a   b   c \n112  97  91 \n\ntable(jsup$dept)\n\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 \n45 25 13 17 16 10 17 17 21 17 20 18 20 15 16 13 \n\ntable(jsup$virtual)\n\n\n  0   1 \n180 120 \n\n\n\n\n\n\nQuestion 2\n\n\nAre there differences in ‘workplace-pride’ between people in different roles?\n\n\n\n\n\n\nHints\n\n\n\n\n\ndoes y [continuous variable] differ by x [three groups]? lm(y ~ x)?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod1 &lt;- lm(wp ~ role, data = jsup)\n\nRather than doing summary(model) - I’m just going to pull out a tidy data.frame of the coefficients, standard errors, t-statistics and p-values.\nIt’s the same information, just neater\n\nlibrary(broom)\ntidy(mod1)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    0.675     0.275      2.45 1.48e- 2\n2 roleb         -1.36      0.404     -3.36 8.81e- 4\n3 rolec         -3.67      0.411     -8.92 4.78e-17\n\n\nIt looks like people in roles B and C report a lot less pride in the workplace, compared to people in role A.\n\n\n\n\nQuestion 3\n\n\nIs it something about the roles that make people report differences in workplace-pride, or is it possibly just that people who are newer to the company tend to feel more pride than those who have been there for a while (they’re all jaded), and the people in role A tend to be much newer to the company (making it look like people in role A take more pride). In other words, if we were to compare people in role A vs role B vs role C but holding constant their employment_length, we might see something different?\n\n\n\n\n\n\nHints\n\n\n\n\n\nso we want to adjust for how long people have been part of the company..\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\ntidy(mod2)\n\n# A tibble: 4 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)          0.709     0.219     3.24  1.34e- 3\n2 employment_length   -1.80      0.136   -13.2   1.19e-31\n3 roleb                0.325     0.346     0.940 3.48e- 1\n4 rolec               -0.354     0.412    -0.860 3.91e- 1\n\n\nNote that there are no significant differences in wp between roles B or C compared to A, after adjusting for employment length.\nIf we plot the data to show all these variables together, we can kind of see why! Given the pattern of wp against employment_length, the wp for different roles are pretty much where we would expect them to be if role doesn’t make any difference (i.e., if role doesn’t shift your wp up or down).\n\nggplot(jsup, aes(x=employment_length,y=wp,col=role))+\n  geom_point(size=3,alpha=.3)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nDo roles differ in their workplace-pride, when adjusting for time in the company?\n\n\n\n\n\n\nHints\n\n\n\n\n\nNote this is not a question about specific group differences. It is about whether, overall, the role groups differ. So it’s wanting to test the joint effect of the two additional parameters we’ve just added to our model. (hint hint model comparison!)\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod2a &lt;- lm(wp ~ employment_length, data = jsup)\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\nanova(mod2a, mod2)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length\nModel 2: wp ~ employment_length + role\n  Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)\n1    298 1607                         \n2    296 1587  2      19.8 1.85   0.16\n\n\n\n\n\n\nQuestion 5\n\n\nLet’s take a step back. We’ve got 300 people in our dataset, from 16 departments.\nDepartments may well differ in the general amount of workplace-pride people report. People love to say that they work in TODO, but other departments might not elicit such pride. We need to be careful not to mistake department differences as something else (like differences due to the job role).\nmake a couple of plots\n\nhow many each role in each department?\nworkplace pride by department\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(jsup, aes(x = role)) + \n  geom_bar()+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nIn this case, it looks like most of the departments have similar numbers of each role, apart from department TODO, where we’ve got loads more of role A, and very few role C..\nNote also that department TODO is, on average, full of employees who take a lot of pride in their work. Is this due to the high proportion of roles? or is the effect of role we’re seeing more due to differences in departments?\n\nggplot(jsup, aes(x = dept, y = wp)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nEven if we had perfectly equal numbers of roles in each department, we’re also adjusting for other things such as employment_length, and our model the extent to which this differs by department can have trickle-on effects on our coefficient of interest (the role coefficients).\n\n\n\n\nQuestion 6\n\n\nAdjusting for both length of employment and department, are there differences in ‘workplace-pride’ between the different roles?\n\n\n\n\n\n\nHints\n\n\n\n\n\nCan you make some plots\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmod3 &lt;- lm(wp ~ employment_length + dept + role, data = jsup)\nsummary(mod3)\n\n\nCall:\nlm(formula = wp ~ employment_length + dept + role, data = jsup)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.126 -0.817  0.000  0.815  3.060 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.3289     0.1945   17.12  &lt; 2e-16 ***\nemployment_length  -1.9203     0.0741  -25.93  &lt; 2e-16 ***\ndept2               0.2334     0.3141    0.74  0.45801    \ndept3              -2.8638     0.3960   -7.23  4.5e-12 ***\ndept4              -2.7000     0.3604   -7.49  8.9e-13 ***\ndept5              -5.0915     0.3667  -13.88  &lt; 2e-16 ***\ndept6              -3.3826     0.4372   -7.74  1.8e-13 ***\ndept7              -2.6698     0.3564   -7.49  8.9e-13 ***\ndept8              -4.5204     0.3598  -12.56  &lt; 2e-16 ***\ndept9              -5.1723     0.3331  -15.53  &lt; 2e-16 ***\ndept10             -6.4843     0.3605  -17.98  &lt; 2e-16 ***\ndept11             -3.0865     0.3405   -9.07  &lt; 2e-16 ***\ndept12             -3.5691     0.3507  -10.18  &lt; 2e-16 ***\ndept13             -5.1963     0.3383  -15.36  &lt; 2e-16 ***\ndept14             -3.1679     0.3747   -8.45  1.5e-15 ***\ndept15             -3.5483     0.3656   -9.71  &lt; 2e-16 ***\ndept16             -4.1888     0.3962  -10.57  &lt; 2e-16 ***\nroleb               0.8988     0.1870    4.81  2.5e-06 ***\nrolec               0.8813     0.2288    3.85  0.00014 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.24 on 281 degrees of freedom\nMultiple R-squared:  0.865, Adjusted R-squared:  0.856 \nF-statistic:  100 on 18 and 281 DF,  p-value: &lt;2e-16\n\n\nIn a way, adding predictors to our model is kind of like splitting up our plots by that predictor to see the patterns. This becomes more and more difficult (/impossible) as we get more variables, but right now we can split the data into all the constituent parts.\nThe association between wp and employment_length is clear in all these little sub-plots - there’s a downward trend. The department differences can be seen too: department 1 is generally a bit higher, departments 5 and 9 a bit lower, and so on. By default, the model captures these coefficients as ‘differences from the reference group’, so most of the coefficients are negative because they’re mostly lower than department 1.\nSeeing the role differences is a bit harder in this plot, but think about what you would expect to see if there were no differences in roles (i.e. imagine if they were all in role A). Take for instance department 2 - for people in role C, for their employment length we would expect their wp to be lower if they were in role A. Likewise for those in role B. Across all these departments, the people in role B and C (green and blue dots respectively) are a bit higher than we would expect. This is what the model coefficients tell us!\n\nggplot(jsup, aes(x = employment_length, y = wp, col = role)) +\n  geom_point(size=3,alpha=.4)+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nSo we’re starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on..\nLet’s try to describe our sample in a bit more detail.\n\nhow many participants do we have, and from how many departments?\nhow many participants are there, on average, from each department? what is the minimum and maximum?\nwhat is the average employment length for our participants?\nhow many departments are ‘virtual departments’ vs office-based?\n\nwhat is the overall average reported workplace-pride?\nhow much variation in workplace-pride is due to differences between departments?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe first lot of these questions can be answered using things like count(), summary(), table(), mean(), min() etc. See 1: Clustered Data #determining-sample-sizes\nFor the last one, we can use the ICC! See 1: Clustered Data #icc\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n# - how many participants do we have, and from how many departments?\nnrow(jsup)\n\n[1] 300\n\nlength(table(jsup$dept))\n\n[1] 16\n\n# - how many ppts on average from each dept? (min, max?)\njsup |&gt; count(dept) |&gt; summarise(min=min(n),max=max(n),median=median(n))\n\n  min max median\n1  10  45     17\n\n# - average employment length of ppts?\nmean(jsup$employment_length)\n\n[1] 0.88\n\n# - how many depts are virtual vs office based?\njsup |&gt; group_by(virtual) |&gt;\n  summarise(\n    ndept = n_distinct(dept)\n  )\n\n# A tibble: 2 × 2\n  virtual ndept\n    &lt;int&gt; &lt;int&gt;\n1       0    11\n2       1     5\n\n# overall average wp\nmean(jsup$wp)\n\n[1] -0.877\n\nsd(jsup$wp)\n\n[1] 3.27\n\n# how much of y variation is due to dept? (ICC)\nICC::ICCbare(x = dept, y = wp, data = jsup)\n\n[1] 0.427\n\n\n\n\n\n\nQuestion 8\n\n\nWhat if I would like to know if, adjusting for differences due to employment length and roles, the workplace-pride differs between people working in virtual-departments compared to office-based ones?\n\n\n\n\n\nSolution\n\n\n\nLet’s add the virtual predictor to our model. Note that we don’t actually get a coefficient here - it is giving us an NA!\n\nmod4 &lt;- lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n\nsummary(mod4)\n\n\nCall:\nlm(formula = wp ~ employment_length + dept + role + virtual, \n    data = jsup)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.126 -0.817  0.000  0.815  3.060 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.3289     0.1945   17.12  &lt; 2e-16 ***\nemployment_length  -1.9203     0.0741  -25.93  &lt; 2e-16 ***\ndept2               0.2334     0.3141    0.74  0.45801    \ndept3              -2.8638     0.3960   -7.23  4.5e-12 ***\ndept4              -2.7000     0.3604   -7.49  8.9e-13 ***\ndept5              -5.0915     0.3667  -13.88  &lt; 2e-16 ***\ndept6              -3.3826     0.4372   -7.74  1.8e-13 ***\ndept7              -2.6698     0.3564   -7.49  8.9e-13 ***\ndept8              -4.5204     0.3598  -12.56  &lt; 2e-16 ***\ndept9              -5.1723     0.3331  -15.53  &lt; 2e-16 ***\ndept10             -6.4843     0.3605  -17.98  &lt; 2e-16 ***\ndept11             -3.0865     0.3405   -9.07  &lt; 2e-16 ***\ndept12             -3.5691     0.3507  -10.18  &lt; 2e-16 ***\ndept13             -5.1963     0.3383  -15.36  &lt; 2e-16 ***\ndept14             -3.1679     0.3747   -8.45  1.5e-15 ***\ndept15             -3.5483     0.3656   -9.71  &lt; 2e-16 ***\ndept16             -4.1888     0.3962  -10.57  &lt; 2e-16 ***\nroleb               0.8988     0.1870    4.81  2.5e-06 ***\nrolec               0.8813     0.2288    3.85  0.00014 ***\nvirtual                 NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.24 on 281 degrees of freedom\nMultiple R-squared:  0.865, Adjusted R-squared:  0.856 \nF-statistic:  100 on 18 and 281 DF,  p-value: &lt;2e-16\n\n\nSo what is happening? If we think about it, if we separate out “differences due to departments” then there is nothing left to compare between departments that are virtual vs office based. Adding the between-department predictor of virtual doesn’t explain anything more - the residual sums of squares doesn’t decrease at all:\n\nanova(\n  lm(wp ~ employment_length + dept + role, data = jsup),\n  lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length + dept + role\nModel 2: wp ~ employment_length + dept + role + virtual\n  Res.Df RSS Df Sum of Sq F Pr(&gt;F)\n1    281 432                      \n2    281 432  0         0         \n\n\nAnother way of thinking about this: knowing average workplace-pride for the department that someone is in tells me what to expect about that person’s workplace pride. But once I know their department’s average workplace-pride, knowing whether it is ‘virtual’ or ‘office-based’ doesn’t tell me anything new, for the very fact that the virtual/office-based distinction comes from comparing department averages.\nBut we’re not really interested in departments specifically! What would be nice would be if we can look at the relevant effects of interest (things like role and virtual), but then just think of the department differences as just some sort of random variation. So we want to think of departments in a similar way to how we think of our individual employees - they vary randomly around what we expect - only they’re at a different level of observation."
  },
  {
    "objectID": "02ex.html",
    "href": "02ex.html",
    "title": "Week 2 Exercises: Introducing MLM",
    "section": "",
    "text": "For our first foray into the multilevel model, we’re going to start with little toy example, and we’re just going to ask you to plot the predictions from a) a simple linear model, b) a model with a random intercept, and c) a model with random intercepts and slopes.\nThis is to build the understanding of the structure of multilevel models. When it comes to actually building models for research purposes, it is not necessary to slowly build up the complexity in this way.\n\nData: New Toys!\nRecall the example from last semesters’ USMR course, where the lectures explored linear regression with a toy dataset of how practice influences the reading age of toy characters (see USMR Week 7 Lecture). We’re going to now broaden our scope to the investigation of how practice affects reading age for all toys (not just Martin’s Playmobil characters).\nYou can find a dataset at https://uoepsy.github.io/data/toy2.csv containing information on 129 different toy characters that come from a selection of different families/types of toy. You can see the variables in the table below1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      variable\n      description\n    \n  \n  \n    toy_type\nType of Toy\n    year\nYear Released\n    toy\nCharacter\n    hrs_week\nHours of practice per week\n    R_AGE\nReading Age\n  \n  \n  \n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and plot the relationship between hours-per-week practice (hrs_week) and reading age (R_AGE).\nFacet the plot by the type of toy.\n\n\n\n\n\n\nHints\n\n\n\n\n\n“facet” is the key word here! See 1A #visualisations\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(tidyverse)\ntoy2 &lt;- read_csv(\"https://uoepsy.github.io/data/toy2.csv\")\n\nhead(toy2)\n\n# A tibble: 6 × 5\n  toy_type  year toy    hrs_week R_AGE\n  &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Barbie    1959 Summer     4.04     8\n2 Barbie    1959 Nikki      2.36     6\n3 Barbie    1959 Barbie     4.02     8\n4 Barbie    1959 Midge      4.97     8\n5 Barbie    1959 Teresa     3.37     6\n6 Barbie    1959 Ken        4.56     8\n\nggplot(toy2,aes(x=hrs_week,y=R_AGE))+\n  geom_point()+\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nBelow is the code to fit a simple linear model and produce some diagnostic plots.\nAfter running the code, do you think that we have violated any assumptions?\n\nmod1 &lt;- lm(R_AGE ~ hrs_week, data = toy2)\nplot(mod1)\n\n\n\n\n\n\nSolution\n\n\n\nWe have violated an assumption here, and we don’t need to look at the plots to realise it! As it happens, the plots don’t actually look terrible (the scale-location plot is a bit meh, but other than that things look okay).\nThe assumption we have violated is that of independence. This is something we know through our understanding of the sampling procedure that has led to this data. We have got a random sample of different types of toys (e.g. power-rangers, toy-story, furbies etc), and within those types, we have a random sample of characters.\nBut it is entirely likely that the type of toy is going to influence their reading age (i.e. farm animals might read worse than playmobil, etc).\nSo this is something we can’t really “see” in the data - we have to think. What do we know about the data generating process? (i.e. the process that led to this data)\n\nmod1 &lt;- lm(R_AGE ~ hrs_week, data = toy2)\nplot(mod1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nThere are lots of ways in R to get predicted values for a linear model (e.g. we saw augment() a lot in USMR).\nThe simplest way is to use functions like predict() or fitted() (they do the same thing), which gives us a vector of predicted values, which we can append to our dataframe (provided we don’t have missing data):\n\ndata$predictedvalues &lt;- predict(model)\n\nAdd the predictions from the linear model in the previous question to the facetted plot that you created in the earlier question. How well does the model fit each type of toy?\n\n\n\n\n\n1 - add predictions to data\n\n\n\nThis only works because we don’t have missing data (and so the length of predict(mod1) is the same as nrow(toy2), and the predictions are in the correct order)\n\n# add predictions to data:\ntoy2$pred &lt;- predict(mod1)\n\n\n\n\n\n\n2 - add predictions to the plot\n\n\n\n\n# plot both predictions and observations:\ntoy2 |&gt;\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=pred)) + # predictions\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nLoad the lme4 package, and fit a model with random intercepts for each toy type.\nUsing either predict() again, or this time you can use augment() from the broom.mixed package, plot the predicted values and the observations.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou can see a model with a random intercept fitted in 1B# fitting-multilevel-models-in-r.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHere’s our model, with a random intercept by toy-type:\n\nlibrary(lme4)\nlibrary(broom.mixed)\n\nmod2 &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 | toy_type), data = toy2)\n\nWe can use augment() from the broom.mixed package, and which gives us the variables in the model along with things like fitted values (in the .fitted column)\n\naugment(mod2)\n\n\n\n# A tibble: 129 × 14\n  R_AGE hrs_week toy_type .fitted  .resid  .hat  .cooksd .fixed   .mu .offset\n  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     8     4.04 Barbie      7.43  0.574  0.158 0.0144     7.14  7.43       0\n2     6     2.36 Barbie      6.23 -0.229  0.183 0.00282    5.94  6.23       0\n3     8     4.02 Barbie      7.41  0.587  0.158 0.0151     7.12  7.41       0\n4     8     4.97 Barbie      8.09 -0.0855 0.170 0.000354   7.80  8.09       0\n5     6     3.37 Barbie      6.95 -0.950  0.161 0.0404     6.66  6.95       0\n# ℹ 124 more rows\n# ℹ 4 more variables: .sqrtXwt &lt;dbl&gt;, .sqrtrwt &lt;dbl&gt;, .weights &lt;dbl&gt;,\n#   .wtres &lt;dbl&gt;\n\n\n\naugment(mod2) |&gt;\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\nNote that the model predictions are now a lot better than they were for the single level linear model. The line has moved up for the “Scooby Doos”, and down for the “Farm Animals”, etc. But the lines are all still the same slope. The slope is “fixed”.\n\n\n\n\nQuestion 5\n\n\nNow fit a model with random intercepts and slopes for each toy type.\nAs before, plot the predicted values of this model alongside the observations\n\n\n\n\n\nSolution\n\n\n\n\nmod3 &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week| toy_type), \n             data = toy2)\n\naugment(mod3) |&gt;\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\nThis looks even better - the lines are at good heights and good angles for each type of toy. Why? Because we have modelled the intercept (line height) and slope of hrs_week (line angle) as varying across types of toy!\n\n\n\n\nQuestion 6\n\n\nFinally, add a geom_smooth to the plot from the previous question (making sure that this is has y=R_AGE).\nThis will add a separate linear model lm() line for each of the facets in the plot.\nWhat differences (look closely!) do you notice between the predictions from the model with random intercepts and slopes, and the simple geom_smooths?\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou could try changing col, lty, and lwd to make things easier to see.\nWhat we’re doing here is showing to ourselves ‘partial pooling’ in action (1B #partial-pooling).\n\n\n\n\n\n\n\n\n1 - adding geom_smooths to the plot\n\n\n\nhere’s the model we are using:\n\nmod3 &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week| toy_type), \n             data = toy2)\n\nand here is our plot:\n\naugment(mod3) |&gt;\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  geom_smooth(aes(y=R_AGE), method=lm, se=F) + # simple smooths\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 - why?\n\n\n\nI’ve made it a bit clearer here by changing up the colours and linewidths (lwd), and subsetting to just a select few of the toy types:\n\naugment(mod3) |&gt;\n  filter(toy_type %in% c(\"Farm Animals\",\"Scooby Doo\",\"Sock Puppets\",\"Polly Pocket\")) |&gt;\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE), alpha=.2) + # observations\n  geom_line(aes(y=.fitted), col=\"orange\", lwd=1) + # predictions\n  geom_smooth(aes(y=R_AGE), method=lm, se=F, lty=\"dashed\") + # simple smooths\n  facet_wrap(~toy_type)\n\n\n\n\n\n\n\n\nFor most of the toy types things look pretty similar. However, for “Sock Puppets” (only has 3 data points) the model predicted slope is shrunk back towards the average. It is also possible to see this in the “Farm Animals” and “Scooby Doo” - the shrinkage is more noticeable on these because they are further away from the average.\n\n\n\n\nQuestion 7\n\n\nHere is the model with the random intercepts (but not random slopes) that we fitted in an earlier question.\nBelow is the code that produces a plot of the fitted values:\n\n\n\n\n\n\nA. Model Equation\n\n\n\n\n\n$$ \\[\\begin{align}\n\\text{For Toy }j\\text{ of Type }i & \\\\\n\\text{Level 1 (Toy):}& \\\\\n\\text{R\\_AGE}_{ij} &= b_{0i} + b_1 \\cdot \\text{hrs\\_week}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Type):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\\]\n$$\n\n\n\n\n\n\n\n\n\nB. Model output\n\n\n\n\n\n\nmod2 &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 | toy_type), \n             data = toy2)\nsummary(mod2)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: R_AGE ~ 1 + hrs_week + (1 | toy_type)\n   Data: toy2\n\nREML criterion at convergence: 544.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.8809 -0.4687  0.0541  0.5579  3.3220 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n toy_type (Intercept) 7.278    2.698   \n Residual             2.550    1.597   \nNumber of obs: 129, groups:  toy_type, 20\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   4.2594     0.9157   4.652\nhrs_week      0.7118     0.1651   4.312\n\nCorrelation of Fixed Effects:\n         (Intr)\nhrs_week -0.736\n\n\n\n\n\n\n\n\n\n\n\nC. Plot of fitted values\n\n\n\n\n\n\naugment(mod2) |&gt;\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.3) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(mod2)[1], \n              slope = fixef(mod2)[2], lwd=1) +  # fixed effect line\n  guides(col=\"none\") + # remove legend\n  xlim(0,7) # extent to x=0\n\n\n\n\n\n\n\n\n\n\n\nMatch the parameters from the model equation, as well as coefficients from model output, to the corresponding points on the plot of fitted values.\n\n\nModel Equation\n\nA1: \\(\\sigma_{0}\\)\n\nA2: \\(\\sigma_{\\varepsilon}\\)\n\nA3: \\(\\gamma_{00}\\)\n\nA4: \\(b_{1}\\)\n\n\nModel Output\n\nB1: 0.7118\n\nB2: 2.698\n\nB3: 1.597\n\nB4: 4.2594\n\n\nPlot of fitted values\n\nC1: the standard deviation of the distances from all the individual toy types lines to the black line\n\nC2: where the black line cuts the y axis\n\nC3: the slope of the black line\n\nC4: the standard deviation of the distances from all the individual observations to the line for the toy type to which it belongs.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nA1 = B2 = C1\nA2 = B3 = C4\nA3 = B4 = C2\nA4 = B1 = C3"
  },
  {
    "objectID": "02ex.html#footnotes",
    "href": "02ex.html#footnotes",
    "title": "Week 2 Exercises: Introducing MLM",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage sources:http://tophatsasquatch.com/2012-tmnt-classics-action-figures/https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/https://www.wish.com/product/5da9bc544ab36314cfa7f70chttps://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asphttps://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.htmlhttps://tvtropes.org/pmwiki/pmwiki.php/Toys/Furbyhttps://www.fun.com/toy-story-4-figure-4-pack.htmlhttps://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461↩︎"
  },
  {
    "objectID": "03ex.html",
    "href": "03ex.html",
    "title": "Week 3 Exercises: Nested and Crossed Structures",
    "section": "",
    "text": "Data: gadeduc.csv\nThis is synthetic data from a randomised controlled trial, in which 30 therapists randomly assigned patients (each therapist saw between 4 and 30 patients) to a control or treatment group, and monitored their scores over time on a measure of generalised anxiety disorder (GAD7 - a 7 item questionnaire with 5 point likert scales).\nThe control group of patients received standard sessions offered by the therapists. For the treatment group, 10 mins of each sessions was replaced with a specific psychoeducational component, and patients were given relevant tasks to complete between each session. All patients had monthly therapy sessions. Generalised Anxiety Disorder was assessed at baseline and then every visit over 4 months of sessions (5 assessments in total).\nThe data are available at https://uoepsy.github.io/data/msmr_gadeduc.csv\nYou can find a data dictionary below:\n\n\n\n\nTable 1: Data Dictionary: msmr_gadeduc.csv\n\n\nvariable\ndescription\n\n\n\n\npatient\nA patient code in which the labels take the form &lt;Therapist initials&gt;_&lt;group&gt;_&lt;patient number&gt;.\n\n\nvisit_0\nScore on the GAD7 at baseline\n\n\nvisit_1\nGAD7 at 1 month assessment\n\n\nvisit_2\nGAD7 at 2 month assessment\n\n\nvisit_3\nGAD7 at 3 month assessment\n\n\nvisit_4\nGAD7 at 4 month assessment\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nUh-oh… these data aren’t in the same shape as the other datasets we’ve been giving you..\nCan you get it into a format that is ready for modelling?\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nIt’s wide, and we want it long.\n\nOnce it’s long. “visit_0”, “visit_1”,.. needs to become the numbers 0, 1, …\nOne variable (patient) contains lots of information that we want to separate out. There’s a handy function in the tidyverse called separate(), check out the help docs!\n\n\n\n\n\n\n\n\n\n1 - reshaping\n\n\n\nHere’s the data. We have one row per patient, but we have multiple observations for each patient across the columns..\n\ngeduc = read_csv(\"../../data/msmr_gadeduc.csv\")\nhead(geduc)\n\n# A tibble: 6 × 6\n  patient        visit_0 visit_1 visit_2 visit_3 visit_4\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 OT_Control_1        26      27      27      27      27\n2 OT_Control_2        25      24      27      26      25\n3 OT_Treatment_3      26      27      24      23      22\n4 OT_Treatment_4      26      26      26      25      25\n5 ND_Control_1        25      25      25      25      25\n6 ND_Control_2        26      24      25      24      23\n\n\nWe can make it long by taking the all the columns from visit_0 to visit_4 and shoving their values into one variable, and keeping the name of the column they come from as another variable:\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\")\n\n# A tibble: 2,600 × 3\n   patient      visit     GAD\n   &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt;\n 1 OT_Control_1 visit_0    26\n 2 OT_Control_1 visit_1    27\n 3 OT_Control_1 visit_2    27\n 4 OT_Control_1 visit_3    27\n 5 OT_Control_1 visit_4    27\n 6 OT_Control_2 visit_0    25\n 7 OT_Control_2 visit_1    24\n 8 OT_Control_2 visit_2    27\n 9 OT_Control_2 visit_3    26\n10 OT_Control_2 visit_4    25\n# ℹ 2,590 more rows\n\n\n\n\n\n\n\n2 - time is numeric\n\n\n\nNow we know how to get our data long, we need to sort out our time variable (visit) and make it into numbers.\nWe can replace all occurrences of the string \"visit_\" with nothingness \"\", and then convert them to numeric.\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) \n\n# A tibble: 2,600 × 3\n   patient      visit   GAD\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 OT_Control_1     0    26\n 2 OT_Control_1     1    27\n 3 OT_Control_1     2    27\n 4 OT_Control_1     3    27\n 5 OT_Control_1     4    27\n 6 OT_Control_2     0    25\n 7 OT_Control_2     1    24\n 8 OT_Control_2     2    27\n 9 OT_Control_2     3    26\n10 OT_Control_2     4    25\n# ℹ 2,590 more rows\n\n\n\n\n\n\n\n3 - splitting up the patient variable\n\n\n\nFinally, we need to sort out the patient variable. It contains 3 bits of information that we will want to have separated out. It has the therapist (their initials), then the group (treatment or control), and then the patient number. These are all separated by an underscore “_“.\nThe separate() function takes a column and separates it into several things (as many things as we give it), splitting them by some user defined separator such as an underscore:\n\ngeduc_long &lt;- geduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |&gt;\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n\nAnd we’re ready to go!\n\ngeduc_long\n\n# A tibble: 2,600 × 5\n   therapist group   patient visit   GAD\n   &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 OT        Control 1           0    26\n 2 OT        Control 1           1    27\n 3 OT        Control 1           2    27\n 4 OT        Control 1           3    27\n 5 OT        Control 1           4    27\n 6 OT        Control 2           0    25\n 7 OT        Control 2           1    24\n 8 OT        Control 2           2    27\n 9 OT        Control 2           3    26\n10 OT        Control 2           4    25\n# ℹ 2,590 more rows\n\n\n\n\n\n\nQuestion 2\n\n\nVisualise the data. Does it look like the treatment had an effect?\nDoes it look like it worked for every therapist?\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nremember, stat_summary() is very useful for aggregating data inside a plot.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHere’s the overall picture. The average score on the GAD7 at each visit gets more and more different between the two groups. The treatment looks effective..\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nLet’s split this up by therapist, so we can see the averages across each therapist’s set of patients.\nThere’s clear variability between therapists in how well the treatment worked. For instance, the therapists PT and GI don’t seem to have much difference between their groups of patients.\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\") +\n  facet_wrap(~therapist)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFit a model to test if the psychoeducational treatment is associated with greater improvement in anxiety over time.\n\n\n\n\n\n1 - fixed effects\n\n\n\nWe want to know if how anxiety (GAD) changes over time (visit) is different between treatment and control (group).\nHopefully this should hopefully come as no surprise1 - it’s an interaction!\n\nlmer(GAD ~ visit * group + ...\n       ...\n     data = geduc_long)\n\n\n\n\n\n\n2 - grouping structure\n\n\n\nWe have multiple observations for each of the 520 patients, and those patients are nested within 30 therapists.\nNote that in our data, the patient variable does not uniquely specify the individual patients. i.e. patient “1” from therapist “OT” is a different person from patient “1” from therapist “ND”. To correctly group the observations into different patients (and not ‘patient numbers’), we need to have therapist:patient.\nSo we capture therapist-level differences in ( ... | therapist) and the patients-within-therapist-level differences in ( ... | therapist:patient):\n\nlmer(GAD ~ visit * group + ...\n       ( ... | therapist) + \n       ( ... | therapist:patient),\n     data = geduc_long)\n\n\n\n\n\n\n3 - random effects\n\n\n\nNote that each patient can change differently in their anxiety levels over time - i.e. the slope of visit could vary by participant.\nLikewise, some therapists could have patients who change differently from patients from another therapist, so visit|therapist can be included.\nEach patient is in one of the two groups - they’re either treatment or control. So we can’t say that “differences in anxiety due to treatment varies between patients”, because for any one patient the “difference in anxiety due to treatment” is not defined in our study design.\nHowever, therapists see multiple different patients, some of which are in the treatment group, and some of which are in the control group. So the treatment effect could be different for different therapists!\n\nmod1 &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|therapist:patient),\n             geduc_long)\n\n\n\n\n\nQuestion 4\n\n\nFor each of the models below, what is wrong with the random effect structure?\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\n\n\n\n\n\nSolution\n\n\n\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\nThe patient variable doesn’t capture the different patients within therapists, so this actually fits crossed random effects and treats all data where patient==1 as from the same group (even if this includes several different patients’ worth of data from different therapists!)\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\nUsing the / here means we have the same random slopes fitted for therapists and for patients-within-therapists. but the effect of group can’t vary by patient, so this doesn’t work. hence why we need to split them up into (...|therapist)+(...|therapist:patient).\n\n\n\n\nQuestion 5\n\n\nLet’s suppose that I don’t want the psychoeducation treatment, I just want the standard therapy sessions that the ‘Control’ group received. Which therapist should I go to?\n\n\n\n\n\n\nHints\n\n\n\n\n\ndotplot.ranef.mer() might help here!\n\n\n\n\n\n\n\n\nSolution\n\n\n\nIt would be best to go to one of the therapists WG, EQ, or EI…\nWhy? These therapists all have the most negative slope of visit:\n\ndotplot.ranef.mer(ranef(mod1))$therapist\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecreate this plot.\nThe faint lines represent the model estimated lines for each patient. The points and ranges represent our fixed effect estimates and their uncertainty.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nyou can get the patient-specific lines using augment() from the broom.mixed package, and the fixed effects estimates using the effects package.\nremember you can pull multiple datasets into ggplot:\n\n\nggplot(data = dataset1, aes(x=x,y=y)) + \n  geom_point() + # points from dataset1\n  geom_line(data = dataset2) # lines from dataset2\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(effects)\nlibrary(broom.mixed)\neffplot &lt;- effect(\"visit*group\",mod1) |&gt;\n  as.data.frame()\n\naugment(mod1) |&gt; \n  mutate(\n    upatient = paste0(therapist,patient)\n  ) |&gt;\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")"
  },
  {
    "objectID": "03ex.html#footnotes",
    "href": "03ex.html#footnotes",
    "title": "Week 3 Exercises: Nested and Crossed Structures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nif it does, head back to where we learned about interactions in the single level regressions lm(). It’s just the same here.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the DAPR3 Lab Workbook",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 3 (DAPR3) lab workbook. Exercises for each week can be found in the menu to the left."
  }
]